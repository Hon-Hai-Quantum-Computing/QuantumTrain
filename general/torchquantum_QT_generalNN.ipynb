{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Tools\n",
    "import time\n",
    "import numpy as np \n",
    "from util import *\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# TorchQuantum\n",
    "import torchquantum as tq\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# torch.manual_seed(42)\n",
    "# np.random.seed(42)\n",
    "\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### Classical target model initialization ###\n",
    "\n",
    "# Define the CNN model\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNModel, self).__init__()\n",
    "        # Writing every operation as layer, so that the extraction function could read\n",
    "        self.conv1 = nn.Conv2d(1, 8, kernel_size=5)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(8, 12, kernel_size=5)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.flatten = nn.Flatten()  \n",
    "        self.fc1 = nn.Linear(12*4*4, 20)\n",
    "        self.fc2 = nn.Linear(20, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool1(self.conv1(x))\n",
    "        x = self.pool2(self.conv2(x))\n",
    "        x = self.flatten(x)  # Use the Flatten layer\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "# Instantiate the model and loss function\n",
    "model = CNNModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of NN parameters:  6690\n",
      "Required qubit number:  13\n"
     ]
    }
   ],
   "source": [
    "n_qubit, nw_list_normal = required_qubits_estimation(model)\n",
    "network_config          = network_config_extract(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### Training setting ########################\n",
    "\n",
    "step       = 1e-4   # Learning rate\n",
    "batch_size = 1000    # Number of samples for each training step\n",
    "num_epochs = 100      # Number of training epochs\n",
    "q_depth    = 16     # Depth of the quantum circuit (number of variational layers)\n",
    "\n",
    "# Dataset setup\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Instantiate the model, move it to GPU, and set up loss function and optimizer\n",
    "model_qt = QuantumTrain(\n",
    "                        model,\n",
    "                        n_qubit,\n",
    "                        nw_list_normal,\n",
    "                        q_depth,\n",
    "                        device,\n",
    "                        network_config\n",
    "                        )().to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# optimizer = optim.Adam(model_qt.parameters(), lr=step, weight_decay=1e-5, eps=1e-6)\n",
    "optimizer = optim.Adam([\n",
    "    {'params': model_qt.QuantumNN.parameters()},\n",
    "    {'params': model_qt.MappingNetwork.parameters()}\n",
    "], lr=step, weight_decay=1e-5, eps=1e-6)\n",
    "\n",
    "\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience = 5, verbose = True, factor = 0.5)  # 'min' because we're minimizing loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of trainable parameter in Mapping model:  249\n",
      "# of trainable parameter in QNN model:  1248\n",
      "# of trainable parameter in full model:  1497\n"
     ]
    }
   ],
   "source": [
    "\n",
    "num_trainable_params_MM = sum(p.numel() for p in model_qt.MappingNetwork.parameters() if p.requires_grad)\n",
    "num_trainable_params_QNN = sum(p.numel() for p in model_qt.QuantumNN.parameters() if p.requires_grad)\n",
    "num_trainable_params = sum(p.numel() for p in model_qt.parameters() if p.requires_grad)\n",
    "\n",
    "print(\"# of trainable parameter in Mapping model: \", num_trainable_params_MM)\n",
    "print(\"# of trainable parameter in QNN model: \", num_trainable_params_QNN)\n",
    "print(\"# of trainable parameter in full model: \", num_trainable_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Step [1/60], Loss: 2.3778, batch time: 4.01, accuracy:  8.10%\n",
      "Epoch [1/100], Step [2/60], Loss: 2.3692, batch time: 0.84, accuracy:  8.80%\n",
      "Epoch [1/100], Step [3/60], Loss: 2.3693, batch time: 0.95, accuracy:  9.10%\n",
      "Epoch [1/100], Step [4/60], Loss: 2.3607, batch time: 0.94, accuracy:  10.20%\n",
      "Epoch [1/100], Step [5/60], Loss: 2.3641, batch time: 0.94, accuracy:  9.20%\n",
      "Epoch [1/100], Step [6/60], Loss: 2.3458, batch time: 0.96, accuracy:  10.90%\n",
      "Epoch [1/100], Step [7/60], Loss: 2.3641, batch time: 0.95, accuracy:  8.90%\n",
      "Epoch [1/100], Step [8/60], Loss: 2.3424, batch time: 0.94, accuracy:  10.00%\n",
      "Epoch [1/100], Step [9/60], Loss: 2.3501, batch time: 0.75, accuracy:  10.10%\n",
      "Epoch [1/100], Step [10/60], Loss: 2.3499, batch time: 0.74, accuracy:  8.10%\n",
      "Epoch [1/100], Step [11/60], Loss: 2.3512, batch time: 0.76, accuracy:  8.90%\n",
      "Epoch [1/100], Step [12/60], Loss: 2.3432, batch time: 0.77, accuracy:  10.30%\n",
      "Epoch [1/100], Step [13/60], Loss: 2.3506, batch time: 0.76, accuracy:  9.30%\n",
      "Epoch [1/100], Step [14/60], Loss: 2.3388, batch time: 0.77, accuracy:  9.70%\n",
      "Epoch [1/100], Step [15/60], Loss: 2.3316, batch time: 0.75, accuracy:  11.30%\n",
      "Epoch [1/100], Step [16/60], Loss: 2.3337, batch time: 0.76, accuracy:  8.80%\n",
      "Epoch [1/100], Step [17/60], Loss: 2.3344, batch time: 0.78, accuracy:  10.70%\n",
      "Epoch [1/100], Step [18/60], Loss: 2.3306, batch time: 0.79, accuracy:  9.90%\n",
      "Epoch [1/100], Step [19/60], Loss: 2.3277, batch time: 0.76, accuracy:  9.90%\n",
      "Epoch [1/100], Step [20/60], Loss: 2.3281, batch time: 0.80, accuracy:  10.30%\n",
      "Epoch [1/100], Step [21/60], Loss: 2.3273, batch time: 0.82, accuracy:  10.40%\n",
      "Epoch [1/100], Step [22/60], Loss: 2.3185, batch time: 0.81, accuracy:  11.30%\n",
      "Epoch [1/100], Step [23/60], Loss: 2.3259, batch time: 0.94, accuracy:  9.80%\n",
      "Epoch [1/100], Step [24/60], Loss: 2.3198, batch time: 0.96, accuracy:  11.90%\n",
      "Epoch [1/100], Step [25/60], Loss: 2.3284, batch time: 0.95, accuracy:  9.50%\n",
      "Epoch [1/100], Step [26/60], Loss: 2.3207, batch time: 0.94, accuracy:  10.40%\n",
      "Epoch [1/100], Step [27/60], Loss: 2.3284, batch time: 0.84, accuracy:  8.40%\n",
      "Epoch [1/100], Step [28/60], Loss: 2.3197, batch time: 0.77, accuracy:  9.00%\n",
      "Epoch [1/100], Step [29/60], Loss: 2.3193, batch time: 0.75, accuracy:  11.60%\n",
      "Epoch [1/100], Step [30/60], Loss: 2.3207, batch time: 0.78, accuracy:  9.40%\n",
      "Epoch [1/100], Step [31/60], Loss: 2.3171, batch time: 0.78, accuracy:  10.00%\n",
      "Epoch [1/100], Step [32/60], Loss: 2.3253, batch time: 0.80, accuracy:  9.30%\n",
      "Epoch [1/100], Step [33/60], Loss: 2.3243, batch time: 0.77, accuracy:  7.80%\n",
      "Epoch [1/100], Step [34/60], Loss: 2.3264, batch time: 0.78, accuracy:  8.30%\n",
      "Epoch [1/100], Step [35/60], Loss: 2.3218, batch time: 0.79, accuracy:  8.70%\n",
      "Epoch [1/100], Step [36/60], Loss: 2.3237, batch time: 0.76, accuracy:  8.50%\n",
      "Epoch [1/100], Step [37/60], Loss: 2.3153, batch time: 0.77, accuracy:  12.10%\n",
      "Epoch [1/100], Step [38/60], Loss: 2.3186, batch time: 0.80, accuracy:  9.40%\n",
      "Epoch [1/100], Step [39/60], Loss: 2.3211, batch time: 0.80, accuracy:  10.30%\n",
      "Epoch [1/100], Step [40/60], Loss: 2.3215, batch time: 0.82, accuracy:  10.20%\n",
      "Epoch [1/100], Step [41/60], Loss: 2.3127, batch time: 0.84, accuracy:  10.50%\n",
      "Epoch [1/100], Step [42/60], Loss: 2.3135, batch time: 0.96, accuracy:  10.90%\n",
      "Epoch [1/100], Step [43/60], Loss: 2.3195, batch time: 0.96, accuracy:  9.00%\n",
      "Epoch [1/100], Step [44/60], Loss: 2.3130, batch time: 0.95, accuracy:  10.80%\n",
      "Epoch [1/100], Step [45/60], Loss: 2.3197, batch time: 0.95, accuracy:  8.40%\n",
      "Epoch [1/100], Step [46/60], Loss: 2.3095, batch time: 0.78, accuracy:  11.50%\n",
      "Epoch [1/100], Step [47/60], Loss: 2.3174, batch time: 0.79, accuracy:  9.90%\n",
      "Epoch [1/100], Step [48/60], Loss: 2.3131, batch time: 0.78, accuracy:  9.30%\n",
      "Epoch [1/100], Step [49/60], Loss: 2.3139, batch time: 0.76, accuracy:  10.90%\n",
      "Epoch [1/100], Step [50/60], Loss: 2.3135, batch time: 0.78, accuracy:  10.60%\n",
      "Epoch [1/100], Step [51/60], Loss: 2.3124, batch time: 0.77, accuracy:  10.20%\n",
      "Epoch [1/100], Step [52/60], Loss: 2.3167, batch time: 0.76, accuracy:  8.70%\n",
      "Epoch [1/100], Step [53/60], Loss: 2.3138, batch time: 0.78, accuracy:  8.70%\n",
      "Epoch [1/100], Step [54/60], Loss: 2.3132, batch time: 0.78, accuracy:  10.60%\n",
      "Epoch [1/100], Step [55/60], Loss: 2.3149, batch time: 0.76, accuracy:  10.20%\n",
      "Epoch [1/100], Step [56/60], Loss: 2.3141, batch time: 0.79, accuracy:  9.60%\n",
      "Epoch [1/100], Step [57/60], Loss: 2.3100, batch time: 0.78, accuracy:  12.20%\n",
      "Epoch [1/100], Step [58/60], Loss: 2.3126, batch time: 0.81, accuracy:  11.20%\n",
      "Epoch [1/100], Step [59/60], Loss: 2.3111, batch time: 0.90, accuracy:  9.80%\n",
      "Epoch [1/100], Step [60/60], Loss: 2.3113, batch time: 0.96, accuracy:  9.90%\n",
      "Epoch [2/100], Step [1/60], Loss: 2.3122, batch time: 0.94, accuracy:  9.90%\n",
      "Epoch [2/100], Step [2/60], Loss: 2.3130, batch time: 0.98, accuracy:  9.70%\n",
      "Epoch [2/100], Step [3/60], Loss: 2.3094, batch time: 0.97, accuracy:  10.30%\n",
      "Epoch [2/100], Step [4/60], Loss: 2.3126, batch time: 0.96, accuracy:  8.90%\n",
      "Epoch [2/100], Step [5/60], Loss: 2.3115, batch time: 0.96, accuracy:  10.60%\n",
      "Epoch [2/100], Step [6/60], Loss: 2.3107, batch time: 0.75, accuracy:  10.90%\n",
      "Epoch [2/100], Step [7/60], Loss: 2.3102, batch time: 0.77, accuracy:  9.50%\n",
      "Epoch [2/100], Step [8/60], Loss: 2.3050, batch time: 0.78, accuracy:  12.70%\n",
      "Epoch [2/100], Step [9/60], Loss: 2.3116, batch time: 0.77, accuracy:  10.40%\n",
      "Epoch [2/100], Step [10/60], Loss: 2.3095, batch time: 0.74, accuracy:  10.00%\n",
      "Epoch [2/100], Step [11/60], Loss: 2.3101, batch time: 0.77, accuracy:  10.00%\n",
      "Epoch [2/100], Step [12/60], Loss: 2.3092, batch time: 0.80, accuracy:  11.20%\n",
      "Epoch [2/100], Step [13/60], Loss: 2.3120, batch time: 0.76, accuracy:  10.10%\n",
      "Epoch [2/100], Step [14/60], Loss: 2.3121, batch time: 0.77, accuracy:  8.40%\n",
      "Epoch [2/100], Step [15/60], Loss: 2.3087, batch time: 0.77, accuracy:  8.50%\n",
      "Epoch [2/100], Step [16/60], Loss: 2.3044, batch time: 0.76, accuracy:  11.80%\n",
      "Epoch [2/100], Step [17/60], Loss: 2.3105, batch time: 0.78, accuracy:  8.40%\n",
      "Epoch [2/100], Step [18/60], Loss: 2.3100, batch time: 0.82, accuracy:  10.30%\n",
      "Epoch [2/100], Step [19/60], Loss: 2.3076, batch time: 0.83, accuracy:  9.90%\n",
      "Epoch [2/100], Step [20/60], Loss: 2.3064, batch time: 0.93, accuracy:  11.00%\n",
      "Epoch [2/100], Step [21/60], Loss: 2.3049, batch time: 0.94, accuracy:  9.90%\n",
      "Epoch [2/100], Step [22/60], Loss: 2.3082, batch time: 0.94, accuracy:  10.30%\n",
      "Epoch [2/100], Step [23/60], Loss: 2.3092, batch time: 0.94, accuracy:  9.70%\n",
      "Epoch [2/100], Step [24/60], Loss: 2.3058, batch time: 0.79, accuracy:  8.70%\n",
      "Epoch [2/100], Step [25/60], Loss: 2.3082, batch time: 0.75, accuracy:  9.50%\n",
      "Epoch [2/100], Step [26/60], Loss: 2.3098, batch time: 0.76, accuracy:  9.80%\n",
      "Epoch [2/100], Step [27/60], Loss: 2.3062, batch time: 0.77, accuracy:  10.90%\n",
      "Epoch [2/100], Step [28/60], Loss: 2.3089, batch time: 0.77, accuracy:  8.80%\n",
      "Epoch [2/100], Step [29/60], Loss: 2.3068, batch time: 0.77, accuracy:  10.90%\n",
      "Epoch [2/100], Step [30/60], Loss: 2.3076, batch time: 0.78, accuracy:  10.10%\n",
      "Epoch [2/100], Step [31/60], Loss: 2.3077, batch time: 0.77, accuracy:  10.40%\n",
      "Epoch [2/100], Step [32/60], Loss: 2.3061, batch time: 0.76, accuracy:  10.30%\n",
      "Epoch [2/100], Step [33/60], Loss: 2.3091, batch time: 0.78, accuracy:  9.00%\n",
      "Epoch [2/100], Step [34/60], Loss: 2.3091, batch time: 0.77, accuracy:  9.20%\n",
      "Epoch [2/100], Step [35/60], Loss: 2.3058, batch time: 0.77, accuracy:  10.30%\n",
      "Epoch [2/100], Step [36/60], Loss: 2.3086, batch time: 0.81, accuracy:  8.00%\n",
      "Epoch [2/100], Step [37/60], Loss: 2.3026, batch time: 0.81, accuracy:  9.70%\n",
      "Epoch [2/100], Step [38/60], Loss: 2.3074, batch time: 0.98, accuracy:  9.20%\n",
      "Epoch [2/100], Step [39/60], Loss: 2.3085, batch time: 0.95, accuracy:  9.20%\n",
      "Epoch [2/100], Step [40/60], Loss: 2.3078, batch time: 0.96, accuracy:  10.20%\n",
      "Epoch [2/100], Step [41/60], Loss: 2.3067, batch time: 0.95, accuracy:  11.40%\n",
      "Epoch [2/100], Step [42/60], Loss: 2.3069, batch time: 0.97, accuracy:  10.50%\n",
      "Epoch [2/100], Step [43/60], Loss: 2.3038, batch time: 0.97, accuracy:  10.10%\n",
      "Epoch [2/100], Step [44/60], Loss: 2.3062, batch time: 0.96, accuracy:  9.60%\n",
      "Epoch [2/100], Step [45/60], Loss: 2.3043, batch time: 0.76, accuracy:  9.00%\n",
      "Epoch [2/100], Step [46/60], Loss: 2.3052, batch time: 0.76, accuracy:  8.90%\n",
      "Epoch [2/100], Step [47/60], Loss: 2.3025, batch time: 0.79, accuracy:  10.20%\n",
      "Epoch [2/100], Step [48/60], Loss: 2.3073, batch time: 0.73, accuracy:  10.60%\n",
      "Epoch [2/100], Step [49/60], Loss: 2.3064, batch time: 0.70, accuracy:  10.30%\n",
      "Epoch [2/100], Step [50/60], Loss: 2.3058, batch time: 0.74, accuracy:  9.70%\n",
      "Epoch [2/100], Step [51/60], Loss: 2.3119, batch time: 0.71, accuracy:  8.20%\n",
      "Epoch [2/100], Step [52/60], Loss: 2.3039, batch time: 0.78, accuracy:  9.70%\n",
      "Epoch [2/100], Step [53/60], Loss: 2.3070, batch time: 0.76, accuracy:  8.80%\n",
      "Epoch [2/100], Step [54/60], Loss: 2.3025, batch time: 0.77, accuracy:  9.80%\n",
      "Epoch [2/100], Step [55/60], Loss: 2.3030, batch time: 0.77, accuracy:  8.40%\n",
      "Epoch [2/100], Step [56/60], Loss: 2.3062, batch time: 0.79, accuracy:  9.10%\n",
      "Epoch [2/100], Step [57/60], Loss: 2.3021, batch time: 0.81, accuracy:  10.60%\n",
      "Epoch [2/100], Step [58/60], Loss: 2.3015, batch time: 0.80, accuracy:  12.30%\n",
      "Epoch [2/100], Step [59/60], Loss: 2.3023, batch time: 0.80, accuracy:  12.80%\n",
      "Epoch [2/100], Step [60/60], Loss: 2.3019, batch time: 0.83, accuracy:  14.10%\n",
      "Epoch [3/100], Step [1/60], Loss: 2.3037, batch time: 0.96, accuracy:  14.70%\n",
      "Epoch [3/100], Step [2/60], Loss: 2.3054, batch time: 0.97, accuracy:  13.50%\n",
      "Epoch [3/100], Step [3/60], Loss: 2.3031, batch time: 0.94, accuracy:  15.40%\n",
      "Epoch [3/100], Step [4/60], Loss: 2.2944, batch time: 0.94, accuracy:  18.40%\n",
      "Epoch [3/100], Step [5/60], Loss: 2.3002, batch time: 0.95, accuracy:  17.30%\n",
      "Epoch [3/100], Step [6/60], Loss: 2.3001, batch time: 0.77, accuracy:  19.70%\n",
      "Epoch [3/100], Step [7/60], Loss: 2.2956, batch time: 0.78, accuracy:  19.00%\n",
      "Epoch [3/100], Step [8/60], Loss: 2.3014, batch time: 0.77, accuracy:  18.20%\n",
      "Epoch [3/100], Step [9/60], Loss: 2.3048, batch time: 0.76, accuracy:  18.20%\n",
      "Epoch [3/100], Step [10/60], Loss: 2.3047, batch time: 0.76, accuracy:  18.40%\n",
      "Epoch [3/100], Step [11/60], Loss: 2.2968, batch time: 0.75, accuracy:  19.80%\n",
      "Epoch [3/100], Step [12/60], Loss: 2.3030, batch time: 0.79, accuracy:  17.40%\n",
      "Epoch [3/100], Step [13/60], Loss: 2.2950, batch time: 0.77, accuracy:  19.40%\n",
      "Epoch [3/100], Step [14/60], Loss: 2.2979, batch time: 0.77, accuracy:  18.20%\n",
      "Epoch [3/100], Step [15/60], Loss: 2.2942, batch time: 0.79, accuracy:  19.30%\n",
      "Epoch [3/100], Step [16/60], Loss: 2.2986, batch time: 0.76, accuracy:  16.80%\n",
      "Epoch [3/100], Step [17/60], Loss: 2.2924, batch time: 0.77, accuracy:  19.10%\n",
      "Epoch [3/100], Step [18/60], Loss: 2.3006, batch time: 0.80, accuracy:  15.10%\n",
      "Epoch [3/100], Step [19/60], Loss: 2.3015, batch time: 0.95, accuracy:  16.40%\n",
      "Epoch [3/100], Step [20/60], Loss: 2.2973, batch time: 0.94, accuracy:  14.30%\n",
      "Epoch [3/100], Step [21/60], Loss: 2.2919, batch time: 1.04, accuracy:  15.80%\n",
      "Epoch [3/100], Step [22/60], Loss: 2.3034, batch time: 1.03, accuracy:  14.10%\n",
      "Epoch [3/100], Step [23/60], Loss: 2.2922, batch time: 0.95, accuracy:  15.90%\n",
      "Epoch [3/100], Step [24/60], Loss: 2.2966, batch time: 0.67, accuracy:  12.90%\n",
      "Epoch [3/100], Step [25/60], Loss: 2.2915, batch time: 0.74, accuracy:  14.30%\n",
      "Epoch [3/100], Step [26/60], Loss: 2.2932, batch time: 0.66, accuracy:  13.30%\n",
      "Epoch [3/100], Step [27/60], Loss: 2.2842, batch time: 0.68, accuracy:  16.30%\n",
      "Epoch [3/100], Step [28/60], Loss: 2.3018, batch time: 0.67, accuracy:  13.30%\n",
      "Epoch [3/100], Step [29/60], Loss: 2.2837, batch time: 0.68, accuracy:  14.80%\n",
      "Epoch [3/100], Step [30/60], Loss: 2.2816, batch time: 0.67, accuracy:  15.70%\n",
      "Epoch [3/100], Step [31/60], Loss: 2.2854, batch time: 0.67, accuracy:  13.80%\n",
      "Epoch [3/100], Step [32/60], Loss: 2.2789, batch time: 0.67, accuracy:  15.00%\n",
      "Epoch [3/100], Step [33/60], Loss: 2.2814, batch time: 0.68, accuracy:  13.20%\n",
      "Epoch [3/100], Step [34/60], Loss: 2.2792, batch time: 0.68, accuracy:  14.10%\n",
      "Epoch [3/100], Step [35/60], Loss: 2.2910, batch time: 0.68, accuracy:  12.80%\n",
      "Epoch [3/100], Step [36/60], Loss: 2.2764, batch time: 0.68, accuracy:  12.20%\n",
      "Epoch [3/100], Step [37/60], Loss: 2.2854, batch time: 0.70, accuracy:  11.50%\n",
      "Epoch [3/100], Step [38/60], Loss: 2.2677, batch time: 0.73, accuracy:  13.80%\n",
      "Epoch [3/100], Step [39/60], Loss: 2.2843, batch time: 0.72, accuracy:  13.10%\n",
      "Epoch [3/100], Step [40/60], Loss: 2.2768, batch time: 0.71, accuracy:  11.30%\n",
      "Epoch [3/100], Step [41/60], Loss: 2.2726, batch time: 0.71, accuracy:  13.80%\n",
      "Epoch [3/100], Step [42/60], Loss: 2.2760, batch time: 0.83, accuracy:  12.20%\n",
      "Epoch [3/100], Step [43/60], Loss: 2.2813, batch time: 0.83, accuracy:  11.20%\n",
      "Epoch [3/100], Step [44/60], Loss: 2.2711, batch time: 0.86, accuracy:  12.90%\n",
      "Epoch [3/100], Step [45/60], Loss: 2.2643, batch time: 0.73, accuracy:  13.30%\n",
      "Epoch [3/100], Step [46/60], Loss: 2.2820, batch time: 0.74, accuracy:  11.50%\n",
      "Epoch [3/100], Step [47/60], Loss: 2.2824, batch time: 0.75, accuracy:  11.60%\n",
      "Epoch [3/100], Step [48/60], Loss: 2.2855, batch time: 0.75, accuracy:  12.90%\n",
      "Epoch [3/100], Step [49/60], Loss: 2.2895, batch time: 0.74, accuracy:  10.70%\n",
      "Epoch [3/100], Step [50/60], Loss: 2.2761, batch time: 0.77, accuracy:  13.30%\n",
      "Epoch [3/100], Step [51/60], Loss: 2.2783, batch time: 0.74, accuracy:  13.80%\n",
      "Epoch [3/100], Step [52/60], Loss: 2.2777, batch time: 0.74, accuracy:  14.30%\n",
      "Epoch [3/100], Step [53/60], Loss: 2.2772, batch time: 0.74, accuracy:  13.70%\n",
      "Epoch [3/100], Step [54/60], Loss: 2.2720, batch time: 0.74, accuracy:  16.10%\n",
      "Epoch [3/100], Step [55/60], Loss: 2.2780, batch time: 0.74, accuracy:  14.60%\n",
      "Epoch [3/100], Step [56/60], Loss: 2.2733, batch time: 0.81, accuracy:  14.70%\n",
      "Epoch [3/100], Step [57/60], Loss: 2.2624, batch time: 0.80, accuracy:  15.60%\n",
      "Epoch [3/100], Step [58/60], Loss: 2.2689, batch time: 0.80, accuracy:  15.10%\n",
      "Epoch [3/100], Step [59/60], Loss: 2.2784, batch time: 0.80, accuracy:  12.60%\n",
      "Epoch [3/100], Step [60/60], Loss: 2.2668, batch time: 0.80, accuracy:  13.50%\n",
      "Epoch [4/100], Step [1/60], Loss: 2.2627, batch time: 1.04, accuracy:  13.60%\n",
      "Epoch [4/100], Step [2/60], Loss: 2.2725, batch time: 0.76, accuracy:  12.80%\n",
      "Epoch [4/100], Step [3/60], Loss: 2.2684, batch time: 0.76, accuracy:  14.20%\n",
      "Epoch [4/100], Step [4/60], Loss: 2.2663, batch time: 0.78, accuracy:  13.00%\n",
      "Epoch [4/100], Step [5/60], Loss: 2.2701, batch time: 0.76, accuracy:  13.30%\n",
      "Epoch [4/100], Step [6/60], Loss: 2.2532, batch time: 0.78, accuracy:  18.20%\n",
      "Epoch [4/100], Step [7/60], Loss: 2.2488, batch time: 0.79, accuracy:  17.90%\n",
      "Epoch [4/100], Step [8/60], Loss: 2.2550, batch time: 0.76, accuracy:  17.90%\n",
      "Epoch [4/100], Step [9/60], Loss: 2.2645, batch time: 0.79, accuracy:  13.60%\n",
      "Epoch [4/100], Step [10/60], Loss: 2.2574, batch time: 0.74, accuracy:  15.90%\n",
      "Epoch [4/100], Step [11/60], Loss: 2.2595, batch time: 0.77, accuracy:  15.80%\n",
      "Epoch [4/100], Step [12/60], Loss: 2.2572, batch time: 0.85, accuracy:  15.80%\n",
      "Epoch [4/100], Step [13/60], Loss: 2.2548, batch time: 0.70, accuracy:  16.50%\n",
      "Epoch [4/100], Step [14/60], Loss: 2.2737, batch time: 0.83, accuracy:  14.10%\n",
      "Epoch [4/100], Step [15/60], Loss: 2.2568, batch time: 0.54, accuracy:  17.80%\n",
      "Epoch [4/100], Step [16/60], Loss: 2.2463, batch time: 0.86, accuracy:  13.90%\n",
      "Epoch [4/100], Step [17/60], Loss: 2.2476, batch time: 0.88, accuracy:  13.10%\n",
      "Epoch [4/100], Step [18/60], Loss: 2.2450, batch time: 0.85, accuracy:  15.30%\n",
      "Epoch [4/100], Step [19/60], Loss: 2.2481, batch time: 0.86, accuracy:  16.40%\n",
      "Epoch [4/100], Step [20/60], Loss: 2.2383, batch time: 0.82, accuracy:  16.00%\n",
      "Epoch [4/100], Step [21/60], Loss: 2.2402, batch time: 0.85, accuracy:  17.90%\n",
      "Epoch [4/100], Step [22/60], Loss: 2.2414, batch time: 0.84, accuracy:  16.40%\n",
      "Epoch [4/100], Step [23/60], Loss: 2.2405, batch time: 0.67, accuracy:  16.80%\n",
      "Epoch [4/100], Step [24/60], Loss: 2.2406, batch time: 0.43, accuracy:  15.30%\n",
      "Epoch [4/100], Step [25/60], Loss: 2.2490, batch time: 0.58, accuracy:  12.60%\n",
      "Epoch [4/100], Step [26/60], Loss: 2.2300, batch time: 0.69, accuracy:  13.40%\n",
      "Epoch [4/100], Step [27/60], Loss: 2.2302, batch time: 0.69, accuracy:  12.40%\n",
      "Epoch [4/100], Step [28/60], Loss: 2.2310, batch time: 0.69, accuracy:  11.40%\n",
      "Epoch [4/100], Step [29/60], Loss: 2.2348, batch time: 0.62, accuracy:  13.40%\n",
      "Epoch [4/100], Step [30/60], Loss: 2.2438, batch time: 0.69, accuracy:  14.10%\n",
      "Epoch [4/100], Step [31/60], Loss: 2.2330, batch time: 0.69, accuracy:  12.90%\n",
      "Epoch [4/100], Step [32/60], Loss: 2.2277, batch time: 0.67, accuracy:  15.20%\n",
      "Epoch [4/100], Step [33/60], Loss: 2.2284, batch time: 0.70, accuracy:  13.20%\n",
      "Epoch [4/100], Step [34/60], Loss: 2.2176, batch time: 0.70, accuracy:  16.50%\n",
      "Epoch [4/100], Step [35/60], Loss: 2.2105, batch time: 0.71, accuracy:  15.20%\n",
      "Epoch [4/100], Step [36/60], Loss: 2.2198, batch time: 0.72, accuracy:  14.20%\n",
      "Epoch [4/100], Step [37/60], Loss: 2.1938, batch time: 0.73, accuracy:  16.00%\n",
      "Epoch [4/100], Step [38/60], Loss: 2.2052, batch time: 0.72, accuracy:  14.80%\n",
      "Epoch [4/100], Step [39/60], Loss: 2.2243, batch time: 0.74, accuracy:  15.30%\n",
      "Epoch [4/100], Step [40/60], Loss: 2.2103, batch time: 0.62, accuracy:  16.20%\n",
      "Epoch [4/100], Step [41/60], Loss: 2.2218, batch time: 0.73, accuracy:  12.40%\n",
      "Epoch [4/100], Step [42/60], Loss: 2.2130, batch time: 0.72, accuracy:  14.10%\n",
      "Epoch [4/100], Step [43/60], Loss: 2.2112, batch time: 0.69, accuracy:  14.50%\n",
      "Epoch [4/100], Step [44/60], Loss: 2.2131, batch time: 0.59, accuracy:  14.90%\n",
      "Epoch [4/100], Step [45/60], Loss: 2.2140, batch time: 0.84, accuracy:  15.60%\n",
      "Epoch [4/100], Step [46/60], Loss: 2.1899, batch time: 0.80, accuracy:  17.90%\n",
      "Epoch [4/100], Step [47/60], Loss: 2.2062, batch time: 0.91, accuracy:  16.70%\n",
      "Epoch [4/100], Step [48/60], Loss: 2.2121, batch time: 0.69, accuracy:  18.20%\n",
      "Epoch [4/100], Step [49/60], Loss: 2.2001, batch time: 0.60, accuracy:  17.20%\n",
      "Epoch [4/100], Step [50/60], Loss: 2.1948, batch time: 0.68, accuracy:  18.90%\n",
      "Epoch [4/100], Step [51/60], Loss: 2.2147, batch time: 0.71, accuracy:  17.90%\n",
      "Epoch [4/100], Step [52/60], Loss: 2.1931, batch time: 0.69, accuracy:  18.50%\n",
      "Epoch [4/100], Step [53/60], Loss: 2.2182, batch time: 0.69, accuracy:  16.30%\n",
      "Epoch [4/100], Step [54/60], Loss: 2.2116, batch time: 0.70, accuracy:  18.10%\n",
      "Epoch [4/100], Step [55/60], Loss: 2.1804, batch time: 0.72, accuracy:  19.70%\n",
      "Epoch [4/100], Step [56/60], Loss: 2.1952, batch time: 0.72, accuracy:  19.90%\n",
      "Epoch [4/100], Step [57/60], Loss: 2.1996, batch time: 0.73, accuracy:  18.60%\n",
      "Epoch [4/100], Step [58/60], Loss: 2.2184, batch time: 0.73, accuracy:  17.20%\n",
      "Epoch [4/100], Step [59/60], Loss: 2.1656, batch time: 0.73, accuracy:  20.30%\n",
      "Epoch [4/100], Step [60/60], Loss: 2.1910, batch time: 0.73, accuracy:  20.40%\n",
      "Epoch [5/100], Step [1/60], Loss: 2.2005, batch time: 0.73, accuracy:  17.60%\n",
      "Epoch [5/100], Step [2/60], Loss: 2.1795, batch time: 0.74, accuracy:  20.60%\n",
      "Epoch [5/100], Step [3/60], Loss: 2.2115, batch time: 0.87, accuracy:  17.80%\n",
      "Epoch [5/100], Step [4/60], Loss: 2.1907, batch time: 0.86, accuracy:  19.90%\n",
      "Epoch [5/100], Step [5/60], Loss: 2.1722, batch time: 0.87, accuracy:  21.00%\n",
      "Epoch [5/100], Step [6/60], Loss: 2.1855, batch time: 0.87, accuracy:  20.10%\n",
      "Epoch [5/100], Step [7/60], Loss: 2.1627, batch time: 0.86, accuracy:  21.60%\n",
      "Epoch [5/100], Step [8/60], Loss: 2.1886, batch time: 0.87, accuracy:  19.90%\n",
      "Epoch [5/100], Step [9/60], Loss: 2.1890, batch time: 0.86, accuracy:  19.60%\n",
      "Epoch [5/100], Step [10/60], Loss: 2.2216, batch time: 0.85, accuracy:  17.90%\n",
      "Epoch [5/100], Step [11/60], Loss: 2.1881, batch time: 0.87, accuracy:  21.80%\n",
      "Epoch [5/100], Step [12/60], Loss: 2.1692, batch time: 0.70, accuracy:  19.80%\n",
      "Epoch [5/100], Step [13/60], Loss: 2.1665, batch time: 0.71, accuracy:  19.10%\n",
      "Epoch [5/100], Step [14/60], Loss: 2.1945, batch time: 0.72, accuracy:  19.80%\n",
      "Epoch [5/100], Step [15/60], Loss: 2.1989, batch time: 0.67, accuracy:  18.50%\n",
      "Epoch [5/100], Step [16/60], Loss: 2.1776, batch time: 0.68, accuracy:  20.20%\n",
      "Epoch [5/100], Step [17/60], Loss: 2.1888, batch time: 0.67, accuracy:  20.50%\n",
      "Epoch [5/100], Step [18/60], Loss: 2.1787, batch time: 0.68, accuracy:  20.10%\n",
      "Epoch [5/100], Step [19/60], Loss: 2.1711, batch time: 0.67, accuracy:  22.40%\n",
      "Epoch [5/100], Step [20/60], Loss: 2.1564, batch time: 0.66, accuracy:  21.60%\n",
      "Epoch [5/100], Step [21/60], Loss: 2.1908, batch time: 0.68, accuracy:  19.40%\n",
      "Epoch [5/100], Step [22/60], Loss: 2.1672, batch time: 0.68, accuracy:  18.70%\n",
      "Epoch [5/100], Step [23/60], Loss: 2.1822, batch time: 0.69, accuracy:  20.60%\n",
      "Epoch [5/100], Step [24/60], Loss: 2.1578, batch time: 0.70, accuracy:  21.20%\n",
      "Epoch [5/100], Step [25/60], Loss: 2.1860, batch time: 0.68, accuracy:  17.90%\n",
      "Epoch [5/100], Step [26/60], Loss: 2.1553, batch time: 0.67, accuracy:  20.70%\n",
      "Epoch [5/100], Step [27/60], Loss: 2.1808, batch time: 0.64, accuracy:  19.70%\n",
      "Epoch [5/100], Step [28/60], Loss: 2.1914, batch time: 0.62, accuracy:  17.90%\n",
      "Epoch [5/100], Step [29/60], Loss: 2.1626, batch time: 0.70, accuracy:  19.50%\n",
      "Epoch [5/100], Step [30/60], Loss: 2.1721, batch time: 0.63, accuracy:  18.70%\n",
      "Epoch [5/100], Step [31/60], Loss: 2.1806, batch time: 0.82, accuracy:  17.40%\n",
      "Epoch [5/100], Step [32/60], Loss: 2.1631, batch time: 0.83, accuracy:  18.80%\n",
      "Epoch [5/100], Step [33/60], Loss: 2.1969, batch time: 0.82, accuracy:  18.60%\n",
      "Epoch [5/100], Step [34/60], Loss: 2.1601, batch time: 0.82, accuracy:  21.80%\n",
      "Epoch [5/100], Step [35/60], Loss: 2.1631, batch time: 0.83, accuracy:  19.40%\n",
      "Epoch [5/100], Step [36/60], Loss: 2.1599, batch time: 0.83, accuracy:  19.60%\n",
      "Epoch [5/100], Step [37/60], Loss: 2.1563, batch time: 0.83, accuracy:  19.90%\n",
      "Epoch [5/100], Step [38/60], Loss: 2.1610, batch time: 0.83, accuracy:  20.80%\n",
      "Epoch [5/100], Step [39/60], Loss: 2.1857, batch time: 0.82, accuracy:  20.40%\n",
      "Epoch [5/100], Step [40/60], Loss: 2.1742, batch time: 0.83, accuracy:  19.00%\n",
      "Epoch [5/100], Step [41/60], Loss: 2.1569, batch time: 0.83, accuracy:  18.40%\n",
      "Epoch [5/100], Step [42/60], Loss: 2.1733, batch time: 0.82, accuracy:  18.80%\n",
      "Epoch [5/100], Step [43/60], Loss: 2.1584, batch time: 0.82, accuracy:  20.00%\n",
      "Epoch [5/100], Step [44/60], Loss: 2.1797, batch time: 0.82, accuracy:  20.00%\n",
      "Epoch [5/100], Step [45/60], Loss: 2.1799, batch time: 0.82, accuracy:  19.50%\n",
      "Epoch [5/100], Step [46/60], Loss: 2.1894, batch time: 0.68, accuracy:  18.00%\n",
      "Epoch [5/100], Step [47/60], Loss: 2.1663, batch time: 0.68, accuracy:  21.20%\n",
      "Epoch [5/100], Step [48/60], Loss: 2.1712, batch time: 0.70, accuracy:  18.70%\n",
      "Epoch [5/100], Step [49/60], Loss: 2.1765, batch time: 0.70, accuracy:  20.70%\n",
      "Epoch [5/100], Step [50/60], Loss: 2.1800, batch time: 0.59, accuracy:  17.40%\n",
      "Epoch [5/100], Step [51/60], Loss: 2.1652, batch time: 0.70, accuracy:  19.10%\n",
      "Epoch [5/100], Step [52/60], Loss: 2.1935, batch time: 0.69, accuracy:  19.60%\n",
      "Epoch [5/100], Step [53/60], Loss: 2.1733, batch time: 0.71, accuracy:  19.70%\n",
      "Epoch [5/100], Step [54/60], Loss: 2.1673, batch time: 0.69, accuracy:  18.40%\n",
      "Epoch [5/100], Step [55/60], Loss: 2.1779, batch time: 0.63, accuracy:  20.50%\n",
      "Epoch [5/100], Step [56/60], Loss: 2.1831, batch time: 0.70, accuracy:  16.80%\n",
      "Epoch [5/100], Step [57/60], Loss: 2.1607, batch time: 0.70, accuracy:  19.10%\n",
      "Epoch [5/100], Step [58/60], Loss: 2.1752, batch time: 0.69, accuracy:  20.50%\n",
      "Epoch [5/100], Step [59/60], Loss: 2.1458, batch time: 0.72, accuracy:  19.90%\n",
      "Epoch [5/100], Step [60/60], Loss: 2.1649, batch time: 0.74, accuracy:  19.30%\n",
      "Epoch [6/100], Step [1/60], Loss: 2.1450, batch time: 0.74, accuracy:  21.40%\n",
      "Epoch [6/100], Step [2/60], Loss: 2.1603, batch time: 0.70, accuracy:  19.40%\n",
      "Epoch [6/100], Step [3/60], Loss: 2.1877, batch time: 0.75, accuracy:  17.90%\n",
      "Epoch [6/100], Step [4/60], Loss: 2.1831, batch time: 0.67, accuracy:  17.10%\n",
      "Epoch [6/100], Step [5/60], Loss: 2.1546, batch time: 0.78, accuracy:  19.40%\n",
      "Epoch [6/100], Step [6/60], Loss: 2.1872, batch time: 0.86, accuracy:  17.80%\n",
      "Epoch [6/100], Step [7/60], Loss: 2.1504, batch time: 0.85, accuracy:  22.00%\n",
      "Epoch [6/100], Step [8/60], Loss: 2.1469, batch time: 0.84, accuracy:  22.00%\n",
      "Epoch [6/100], Step [9/60], Loss: 2.1733, batch time: 0.86, accuracy:  18.10%\n",
      "Epoch [6/100], Step [10/60], Loss: 2.1445, batch time: 0.84, accuracy:  19.30%\n",
      "Epoch [6/100], Step [11/60], Loss: 2.1365, batch time: 0.82, accuracy:  20.70%\n",
      "Epoch [6/100], Step [12/60], Loss: 2.1285, batch time: 0.82, accuracy:  20.30%\n",
      "Epoch [6/100], Step [13/60], Loss: 2.1585, batch time: 0.82, accuracy:  19.50%\n",
      "Epoch [6/100], Step [14/60], Loss: 2.1676, batch time: 0.82, accuracy:  18.70%\n",
      "Epoch [6/100], Step [15/60], Loss: 2.1711, batch time: 0.82, accuracy:  17.60%\n",
      "Epoch [6/100], Step [16/60], Loss: 2.1258, batch time: 0.68, accuracy:  19.70%\n",
      "Epoch [6/100], Step [17/60], Loss: 2.1582, batch time: 0.68, accuracy:  18.60%\n",
      "Epoch [6/100], Step [18/60], Loss: 2.1796, batch time: 0.68, accuracy:  17.90%\n",
      "Epoch [6/100], Step [19/60], Loss: 2.1500, batch time: 0.68, accuracy:  20.70%\n",
      "Epoch [6/100], Step [20/60], Loss: 2.1671, batch time: 0.68, accuracy:  20.00%\n",
      "Epoch [6/100], Step [21/60], Loss: 2.1626, batch time: 0.68, accuracy:  17.90%\n",
      "Epoch [6/100], Step [22/60], Loss: 2.1701, batch time: 0.69, accuracy:  16.20%\n",
      "Epoch [6/100], Step [23/60], Loss: 2.1604, batch time: 0.65, accuracy:  19.20%\n",
      "Epoch [6/100], Step [24/60], Loss: 2.1392, batch time: 0.69, accuracy:  19.60%\n",
      "Epoch [6/100], Step [25/60], Loss: 2.1197, batch time: 0.68, accuracy:  21.60%\n",
      "Epoch [6/100], Step [26/60], Loss: 2.1445, batch time: 0.69, accuracy:  18.60%\n",
      "Epoch [6/100], Step [27/60], Loss: 2.1674, batch time: 0.68, accuracy:  18.30%\n",
      "Epoch [6/100], Step [28/60], Loss: 2.1385, batch time: 0.69, accuracy:  18.40%\n",
      "Epoch [6/100], Step [29/60], Loss: 2.1507, batch time: 0.69, accuracy:  18.60%\n",
      "Epoch [6/100], Step [30/60], Loss: 2.1193, batch time: 0.70, accuracy:  22.00%\n",
      "Epoch [6/100], Step [31/60], Loss: 2.1526, batch time: 0.72, accuracy:  18.60%\n",
      "Epoch [6/100], Step [32/60], Loss: 2.1104, batch time: 0.82, accuracy:  22.20%\n",
      "Epoch [6/100], Step [33/60], Loss: 2.1322, batch time: 0.82, accuracy:  18.70%\n",
      "Epoch [6/100], Step [34/60], Loss: 2.1447, batch time: 0.82, accuracy:  19.20%\n",
      "Epoch [6/100], Step [35/60], Loss: 2.1499, batch time: 0.83, accuracy:  18.50%\n",
      "Epoch [6/100], Step [36/60], Loss: 2.1718, batch time: 0.68, accuracy:  18.30%\n",
      "Epoch [6/100], Step [37/60], Loss: 2.1411, batch time: 0.68, accuracy:  19.70%\n",
      "Epoch [6/100], Step [38/60], Loss: 2.1534, batch time: 0.68, accuracy:  18.40%\n",
      "Epoch [6/100], Step [39/60], Loss: 2.1365, batch time: 0.69, accuracy:  18.90%\n",
      "Epoch [6/100], Step [40/60], Loss: 2.1156, batch time: 0.69, accuracy:  20.30%\n",
      "Epoch [6/100], Step [41/60], Loss: 2.1807, batch time: 0.69, accuracy:  16.30%\n",
      "Epoch [6/100], Step [42/60], Loss: 2.1360, batch time: 0.69, accuracy:  19.30%\n",
      "Epoch [6/100], Step [43/60], Loss: 2.1261, batch time: 0.72, accuracy:  20.00%\n",
      "Epoch [6/100], Step [44/60], Loss: 2.1152, batch time: 0.61, accuracy:  22.40%\n",
      "Epoch [6/100], Step [45/60], Loss: 2.1623, batch time: 0.45, accuracy:  19.40%\n",
      "Epoch [6/100], Step [46/60], Loss: 2.1483, batch time: 0.45, accuracy:  17.80%\n",
      "Epoch [6/100], Step [47/60], Loss: 2.1242, batch time: 0.45, accuracy:  18.80%\n",
      "Epoch [6/100], Step [48/60], Loss: 2.1510, batch time: 0.45, accuracy:  19.50%\n",
      "Epoch [6/100], Step [49/60], Loss: 2.1416, batch time: 0.46, accuracy:  19.20%\n",
      "Epoch [6/100], Step [50/60], Loss: 2.1427, batch time: 0.45, accuracy:  18.60%\n",
      "Epoch [6/100], Step [51/60], Loss: 2.1483, batch time: 0.48, accuracy:  19.50%\n",
      "Epoch [6/100], Step [52/60], Loss: 2.1452, batch time: 0.45, accuracy:  19.90%\n",
      "Epoch [6/100], Step [53/60], Loss: 2.1186, batch time: 0.46, accuracy:  20.70%\n",
      "Epoch [6/100], Step [54/60], Loss: 2.1614, batch time: 0.52, accuracy:  16.90%\n",
      "Epoch [6/100], Step [55/60], Loss: 2.1378, batch time: 0.53, accuracy:  17.50%\n",
      "Epoch [6/100], Step [56/60], Loss: 2.1153, batch time: 0.54, accuracy:  21.30%\n",
      "Epoch [6/100], Step [57/60], Loss: 2.1556, batch time: 0.54, accuracy:  18.60%\n",
      "Epoch [6/100], Step [58/60], Loss: 2.1250, batch time: 0.54, accuracy:  21.50%\n",
      "Epoch [6/100], Step [59/60], Loss: 2.1624, batch time: 0.56, accuracy:  18.00%\n",
      "Epoch [6/100], Step [60/60], Loss: 2.1196, batch time: 0.54, accuracy:  20.60%\n",
      "Epoch [7/100], Step [1/60], Loss: 2.1351, batch time: 0.56, accuracy:  19.10%\n",
      "Epoch [7/100], Step [2/60], Loss: 2.1256, batch time: 0.53, accuracy:  18.30%\n",
      "Epoch [7/100], Step [3/60], Loss: 2.1390, batch time: 0.54, accuracy:  18.30%\n",
      "Epoch [7/100], Step [4/60], Loss: 2.1313, batch time: 0.54, accuracy:  19.40%\n",
      "Epoch [7/100], Step [5/60], Loss: 2.1291, batch time: 0.51, accuracy:  20.30%\n",
      "Epoch [7/100], Step [6/60], Loss: 2.1040, batch time: 0.45, accuracy:  22.20%\n",
      "Epoch [7/100], Step [7/60], Loss: 2.1665, batch time: 0.46, accuracy:  17.00%\n",
      "Epoch [7/100], Step [8/60], Loss: 2.1075, batch time: 0.46, accuracy:  20.10%\n",
      "Epoch [7/100], Step [9/60], Loss: 2.1076, batch time: 0.45, accuracy:  21.10%\n",
      "Epoch [7/100], Step [10/60], Loss: 2.1126, batch time: 0.45, accuracy:  21.30%\n",
      "Epoch [7/100], Step [11/60], Loss: 2.1542, batch time: 0.45, accuracy:  18.30%\n",
      "Epoch [7/100], Step [12/60], Loss: 2.1352, batch time: 0.45, accuracy:  21.20%\n",
      "Epoch [7/100], Step [13/60], Loss: 2.1668, batch time: 0.45, accuracy:  19.70%\n",
      "Epoch [7/100], Step [14/60], Loss: 2.1253, batch time: 0.46, accuracy:  19.80%\n",
      "Epoch [7/100], Step [15/60], Loss: 2.1165, batch time: 0.44, accuracy:  20.00%\n",
      "Epoch [7/100], Step [16/60], Loss: 2.1351, batch time: 0.48, accuracy:  19.90%\n",
      "Epoch [7/100], Step [17/60], Loss: 2.1131, batch time: 0.45, accuracy:  20.00%\n",
      "Epoch [7/100], Step [18/60], Loss: 2.0948, batch time: 0.45, accuracy:  22.30%\n",
      "Epoch [7/100], Step [19/60], Loss: 2.1158, batch time: 0.46, accuracy:  19.80%\n",
      "Epoch [7/100], Step [20/60], Loss: 2.1016, batch time: 0.47, accuracy:  21.50%\n",
      "Epoch [7/100], Step [21/60], Loss: 2.1233, batch time: 0.44, accuracy:  19.60%\n",
      "Epoch [7/100], Step [22/60], Loss: 2.1011, batch time: 0.46, accuracy:  21.50%\n",
      "Epoch [7/100], Step [23/60], Loss: 2.1365, batch time: 0.45, accuracy:  19.40%\n",
      "Epoch [7/100], Step [24/60], Loss: 2.1290, batch time: 0.45, accuracy:  20.20%\n",
      "Epoch [7/100], Step [25/60], Loss: 2.1608, batch time: 0.48, accuracy:  18.10%\n",
      "Epoch [7/100], Step [26/60], Loss: 2.1313, batch time: 0.45, accuracy:  19.90%\n",
      "Epoch [7/100], Step [27/60], Loss: 2.1335, batch time: 0.53, accuracy:  20.80%\n",
      "Epoch [7/100], Step [28/60], Loss: 2.1190, batch time: 0.46, accuracy:  20.50%\n",
      "Epoch [7/100], Step [29/60], Loss: 2.1516, batch time: 0.54, accuracy:  19.20%\n",
      "Epoch [7/100], Step [30/60], Loss: 2.1525, batch time: 0.54, accuracy:  18.90%\n",
      "Epoch [7/100], Step [31/60], Loss: 2.1188, batch time: 0.55, accuracy:  21.00%\n",
      "Epoch [7/100], Step [32/60], Loss: 2.1274, batch time: 0.56, accuracy:  19.70%\n",
      "Epoch [7/100], Step [33/60], Loss: 2.1271, batch time: 0.57, accuracy:  19.80%\n",
      "Epoch [7/100], Step [34/60], Loss: 2.1375, batch time: 0.58, accuracy:  19.60%\n",
      "Epoch [7/100], Step [35/60], Loss: 2.1326, batch time: 0.54, accuracy:  17.80%\n",
      "Epoch [7/100], Step [36/60], Loss: 2.1317, batch time: 0.54, accuracy:  19.60%\n",
      "Epoch [7/100], Step [37/60], Loss: 2.1461, batch time: 0.56, accuracy:  17.10%\n",
      "Epoch [7/100], Step [38/60], Loss: 2.1165, batch time: 0.55, accuracy:  19.40%\n",
      "Epoch [7/100], Step [39/60], Loss: 2.1299, batch time: 0.56, accuracy:  19.70%\n",
      "Epoch [7/100], Step [40/60], Loss: 2.1383, batch time: 0.54, accuracy:  19.10%\n",
      "Epoch [7/100], Step [41/60], Loss: 2.1340, batch time: 0.55, accuracy:  19.10%\n",
      "Epoch [7/100], Step [42/60], Loss: 2.1114, batch time: 0.54, accuracy:  19.20%\n",
      "Epoch [7/100], Step [43/60], Loss: 2.1231, batch time: 0.54, accuracy:  20.40%\n",
      "Epoch [7/100], Step [44/60], Loss: 2.1264, batch time: 0.46, accuracy:  19.70%\n",
      "Epoch [7/100], Step [45/60], Loss: 2.1038, batch time: 0.44, accuracy:  20.20%\n",
      "Epoch [7/100], Step [46/60], Loss: 2.1038, batch time: 0.45, accuracy:  21.90%\n",
      "Epoch [7/100], Step [47/60], Loss: 2.1157, batch time: 0.44, accuracy:  20.20%\n",
      "Epoch [7/100], Step [48/60], Loss: 2.1267, batch time: 0.43, accuracy:  21.00%\n",
      "Epoch [7/100], Step [49/60], Loss: 2.0902, batch time: 0.47, accuracy:  20.50%\n",
      "Epoch [7/100], Step [50/60], Loss: 2.1221, batch time: 0.43, accuracy:  20.30%\n",
      "Epoch [7/100], Step [51/60], Loss: 2.1039, batch time: 0.45, accuracy:  19.80%\n",
      "Epoch [7/100], Step [52/60], Loss: 2.1120, batch time: 0.46, accuracy:  20.20%\n",
      "Epoch [7/100], Step [53/60], Loss: 2.1430, batch time: 0.44, accuracy:  18.80%\n",
      "Epoch [7/100], Step [54/60], Loss: 2.1090, batch time: 0.45, accuracy:  19.90%\n",
      "Epoch [7/100], Step [55/60], Loss: 2.1281, batch time: 0.44, accuracy:  19.80%\n",
      "Epoch [7/100], Step [56/60], Loss: 2.0876, batch time: 0.44, accuracy:  19.60%\n",
      "Epoch [7/100], Step [57/60], Loss: 2.1209, batch time: 0.44, accuracy:  19.40%\n",
      "Epoch [7/100], Step [58/60], Loss: 2.1125, batch time: 0.45, accuracy:  19.50%\n",
      "Epoch [7/100], Step [59/60], Loss: 2.1464, batch time: 0.44, accuracy:  18.60%\n",
      "Epoch [7/100], Step [60/60], Loss: 2.0848, batch time: 0.45, accuracy:  23.10%\n",
      "Epoch [8/100], Step [1/60], Loss: 2.1270, batch time: 0.46, accuracy:  22.00%\n",
      "Epoch [8/100], Step [2/60], Loss: 2.1184, batch time: 0.44, accuracy:  20.30%\n",
      "Epoch [8/100], Step [3/60], Loss: 2.1329, batch time: 0.45, accuracy:  19.30%\n",
      "Epoch [8/100], Step [4/60], Loss: 2.1071, batch time: 0.43, accuracy:  20.70%\n",
      "Epoch [8/100], Step [5/60], Loss: 2.1026, batch time: 0.45, accuracy:  18.90%\n",
      "Epoch [8/100], Step [6/60], Loss: 2.1327, batch time: 0.45, accuracy:  19.20%\n",
      "Epoch [8/100], Step [7/60], Loss: 2.1331, batch time: 0.45, accuracy:  18.60%\n",
      "Epoch [8/100], Step [8/60], Loss: 2.1087, batch time: 0.55, accuracy:  20.20%\n",
      "Epoch [8/100], Step [9/60], Loss: 2.1134, batch time: 0.61, accuracy:  19.80%\n",
      "Epoch [8/100], Step [10/60], Loss: 2.1209, batch time: 0.54, accuracy:  18.60%\n",
      "Epoch [8/100], Step [11/60], Loss: 2.1043, batch time: 0.54, accuracy:  18.60%\n",
      "Epoch [8/100], Step [12/60], Loss: 2.1162, batch time: 0.53, accuracy:  18.90%\n",
      "Epoch [8/100], Step [13/60], Loss: 2.1183, batch time: 0.54, accuracy:  20.50%\n",
      "Epoch [8/100], Step [14/60], Loss: 2.1011, batch time: 0.53, accuracy:  21.50%\n",
      "Epoch [8/100], Step [15/60], Loss: 2.1344, batch time: 0.61, accuracy:  20.40%\n",
      "Epoch [8/100], Step [16/60], Loss: 2.1095, batch time: 0.47, accuracy:  20.70%\n",
      "Epoch [8/100], Step [17/60], Loss: 2.0937, batch time: 0.44, accuracy:  20.50%\n",
      "Epoch [8/100], Step [18/60], Loss: 2.1149, batch time: 0.46, accuracy:  20.70%\n",
      "Epoch [8/100], Step [19/60], Loss: 2.0781, batch time: 0.45, accuracy:  20.90%\n",
      "Epoch [8/100], Step [20/60], Loss: 2.1242, batch time: 0.72, accuracy:  17.50%\n",
      "Epoch [8/100], Step [21/60], Loss: 2.1333, batch time: 0.44, accuracy:  19.10%\n",
      "Epoch [8/100], Step [22/60], Loss: 2.0840, batch time: 0.44, accuracy:  22.80%\n",
      "Epoch [8/100], Step [23/60], Loss: 2.1194, batch time: 0.45, accuracy:  20.50%\n",
      "Epoch [8/100], Step [24/60], Loss: 2.1099, batch time: 0.45, accuracy:  20.80%\n",
      "Epoch [8/100], Step [25/60], Loss: 2.0960, batch time: 0.45, accuracy:  22.00%\n",
      "Epoch [8/100], Step [26/60], Loss: 2.1168, batch time: 0.44, accuracy:  20.30%\n",
      "Epoch [8/100], Step [27/60], Loss: 2.0836, batch time: 0.43, accuracy:  21.90%\n",
      "Epoch [8/100], Step [28/60], Loss: 2.0889, batch time: 0.46, accuracy:  20.40%\n",
      "Epoch [8/100], Step [29/60], Loss: 2.1337, batch time: 0.44, accuracy:  18.50%\n",
      "Epoch [8/100], Step [30/60], Loss: 2.0815, batch time: 0.44, accuracy:  23.40%\n",
      "Epoch [8/100], Step [31/60], Loss: 2.1171, batch time: 0.45, accuracy:  20.30%\n",
      "Epoch [8/100], Step [32/60], Loss: 2.0859, batch time: 0.46, accuracy:  22.20%\n",
      "Epoch [8/100], Step [33/60], Loss: 2.0622, batch time: 0.45, accuracy:  22.90%\n",
      "Epoch [8/100], Step [34/60], Loss: 2.0978, batch time: 0.45, accuracy:  20.50%\n",
      "Epoch [8/100], Step [35/60], Loss: 2.0799, batch time: 0.43, accuracy:  21.70%\n",
      "Epoch [8/100], Step [36/60], Loss: 2.1051, batch time: 0.45, accuracy:  21.00%\n",
      "Epoch [8/100], Step [37/60], Loss: 2.0934, batch time: 0.45, accuracy:  21.50%\n",
      "Epoch [8/100], Step [38/60], Loss: 2.1316, batch time: 0.45, accuracy:  20.60%\n",
      "Epoch [8/100], Step [39/60], Loss: 2.1378, batch time: 0.54, accuracy:  20.30%\n",
      "Epoch [8/100], Step [40/60], Loss: 2.1062, batch time: 0.53, accuracy:  22.30%\n",
      "Epoch [8/100], Step [41/60], Loss: 2.1141, batch time: 0.60, accuracy:  20.00%\n",
      "Epoch [8/100], Step [42/60], Loss: 2.0564, batch time: 0.72, accuracy:  23.80%\n",
      "Epoch [8/100], Step [43/60], Loss: 2.1038, batch time: 0.54, accuracy:  19.40%\n",
      "Epoch [8/100], Step [44/60], Loss: 2.0896, batch time: 0.56, accuracy:  20.00%\n",
      "Epoch [8/100], Step [45/60], Loss: 2.0820, batch time: 0.49, accuracy:  22.40%\n",
      "Epoch [8/100], Step [46/60], Loss: 2.1083, batch time: 0.45, accuracy:  21.50%\n",
      "Epoch [8/100], Step [47/60], Loss: 2.1312, batch time: 0.44, accuracy:  18.10%\n",
      "Epoch [8/100], Step [48/60], Loss: 2.0690, batch time: 0.45, accuracy:  21.50%\n",
      "Epoch [8/100], Step [49/60], Loss: 2.1105, batch time: 0.46, accuracy:  18.70%\n",
      "Epoch [8/100], Step [50/60], Loss: 2.1066, batch time: 0.51, accuracy:  19.70%\n",
      "Epoch [8/100], Step [51/60], Loss: 2.0931, batch time: 0.54, accuracy:  21.10%\n",
      "Epoch [8/100], Step [52/60], Loss: 2.0977, batch time: 0.46, accuracy:  20.90%\n",
      "Epoch [8/100], Step [53/60], Loss: 2.1156, batch time: 0.44, accuracy:  18.30%\n",
      "Epoch [8/100], Step [54/60], Loss: 2.0861, batch time: 0.46, accuracy:  22.60%\n",
      "Epoch [8/100], Step [55/60], Loss: 2.1386, batch time: 0.45, accuracy:  17.70%\n",
      "Epoch [8/100], Step [56/60], Loss: 2.1144, batch time: 0.44, accuracy:  18.90%\n",
      "Epoch [8/100], Step [57/60], Loss: 2.0851, batch time: 0.44, accuracy:  20.20%\n",
      "Epoch [8/100], Step [58/60], Loss: 2.0760, batch time: 0.46, accuracy:  21.00%\n",
      "Epoch [8/100], Step [59/60], Loss: 2.0735, batch time: 0.44, accuracy:  22.50%\n",
      "Epoch [8/100], Step [60/60], Loss: 2.1231, batch time: 0.65, accuracy:  19.10%\n",
      "Epoch [9/100], Step [1/60], Loss: 2.0971, batch time: 0.83, accuracy:  22.00%\n",
      "Epoch [9/100], Step [2/60], Loss: 2.0907, batch time: 0.88, accuracy:  20.70%\n",
      "Epoch [9/100], Step [3/60], Loss: 2.0842, batch time: 0.79, accuracy:  22.00%\n",
      "Epoch [9/100], Step [4/60], Loss: 2.1002, batch time: 0.84, accuracy:  21.30%\n",
      "Epoch [9/100], Step [5/60], Loss: 2.0987, batch time: 0.93, accuracy:  19.70%\n",
      "Epoch [9/100], Step [6/60], Loss: 2.1022, batch time: 0.91, accuracy:  19.50%\n",
      "Epoch [9/100], Step [7/60], Loss: 2.1024, batch time: 0.89, accuracy:  20.30%\n",
      "Epoch [9/100], Step [8/60], Loss: 2.1090, batch time: 0.74, accuracy:  18.70%\n",
      "Epoch [9/100], Step [9/60], Loss: 2.1011, batch time: 0.79, accuracy:  19.80%\n",
      "Epoch [9/100], Step [10/60], Loss: 2.0805, batch time: 0.61, accuracy:  21.50%\n",
      "Epoch [9/100], Step [11/60], Loss: 2.0912, batch time: 0.72, accuracy:  21.20%\n",
      "Epoch [9/100], Step [12/60], Loss: 2.0693, batch time: 0.70, accuracy:  22.70%\n",
      "Epoch [9/100], Step [13/60], Loss: 2.0930, batch time: 0.69, accuracy:  20.60%\n",
      "Epoch [9/100], Step [14/60], Loss: 2.0918, batch time: 0.68, accuracy:  19.90%\n",
      "Epoch [9/100], Step [15/60], Loss: 2.0758, batch time: 0.70, accuracy:  22.40%\n",
      "Epoch [9/100], Step [16/60], Loss: 2.0968, batch time: 0.64, accuracy:  19.60%\n",
      "Epoch [9/100], Step [17/60], Loss: 2.0726, batch time: 0.42, accuracy:  22.10%\n",
      "Epoch [9/100], Step [18/60], Loss: 2.0820, batch time: 0.56, accuracy:  21.00%\n",
      "Epoch [9/100], Step [19/60], Loss: 2.0614, batch time: 0.73, accuracy:  23.10%\n",
      "Epoch [9/100], Step [20/60], Loss: 2.0887, batch time: 0.73, accuracy:  21.40%\n",
      "Epoch [9/100], Step [21/60], Loss: 2.0936, batch time: 0.75, accuracy:  19.00%\n",
      "Epoch [9/100], Step [22/60], Loss: 2.0893, batch time: 0.76, accuracy:  22.90%\n",
      "Epoch [9/100], Step [23/60], Loss: 2.0956, batch time: 0.87, accuracy:  21.00%\n",
      "Epoch [9/100], Step [24/60], Loss: 2.1197, batch time: 0.87, accuracy:  19.80%\n",
      "Epoch [9/100], Step [25/60], Loss: 2.0889, batch time: 0.87, accuracy:  20.10%\n",
      "Epoch [9/100], Step [26/60], Loss: 2.1049, batch time: 0.88, accuracy:  19.10%\n",
      "Epoch [9/100], Step [27/60], Loss: 2.0939, batch time: 0.88, accuracy:  21.40%\n",
      "Epoch [9/100], Step [28/60], Loss: 2.0859, batch time: 0.84, accuracy:  21.20%\n",
      "Epoch [9/100], Step [29/60], Loss: 2.0973, batch time: 0.72, accuracy:  21.00%\n",
      "Epoch [9/100], Step [30/60], Loss: 2.1143, batch time: 0.67, accuracy:  20.10%\n",
      "Epoch [9/100], Step [31/60], Loss: 2.0886, batch time: 0.68, accuracy:  20.90%\n",
      "Epoch [9/100], Step [32/60], Loss: 2.0599, batch time: 0.67, accuracy:  21.70%\n",
      "Epoch [9/100], Step [33/60], Loss: 2.1087, batch time: 0.67, accuracy:  19.20%\n",
      "Epoch [9/100], Step [34/60], Loss: 2.0805, batch time: 0.75, accuracy:  23.10%\n",
      "Epoch [9/100], Step [35/60], Loss: 2.0776, batch time: 0.68, accuracy:  20.50%\n",
      "Epoch [9/100], Step [36/60], Loss: 2.0751, batch time: 0.68, accuracy:  21.60%\n",
      "Epoch [9/100], Step [37/60], Loss: 2.0761, batch time: 0.68, accuracy:  23.40%\n",
      "Epoch [9/100], Step [38/60], Loss: 2.0517, batch time: 0.68, accuracy:  22.80%\n",
      "Epoch [9/100], Step [39/60], Loss: 2.0734, batch time: 0.49, accuracy:  20.80%\n",
      "Epoch [9/100], Step [40/60], Loss: 2.1008, batch time: 0.68, accuracy:  20.00%\n",
      "Epoch [9/100], Step [41/60], Loss: 2.0827, batch time: 0.68, accuracy:  20.90%\n",
      "Epoch [9/100], Step [42/60], Loss: 2.0634, batch time: 0.69, accuracy:  22.80%\n",
      "Epoch [9/100], Step [43/60], Loss: 2.0632, batch time: 0.70, accuracy:  21.50%\n",
      "Epoch [9/100], Step [44/60], Loss: 2.0980, batch time: 0.75, accuracy:  21.50%\n",
      "Epoch [9/100], Step [45/60], Loss: 2.0724, batch time: 0.80, accuracy:  22.50%\n",
      "Epoch [9/100], Step [46/60], Loss: 2.0820, batch time: 0.87, accuracy:  20.40%\n",
      "Epoch [9/100], Step [47/60], Loss: 2.0868, batch time: 0.84, accuracy:  21.20%\n",
      "Epoch [9/100], Step [48/60], Loss: 2.0978, batch time: 0.71, accuracy:  19.40%\n",
      "Epoch [9/100], Step [49/60], Loss: 2.0880, batch time: 0.66, accuracy:  21.10%\n",
      "Epoch [9/100], Step [50/60], Loss: 2.0733, batch time: 0.71, accuracy:  21.80%\n",
      "Epoch [9/100], Step [51/60], Loss: 2.0744, batch time: 0.68, accuracy:  21.20%\n",
      "Epoch [9/100], Step [52/60], Loss: 2.0749, batch time: 0.71, accuracy:  20.60%\n",
      "Epoch [9/100], Step [53/60], Loss: 2.0521, batch time: 0.69, accuracy:  22.00%\n",
      "Epoch [9/100], Step [54/60], Loss: 2.0620, batch time: 0.68, accuracy:  21.60%\n",
      "Epoch [9/100], Step [55/60], Loss: 2.1024, batch time: 0.73, accuracy:  20.80%\n",
      "Epoch [9/100], Step [56/60], Loss: 2.0875, batch time: 0.68, accuracy:  20.40%\n",
      "Epoch [9/100], Step [57/60], Loss: 2.0447, batch time: 0.68, accuracy:  23.10%\n",
      "Epoch [9/100], Step [58/60], Loss: 2.1302, batch time: 0.69, accuracy:  19.40%\n",
      "Epoch [9/100], Step [59/60], Loss: 2.1051, batch time: 0.70, accuracy:  20.60%\n",
      "Epoch [9/100], Step [60/60], Loss: 2.0761, batch time: 0.72, accuracy:  20.10%\n",
      "Epoch [10/100], Step [1/60], Loss: 2.0952, batch time: 0.60, accuracy:  19.50%\n",
      "Epoch [10/100], Step [2/60], Loss: 2.0658, batch time: 0.74, accuracy:  21.40%\n",
      "Epoch [10/100], Step [3/60], Loss: 2.0282, batch time: 0.73, accuracy:  22.20%\n",
      "Epoch [10/100], Step [4/60], Loss: 2.1015, batch time: 0.75, accuracy:  19.00%\n",
      "Epoch [10/100], Step [5/60], Loss: 2.0782, batch time: 0.65, accuracy:  21.40%\n",
      "Epoch [10/100], Step [6/60], Loss: 2.0949, batch time: 0.77, accuracy:  19.50%\n",
      "Epoch [10/100], Step [7/60], Loss: 2.0697, batch time: 0.92, accuracy:  20.60%\n",
      "Epoch [10/100], Step [8/60], Loss: 2.1026, batch time: 0.83, accuracy:  20.00%\n",
      "Epoch [10/100], Step [9/60], Loss: 2.0603, batch time: 0.87, accuracy:  22.00%\n",
      "Epoch [10/100], Step [10/60], Loss: 2.0810, batch time: 0.87, accuracy:  21.40%\n",
      "Epoch [10/100], Step [11/60], Loss: 2.0780, batch time: 0.87, accuracy:  22.90%\n",
      "Epoch [10/100], Step [12/60], Loss: 2.0844, batch time: 0.72, accuracy:  21.00%\n",
      "Epoch [10/100], Step [13/60], Loss: 2.0659, batch time: 0.62, accuracy:  21.50%\n",
      "Epoch [10/100], Step [14/60], Loss: 2.0743, batch time: 0.69, accuracy:  21.40%\n",
      "Epoch [10/100], Step [15/60], Loss: 2.0598, batch time: 0.67, accuracy:  21.80%\n",
      "Epoch [10/100], Step [16/60], Loss: 2.0582, batch time: 0.69, accuracy:  22.90%\n",
      "Epoch [10/100], Step [17/60], Loss: 2.0646, batch time: 0.59, accuracy:  22.20%\n",
      "Epoch [10/100], Step [18/60], Loss: 2.0881, batch time: 0.70, accuracy:  20.00%\n",
      "Epoch [10/100], Step [19/60], Loss: 2.0662, batch time: 0.63, accuracy:  22.20%\n",
      "Epoch [10/100], Step [20/60], Loss: 2.0579, batch time: 0.44, accuracy:  22.30%\n",
      "Epoch [10/100], Step [21/60], Loss: 2.0826, batch time: 0.45, accuracy:  20.40%\n",
      "Epoch [10/100], Step [22/60], Loss: 2.0753, batch time: 0.46, accuracy:  19.90%\n",
      "Epoch [10/100], Step [23/60], Loss: 2.0051, batch time: 0.46, accuracy:  23.60%\n",
      "Epoch [10/100], Step [24/60], Loss: 2.0871, batch time: 0.68, accuracy:  20.80%\n",
      "Epoch [10/100], Step [25/60], Loss: 2.0730, batch time: 0.71, accuracy:  21.20%\n",
      "Epoch [10/100], Step [26/60], Loss: 2.0807, batch time: 0.71, accuracy:  22.00%\n",
      "Epoch [10/100], Step [27/60], Loss: 2.0695, batch time: 0.85, accuracy:  22.50%\n",
      "Epoch [10/100], Step [28/60], Loss: 2.0913, batch time: 0.76, accuracy:  19.80%\n",
      "Epoch [10/100], Step [29/60], Loss: 2.0880, batch time: 0.80, accuracy:  20.50%\n",
      "Epoch [10/100], Step [30/60], Loss: 2.0506, batch time: 0.90, accuracy:  20.80%\n",
      "Epoch [10/100], Step [31/60], Loss: 2.0982, batch time: 0.84, accuracy:  21.10%\n",
      "Epoch [10/100], Step [32/60], Loss: 2.0677, batch time: 0.81, accuracy:  22.20%\n",
      "Epoch [10/100], Step [33/60], Loss: 2.0388, batch time: 0.74, accuracy:  21.90%\n",
      "Epoch [10/100], Step [34/60], Loss: 2.0713, batch time: 0.74, accuracy:  21.00%\n",
      "Epoch [10/100], Step [35/60], Loss: 2.0353, batch time: 0.75, accuracy:  22.30%\n",
      "Epoch [10/100], Step [36/60], Loss: 2.1118, batch time: 0.80, accuracy:  20.10%\n",
      "Epoch [10/100], Step [37/60], Loss: 2.0637, batch time: 0.82, accuracy:  22.40%\n",
      "Epoch [10/100], Step [38/60], Loss: 2.0898, batch time: 0.82, accuracy:  21.00%\n",
      "Epoch [10/100], Step [39/60], Loss: 2.0369, batch time: 0.82, accuracy:  22.60%\n",
      "Epoch [10/100], Step [40/60], Loss: 2.1283, batch time: 0.68, accuracy:  18.80%\n",
      "Epoch [10/100], Step [41/60], Loss: 2.0380, batch time: 0.68, accuracy:  23.40%\n",
      "Epoch [10/100], Step [42/60], Loss: 2.0960, batch time: 0.83, accuracy:  20.30%\n",
      "Epoch [10/100], Step [43/60], Loss: 2.0414, batch time: 0.68, accuracy:  23.80%\n",
      "Epoch [10/100], Step [44/60], Loss: 2.0471, batch time: 0.86, accuracy:  23.40%\n",
      "Epoch [10/100], Step [45/60], Loss: 2.0811, batch time: 0.78, accuracy:  20.60%\n",
      "Epoch [10/100], Step [46/60], Loss: 2.0609, batch time: 0.75, accuracy:  20.50%\n",
      "Epoch [10/100], Step [47/60], Loss: 2.0370, batch time: 0.71, accuracy:  22.90%\n",
      "Epoch [10/100], Step [48/60], Loss: 2.1076, batch time: 0.72, accuracy:  19.30%\n",
      "Epoch [10/100], Step [49/60], Loss: 2.0684, batch time: 0.80, accuracy:  22.30%\n",
      "Epoch [10/100], Step [50/60], Loss: 2.0594, batch time: 0.64, accuracy:  22.10%\n",
      "Epoch [10/100], Step [51/60], Loss: 2.0514, batch time: 0.66, accuracy:  21.90%\n",
      "Epoch [10/100], Step [52/60], Loss: 2.0692, batch time: 0.76, accuracy:  20.90%\n",
      "Epoch [10/100], Step [53/60], Loss: 2.0187, batch time: 0.76, accuracy:  23.80%\n",
      "Epoch [10/100], Step [54/60], Loss: 2.0505, batch time: 0.64, accuracy:  22.50%\n",
      "Epoch [10/100], Step [55/60], Loss: 2.0844, batch time: 0.71, accuracy:  21.00%\n",
      "Epoch [10/100], Step [56/60], Loss: 2.0443, batch time: 0.69, accuracy:  22.70%\n",
      "Epoch [10/100], Step [57/60], Loss: 2.0906, batch time: 0.81, accuracy:  21.70%\n",
      "Epoch [10/100], Step [58/60], Loss: 2.0785, batch time: 0.74, accuracy:  19.80%\n",
      "Epoch [10/100], Step [59/60], Loss: 2.0561, batch time: 0.71, accuracy:  22.00%\n",
      "Epoch [10/100], Step [60/60], Loss: 2.0578, batch time: 0.69, accuracy:  22.20%\n",
      "Epoch [11/100], Step [1/60], Loss: 2.0560, batch time: 0.71, accuracy:  20.70%\n",
      "Epoch [11/100], Step [2/60], Loss: 2.0823, batch time: 0.62, accuracy:  20.40%\n",
      "Epoch [11/100], Step [3/60], Loss: 2.0677, batch time: 0.71, accuracy:  21.30%\n",
      "Epoch [11/100], Step [4/60], Loss: 2.0569, batch time: 0.59, accuracy:  21.00%\n",
      "Epoch [11/100], Step [5/60], Loss: 2.0718, batch time: 0.65, accuracy:  21.10%\n",
      "Epoch [11/100], Step [6/60], Loss: 2.0269, batch time: 0.69, accuracy:  22.90%\n",
      "Epoch [11/100], Step [7/60], Loss: 2.0579, batch time: 0.63, accuracy:  22.00%\n",
      "Epoch [11/100], Step [8/60], Loss: 2.0651, batch time: 0.70, accuracy:  20.90%\n",
      "Epoch [11/100], Step [9/60], Loss: 2.0554, batch time: 0.58, accuracy:  23.90%\n",
      "Epoch [11/100], Step [10/60], Loss: 2.0516, batch time: 0.64, accuracy:  21.30%\n",
      "Epoch [11/100], Step [11/60], Loss: 2.0577, batch time: 0.46, accuracy:  23.10%\n",
      "Epoch [11/100], Step [12/60], Loss: 2.0605, batch time: 0.45, accuracy:  22.10%\n",
      "Epoch [11/100], Step [13/60], Loss: 2.0682, batch time: 0.47, accuracy:  21.20%\n",
      "Epoch [11/100], Step [14/60], Loss: 2.0891, batch time: 0.49, accuracy:  20.30%\n",
      "Epoch [11/100], Step [15/60], Loss: 2.0723, batch time: 0.72, accuracy:  21.40%\n",
      "Epoch [11/100], Step [16/60], Loss: 2.0370, batch time: 0.88, accuracy:  22.30%\n",
      "Epoch [11/100], Step [17/60], Loss: 2.0498, batch time: 1.05, accuracy:  23.10%\n",
      "Epoch [11/100], Step [18/60], Loss: 2.0556, batch time: 1.01, accuracy:  21.90%\n",
      "Epoch [11/100], Step [19/60], Loss: 2.0760, batch time: 0.99, accuracy:  21.10%\n",
      "Epoch [11/100], Step [20/60], Loss: 2.0577, batch time: 0.82, accuracy:  23.20%\n",
      "Epoch [11/100], Step [21/60], Loss: 2.0581, batch time: 0.72, accuracy:  21.30%\n",
      "Epoch [11/100], Step [22/60], Loss: 2.0577, batch time: 0.72, accuracy:  21.40%\n",
      "Epoch [11/100], Step [23/60], Loss: 2.0939, batch time: 0.68, accuracy:  20.50%\n",
      "Epoch [11/100], Step [24/60], Loss: 2.0485, batch time: 0.68, accuracy:  21.20%\n",
      "Epoch [11/100], Step [25/60], Loss: 2.0834, batch time: 0.81, accuracy:  19.60%\n",
      "Epoch [11/100], Step [26/60], Loss: 2.0528, batch time: 0.73, accuracy:  21.90%\n",
      "Epoch [11/100], Step [27/60], Loss: 2.0863, batch time: 0.73, accuracy:  19.70%\n",
      "Epoch [11/100], Step [28/60], Loss: 2.0740, batch time: 0.75, accuracy:  22.00%\n",
      "Epoch [11/100], Step [29/60], Loss: 2.0840, batch time: 0.72, accuracy:  20.00%\n",
      "Epoch [11/100], Step [30/60], Loss: 2.0550, batch time: 0.73, accuracy:  21.70%\n",
      "Epoch [11/100], Step [31/60], Loss: 2.0478, batch time: 0.74, accuracy:  22.50%\n",
      "Epoch [11/100], Step [32/60], Loss: 2.0870, batch time: 0.72, accuracy:  20.30%\n",
      "Epoch [11/100], Step [33/60], Loss: 2.0500, batch time: 0.77, accuracy:  21.80%\n",
      "Epoch [11/100], Step [34/60], Loss: 2.0458, batch time: 0.76, accuracy:  21.50%\n",
      "Epoch [11/100], Step [35/60], Loss: 2.0557, batch time: 0.82, accuracy:  22.50%\n",
      "Epoch [11/100], Step [36/60], Loss: 2.0075, batch time: 0.89, accuracy:  22.40%\n",
      "Epoch [11/100], Step [37/60], Loss: 2.0321, batch time: 0.89, accuracy:  20.70%\n",
      "Epoch [11/100], Step [38/60], Loss: 2.0722, batch time: 0.91, accuracy:  21.20%\n",
      "Epoch [11/100], Step [39/60], Loss: 2.0968, batch time: 0.93, accuracy:  20.30%\n",
      "Epoch [11/100], Step [40/60], Loss: 2.0502, batch time: 0.91, accuracy:  22.70%\n",
      "Epoch [11/100], Step [41/60], Loss: 2.0702, batch time: 0.91, accuracy:  22.10%\n",
      "Epoch [11/100], Step [42/60], Loss: 2.0598, batch time: 0.73, accuracy:  21.10%\n",
      "Epoch [11/100], Step [43/60], Loss: 2.0249, batch time: 0.73, accuracy:  23.50%\n",
      "Epoch [11/100], Step [44/60], Loss: 2.0435, batch time: 0.72, accuracy:  21.90%\n",
      "Epoch [11/100], Step [45/60], Loss: 2.0479, batch time: 0.81, accuracy:  20.50%\n",
      "Epoch [11/100], Step [46/60], Loss: 2.0193, batch time: 0.72, accuracy:  24.20%\n",
      "Epoch [11/100], Step [47/60], Loss: 2.0091, batch time: 0.77, accuracy:  23.90%\n",
      "Epoch [11/100], Step [48/60], Loss: 2.0575, batch time: 0.81, accuracy:  20.80%\n",
      "Epoch [11/100], Step [49/60], Loss: 2.0408, batch time: 0.77, accuracy:  21.80%\n",
      "Epoch [11/100], Step [50/60], Loss: 2.0741, batch time: 0.76, accuracy:  21.90%\n",
      "Epoch [11/100], Step [51/60], Loss: 2.0216, batch time: 0.77, accuracy:  22.40%\n",
      "Epoch [11/100], Step [52/60], Loss: 2.0093, batch time: 0.79, accuracy:  23.20%\n",
      "Epoch [11/100], Step [53/60], Loss: 2.0460, batch time: 0.83, accuracy:  22.40%\n",
      "Epoch [11/100], Step [54/60], Loss: 2.0370, batch time: 0.82, accuracy:  22.50%\n",
      "Epoch [11/100], Step [55/60], Loss: 2.0230, batch time: 0.86, accuracy:  22.30%\n",
      "Epoch [11/100], Step [56/60], Loss: 2.0533, batch time: 1.17, accuracy:  21.70%\n",
      "Epoch [11/100], Step [57/60], Loss: 2.0350, batch time: 0.77, accuracy:  21.70%\n",
      "Epoch [11/100], Step [58/60], Loss: 2.0108, batch time: 0.81, accuracy:  23.90%\n",
      "Epoch [11/100], Step [59/60], Loss: 2.0385, batch time: 0.79, accuracy:  22.00%\n",
      "Epoch [11/100], Step [60/60], Loss: 2.0342, batch time: 0.79, accuracy:  22.70%\n",
      "Epoch [12/100], Step [1/60], Loss: 2.0923, batch time: 0.83, accuracy:  19.90%\n",
      "Epoch [12/100], Step [2/60], Loss: 2.0784, batch time: 0.81, accuracy:  19.80%\n",
      "Epoch [12/100], Step [3/60], Loss: 2.0647, batch time: 0.80, accuracy:  20.20%\n",
      "Epoch [12/100], Step [4/60], Loss: 2.0710, batch time: 0.80, accuracy:  22.90%\n",
      "Epoch [12/100], Step [5/60], Loss: 2.0324, batch time: 0.81, accuracy:  22.00%\n",
      "Epoch [12/100], Step [6/60], Loss: 2.0297, batch time: 0.79, accuracy:  23.00%\n",
      "Epoch [12/100], Step [7/60], Loss: 2.0479, batch time: 0.80, accuracy:  22.00%\n",
      "Epoch [12/100], Step [8/60], Loss: 2.0465, batch time: 0.83, accuracy:  21.10%\n",
      "Epoch [12/100], Step [9/60], Loss: 2.0346, batch time: 0.82, accuracy:  22.60%\n",
      "Epoch [12/100], Step [10/60], Loss: 2.0439, batch time: 0.98, accuracy:  21.80%\n",
      "Epoch [12/100], Step [11/60], Loss: 2.0730, batch time: 0.97, accuracy:  19.70%\n",
      "Epoch [12/100], Step [12/60], Loss: 2.0529, batch time: 0.96, accuracy:  21.00%\n",
      "Epoch [12/100], Step [13/60], Loss: 1.9950, batch time: 0.98, accuracy:  23.70%\n",
      "Epoch [12/100], Step [14/60], Loss: 2.0357, batch time: 1.08, accuracy:  23.50%\n",
      "Epoch [12/100], Step [15/60], Loss: 2.0532, batch time: 0.99, accuracy:  21.90%\n",
      "Epoch [12/100], Step [16/60], Loss: 2.0384, batch time: 0.99, accuracy:  20.90%\n",
      "Epoch [12/100], Step [17/60], Loss: 2.0139, batch time: 0.99, accuracy:  22.40%\n",
      "Epoch [12/100], Step [18/60], Loss: 2.0661, batch time: 0.85, accuracy:  21.10%\n",
      "Epoch [12/100], Step [19/60], Loss: 2.0391, batch time: 0.79, accuracy:  20.80%\n",
      "Epoch [12/100], Step [20/60], Loss: 2.0220, batch time: 0.79, accuracy:  23.40%\n",
      "Epoch [12/100], Step [21/60], Loss: 2.0624, batch time: 0.81, accuracy:  21.70%\n",
      "Epoch [12/100], Step [22/60], Loss: 2.0253, batch time: 0.80, accuracy:  22.80%\n",
      "Epoch [12/100], Step [23/60], Loss: 2.0591, batch time: 0.90, accuracy:  20.90%\n",
      "Epoch [12/100], Step [24/60], Loss: 2.0341, batch time: 0.79, accuracy:  22.30%\n",
      "Epoch [12/100], Step [25/60], Loss: 2.0505, batch time: 0.79, accuracy:  20.40%\n",
      "Epoch [12/100], Step [26/60], Loss: 1.9807, batch time: 0.79, accuracy:  25.90%\n",
      "Epoch [12/100], Step [27/60], Loss: 2.0427, batch time: 0.82, accuracy:  21.30%\n",
      "Epoch [12/100], Step [28/60], Loss: 2.0326, batch time: 0.80, accuracy:  22.30%\n",
      "Epoch [12/100], Step [29/60], Loss: 2.0409, batch time: 0.80, accuracy:  21.90%\n",
      "Epoch [12/100], Step [30/60], Loss: 1.9804, batch time: 0.82, accuracy:  25.20%\n",
      "Epoch [12/100], Step [31/60], Loss: 2.0455, batch time: 0.85, accuracy:  21.20%\n",
      "Epoch [12/100], Step [32/60], Loss: 2.0220, batch time: 0.99, accuracy:  21.10%\n",
      "Epoch [12/100], Step [33/60], Loss: 2.0037, batch time: 0.99, accuracy:  23.50%\n",
      "Epoch [12/100], Step [34/60], Loss: 2.0586, batch time: 0.96, accuracy:  19.90%\n",
      "Epoch [12/100], Step [35/60], Loss: 2.0689, batch time: 0.91, accuracy:  20.70%\n",
      "Epoch [12/100], Step [36/60], Loss: 2.0058, batch time: 0.91, accuracy:  23.20%\n",
      "Epoch [12/100], Step [37/60], Loss: 2.0718, batch time: 0.92, accuracy:  21.60%\n",
      "Epoch [12/100], Step [38/60], Loss: 1.9827, batch time: 0.94, accuracy:  25.00%\n",
      "Epoch [12/100], Step [39/60], Loss: 1.9804, batch time: 0.90, accuracy:  24.60%\n",
      "Epoch [12/100], Step [40/60], Loss: 2.0139, batch time: 0.78, accuracy:  22.00%\n",
      "Epoch [12/100], Step [41/60], Loss: 2.0094, batch time: 0.80, accuracy:  24.10%\n",
      "Epoch [12/100], Step [42/60], Loss: 2.0106, batch time: 0.79, accuracy:  24.30%\n",
      "Epoch [12/100], Step [43/60], Loss: 2.0566, batch time: 0.79, accuracy:  21.20%\n",
      "Epoch [12/100], Step [44/60], Loss: 2.0022, batch time: 0.78, accuracy:  23.30%\n",
      "Epoch [12/100], Step [45/60], Loss: 2.0105, batch time: 0.78, accuracy:  24.20%\n",
      "Epoch [12/100], Step [46/60], Loss: 2.0203, batch time: 0.81, accuracy:  20.90%\n",
      "Epoch [12/100], Step [47/60], Loss: 2.0309, batch time: 0.88, accuracy:  21.40%\n",
      "Epoch [12/100], Step [48/60], Loss: 2.0459, batch time: 0.79, accuracy:  20.60%\n",
      "Epoch [12/100], Step [49/60], Loss: 2.0224, batch time: 0.80, accuracy:  23.30%\n",
      "Epoch [12/100], Step [50/60], Loss: 2.0315, batch time: 0.78, accuracy:  23.30%\n",
      "Epoch [12/100], Step [51/60], Loss: 2.0429, batch time: 0.82, accuracy:  21.40%\n",
      "Epoch [12/100], Step [52/60], Loss: 2.0216, batch time: 0.83, accuracy:  24.60%\n",
      "Epoch [12/100], Step [53/60], Loss: 2.0507, batch time: 0.97, accuracy:  21.10%\n",
      "Epoch [12/100], Step [54/60], Loss: 2.0700, batch time: 0.97, accuracy:  21.70%\n",
      "Epoch [12/100], Step [55/60], Loss: 2.0474, batch time: 0.98, accuracy:  21.40%\n",
      "Epoch [12/100], Step [56/60], Loss: 1.9994, batch time: 0.93, accuracy:  25.20%\n",
      "Epoch [12/100], Step [57/60], Loss: 2.0392, batch time: 0.78, accuracy:  22.20%\n",
      "Epoch [12/100], Step [58/60], Loss: 2.0498, batch time: 0.79, accuracy:  20.80%\n",
      "Epoch [12/100], Step [59/60], Loss: 1.9741, batch time: 0.79, accuracy:  24.60%\n",
      "Epoch [12/100], Step [60/60], Loss: 2.0243, batch time: 0.78, accuracy:  23.50%\n",
      "Epoch [13/100], Step [1/60], Loss: 2.0372, batch time: 0.80, accuracy:  21.00%\n",
      "Epoch [13/100], Step [2/60], Loss: 2.0492, batch time: 0.81, accuracy:  21.20%\n",
      "Epoch [13/100], Step [3/60], Loss: 2.0109, batch time: 0.78, accuracy:  22.90%\n",
      "Epoch [13/100], Step [4/60], Loss: 2.0131, batch time: 0.79, accuracy:  23.90%\n",
      "Epoch [13/100], Step [5/60], Loss: 2.0064, batch time: 0.81, accuracy:  24.20%\n",
      "Epoch [13/100], Step [6/60], Loss: 2.0287, batch time: 0.81, accuracy:  20.90%\n",
      "Epoch [13/100], Step [7/60], Loss: 2.0229, batch time: 0.81, accuracy:  23.50%\n",
      "Epoch [13/100], Step [8/60], Loss: 2.0230, batch time: 0.81, accuracy:  22.30%\n",
      "Epoch [13/100], Step [9/60], Loss: 2.0458, batch time: 0.83, accuracy:  21.70%\n",
      "Epoch [13/100], Step [10/60], Loss: 2.0332, batch time: 0.98, accuracy:  21.70%\n",
      "Epoch [13/100], Step [11/60], Loss: 2.0077, batch time: 1.05, accuracy:  23.00%\n",
      "Epoch [13/100], Step [12/60], Loss: 2.0528, batch time: 0.96, accuracy:  19.70%\n",
      "Epoch [13/100], Step [13/60], Loss: 2.0253, batch time: 0.95, accuracy:  23.40%\n",
      "Epoch [13/100], Step [14/60], Loss: 2.0071, batch time: 0.97, accuracy:  23.90%\n",
      "Epoch [13/100], Step [15/60], Loss: 2.0382, batch time: 0.99, accuracy:  22.70%\n",
      "Epoch [13/100], Step [16/60], Loss: 2.0050, batch time: 0.92, accuracy:  24.10%\n",
      "Epoch [13/100], Step [17/60], Loss: 2.0105, batch time: 0.77, accuracy:  22.90%\n",
      "Epoch [13/100], Step [18/60], Loss: 2.0105, batch time: 0.78, accuracy:  21.30%\n",
      "Epoch [13/100], Step [19/60], Loss: 1.9725, batch time: 0.77, accuracy:  26.80%\n",
      "Epoch [13/100], Step [20/60], Loss: 1.9940, batch time: 0.81, accuracy:  23.90%\n",
      "Epoch [13/100], Step [21/60], Loss: 2.0198, batch time: 0.80, accuracy:  22.00%\n",
      "Epoch [13/100], Step [22/60], Loss: 1.9995, batch time: 0.77, accuracy:  24.00%\n",
      "Epoch [13/100], Step [23/60], Loss: 2.0222, batch time: 0.80, accuracy:  24.00%\n",
      "Epoch [13/100], Step [24/60], Loss: 2.0571, batch time: 0.78, accuracy:  22.90%\n",
      "Epoch [13/100], Step [25/60], Loss: 2.0161, batch time: 0.89, accuracy:  21.70%\n",
      "Epoch [13/100], Step [26/60], Loss: 2.0351, batch time: 0.84, accuracy:  20.70%\n",
      "Epoch [13/100], Step [27/60], Loss: 1.9935, batch time: 0.70, accuracy:  24.50%\n",
      "Epoch [13/100], Step [28/60], Loss: 2.0263, batch time: 0.82, accuracy:  20.40%\n",
      "Epoch [13/100], Step [29/60], Loss: 1.9954, batch time: 0.84, accuracy:  22.50%\n",
      "Epoch [13/100], Step [30/60], Loss: 1.9934, batch time: 0.85, accuracy:  23.50%\n",
      "Epoch [13/100], Step [31/60], Loss: 2.0172, batch time: 0.73, accuracy:  24.40%\n",
      "Epoch [13/100], Step [32/60], Loss: 2.0339, batch time: 0.73, accuracy:  21.30%\n",
      "Epoch [13/100], Step [33/60], Loss: 2.0228, batch time: 0.71, accuracy:  22.00%\n",
      "Epoch [13/100], Step [34/60], Loss: 2.0076, batch time: 0.74, accuracy:  24.20%\n",
      "Epoch [13/100], Step [35/60], Loss: 2.0295, batch time: 0.76, accuracy:  23.80%\n",
      "Epoch [13/100], Step [36/60], Loss: 2.0357, batch time: 0.78, accuracy:  22.20%\n",
      "Epoch [13/100], Step [37/60], Loss: 2.0071, batch time: 0.77, accuracy:  22.40%\n",
      "Epoch [13/100], Step [38/60], Loss: 1.9829, batch time: 0.76, accuracy:  24.00%\n",
      "Epoch [13/100], Step [39/60], Loss: 1.9937, batch time: 0.76, accuracy:  24.70%\n",
      "Epoch [13/100], Step [40/60], Loss: 2.0029, batch time: 0.79, accuracy:  25.20%\n",
      "Epoch [13/100], Step [41/60], Loss: 1.9912, batch time: 0.78, accuracy:  23.20%\n",
      "Epoch [13/100], Step [42/60], Loss: 2.0039, batch time: 0.83, accuracy:  22.60%\n",
      "Epoch [13/100], Step [43/60], Loss: 2.0190, batch time: 0.81, accuracy:  22.10%\n",
      "Epoch [13/100], Step [44/60], Loss: 2.0313, batch time: 0.82, accuracy:  22.40%\n",
      "Epoch [13/100], Step [45/60], Loss: 2.0350, batch time: 0.83, accuracy:  20.50%\n",
      "Epoch [13/100], Step [46/60], Loss: 2.0018, batch time: 0.83, accuracy:  22.80%\n",
      "Epoch [13/100], Step [47/60], Loss: 2.0223, batch time: 0.82, accuracy:  23.10%\n",
      "Epoch [13/100], Step [48/60], Loss: 2.0545, batch time: 0.84, accuracy:  21.80%\n",
      "Epoch [13/100], Step [49/60], Loss: 2.0328, batch time: 0.83, accuracy:  22.10%\n",
      "Epoch [13/100], Step [50/60], Loss: 2.0097, batch time: 0.80, accuracy:  23.50%\n",
      "Epoch [13/100], Step [51/60], Loss: 2.0280, batch time: 0.83, accuracy:  23.70%\n",
      "Epoch [13/100], Step [52/60], Loss: 1.9783, batch time: 0.81, accuracy:  22.60%\n",
      "Epoch [13/100], Step [53/60], Loss: 2.0084, batch time: 0.81, accuracy:  23.20%\n",
      "Epoch [13/100], Step [54/60], Loss: 2.0180, batch time: 0.81, accuracy:  22.90%\n",
      "Epoch [13/100], Step [55/60], Loss: 1.9854, batch time: 0.81, accuracy:  22.70%\n",
      "Epoch [13/100], Step [56/60], Loss: 2.0302, batch time: 0.82, accuracy:  22.30%\n",
      "Epoch [13/100], Step [57/60], Loss: 2.0198, batch time: 0.79, accuracy:  22.00%\n",
      "Epoch [13/100], Step [58/60], Loss: 2.0169, batch time: 0.74, accuracy:  21.70%\n",
      "Epoch [13/100], Step [59/60], Loss: 2.0230, batch time: 0.82, accuracy:  22.60%\n",
      "Epoch [13/100], Step [60/60], Loss: 2.0000, batch time: 0.99, accuracy:  23.60%\n",
      "Epoch [14/100], Step [1/60], Loss: 1.9963, batch time: 0.94, accuracy:  22.50%\n",
      "Epoch [14/100], Step [2/60], Loss: 1.9893, batch time: 0.75, accuracy:  23.80%\n",
      "Epoch [14/100], Step [3/60], Loss: 2.0011, batch time: 0.75, accuracy:  23.00%\n",
      "Epoch [14/100], Step [4/60], Loss: 1.9476, batch time: 0.70, accuracy:  25.80%\n",
      "Epoch [14/100], Step [5/60], Loss: 2.0096, batch time: 0.78, accuracy:  22.80%\n",
      "Epoch [14/100], Step [6/60], Loss: 2.0348, batch time: 0.71, accuracy:  22.90%\n",
      "Epoch [14/100], Step [7/60], Loss: 2.0357, batch time: 0.71, accuracy:  21.60%\n",
      "Epoch [14/100], Step [8/60], Loss: 1.9670, batch time: 0.71, accuracy:  25.20%\n",
      "Epoch [14/100], Step [9/60], Loss: 1.9966, batch time: 0.72, accuracy:  22.80%\n",
      "Epoch [14/100], Step [10/60], Loss: 2.0190, batch time: 0.70, accuracy:  22.30%\n",
      "Epoch [14/100], Step [11/60], Loss: 1.9892, batch time: 0.71, accuracy:  23.30%\n",
      "Epoch [14/100], Step [12/60], Loss: 2.0368, batch time: 0.74, accuracy:  24.30%\n",
      "Epoch [14/100], Step [13/60], Loss: 2.0018, batch time: 0.74, accuracy:  23.50%\n",
      "Epoch [14/100], Step [14/60], Loss: 2.0298, batch time: 0.76, accuracy:  21.70%\n",
      "Epoch [14/100], Step [15/60], Loss: 2.0373, batch time: 0.76, accuracy:  21.60%\n",
      "Epoch [14/100], Step [16/60], Loss: 2.0454, batch time: 0.82, accuracy:  21.00%\n",
      "Epoch [14/100], Step [17/60], Loss: 1.9930, batch time: 0.90, accuracy:  23.80%\n",
      "Epoch [14/100], Step [18/60], Loss: 2.0086, batch time: 0.93, accuracy:  23.30%\n",
      "Epoch [14/100], Step [19/60], Loss: 2.0027, batch time: 0.91, accuracy:  24.30%\n",
      "Epoch [14/100], Step [20/60], Loss: 1.9996, batch time: 0.79, accuracy:  23.00%\n",
      "Epoch [14/100], Step [21/60], Loss: 2.0081, batch time: 0.65, accuracy:  21.50%\n",
      "Epoch [14/100], Step [22/60], Loss: 2.0050, batch time: 0.65, accuracy:  23.00%\n",
      "Epoch [14/100], Step [23/60], Loss: 2.0033, batch time: 0.68, accuracy:  21.80%\n",
      "Epoch [14/100], Step [24/60], Loss: 2.0035, batch time: 0.67, accuracy:  24.20%\n",
      "Epoch [14/100], Step [25/60], Loss: 1.9989, batch time: 0.66, accuracy:  24.50%\n",
      "Epoch [14/100], Step [26/60], Loss: 2.0152, batch time: 0.66, accuracy:  22.90%\n",
      "Epoch [14/100], Step [27/60], Loss: 2.0309, batch time: 0.65, accuracy:  19.70%\n",
      "Epoch [14/100], Step [28/60], Loss: 2.0221, batch time: 0.66, accuracy:  22.60%\n",
      "Epoch [14/100], Step [29/60], Loss: 1.9835, batch time: 0.66, accuracy:  24.90%\n",
      "Epoch [14/100], Step [30/60], Loss: 2.0347, batch time: 0.61, accuracy:  20.90%\n",
      "Epoch [14/100], Step [31/60], Loss: 1.9895, batch time: 0.63, accuracy:  24.30%\n",
      "Epoch [14/100], Step [32/60], Loss: 1.9630, batch time: 0.62, accuracy:  24.50%\n",
      "Epoch [14/100], Step [33/60], Loss: 1.9741, batch time: 0.69, accuracy:  24.30%\n",
      "Epoch [14/100], Step [34/60], Loss: 2.0176, batch time: 0.72, accuracy:  23.70%\n",
      "Epoch [14/100], Step [35/60], Loss: 2.0283, batch time: 0.72, accuracy:  22.10%\n",
      "Epoch [14/100], Step [36/60], Loss: 2.0064, batch time: 0.74, accuracy:  22.80%\n",
      "Epoch [14/100], Step [37/60], Loss: 2.0089, batch time: 0.78, accuracy:  22.90%\n",
      "Epoch [14/100], Step [38/60], Loss: 2.0178, batch time: 0.84, accuracy:  23.40%\n",
      "Epoch [14/100], Step [39/60], Loss: 2.0227, batch time: 0.83, accuracy:  22.70%\n",
      "Epoch [14/100], Step [40/60], Loss: 1.9830, batch time: 0.84, accuracy:  24.00%\n",
      "Epoch [14/100], Step [41/60], Loss: 1.9981, batch time: 0.94, accuracy:  23.90%\n",
      "Epoch [14/100], Step [42/60], Loss: 2.0131, batch time: 0.85, accuracy:  21.10%\n",
      "Epoch [14/100], Step [43/60], Loss: 1.9984, batch time: 0.76, accuracy:  22.80%\n",
      "Epoch [14/100], Step [44/60], Loss: 1.9617, batch time: 0.67, accuracy:  25.20%\n",
      "Epoch [14/100], Step [45/60], Loss: 1.9925, batch time: 0.67, accuracy:  24.40%\n",
      "Epoch [14/100], Step [46/60], Loss: 2.0021, batch time: 0.69, accuracy:  22.80%\n",
      "Epoch [14/100], Step [47/60], Loss: 2.0141, batch time: 0.67, accuracy:  22.70%\n",
      "Epoch [14/100], Step [48/60], Loss: 1.9878, batch time: 0.70, accuracy:  25.70%\n",
      "Epoch [14/100], Step [49/60], Loss: 1.9928, batch time: 0.67, accuracy:  23.00%\n",
      "Epoch [14/100], Step [50/60], Loss: 1.9926, batch time: 0.69, accuracy:  23.40%\n",
      "Epoch [14/100], Step [51/60], Loss: 2.0017, batch time: 0.69, accuracy:  24.60%\n",
      "Epoch [14/100], Step [52/60], Loss: 1.9691, batch time: 0.71, accuracy:  24.50%\n",
      "Epoch [14/100], Step [53/60], Loss: 2.0097, batch time: 0.68, accuracy:  22.80%\n",
      "Epoch [14/100], Step [54/60], Loss: 1.9951, batch time: 0.75, accuracy:  22.90%\n",
      "Epoch [14/100], Step [55/60], Loss: 1.9852, batch time: 0.69, accuracy:  21.60%\n",
      "Epoch [14/100], Step [56/60], Loss: 1.9841, batch time: 0.73, accuracy:  23.30%\n",
      "Epoch [14/100], Step [57/60], Loss: 1.9872, batch time: 0.73, accuracy:  24.60%\n",
      "Epoch [14/100], Step [58/60], Loss: 1.9873, batch time: 0.74, accuracy:  24.60%\n",
      "Epoch [14/100], Step [59/60], Loss: 1.9367, batch time: 0.73, accuracy:  26.00%\n",
      "Epoch [14/100], Step [60/60], Loss: 2.0017, batch time: 0.84, accuracy:  22.70%\n",
      "Epoch [15/100], Step [1/60], Loss: 1.9830, batch time: 0.84, accuracy:  22.70%\n",
      "Epoch [15/100], Step [2/60], Loss: 2.0076, batch time: 0.84, accuracy:  21.50%\n",
      "Epoch [15/100], Step [3/60], Loss: 2.0052, batch time: 0.87, accuracy:  22.70%\n",
      "Epoch [15/100], Step [4/60], Loss: 2.0202, batch time: 0.67, accuracy:  20.80%\n",
      "Epoch [15/100], Step [5/60], Loss: 1.9869, batch time: 0.69, accuracy:  24.80%\n",
      "Epoch [15/100], Step [6/60], Loss: 2.0020, batch time: 0.68, accuracy:  25.00%\n",
      "Epoch [15/100], Step [7/60], Loss: 1.9996, batch time: 0.70, accuracy:  23.10%\n",
      "Epoch [15/100], Step [8/60], Loss: 2.0229, batch time: 0.68, accuracy:  23.80%\n",
      "Epoch [15/100], Step [9/60], Loss: 1.9934, batch time: 0.71, accuracy:  22.60%\n",
      "Epoch [15/100], Step [10/60], Loss: 1.9739, batch time: 0.70, accuracy:  23.30%\n",
      "Epoch [15/100], Step [11/60], Loss: 1.9305, batch time: 0.68, accuracy:  25.10%\n",
      "Epoch [15/100], Step [12/60], Loss: 2.0096, batch time: 0.69, accuracy:  22.50%\n",
      "Epoch [15/100], Step [13/60], Loss: 2.0022, batch time: 0.68, accuracy:  23.20%\n",
      "Epoch [15/100], Step [14/60], Loss: 1.9764, batch time: 0.70, accuracy:  24.90%\n",
      "Epoch [15/100], Step [15/60], Loss: 2.0182, batch time: 0.72, accuracy:  23.20%\n",
      "Epoch [15/100], Step [16/60], Loss: 1.9775, batch time: 0.72, accuracy:  24.00%\n",
      "Epoch [15/100], Step [17/60], Loss: 1.9767, batch time: 0.75, accuracy:  25.10%\n",
      "Epoch [15/100], Step [18/60], Loss: 2.0281, batch time: 0.72, accuracy:  21.90%\n",
      "Epoch [15/100], Step [19/60], Loss: 1.9835, batch time: 0.81, accuracy:  21.50%\n",
      "Epoch [15/100], Step [20/60], Loss: 1.9572, batch time: 0.86, accuracy:  25.40%\n",
      "Epoch [15/100], Step [21/60], Loss: 2.0063, batch time: 0.85, accuracy:  22.60%\n",
      "Epoch [15/100], Step [22/60], Loss: 2.0111, batch time: 0.84, accuracy:  23.30%\n",
      "Epoch [15/100], Step [23/60], Loss: 1.9631, batch time: 0.72, accuracy:  24.40%\n",
      "Epoch [15/100], Step [24/60], Loss: 1.9310, batch time: 0.69, accuracy:  25.80%\n",
      "Epoch [15/100], Step [25/60], Loss: 1.9706, batch time: 0.68, accuracy:  23.50%\n",
      "Epoch [15/100], Step [26/60], Loss: 2.0066, batch time: 0.70, accuracy:  23.60%\n",
      "Epoch [15/100], Step [27/60], Loss: 1.9455, batch time: 0.78, accuracy:  25.50%\n",
      "Epoch [15/100], Step [28/60], Loss: 2.0531, batch time: 0.68, accuracy:  21.50%\n",
      "Epoch [15/100], Step [29/60], Loss: 1.9992, batch time: 0.69, accuracy:  22.10%\n",
      "Epoch [15/100], Step [30/60], Loss: 1.9826, batch time: 0.67, accuracy:  24.60%\n",
      "Epoch [15/100], Step [31/60], Loss: 1.9743, batch time: 0.67, accuracy:  24.40%\n",
      "Epoch [15/100], Step [32/60], Loss: 1.9930, batch time: 0.70, accuracy:  23.70%\n",
      "Epoch [15/100], Step [33/60], Loss: 1.9742, batch time: 0.70, accuracy:  23.90%\n",
      "Epoch [15/100], Step [34/60], Loss: 2.0036, batch time: 0.68, accuracy:  23.40%\n",
      "Epoch [15/100], Step [35/60], Loss: 1.9701, batch time: 0.73, accuracy:  23.20%\n",
      "Epoch [15/100], Step [36/60], Loss: 2.0006, batch time: 0.72, accuracy:  24.00%\n",
      "Epoch [15/100], Step [37/60], Loss: 2.0069, batch time: 0.71, accuracy:  23.30%\n",
      "Epoch [15/100], Step [38/60], Loss: 1.9634, batch time: 0.78, accuracy:  25.80%\n",
      "Epoch [15/100], Step [39/60], Loss: 1.9655, batch time: 0.85, accuracy:  25.30%\n",
      "Epoch [15/100], Step [40/60], Loss: 1.9554, batch time: 0.84, accuracy:  25.70%\n",
      "Epoch [15/100], Step [41/60], Loss: 1.9943, batch time: 0.85, accuracy:  23.00%\n",
      "Epoch [15/100], Step [42/60], Loss: 1.9723, batch time: 0.85, accuracy:  24.00%\n",
      "Epoch [15/100], Step [43/60], Loss: 1.9647, batch time: 0.76, accuracy:  24.20%\n",
      "Epoch [15/100], Step [44/60], Loss: 2.0055, batch time: 0.69, accuracy:  22.90%\n",
      "Epoch [15/100], Step [45/60], Loss: 1.9473, batch time: 0.67, accuracy:  25.70%\n",
      "Epoch [15/100], Step [46/60], Loss: 1.9473, batch time: 0.69, accuracy:  24.80%\n",
      "Epoch [15/100], Step [47/60], Loss: 1.9663, batch time: 0.67, accuracy:  24.60%\n",
      "Epoch [15/100], Step [48/60], Loss: 2.0041, batch time: 0.67, accuracy:  22.20%\n",
      "Epoch [15/100], Step [49/60], Loss: 1.9761, batch time: 0.68, accuracy:  22.70%\n",
      "Epoch [15/100], Step [50/60], Loss: 1.9936, batch time: 0.68, accuracy:  22.40%\n",
      "Epoch [15/100], Step [51/60], Loss: 1.9533, batch time: 0.72, accuracy:  27.20%\n",
      "Epoch [15/100], Step [52/60], Loss: 1.9880, batch time: 0.83, accuracy:  24.50%\n",
      "Epoch [15/100], Step [53/60], Loss: 1.9864, batch time: 0.79, accuracy:  22.40%\n",
      "Epoch [15/100], Step [54/60], Loss: 1.9507, batch time: 0.78, accuracy:  25.00%\n",
      "Epoch [15/100], Step [55/60], Loss: 1.9768, batch time: 0.81, accuracy:  24.50%\n",
      "Epoch [15/100], Step [56/60], Loss: 1.9870, batch time: 0.76, accuracy:  23.40%\n",
      "Epoch [15/100], Step [57/60], Loss: 1.9973, batch time: 0.74, accuracy:  24.00%\n",
      "Epoch [15/100], Step [58/60], Loss: 1.9717, batch time: 0.82, accuracy:  24.20%\n",
      "Epoch [15/100], Step [59/60], Loss: 1.9258, batch time: 0.86, accuracy:  24.40%\n",
      "Epoch [15/100], Step [60/60], Loss: 2.0221, batch time: 0.98, accuracy:  20.20%\n",
      "Epoch [16/100], Step [1/60], Loss: 1.9700, batch time: 0.99, accuracy:  23.70%\n",
      "Epoch [16/100], Step [2/60], Loss: 1.9629, batch time: 0.98, accuracy:  25.50%\n",
      "Epoch [16/100], Step [3/60], Loss: 1.9901, batch time: 0.98, accuracy:  21.10%\n",
      "Epoch [16/100], Step [4/60], Loss: 1.9773, batch time: 0.98, accuracy:  24.80%\n",
      "Epoch [16/100], Step [5/60], Loss: 2.0277, batch time: 0.96, accuracy:  20.90%\n",
      "Epoch [16/100], Step [6/60], Loss: 1.9445, batch time: 0.78, accuracy:  25.40%\n",
      "Epoch [16/100], Step [7/60], Loss: 1.9468, batch time: 0.78, accuracy:  24.50%\n",
      "Epoch [16/100], Step [8/60], Loss: 2.0025, batch time: 0.76, accuracy:  22.40%\n",
      "Epoch [16/100], Step [9/60], Loss: 1.9652, batch time: 0.85, accuracy:  22.80%\n",
      "Epoch [16/100], Step [10/60], Loss: 1.9682, batch time: 0.78, accuracy:  25.50%\n",
      "Epoch [16/100], Step [11/60], Loss: 2.0109, batch time: 0.78, accuracy:  21.50%\n",
      "Epoch [16/100], Step [12/60], Loss: 1.9393, batch time: 0.77, accuracy:  26.30%\n",
      "Epoch [16/100], Step [13/60], Loss: 1.9477, batch time: 0.77, accuracy:  26.40%\n",
      "Epoch [16/100], Step [14/60], Loss: 2.0164, batch time: 0.78, accuracy:  22.60%\n",
      "Epoch [16/100], Step [15/60], Loss: 1.9997, batch time: 0.78, accuracy:  22.60%\n",
      "Epoch [16/100], Step [16/60], Loss: 1.9614, batch time: 0.77, accuracy:  24.50%\n",
      "Epoch [16/100], Step [17/60], Loss: 1.9579, batch time: 0.83, accuracy:  23.80%\n",
      "Epoch [16/100], Step [18/60], Loss: 1.9722, batch time: 0.83, accuracy:  23.20%\n",
      "Epoch [16/100], Step [19/60], Loss: 1.9589, batch time: 0.84, accuracy:  25.10%\n",
      "Epoch [16/100], Step [20/60], Loss: 2.0013, batch time: 0.84, accuracy:  22.10%\n",
      "Epoch [16/100], Step [21/60], Loss: 1.9697, batch time: 0.97, accuracy:  22.50%\n",
      "Epoch [16/100], Step [22/60], Loss: 1.9852, batch time: 0.96, accuracy:  23.10%\n",
      "Epoch [16/100], Step [23/60], Loss: 1.9954, batch time: 1.00, accuracy:  22.60%\n",
      "Epoch [16/100], Step [24/60], Loss: 1.9718, batch time: 0.96, accuracy:  23.40%\n",
      "Epoch [16/100], Step [25/60], Loss: 1.9608, batch time: 0.77, accuracy:  24.10%\n",
      "Epoch [16/100], Step [26/60], Loss: 1.9624, batch time: 0.76, accuracy:  25.60%\n",
      "Epoch [16/100], Step [27/60], Loss: 1.9494, batch time: 0.76, accuracy:  26.30%\n",
      "Epoch [16/100], Step [28/60], Loss: 1.9607, batch time: 0.76, accuracy:  22.70%\n",
      "Epoch [16/100], Step [29/60], Loss: 1.9831, batch time: 0.76, accuracy:  24.10%\n",
      "Epoch [16/100], Step [30/60], Loss: 2.0193, batch time: 0.77, accuracy:  22.40%\n",
      "Epoch [16/100], Step [31/60], Loss: 1.9562, batch time: 0.81, accuracy:  25.60%\n",
      "Epoch [16/100], Step [32/60], Loss: 1.9907, batch time: 0.74, accuracy:  23.30%\n",
      "Epoch [16/100], Step [33/60], Loss: 1.9626, batch time: 0.70, accuracy:  24.10%\n",
      "Epoch [16/100], Step [34/60], Loss: 2.0255, batch time: 0.73, accuracy:  22.90%\n",
      "Epoch [16/100], Step [35/60], Loss: 1.9664, batch time: 0.72, accuracy:  25.80%\n",
      "Epoch [16/100], Step [36/60], Loss: 2.0047, batch time: 0.75, accuracy:  23.30%\n",
      "Epoch [16/100], Step [37/60], Loss: 1.9610, batch time: 0.68, accuracy:  26.00%\n",
      "Epoch [16/100], Step [38/60], Loss: 1.9227, batch time: 0.46, accuracy:  25.30%\n",
      "Epoch [16/100], Step [39/60], Loss: 1.9738, batch time: 0.47, accuracy:  22.70%\n",
      "Epoch [16/100], Step [40/60], Loss: 1.9525, batch time: 0.53, accuracy:  26.20%\n",
      "Epoch [16/100], Step [41/60], Loss: 1.9728, batch time: 0.58, accuracy:  24.80%\n",
      "Epoch [16/100], Step [42/60], Loss: 1.9640, batch time: 0.55, accuracy:  22.90%\n",
      "Epoch [16/100], Step [43/60], Loss: 1.9709, batch time: 0.54, accuracy:  22.50%\n",
      "Epoch [16/100], Step [44/60], Loss: 2.0173, batch time: 0.55, accuracy:  21.20%\n",
      "Epoch [16/100], Step [45/60], Loss: 1.9791, batch time: 0.60, accuracy:  24.30%\n",
      "Epoch [16/100], Step [46/60], Loss: 1.9655, batch time: 0.57, accuracy:  22.50%\n",
      "Epoch [16/100], Step [47/60], Loss: 1.9765, batch time: 0.54, accuracy:  22.90%\n",
      "Epoch [16/100], Step [48/60], Loss: 1.9771, batch time: 0.57, accuracy:  24.40%\n",
      "Epoch [16/100], Step [49/60], Loss: 2.0273, batch time: 0.57, accuracy:  21.70%\n",
      "Epoch [16/100], Step [50/60], Loss: 1.9562, batch time: 0.56, accuracy:  25.30%\n",
      "Epoch [16/100], Step [51/60], Loss: 1.9353, batch time: 0.54, accuracy:  26.40%\n",
      "Epoch [16/100], Step [52/60], Loss: 1.9974, batch time: 0.55, accuracy:  24.10%\n",
      "Epoch [16/100], Step [53/60], Loss: 1.9617, batch time: 0.54, accuracy:  25.90%\n",
      "Epoch [16/100], Step [54/60], Loss: 1.9986, batch time: 0.55, accuracy:  23.90%\n",
      "Epoch [16/100], Step [55/60], Loss: 1.9773, batch time: 0.54, accuracy:  23.40%\n",
      "Epoch [16/100], Step [56/60], Loss: 1.9555, batch time: 0.56, accuracy:  26.20%\n",
      "Epoch [16/100], Step [57/60], Loss: 1.9947, batch time: 0.56, accuracy:  22.30%\n",
      "Epoch [16/100], Step [58/60], Loss: 1.9644, batch time: 0.54, accuracy:  26.10%\n",
      "Epoch [16/100], Step [59/60], Loss: 1.9203, batch time: 0.54, accuracy:  26.60%\n",
      "Epoch [16/100], Step [60/60], Loss: 1.9825, batch time: 0.53, accuracy:  22.40%\n",
      "Epoch [17/100], Step [1/60], Loss: 1.9571, batch time: 0.59, accuracy:  26.50%\n",
      "Epoch [17/100], Step [2/60], Loss: 1.9559, batch time: 0.52, accuracy:  22.70%\n",
      "Epoch [17/100], Step [3/60], Loss: 1.8913, batch time: 0.54, accuracy:  28.90%\n",
      "Epoch [17/100], Step [4/60], Loss: 1.9323, batch time: 0.54, accuracy:  24.90%\n",
      "Epoch [17/100], Step [5/60], Loss: 2.0011, batch time: 0.54, accuracy:  24.50%\n",
      "Epoch [17/100], Step [6/60], Loss: 1.9493, batch time: 0.55, accuracy:  23.10%\n",
      "Epoch [17/100], Step [7/60], Loss: 1.9415, batch time: 0.54, accuracy:  24.70%\n",
      "Epoch [17/100], Step [8/60], Loss: 1.9587, batch time: 0.54, accuracy:  24.70%\n",
      "Epoch [17/100], Step [9/60], Loss: 1.9985, batch time: 0.55, accuracy:  23.10%\n",
      "Epoch [17/100], Step [10/60], Loss: 1.9500, batch time: 0.53, accuracy:  26.30%\n",
      "Epoch [17/100], Step [11/60], Loss: 1.9968, batch time: 0.56, accuracy:  22.70%\n",
      "Epoch [17/100], Step [12/60], Loss: 1.9825, batch time: 0.54, accuracy:  23.00%\n",
      "Epoch [17/100], Step [13/60], Loss: 1.9470, batch time: 0.55, accuracy:  24.00%\n",
      "Epoch [17/100], Step [14/60], Loss: 1.9614, batch time: 0.54, accuracy:  25.10%\n",
      "Epoch [17/100], Step [15/60], Loss: 1.9533, batch time: 0.54, accuracy:  24.50%\n",
      "Epoch [17/100], Step [16/60], Loss: 1.9574, batch time: 0.49, accuracy:  23.10%\n",
      "Epoch [17/100], Step [17/60], Loss: 1.9965, batch time: 0.44, accuracy:  22.50%\n",
      "Epoch [17/100], Step [18/60], Loss: 1.9362, batch time: 0.47, accuracy:  26.40%\n",
      "Epoch [17/100], Step [19/60], Loss: 1.9811, batch time: 0.47, accuracy:  23.10%\n",
      "Epoch [17/100], Step [20/60], Loss: 1.9717, batch time: 0.47, accuracy:  23.10%\n",
      "Epoch [17/100], Step [21/60], Loss: 1.9409, batch time: 0.46, accuracy:  25.10%\n",
      "Epoch [17/100], Step [22/60], Loss: 1.9567, batch time: 0.45, accuracy:  26.20%\n",
      "Epoch [17/100], Step [23/60], Loss: 1.9632, batch time: 0.45, accuracy:  23.70%\n",
      "Epoch [17/100], Step [24/60], Loss: 1.9974, batch time: 0.45, accuracy:  22.00%\n",
      "Epoch [17/100], Step [25/60], Loss: 1.9583, batch time: 0.45, accuracy:  24.50%\n",
      "Epoch [17/100], Step [26/60], Loss: 1.9307, batch time: 0.47, accuracy:  27.30%\n",
      "Epoch [17/100], Step [27/60], Loss: 1.9546, batch time: 0.45, accuracy:  23.40%\n",
      "Epoch [17/100], Step [28/60], Loss: 1.9754, batch time: 0.47, accuracy:  25.90%\n",
      "Epoch [17/100], Step [29/60], Loss: 1.9598, batch time: 0.48, accuracy:  24.30%\n",
      "Epoch [17/100], Step [30/60], Loss: 1.9432, batch time: 0.50, accuracy:  24.40%\n",
      "Epoch [17/100], Step [31/60], Loss: 1.9750, batch time: 0.51, accuracy:  22.70%\n",
      "Epoch [17/100], Step [32/60], Loss: 1.9585, batch time: 0.46, accuracy:  24.70%\n",
      "Epoch [17/100], Step [33/60], Loss: 1.9431, batch time: 0.46, accuracy:  23.50%\n",
      "Epoch [17/100], Step [34/60], Loss: 1.9655, batch time: 0.53, accuracy:  25.90%\n",
      "Epoch [17/100], Step [35/60], Loss: 1.9892, batch time: 0.51, accuracy:  24.50%\n",
      "Epoch [17/100], Step [36/60], Loss: 1.9802, batch time: 0.52, accuracy:  23.10%\n",
      "Epoch [17/100], Step [37/60], Loss: 1.9554, batch time: 0.47, accuracy:  25.60%\n",
      "Epoch [17/100], Step [38/60], Loss: 1.9717, batch time: 0.47, accuracy:  25.00%\n",
      "Epoch [17/100], Step [39/60], Loss: 1.9558, batch time: 0.53, accuracy:  23.80%\n",
      "Epoch [17/100], Step [40/60], Loss: 1.9696, batch time: 0.54, accuracy:  25.70%\n",
      "Epoch [17/100], Step [41/60], Loss: 1.9673, batch time: 0.54, accuracy:  26.00%\n",
      "Epoch [17/100], Step [42/60], Loss: 1.9630, batch time: 0.54, accuracy:  25.20%\n",
      "Epoch [17/100], Step [43/60], Loss: 1.9116, batch time: 0.53, accuracy:  28.00%\n",
      "Epoch [17/100], Step [44/60], Loss: 1.9588, batch time: 0.58, accuracy:  24.40%\n",
      "Epoch [17/100], Step [45/60], Loss: 1.9646, batch time: 0.54, accuracy:  24.00%\n",
      "Epoch [17/100], Step [46/60], Loss: 1.9625, batch time: 0.55, accuracy:  24.30%\n",
      "Epoch [17/100], Step [47/60], Loss: 1.9685, batch time: 0.55, accuracy:  25.00%\n",
      "Epoch [17/100], Step [48/60], Loss: 1.9311, batch time: 0.50, accuracy:  26.40%\n",
      "Epoch [17/100], Step [49/60], Loss: 1.9437, batch time: 0.45, accuracy:  25.60%\n",
      "Epoch [17/100], Step [50/60], Loss: 1.9290, batch time: 0.45, accuracy:  24.50%\n",
      "Epoch [17/100], Step [51/60], Loss: 1.9816, batch time: 0.45, accuracy:  23.80%\n",
      "Epoch [17/100], Step [52/60], Loss: 1.9348, batch time: 0.47, accuracy:  25.80%\n",
      "Epoch [17/100], Step [53/60], Loss: 1.9066, batch time: 0.45, accuracy:  26.20%\n",
      "Epoch [17/100], Step [54/60], Loss: 1.9667, batch time: 0.46, accuracy:  26.60%\n",
      "Epoch [17/100], Step [55/60], Loss: 1.9613, batch time: 0.46, accuracy:  25.90%\n",
      "Epoch [17/100], Step [56/60], Loss: 1.9830, batch time: 0.45, accuracy:  25.40%\n",
      "Epoch [17/100], Step [57/60], Loss: 1.9719, batch time: 0.46, accuracy:  23.70%\n",
      "Epoch [17/100], Step [58/60], Loss: 1.9427, batch time: 0.46, accuracy:  23.60%\n",
      "Epoch [17/100], Step [59/60], Loss: 1.9446, batch time: 0.45, accuracy:  25.40%\n",
      "Epoch [17/100], Step [60/60], Loss: 1.9365, batch time: 0.46, accuracy:  26.60%\n",
      "Epoch [18/100], Step [1/60], Loss: 1.9764, batch time: 0.64, accuracy:  22.30%\n",
      "Epoch [18/100], Step [2/60], Loss: 1.9323, batch time: 0.71, accuracy:  26.80%\n",
      "Epoch [18/100], Step [3/60], Loss: 1.9237, batch time: 0.73, accuracy:  27.80%\n",
      "Epoch [18/100], Step [4/60], Loss: 1.9245, batch time: 0.72, accuracy:  26.60%\n",
      "Epoch [18/100], Step [5/60], Loss: 1.9575, batch time: 0.72, accuracy:  25.60%\n",
      "Epoch [18/100], Step [6/60], Loss: 1.9288, batch time: 0.75, accuracy:  27.20%\n",
      "Epoch [18/100], Step [7/60], Loss: 1.9159, batch time: 0.83, accuracy:  26.90%\n",
      "Epoch [18/100], Step [8/60], Loss: 1.9402, batch time: 0.75, accuracy:  26.30%\n",
      "Epoch [18/100], Step [9/60], Loss: 1.9606, batch time: 0.88, accuracy:  25.20%\n",
      "Epoch [18/100], Step [10/60], Loss: 1.8916, batch time: 0.89, accuracy:  28.10%\n",
      "Epoch [18/100], Step [11/60], Loss: 1.9478, batch time: 0.72, accuracy:  27.90%\n",
      "Epoch [18/100], Step [12/60], Loss: 1.9221, batch time: 0.72, accuracy:  28.20%\n",
      "Epoch [18/100], Step [13/60], Loss: 1.9464, batch time: 0.70, accuracy:  24.90%\n",
      "Epoch [18/100], Step [14/60], Loss: 1.9435, batch time: 0.48, accuracy:  24.70%\n",
      "Epoch [18/100], Step [15/60], Loss: 1.9474, batch time: 0.45, accuracy:  26.50%\n",
      "Epoch [18/100], Step [16/60], Loss: 1.9621, batch time: 0.47, accuracy:  24.00%\n",
      "Epoch [18/100], Step [17/60], Loss: 2.0155, batch time: 0.46, accuracy:  23.70%\n",
      "Epoch [18/100], Step [18/60], Loss: 1.9815, batch time: 0.46, accuracy:  25.10%\n",
      "Epoch [18/100], Step [19/60], Loss: 1.9338, batch time: 0.47, accuracy:  27.10%\n",
      "Epoch [18/100], Step [20/60], Loss: 1.9993, batch time: 0.47, accuracy:  23.70%\n",
      "Epoch [18/100], Step [21/60], Loss: 1.9235, batch time: 0.45, accuracy:  27.00%\n",
      "Epoch [18/100], Step [22/60], Loss: 1.9306, batch time: 0.48, accuracy:  26.70%\n",
      "Epoch [18/100], Step [23/60], Loss: 1.9990, batch time: 0.45, accuracy:  25.10%\n",
      "Epoch [18/100], Step [24/60], Loss: 1.9405, batch time: 0.45, accuracy:  24.90%\n",
      "Epoch [18/100], Step [25/60], Loss: 1.9548, batch time: 0.47, accuracy:  25.90%\n",
      "Epoch [18/100], Step [26/60], Loss: 1.9712, batch time: 0.45, accuracy:  25.40%\n",
      "Epoch [18/100], Step [27/60], Loss: 1.9701, batch time: 0.46, accuracy:  25.50%\n",
      "Epoch [18/100], Step [28/60], Loss: 1.9358, batch time: 0.47, accuracy:  27.00%\n",
      "Epoch [18/100], Step [29/60], Loss: 1.9777, batch time: 0.48, accuracy:  25.60%\n",
      "Epoch [18/100], Step [30/60], Loss: 1.9808, batch time: 0.48, accuracy:  25.00%\n",
      "Epoch [18/100], Step [31/60], Loss: 1.9215, batch time: 0.46, accuracy:  29.00%\n",
      "Epoch [18/100], Step [32/60], Loss: 1.9472, batch time: 0.52, accuracy:  27.40%\n",
      "Epoch [18/100], Step [33/60], Loss: 1.9754, batch time: 0.55, accuracy:  25.40%\n",
      "Epoch [18/100], Step [34/60], Loss: 1.9473, batch time: 0.54, accuracy:  26.90%\n",
      "Epoch [18/100], Step [35/60], Loss: 1.9542, batch time: 0.55, accuracy:  24.80%\n",
      "Epoch [18/100], Step [36/60], Loss: 1.9551, batch time: 0.54, accuracy:  25.10%\n",
      "Epoch [18/100], Step [37/60], Loss: 1.9307, batch time: 0.57, accuracy:  26.70%\n",
      "Epoch [18/100], Step [38/60], Loss: 1.9351, batch time: 0.55, accuracy:  25.70%\n",
      "Epoch [18/100], Step [39/60], Loss: 1.9619, batch time: 0.54, accuracy:  25.30%\n",
      "Epoch [18/100], Step [40/60], Loss: 1.9042, batch time: 0.56, accuracy:  28.70%\n",
      "Epoch [18/100], Step [41/60], Loss: 1.9194, batch time: 0.54, accuracy:  29.30%\n",
      "Epoch [18/100], Step [42/60], Loss: 1.9354, batch time: 0.56, accuracy:  27.30%\n",
      "Epoch [18/100], Step [43/60], Loss: 1.9182, batch time: 0.54, accuracy:  29.70%\n",
      "Epoch [18/100], Step [44/60], Loss: 1.9673, batch time: 0.51, accuracy:  25.90%\n",
      "Epoch [18/100], Step [45/60], Loss: 1.9757, batch time: 0.48, accuracy:  25.10%\n",
      "Epoch [18/100], Step [46/60], Loss: 1.9563, batch time: 0.45, accuracy:  24.50%\n",
      "Epoch [18/100], Step [47/60], Loss: 1.9606, batch time: 0.47, accuracy:  28.10%\n",
      "Epoch [18/100], Step [48/60], Loss: 1.9016, batch time: 0.46, accuracy:  29.10%\n",
      "Epoch [18/100], Step [49/60], Loss: 1.9640, batch time: 0.50, accuracy:  27.30%\n",
      "Epoch [18/100], Step [50/60], Loss: 1.9268, batch time: 0.46, accuracy:  26.70%\n",
      "Epoch [18/100], Step [51/60], Loss: 1.9170, batch time: 0.45, accuracy:  27.80%\n",
      "Epoch [18/100], Step [52/60], Loss: 1.9406, batch time: 0.45, accuracy:  28.80%\n",
      "Epoch [18/100], Step [53/60], Loss: 1.9339, batch time: 0.46, accuracy:  25.70%\n",
      "Epoch [18/100], Step [54/60], Loss: 1.9728, batch time: 0.47, accuracy:  24.60%\n",
      "Epoch [18/100], Step [55/60], Loss: 1.9686, batch time: 0.46, accuracy:  26.20%\n",
      "Epoch [18/100], Step [56/60], Loss: 1.9794, batch time: 0.46, accuracy:  26.00%\n",
      "Epoch [18/100], Step [57/60], Loss: 1.9376, batch time: 0.45, accuracy:  28.70%\n",
      "Epoch [18/100], Step [58/60], Loss: 1.9123, batch time: 0.47, accuracy:  27.40%\n",
      "Epoch [18/100], Step [59/60], Loss: 1.9213, batch time: 0.45, accuracy:  29.40%\n",
      "Epoch [18/100], Step [60/60], Loss: 1.9623, batch time: 0.45, accuracy:  27.80%\n",
      "Epoch [19/100], Step [1/60], Loss: 1.9071, batch time: 0.51, accuracy:  27.90%\n",
      "Epoch [19/100], Step [2/60], Loss: 1.9380, batch time: 0.45, accuracy:  29.20%\n",
      "Epoch [19/100], Step [3/60], Loss: 1.9391, batch time: 0.49, accuracy:  28.80%\n",
      "Epoch [19/100], Step [4/60], Loss: 1.9434, batch time: 0.46, accuracy:  28.20%\n",
      "Epoch [19/100], Step [5/60], Loss: 1.9194, batch time: 0.45, accuracy:  27.60%\n",
      "Epoch [19/100], Step [6/60], Loss: 1.9514, batch time: 0.47, accuracy:  28.20%\n",
      "Epoch [19/100], Step [7/60], Loss: 1.9635, batch time: 0.47, accuracy:  25.20%\n",
      "Epoch [19/100], Step [8/60], Loss: 1.8870, batch time: 0.54, accuracy:  29.70%\n",
      "Epoch [19/100], Step [9/60], Loss: 1.8980, batch time: 0.54, accuracy:  31.40%\n",
      "Epoch [19/100], Step [10/60], Loss: 1.9253, batch time: 0.54, accuracy:  27.10%\n",
      "Epoch [19/100], Step [11/60], Loss: 1.9184, batch time: 0.58, accuracy:  27.10%\n",
      "Epoch [19/100], Step [12/60], Loss: 1.9308, batch time: 0.54, accuracy:  28.40%\n",
      "Epoch [19/100], Step [13/60], Loss: 1.9599, batch time: 0.56, accuracy:  26.80%\n",
      "Epoch [19/100], Step [14/60], Loss: 1.9702, batch time: 0.54, accuracy:  27.00%\n",
      "Epoch [19/100], Step [15/60], Loss: 1.9558, batch time: 0.54, accuracy:  29.20%\n",
      "Epoch [19/100], Step [16/60], Loss: 1.9492, batch time: 0.52, accuracy:  27.40%\n",
      "Epoch [19/100], Step [17/60], Loss: 1.9523, batch time: 0.51, accuracy:  26.50%\n",
      "Epoch [19/100], Step [18/60], Loss: 1.8818, batch time: 0.53, accuracy:  29.30%\n",
      "Epoch [19/100], Step [19/60], Loss: 1.9600, batch time: 0.54, accuracy:  26.40%\n",
      "Epoch [19/100], Step [20/60], Loss: 1.9225, batch time: 0.55, accuracy:  27.00%\n",
      "Epoch [19/100], Step [21/60], Loss: 1.8927, batch time: 0.53, accuracy:  30.30%\n",
      "Epoch [19/100], Step [22/60], Loss: 1.9616, batch time: 0.52, accuracy:  26.40%\n",
      "Epoch [19/100], Step [23/60], Loss: 1.9209, batch time: 0.54, accuracy:  25.80%\n",
      "Epoch [19/100], Step [24/60], Loss: 1.8973, batch time: 0.52, accuracy:  29.40%\n",
      "Epoch [19/100], Step [25/60], Loss: 2.0106, batch time: 0.60, accuracy:  24.70%\n",
      "Epoch [19/100], Step [26/60], Loss: 1.9025, batch time: 0.55, accuracy:  30.50%\n",
      "Epoch [19/100], Step [27/60], Loss: 1.9166, batch time: 0.51, accuracy:  29.30%\n",
      "Epoch [19/100], Step [28/60], Loss: 1.9187, batch time: 0.44, accuracy:  29.20%\n",
      "Epoch [19/100], Step [29/60], Loss: 1.9352, batch time: 0.43, accuracy:  28.10%\n",
      "Epoch [19/100], Step [30/60], Loss: 1.9448, batch time: 0.45, accuracy:  28.10%\n",
      "Epoch [19/100], Step [31/60], Loss: 1.9515, batch time: 0.54, accuracy:  26.20%\n",
      "Epoch [19/100], Step [32/60], Loss: 1.9003, batch time: 0.43, accuracy:  31.20%\n",
      "Epoch [19/100], Step [33/60], Loss: 1.9493, batch time: 0.44, accuracy:  27.60%\n",
      "Epoch [19/100], Step [34/60], Loss: 1.9253, batch time: 0.43, accuracy:  28.80%\n",
      "Epoch [19/100], Step [35/60], Loss: 1.8678, batch time: 0.45, accuracy:  28.40%\n",
      "Epoch [19/100], Step [36/60], Loss: 1.9253, batch time: 0.45, accuracy:  28.80%\n",
      "Epoch [19/100], Step [37/60], Loss: 1.9074, batch time: 0.44, accuracy:  28.20%\n",
      "Epoch [19/100], Step [38/60], Loss: 1.9301, batch time: 0.44, accuracy:  29.90%\n",
      "Epoch [19/100], Step [39/60], Loss: 1.8859, batch time: 0.45, accuracy:  30.80%\n",
      "Epoch [19/100], Step [40/60], Loss: 1.9191, batch time: 0.43, accuracy:  30.80%\n",
      "Epoch [19/100], Step [41/60], Loss: 1.9256, batch time: 0.44, accuracy:  29.30%\n",
      "Epoch [19/100], Step [42/60], Loss: 1.9779, batch time: 0.45, accuracy:  28.60%\n",
      "Epoch [19/100], Step [43/60], Loss: 1.9785, batch time: 0.44, accuracy:  24.70%\n",
      "Epoch [19/100], Step [44/60], Loss: 1.9156, batch time: 0.44, accuracy:  28.20%\n",
      "Epoch [19/100], Step [45/60], Loss: 1.9507, batch time: 0.45, accuracy:  26.30%\n",
      "Epoch [19/100], Step [46/60], Loss: 1.9153, batch time: 0.44, accuracy:  28.70%\n",
      "Epoch [19/100], Step [47/60], Loss: 1.9408, batch time: 0.45, accuracy:  28.80%\n",
      "Epoch [19/100], Step [48/60], Loss: 1.9347, batch time: 0.45, accuracy:  30.80%\n",
      "Epoch [19/100], Step [49/60], Loss: 1.9457, batch time: 0.45, accuracy:  26.80%\n",
      "Epoch [19/100], Step [50/60], Loss: 1.9301, batch time: 0.46, accuracy:  27.40%\n",
      "Epoch [19/100], Step [51/60], Loss: 1.9638, batch time: 0.47, accuracy:  27.40%\n",
      "Epoch [19/100], Step [52/60], Loss: 1.9392, batch time: 0.53, accuracy:  29.40%\n",
      "Epoch [19/100], Step [53/60], Loss: 1.9261, batch time: 0.54, accuracy:  26.80%\n",
      "Epoch [19/100], Step [54/60], Loss: 1.9413, batch time: 0.53, accuracy:  27.40%\n",
      "Epoch [19/100], Step [55/60], Loss: 1.9264, batch time: 0.54, accuracy:  28.50%\n",
      "Epoch [19/100], Step [56/60], Loss: 1.8920, batch time: 0.54, accuracy:  28.30%\n",
      "Epoch [19/100], Step [57/60], Loss: 1.9378, batch time: 0.45, accuracy:  28.00%\n",
      "Epoch [19/100], Step [58/60], Loss: 1.9529, batch time: 0.44, accuracy:  27.80%\n",
      "Epoch [19/100], Step [59/60], Loss: 1.9494, batch time: 0.43, accuracy:  27.10%\n",
      "Epoch [19/100], Step [60/60], Loss: 1.9006, batch time: 0.45, accuracy:  30.50%\n",
      "Epoch [20/100], Step [1/60], Loss: 1.9557, batch time: 0.45, accuracy:  26.90%\n",
      "Epoch [20/100], Step [2/60], Loss: 1.9244, batch time: 0.46, accuracy:  27.00%\n",
      "Epoch [20/100], Step [3/60], Loss: 1.9347, batch time: 0.45, accuracy:  28.50%\n",
      "Epoch [20/100], Step [4/60], Loss: 1.9384, batch time: 0.44, accuracy:  28.50%\n",
      "Epoch [20/100], Step [5/60], Loss: 1.9257, batch time: 0.44, accuracy:  29.10%\n",
      "Epoch [20/100], Step [6/60], Loss: 1.8820, batch time: 0.45, accuracy:  29.00%\n",
      "Epoch [20/100], Step [7/60], Loss: 1.9516, batch time: 0.44, accuracy:  28.00%\n",
      "Epoch [20/100], Step [8/60], Loss: 1.9640, batch time: 0.44, accuracy:  27.60%\n",
      "Epoch [20/100], Step [9/60], Loss: 1.9196, batch time: 0.45, accuracy:  28.10%\n",
      "Epoch [20/100], Step [10/60], Loss: 1.9293, batch time: 0.44, accuracy:  28.10%\n",
      "Epoch [20/100], Step [11/60], Loss: 1.9348, batch time: 0.46, accuracy:  29.90%\n",
      "Epoch [20/100], Step [12/60], Loss: 1.9297, batch time: 0.45, accuracy:  29.70%\n",
      "Epoch [20/100], Step [13/60], Loss: 1.9084, batch time: 0.44, accuracy:  28.90%\n",
      "Epoch [20/100], Step [14/60], Loss: 1.9245, batch time: 0.52, accuracy:  29.90%\n",
      "Epoch [20/100], Step [15/60], Loss: 1.9030, batch time: 0.44, accuracy:  31.70%\n",
      "Epoch [20/100], Step [16/60], Loss: 1.9108, batch time: 0.45, accuracy:  28.20%\n",
      "Epoch [20/100], Step [17/60], Loss: 1.9201, batch time: 0.45, accuracy:  29.80%\n",
      "Epoch [20/100], Step [18/60], Loss: 1.9093, batch time: 0.45, accuracy:  30.40%\n",
      "Epoch [20/100], Step [19/60], Loss: 1.9096, batch time: 0.46, accuracy:  29.00%\n",
      "Epoch [20/100], Step [20/60], Loss: 1.9038, batch time: 0.54, accuracy:  29.50%\n",
      "Epoch [20/100], Step [21/60], Loss: 1.9119, batch time: 0.52, accuracy:  30.60%\n",
      "Epoch [20/100], Step [22/60], Loss: 1.9435, batch time: 0.55, accuracy:  27.00%\n",
      "Epoch [20/100], Step [23/60], Loss: 1.9810, batch time: 0.52, accuracy:  25.60%\n",
      "Epoch [20/100], Step [24/60], Loss: 1.9098, batch time: 0.54, accuracy:  29.10%\n",
      "Epoch [20/100], Step [25/60], Loss: 1.9782, batch time: 0.53, accuracy:  25.10%\n",
      "Epoch [20/100], Step [26/60], Loss: 1.9056, batch time: 0.54, accuracy:  29.80%\n",
      "Epoch [20/100], Step [27/60], Loss: 1.9268, batch time: 0.54, accuracy:  28.80%\n",
      "Epoch [20/100], Step [28/60], Loss: 1.9229, batch time: 0.56, accuracy:  29.60%\n",
      "Epoch [20/100], Step [29/60], Loss: 1.9030, batch time: 0.54, accuracy:  29.50%\n",
      "Epoch [20/100], Step [30/60], Loss: 1.9048, batch time: 0.53, accuracy:  28.00%\n",
      "Epoch [20/100], Step [31/60], Loss: 1.9391, batch time: 0.45, accuracy:  28.30%\n",
      "Epoch [20/100], Step [32/60], Loss: 1.8659, batch time: 0.43, accuracy:  32.20%\n",
      "Epoch [20/100], Step [33/60], Loss: 1.8909, batch time: 0.43, accuracy:  32.20%\n",
      "Epoch [20/100], Step [34/60], Loss: 1.8809, batch time: 0.46, accuracy:  31.10%\n",
      "Epoch [20/100], Step [35/60], Loss: 1.9269, batch time: 0.43, accuracy:  29.50%\n",
      "Epoch [20/100], Step [36/60], Loss: 1.8803, batch time: 0.44, accuracy:  30.70%\n",
      "Epoch [20/100], Step [37/60], Loss: 1.9318, batch time: 0.47, accuracy:  27.80%\n",
      "Epoch [20/100], Step [38/60], Loss: 1.8741, batch time: 0.44, accuracy:  32.50%\n",
      "Epoch [20/100], Step [39/60], Loss: 1.8968, batch time: 0.45, accuracy:  29.60%\n",
      "Epoch [20/100], Step [40/60], Loss: 1.9238, batch time: 0.45, accuracy:  27.90%\n",
      "Epoch [20/100], Step [41/60], Loss: 1.9250, batch time: 0.43, accuracy:  30.70%\n",
      "Epoch [20/100], Step [42/60], Loss: 1.9200, batch time: 0.45, accuracy:  27.40%\n",
      "Epoch [20/100], Step [43/60], Loss: 1.8989, batch time: 0.44, accuracy:  29.00%\n",
      "Epoch [20/100], Step [44/60], Loss: 1.9173, batch time: 0.44, accuracy:  28.50%\n",
      "Epoch [20/100], Step [45/60], Loss: 1.9332, batch time: 0.45, accuracy:  27.10%\n",
      "Epoch [20/100], Step [46/60], Loss: 1.9261, batch time: 0.46, accuracy:  29.30%\n",
      "Epoch [20/100], Step [47/60], Loss: 1.9024, batch time: 0.50, accuracy:  28.40%\n",
      "Epoch [20/100], Step [48/60], Loss: 1.9255, batch time: 0.46, accuracy:  28.50%\n",
      "Epoch [20/100], Step [49/60], Loss: 1.9199, batch time: 0.44, accuracy:  29.00%\n",
      "Epoch [20/100], Step [50/60], Loss: 1.8709, batch time: 0.45, accuracy:  32.20%\n",
      "Epoch [20/100], Step [51/60], Loss: 1.9368, batch time: 0.45, accuracy:  29.70%\n",
      "Epoch [20/100], Step [52/60], Loss: 1.9001, batch time: 0.44, accuracy:  30.50%\n",
      "Epoch [20/100], Step [53/60], Loss: 1.9358, batch time: 0.47, accuracy:  27.80%\n",
      "Epoch [20/100], Step [54/60], Loss: 1.8887, batch time: 0.46, accuracy:  30.70%\n",
      "Epoch [20/100], Step [55/60], Loss: 1.9166, batch time: 0.55, accuracy:  28.80%\n",
      "Epoch [20/100], Step [56/60], Loss: 1.9046, batch time: 0.54, accuracy:  30.20%\n",
      "Epoch [20/100], Step [57/60], Loss: 1.8845, batch time: 0.53, accuracy:  30.60%\n",
      "Epoch [20/100], Step [58/60], Loss: 1.9867, batch time: 0.55, accuracy:  26.70%\n",
      "Epoch [20/100], Step [59/60], Loss: 1.9170, batch time: 0.53, accuracy:  27.80%\n",
      "Epoch [20/100], Step [60/60], Loss: 1.8720, batch time: 0.54, accuracy:  32.70%\n",
      "Epoch [21/100], Step [1/60], Loss: 1.8634, batch time: 0.55, accuracy:  30.70%\n",
      "Epoch [21/100], Step [2/60], Loss: 1.9075, batch time: 0.53, accuracy:  28.30%\n",
      "Epoch [21/100], Step [3/60], Loss: 1.9114, batch time: 0.56, accuracy:  29.00%\n",
      "Epoch [21/100], Step [4/60], Loss: 1.9137, batch time: 0.53, accuracy:  29.90%\n",
      "Epoch [21/100], Step [5/60], Loss: 1.8977, batch time: 0.55, accuracy:  31.90%\n",
      "Epoch [21/100], Step [6/60], Loss: 1.9229, batch time: 0.53, accuracy:  28.40%\n",
      "Epoch [21/100], Step [7/60], Loss: 1.9028, batch time: 0.54, accuracy:  29.40%\n",
      "Epoch [21/100], Step [8/60], Loss: 1.9061, batch time: 0.51, accuracy:  28.30%\n",
      "Epoch [21/100], Step [9/60], Loss: 1.9434, batch time: 0.43, accuracy:  27.20%\n",
      "Epoch [21/100], Step [10/60], Loss: 1.8927, batch time: 0.45, accuracy:  30.70%\n",
      "Epoch [21/100], Step [11/60], Loss: 1.9126, batch time: 0.45, accuracy:  29.80%\n",
      "Epoch [21/100], Step [12/60], Loss: 1.9330, batch time: 0.44, accuracy:  28.00%\n",
      "Epoch [21/100], Step [13/60], Loss: 1.8675, batch time: 0.45, accuracy:  30.50%\n",
      "Epoch [21/100], Step [14/60], Loss: 1.9267, batch time: 0.43, accuracy:  28.20%\n",
      "Epoch [21/100], Step [15/60], Loss: 1.8842, batch time: 0.44, accuracy:  29.80%\n",
      "Epoch [21/100], Step [16/60], Loss: 1.8867, batch time: 0.45, accuracy:  31.00%\n",
      "Epoch [21/100], Step [17/60], Loss: 1.8884, batch time: 0.43, accuracy:  31.90%\n",
      "Epoch [21/100], Step [18/60], Loss: 1.9038, batch time: 0.44, accuracy:  30.40%\n",
      "Epoch [21/100], Step [19/60], Loss: 1.9231, batch time: 0.44, accuracy:  28.10%\n",
      "Epoch [21/100], Step [20/60], Loss: 1.9010, batch time: 0.46, accuracy:  29.10%\n",
      "Epoch [21/100], Step [21/60], Loss: 1.9134, batch time: 0.46, accuracy:  29.80%\n",
      "Epoch [21/100], Step [22/60], Loss: 1.9412, batch time: 0.44, accuracy:  27.20%\n",
      "Epoch [21/100], Step [23/60], Loss: 1.9375, batch time: 0.44, accuracy:  30.10%\n",
      "Epoch [21/100], Step [24/60], Loss: 1.9307, batch time: 0.46, accuracy:  27.80%\n",
      "Epoch [21/100], Step [25/60], Loss: 1.8628, batch time: 0.44, accuracy:  31.80%\n",
      "Epoch [21/100], Step [26/60], Loss: 1.9099, batch time: 0.44, accuracy:  29.70%\n",
      "Epoch [21/100], Step [27/60], Loss: 1.8945, batch time: 0.46, accuracy:  30.10%\n",
      "Epoch [21/100], Step [28/60], Loss: 1.9180, batch time: 0.44, accuracy:  29.00%\n",
      "Epoch [21/100], Step [29/60], Loss: 1.9320, batch time: 0.52, accuracy:  30.50%\n",
      "Epoch [21/100], Step [30/60], Loss: 1.9256, batch time: 0.44, accuracy:  28.80%\n",
      "Epoch [21/100], Step [31/60], Loss: 1.9262, batch time: 0.45, accuracy:  29.20%\n",
      "Epoch [21/100], Step [32/60], Loss: 1.8541, batch time: 0.48, accuracy:  32.40%\n",
      "Epoch [21/100], Step [33/60], Loss: 1.8671, batch time: 0.52, accuracy:  30.70%\n",
      "Epoch [21/100], Step [34/60], Loss: 1.9012, batch time: 0.53, accuracy:  30.70%\n",
      "Epoch [21/100], Step [35/60], Loss: 1.9454, batch time: 0.54, accuracy:  29.50%\n",
      "Epoch [21/100], Step [36/60], Loss: 1.9078, batch time: 0.52, accuracy:  29.50%\n",
      "Epoch [21/100], Step [37/60], Loss: 1.9423, batch time: 0.55, accuracy:  28.40%\n",
      "Epoch [21/100], Step [38/60], Loss: 1.9117, batch time: 0.54, accuracy:  29.90%\n",
      "Epoch [21/100], Step [39/60], Loss: 1.8771, batch time: 0.55, accuracy:  33.10%\n",
      "Epoch [21/100], Step [40/60], Loss: 1.8807, batch time: 0.52, accuracy:  31.50%\n",
      "Epoch [21/100], Step [41/60], Loss: 1.9286, batch time: 0.53, accuracy:  31.00%\n",
      "Epoch [21/100], Step [42/60], Loss: 1.8713, batch time: 0.54, accuracy:  32.60%\n",
      "Epoch [21/100], Step [43/60], Loss: 1.8886, batch time: 0.53, accuracy:  31.30%\n",
      "Epoch [21/100], Step [44/60], Loss: 1.8846, batch time: 0.54, accuracy:  30.60%\n",
      "Epoch [21/100], Step [45/60], Loss: 1.8798, batch time: 0.55, accuracy:  31.70%\n",
      "Epoch [21/100], Step [46/60], Loss: 1.8930, batch time: 0.54, accuracy:  30.60%\n",
      "Epoch [21/100], Step [47/60], Loss: 1.9083, batch time: 0.53, accuracy:  31.10%\n",
      "Epoch [21/100], Step [48/60], Loss: 1.8813, batch time: 0.53, accuracy:  30.70%\n",
      "Epoch [21/100], Step [49/60], Loss: 1.8780, batch time: 0.53, accuracy:  29.40%\n",
      "Epoch [21/100], Step [50/60], Loss: 1.8848, batch time: 0.43, accuracy:  30.60%\n",
      "Epoch [21/100], Step [51/60], Loss: 1.9166, batch time: 0.44, accuracy:  27.60%\n",
      "Epoch [21/100], Step [52/60], Loss: 1.8817, batch time: 0.44, accuracy:  29.30%\n",
      "Epoch [21/100], Step [53/60], Loss: 1.8990, batch time: 0.43, accuracy:  30.70%\n",
      "Epoch [21/100], Step [54/60], Loss: 1.8958, batch time: 0.46, accuracy:  30.00%\n",
      "Epoch [21/100], Step [55/60], Loss: 1.8881, batch time: 0.44, accuracy:  31.60%\n",
      "Epoch [21/100], Step [56/60], Loss: 1.9388, batch time: 0.43, accuracy:  29.80%\n",
      "Epoch [21/100], Step [57/60], Loss: 1.9210, batch time: 0.45, accuracy:  30.10%\n",
      "Epoch [21/100], Step [58/60], Loss: 1.8828, batch time: 0.44, accuracy:  31.30%\n",
      "Epoch [21/100], Step [59/60], Loss: 1.9024, batch time: 0.43, accuracy:  28.50%\n",
      "Epoch [21/100], Step [60/60], Loss: 1.8819, batch time: 0.45, accuracy:  30.50%\n",
      "Epoch [22/100], Step [1/60], Loss: 1.8881, batch time: 0.46, accuracy:  30.60%\n",
      "Epoch [22/100], Step [2/60], Loss: 1.9005, batch time: 0.43, accuracy:  31.00%\n",
      "Epoch [22/100], Step [3/60], Loss: 1.9006, batch time: 0.48, accuracy:  28.50%\n",
      "Epoch [22/100], Step [4/60], Loss: 1.9231, batch time: 0.43, accuracy:  29.00%\n",
      "Epoch [22/100], Step [5/60], Loss: 1.8731, batch time: 0.50, accuracy:  30.40%\n",
      "Epoch [22/100], Step [6/60], Loss: 1.9365, batch time: 0.45, accuracy:  30.00%\n",
      "Epoch [22/100], Step [7/60], Loss: 1.8948, batch time: 0.43, accuracy:  29.00%\n",
      "Epoch [22/100], Step [8/60], Loss: 1.8742, batch time: 0.45, accuracy:  29.70%\n",
      "Epoch [22/100], Step [9/60], Loss: 1.8673, batch time: 0.44, accuracy:  32.30%\n",
      "Epoch [22/100], Step [10/60], Loss: 1.8895, batch time: 0.43, accuracy:  32.00%\n",
      "Epoch [22/100], Step [11/60], Loss: 1.8528, batch time: 0.46, accuracy:  31.60%\n",
      "Epoch [22/100], Step [12/60], Loss: 1.8670, batch time: 0.47, accuracy:  32.80%\n",
      "Epoch [22/100], Step [13/60], Loss: 1.9395, batch time: 0.46, accuracy:  27.00%\n",
      "Epoch [22/100], Step [14/60], Loss: 1.9271, batch time: 0.55, accuracy:  27.60%\n",
      "Epoch [22/100], Step [15/60], Loss: 1.9171, batch time: 0.52, accuracy:  29.60%\n",
      "Epoch [22/100], Step [16/60], Loss: 1.9192, batch time: 0.54, accuracy:  28.70%\n",
      "Epoch [22/100], Step [17/60], Loss: 1.9108, batch time: 0.53, accuracy:  29.50%\n",
      "Epoch [22/100], Step [18/60], Loss: 1.8865, batch time: 0.56, accuracy:  30.70%\n",
      "Epoch [22/100], Step [19/60], Loss: 1.9064, batch time: 0.44, accuracy:  31.70%\n",
      "Epoch [22/100], Step [20/60], Loss: 1.8915, batch time: 0.47, accuracy:  31.20%\n",
      "Epoch [22/100], Step [21/60], Loss: 1.8614, batch time: 0.54, accuracy:  31.60%\n",
      "Epoch [22/100], Step [22/60], Loss: 1.8847, batch time: 0.44, accuracy:  30.90%\n",
      "Epoch [22/100], Step [23/60], Loss: 1.8189, batch time: 0.43, accuracy:  33.30%\n",
      "Epoch [22/100], Step [24/60], Loss: 1.9204, batch time: 0.45, accuracy:  31.60%\n",
      "Epoch [22/100], Step [25/60], Loss: 1.8775, batch time: 0.44, accuracy:  32.60%\n",
      "Epoch [22/100], Step [26/60], Loss: 1.9137, batch time: 0.44, accuracy:  31.90%\n",
      "Epoch [22/100], Step [27/60], Loss: 1.9080, batch time: 0.45, accuracy:  28.30%\n",
      "Epoch [22/100], Step [28/60], Loss: 1.8956, batch time: 0.44, accuracy:  30.20%\n",
      "Epoch [22/100], Step [29/60], Loss: 1.8492, batch time: 0.46, accuracy:  30.80%\n",
      "Epoch [22/100], Step [30/60], Loss: 1.8950, batch time: 0.44, accuracy:  29.60%\n",
      "Epoch [22/100], Step [31/60], Loss: 1.9263, batch time: 0.44, accuracy:  30.30%\n",
      "Epoch [22/100], Step [32/60], Loss: 1.8763, batch time: 0.45, accuracy:  30.00%\n",
      "Epoch [22/100], Step [33/60], Loss: 1.9307, batch time: 0.45, accuracy:  28.00%\n",
      "Epoch [22/100], Step [34/60], Loss: 1.9067, batch time: 0.44, accuracy:  28.20%\n",
      "Epoch [22/100], Step [35/60], Loss: 1.8991, batch time: 0.46, accuracy:  30.40%\n",
      "Epoch [22/100], Step [36/60], Loss: 1.9454, batch time: 0.44, accuracy:  29.50%\n",
      "Epoch [22/100], Step [37/60], Loss: 1.8742, batch time: 0.44, accuracy:  30.40%\n",
      "Epoch [22/100], Step [38/60], Loss: 1.9284, batch time: 0.46, accuracy:  30.20%\n",
      "Epoch [22/100], Step [39/60], Loss: 1.9285, batch time: 0.46, accuracy:  28.90%\n",
      "Epoch [22/100], Step [40/60], Loss: 1.8594, batch time: 0.45, accuracy:  30.80%\n",
      "Epoch [22/100], Step [41/60], Loss: 1.8734, batch time: 0.47, accuracy:  30.20%\n",
      "Epoch [22/100], Step [42/60], Loss: 1.8549, batch time: 0.52, accuracy:  32.30%\n",
      "Epoch [22/100], Step [43/60], Loss: 1.8462, batch time: 0.55, accuracy:  33.20%\n",
      "Epoch [22/100], Step [44/60], Loss: 1.8847, batch time: 0.52, accuracy:  29.30%\n",
      "Epoch [22/100], Step [45/60], Loss: 1.8938, batch time: 0.63, accuracy:  31.20%\n",
      "Epoch [22/100], Step [46/60], Loss: 1.8511, batch time: 0.44, accuracy:  29.90%\n",
      "Epoch [22/100], Step [47/60], Loss: 1.8712, batch time: 0.46, accuracy:  31.70%\n",
      "Epoch [22/100], Step [48/60], Loss: 1.8892, batch time: 0.45, accuracy:  31.80%\n",
      "Epoch [22/100], Step [49/60], Loss: 1.8541, batch time: 0.44, accuracy:  34.80%\n",
      "Epoch [22/100], Step [50/60], Loss: 1.8781, batch time: 0.44, accuracy:  31.50%\n",
      "Epoch [22/100], Step [51/60], Loss: 1.8518, batch time: 0.46, accuracy:  32.00%\n",
      "Epoch [22/100], Step [52/60], Loss: 1.8857, batch time: 0.44, accuracy:  31.50%\n",
      "Epoch [22/100], Step [53/60], Loss: 1.8528, batch time: 0.44, accuracy:  33.10%\n",
      "Epoch [22/100], Step [54/60], Loss: 1.8799, batch time: 0.51, accuracy:  32.50%\n",
      "Epoch [22/100], Step [55/60], Loss: 1.8853, batch time: 0.44, accuracy:  30.70%\n",
      "Epoch [22/100], Step [56/60], Loss: 1.9012, batch time: 0.47, accuracy:  31.40%\n",
      "Epoch [22/100], Step [57/60], Loss: 1.9060, batch time: 0.44, accuracy:  30.80%\n",
      "Epoch [22/100], Step [58/60], Loss: 1.9000, batch time: 0.44, accuracy:  29.60%\n",
      "Epoch [22/100], Step [59/60], Loss: 1.8873, batch time: 0.45, accuracy:  31.70%\n",
      "Epoch [22/100], Step [60/60], Loss: 1.8614, batch time: 0.44, accuracy:  31.70%\n",
      "Epoch [23/100], Step [1/60], Loss: 1.8608, batch time: 0.46, accuracy:  30.60%\n",
      "Epoch [23/100], Step [2/60], Loss: 1.8811, batch time: 0.46, accuracy:  31.40%\n",
      "Epoch [23/100], Step [3/60], Loss: 1.8765, batch time: 0.44, accuracy:  31.60%\n",
      "Epoch [23/100], Step [4/60], Loss: 1.8780, batch time: 0.44, accuracy:  29.50%\n",
      "Epoch [23/100], Step [5/60], Loss: 1.8554, batch time: 0.47, accuracy:  32.30%\n",
      "Epoch [23/100], Step [6/60], Loss: 1.8252, batch time: 0.44, accuracy:  34.00%\n",
      "Epoch [23/100], Step [7/60], Loss: 1.8357, batch time: 0.46, accuracy:  32.10%\n",
      "Epoch [23/100], Step [8/60], Loss: 1.9300, batch time: 0.46, accuracy:  29.10%\n",
      "Epoch [23/100], Step [9/60], Loss: 1.8047, batch time: 0.53, accuracy:  33.90%\n",
      "Epoch [23/100], Step [10/60], Loss: 1.8830, batch time: 0.55, accuracy:  30.40%\n",
      "Epoch [23/100], Step [11/60], Loss: 1.8637, batch time: 0.53, accuracy:  32.30%\n",
      "Epoch [23/100], Step [12/60], Loss: 1.8876, batch time: 0.55, accuracy:  31.60%\n",
      "Epoch [23/100], Step [13/60], Loss: 1.9078, batch time: 0.53, accuracy:  29.70%\n",
      "Epoch [23/100], Step [14/60], Loss: 1.8930, batch time: 0.83, accuracy:  28.80%\n",
      "Epoch [23/100], Step [15/60], Loss: 1.8310, batch time: 0.80, accuracy:  31.60%\n",
      "Epoch [23/100], Step [16/60], Loss: 1.9209, batch time: 0.80, accuracy:  30.10%\n",
      "Epoch [23/100], Step [17/60], Loss: 1.8642, batch time: 0.80, accuracy:  33.70%\n",
      "Epoch [23/100], Step [18/60], Loss: 1.8851, batch time: 0.79, accuracy:  30.80%\n",
      "Epoch [23/100], Step [19/60], Loss: 1.9061, batch time: 0.87, accuracy:  28.90%\n",
      "Epoch [23/100], Step [20/60], Loss: 1.8735, batch time: 0.71, accuracy:  31.40%\n",
      "Epoch [23/100], Step [21/60], Loss: 1.8959, batch time: 0.72, accuracy:  31.10%\n",
      "Epoch [23/100], Step [22/60], Loss: 1.8894, batch time: 0.71, accuracy:  32.30%\n",
      "Epoch [23/100], Step [23/60], Loss: 1.8840, batch time: 0.73, accuracy:  30.70%\n",
      "Epoch [23/100], Step [24/60], Loss: 1.8696, batch time: 0.73, accuracy:  30.00%\n",
      "Epoch [23/100], Step [25/60], Loss: 1.8665, batch time: 0.73, accuracy:  32.40%\n",
      "Epoch [23/100], Step [26/60], Loss: 1.8988, batch time: 0.70, accuracy:  33.40%\n",
      "Epoch [23/100], Step [27/60], Loss: 1.8339, batch time: 0.80, accuracy:  33.10%\n",
      "Epoch [23/100], Step [28/60], Loss: 1.9079, batch time: 0.62, accuracy:  29.80%\n",
      "Epoch [23/100], Step [29/60], Loss: 1.8202, batch time: 0.73, accuracy:  34.60%\n",
      "Epoch [23/100], Step [30/60], Loss: 1.8728, batch time: 0.62, accuracy:  31.20%\n",
      "Epoch [23/100], Step [31/60], Loss: 1.8797, batch time: 0.73, accuracy:  32.20%\n",
      "Epoch [23/100], Step [32/60], Loss: 1.8553, batch time: 0.74, accuracy:  32.30%\n",
      "Epoch [23/100], Step [33/60], Loss: 1.8630, batch time: 0.75, accuracy:  33.60%\n",
      "Epoch [23/100], Step [34/60], Loss: 1.9064, batch time: 0.68, accuracy:  28.00%\n",
      "Epoch [23/100], Step [35/60], Loss: 1.8889, batch time: 0.67, accuracy:  32.60%\n",
      "Epoch [23/100], Step [36/60], Loss: 1.9345, batch time: 0.85, accuracy:  27.70%\n",
      "Epoch [23/100], Step [37/60], Loss: 1.8503, batch time: 0.87, accuracy:  32.10%\n",
      "Epoch [23/100], Step [38/60], Loss: 1.8812, batch time: 0.77, accuracy:  30.80%\n",
      "Epoch [23/100], Step [39/60], Loss: 1.8370, batch time: 0.70, accuracy:  30.70%\n",
      "Epoch [23/100], Step [40/60], Loss: 1.9279, batch time: 0.69, accuracy:  32.20%\n",
      "Epoch [23/100], Step [41/60], Loss: 1.8901, batch time: 0.71, accuracy:  31.60%\n",
      "Epoch [23/100], Step [42/60], Loss: 1.9087, batch time: 0.63, accuracy:  29.70%\n",
      "Epoch [23/100], Step [43/60], Loss: 1.8716, batch time: 0.72, accuracy:  32.40%\n",
      "Epoch [23/100], Step [44/60], Loss: 1.8534, batch time: 0.72, accuracy:  35.40%\n",
      "Epoch [23/100], Step [45/60], Loss: 1.8505, batch time: 0.63, accuracy:  32.70%\n",
      "Epoch [23/100], Step [46/60], Loss: 1.8337, batch time: 0.70, accuracy:  31.90%\n",
      "Epoch [23/100], Step [47/60], Loss: 1.9009, batch time: 0.67, accuracy:  31.00%\n",
      "Epoch [23/100], Step [48/60], Loss: 1.8506, batch time: 0.65, accuracy:  32.30%\n",
      "Epoch [23/100], Step [49/60], Loss: 1.8926, batch time: 0.66, accuracy:  32.60%\n",
      "Epoch [23/100], Step [50/60], Loss: 1.9042, batch time: 0.74, accuracy:  31.50%\n",
      "Epoch [23/100], Step [51/60], Loss: 1.8540, batch time: 0.72, accuracy:  32.10%\n",
      "Epoch [23/100], Step [52/60], Loss: 1.8417, batch time: 0.76, accuracy:  32.00%\n",
      "Epoch [23/100], Step [53/60], Loss: 1.8678, batch time: 0.76, accuracy:  31.80%\n",
      "Epoch [23/100], Step [54/60], Loss: 1.9127, batch time: 0.95, accuracy:  29.30%\n",
      "Epoch [23/100], Step [55/60], Loss: 1.8358, batch time: 0.71, accuracy:  33.10%\n",
      "Epoch [23/100], Step [56/60], Loss: 1.8772, batch time: 0.70, accuracy:  30.40%\n",
      "Epoch [23/100], Step [57/60], Loss: 1.8905, batch time: 0.70, accuracy:  31.40%\n",
      "Epoch [23/100], Step [58/60], Loss: 1.8465, batch time: 0.71, accuracy:  33.30%\n",
      "Epoch [23/100], Step [59/60], Loss: 1.8590, batch time: 0.71, accuracy:  33.00%\n",
      "Epoch [23/100], Step [60/60], Loss: 1.8376, batch time: 0.70, accuracy:  30.80%\n",
      "Epoch [24/100], Step [1/60], Loss: 1.9000, batch time: 0.63, accuracy:  30.60%\n",
      "Epoch [24/100], Step [2/60], Loss: 1.8672, batch time: 0.70, accuracy:  31.20%\n",
      "Epoch [24/100], Step [3/60], Loss: 1.8909, batch time: 0.70, accuracy:  31.70%\n",
      "Epoch [24/100], Step [4/60], Loss: 1.8685, batch time: 0.71, accuracy:  31.50%\n",
      "Epoch [24/100], Step [5/60], Loss: 1.8915, batch time: 0.72, accuracy:  32.60%\n",
      "Epoch [24/100], Step [6/60], Loss: 1.8664, batch time: 0.72, accuracy:  31.30%\n",
      "Epoch [24/100], Step [7/60], Loss: 1.8345, batch time: 0.72, accuracy:  33.70%\n",
      "Epoch [24/100], Step [8/60], Loss: 1.8549, batch time: 0.62, accuracy:  32.70%\n",
      "Epoch [24/100], Step [9/60], Loss: 1.8653, batch time: 0.55, accuracy:  31.30%\n",
      "Epoch [24/100], Step [10/60], Loss: 1.8768, batch time: 0.83, accuracy:  31.50%\n",
      "Epoch [24/100], Step [11/60], Loss: 1.8772, batch time: 0.86, accuracy:  32.10%\n",
      "Epoch [24/100], Step [12/60], Loss: 1.8380, batch time: 0.85, accuracy:  31.10%\n",
      "Epoch [24/100], Step [13/60], Loss: 1.8885, batch time: 0.83, accuracy:  30.50%\n",
      "Epoch [24/100], Step [14/60], Loss: 1.8450, batch time: 0.73, accuracy:  33.60%\n",
      "Epoch [24/100], Step [15/60], Loss: 1.8579, batch time: 0.70, accuracy:  34.70%\n",
      "Epoch [24/100], Step [16/60], Loss: 1.8599, batch time: 0.72, accuracy:  30.90%\n",
      "Epoch [24/100], Step [17/60], Loss: 1.8775, batch time: 0.71, accuracy:  30.20%\n",
      "Epoch [24/100], Step [18/60], Loss: 1.8499, batch time: 0.71, accuracy:  30.40%\n",
      "Epoch [24/100], Step [19/60], Loss: 1.8690, batch time: 0.70, accuracy:  33.40%\n",
      "Epoch [24/100], Step [20/60], Loss: 1.8532, batch time: 0.70, accuracy:  32.70%\n",
      "Epoch [24/100], Step [21/60], Loss: 1.8893, batch time: 0.71, accuracy:  30.40%\n",
      "Epoch [24/100], Step [22/60], Loss: 1.9054, batch time: 0.70, accuracy:  28.30%\n",
      "Epoch [24/100], Step [23/60], Loss: 1.9312, batch time: 0.70, accuracy:  29.90%\n",
      "Epoch [24/100], Step [24/60], Loss: 1.8487, batch time: 0.70, accuracy:  32.80%\n",
      "Epoch [24/100], Step [25/60], Loss: 1.9121, batch time: 0.71, accuracy:  29.40%\n",
      "Epoch [24/100], Step [26/60], Loss: 1.8937, batch time: 0.71, accuracy:  32.50%\n",
      "Epoch [24/100], Step [27/60], Loss: 1.8738, batch time: 0.71, accuracy:  32.60%\n",
      "Epoch [24/100], Step [28/60], Loss: 1.8918, batch time: 0.71, accuracy:  31.50%\n",
      "Epoch [24/100], Step [29/60], Loss: 1.8727, batch time: 0.83, accuracy:  31.50%\n",
      "Epoch [24/100], Step [30/60], Loss: 1.8792, batch time: 0.86, accuracy:  30.60%\n",
      "Epoch [24/100], Step [31/60], Loss: 1.8753, batch time: 0.86, accuracy:  30.60%\n",
      "Epoch [24/100], Step [32/60], Loss: 1.8626, batch time: 0.86, accuracy:  31.30%\n",
      "Epoch [24/100], Step [33/60], Loss: 1.8603, batch time: 0.77, accuracy:  33.70%\n",
      "Epoch [24/100], Step [34/60], Loss: 1.8019, batch time: 0.87, accuracy:  35.50%\n",
      "Epoch [24/100], Step [35/60], Loss: 1.8407, batch time: 0.86, accuracy:  31.40%\n",
      "Epoch [24/100], Step [36/60], Loss: 1.8137, batch time: 0.84, accuracy:  33.50%\n",
      "Epoch [24/100], Step [37/60], Loss: 1.8927, batch time: 0.86, accuracy:  33.10%\n",
      "Epoch [24/100], Step [38/60], Loss: 1.8083, batch time: 0.87, accuracy:  34.90%\n",
      "Epoch [24/100], Step [39/60], Loss: 1.8552, batch time: 0.84, accuracy:  33.60%\n",
      "Epoch [24/100], Step [40/60], Loss: 1.8543, batch time: 0.86, accuracy:  34.20%\n",
      "Epoch [24/100], Step [41/60], Loss: 1.8586, batch time: 0.83, accuracy:  30.40%\n",
      "Epoch [24/100], Step [42/60], Loss: 1.8490, batch time: 0.74, accuracy:  32.70%\n",
      "Epoch [24/100], Step [43/60], Loss: 1.8456, batch time: 0.72, accuracy:  33.80%\n",
      "Epoch [24/100], Step [44/60], Loss: 1.8316, batch time: 0.59, accuracy:  33.00%\n",
      "Epoch [24/100], Step [45/60], Loss: 1.8173, batch time: 0.78, accuracy:  34.10%\n",
      "Epoch [24/100], Step [46/60], Loss: 1.8255, batch time: 0.69, accuracy:  33.70%\n",
      "Epoch [24/100], Step [47/60], Loss: 1.8894, batch time: 0.69, accuracy:  30.90%\n",
      "Epoch [24/100], Step [48/60], Loss: 1.8598, batch time: 0.70, accuracy:  30.60%\n",
      "Epoch [24/100], Step [49/60], Loss: 1.8451, batch time: 0.69, accuracy:  31.30%\n",
      "Epoch [24/100], Step [50/60], Loss: 1.8682, batch time: 0.71, accuracy:  31.70%\n",
      "Epoch [24/100], Step [51/60], Loss: 1.8444, batch time: 0.70, accuracy:  31.60%\n",
      "Epoch [24/100], Step [52/60], Loss: 1.8914, batch time: 0.71, accuracy:  31.00%\n",
      "Epoch [24/100], Step [53/60], Loss: 1.8446, batch time: 0.70, accuracy:  33.90%\n",
      "Epoch [24/100], Step [54/60], Loss: 1.7912, batch time: 0.71, accuracy:  33.20%\n",
      "Epoch [24/100], Step [55/60], Loss: 1.8440, batch time: 0.69, accuracy:  33.20%\n",
      "Epoch [24/100], Step [56/60], Loss: 1.8416, batch time: 0.74, accuracy:  32.40%\n",
      "Epoch [24/100], Step [57/60], Loss: 1.8624, batch time: 0.72, accuracy:  33.50%\n",
      "Epoch [24/100], Step [58/60], Loss: 1.8881, batch time: 0.73, accuracy:  30.00%\n",
      "Epoch [24/100], Step [59/60], Loss: 1.8668, batch time: 0.74, accuracy:  33.70%\n",
      "Epoch [24/100], Step [60/60], Loss: 1.8880, batch time: 0.74, accuracy:  31.40%\n",
      "Epoch [25/100], Step [1/60], Loss: 1.8534, batch time: 0.76, accuracy:  34.40%\n",
      "Epoch [25/100], Step [2/60], Loss: 1.8462, batch time: 0.88, accuracy:  33.10%\n",
      "Epoch [25/100], Step [3/60], Loss: 1.8613, batch time: 0.86, accuracy:  32.80%\n",
      "Epoch [25/100], Step [4/60], Loss: 1.8225, batch time: 0.68, accuracy:  33.30%\n",
      "Epoch [25/100], Step [5/60], Loss: 1.8622, batch time: 0.72, accuracy:  31.50%\n",
      "Epoch [25/100], Step [6/60], Loss: 1.8751, batch time: 0.72, accuracy:  32.30%\n",
      "Epoch [25/100], Step [7/60], Loss: 1.8465, batch time: 0.73, accuracy:  33.60%\n",
      "Epoch [25/100], Step [8/60], Loss: 1.8701, batch time: 0.69, accuracy:  33.00%\n",
      "Epoch [25/100], Step [9/60], Loss: 1.8633, batch time: 0.72, accuracy:  32.70%\n",
      "Epoch [25/100], Step [10/60], Loss: 1.8423, batch time: 0.68, accuracy:  33.90%\n",
      "Epoch [25/100], Step [11/60], Loss: 1.8690, batch time: 0.67, accuracy:  31.50%\n",
      "Epoch [25/100], Step [12/60], Loss: 1.8489, batch time: 0.68, accuracy:  33.00%\n",
      "Epoch [25/100], Step [13/60], Loss: 1.8988, batch time: 0.68, accuracy:  30.90%\n",
      "Epoch [25/100], Step [14/60], Loss: 1.8745, batch time: 0.68, accuracy:  33.10%\n",
      "Epoch [25/100], Step [15/60], Loss: 1.8774, batch time: 0.68, accuracy:  31.80%\n",
      "Epoch [25/100], Step [16/60], Loss: 1.8500, batch time: 0.72, accuracy:  31.00%\n",
      "Epoch [25/100], Step [17/60], Loss: 1.8338, batch time: 0.72, accuracy:  33.20%\n",
      "Epoch [25/100], Step [18/60], Loss: 1.8094, batch time: 0.75, accuracy:  35.10%\n",
      "Epoch [25/100], Step [19/60], Loss: 1.8526, batch time: 0.72, accuracy:  33.00%\n",
      "Epoch [25/100], Step [20/60], Loss: 1.8309, batch time: 0.84, accuracy:  35.30%\n",
      "Epoch [25/100], Step [21/60], Loss: 1.8680, batch time: 0.86, accuracy:  31.30%\n",
      "Epoch [25/100], Step [22/60], Loss: 1.8617, batch time: 0.86, accuracy:  31.40%\n",
      "Epoch [25/100], Step [23/60], Loss: 1.8415, batch time: 0.69, accuracy:  32.60%\n",
      "Epoch [25/100], Step [24/60], Loss: 1.8910, batch time: 0.52, accuracy:  32.30%\n",
      "Epoch [25/100], Step [25/60], Loss: 1.8330, batch time: 0.43, accuracy:  33.20%\n",
      "Epoch [25/100], Step [26/60], Loss: 1.8509, batch time: 0.44, accuracy:  33.50%\n",
      "Epoch [25/100], Step [27/60], Loss: 1.8273, batch time: 0.44, accuracy:  33.30%\n",
      "Epoch [25/100], Step [28/60], Loss: 1.8084, batch time: 0.44, accuracy:  33.30%\n",
      "Epoch [25/100], Step [29/60], Loss: 1.8503, batch time: 0.44, accuracy:  31.30%\n",
      "Epoch [25/100], Step [30/60], Loss: 1.9023, batch time: 0.45, accuracy:  31.70%\n",
      "Epoch [25/100], Step [31/60], Loss: 1.8347, batch time: 0.44, accuracy:  35.40%\n",
      "Epoch [25/100], Step [32/60], Loss: 1.8761, batch time: 0.45, accuracy:  31.20%\n",
      "Epoch [25/100], Step [33/60], Loss: 1.8475, batch time: 0.45, accuracy:  30.40%\n",
      "Epoch [25/100], Step [34/60], Loss: 1.8574, batch time: 0.50, accuracy:  31.00%\n",
      "Epoch [25/100], Step [35/60], Loss: 1.8780, batch time: 0.52, accuracy:  30.20%\n",
      "Epoch [25/100], Step [36/60], Loss: 1.8677, batch time: 0.45, accuracy:  31.00%\n",
      "Epoch [25/100], Step [37/60], Loss: 1.8219, batch time: 0.44, accuracy:  33.00%\n",
      "Epoch [25/100], Step [38/60], Loss: 1.7876, batch time: 0.45, accuracy:  35.80%\n",
      "Epoch [25/100], Step [39/60], Loss: 1.8516, batch time: 0.44, accuracy:  31.90%\n",
      "Epoch [25/100], Step [40/60], Loss: 1.8001, batch time: 0.44, accuracy:  35.90%\n",
      "Epoch [25/100], Step [41/60], Loss: 1.8411, batch time: 0.47, accuracy:  33.20%\n",
      "Epoch [25/100], Step [42/60], Loss: 1.8617, batch time: 0.45, accuracy:  31.80%\n",
      "Epoch [25/100], Step [43/60], Loss: 1.8564, batch time: 0.47, accuracy:  30.90%\n",
      "Epoch [25/100], Step [44/60], Loss: 1.8246, batch time: 0.51, accuracy:  33.30%\n",
      "Epoch [25/100], Step [45/60], Loss: 1.8175, batch time: 0.52, accuracy:  33.50%\n",
      "Epoch [25/100], Step [46/60], Loss: 1.8420, batch time: 0.54, accuracy:  32.90%\n",
      "Epoch [25/100], Step [47/60], Loss: 1.8728, batch time: 0.53, accuracy:  31.50%\n",
      "Epoch [25/100], Step [48/60], Loss: 1.8430, batch time: 0.54, accuracy:  33.30%\n",
      "Epoch [25/100], Step [49/60], Loss: 1.8254, batch time: 0.56, accuracy:  33.90%\n",
      "Epoch [25/100], Step [50/60], Loss: 1.8533, batch time: 0.54, accuracy:  31.10%\n",
      "Epoch [25/100], Step [51/60], Loss: 1.8069, batch time: 0.53, accuracy:  33.30%\n",
      "Epoch [25/100], Step [52/60], Loss: 1.8466, batch time: 0.53, accuracy:  32.50%\n",
      "Epoch [25/100], Step [53/60], Loss: 1.8365, batch time: 0.54, accuracy:  32.80%\n",
      "Epoch [25/100], Step [54/60], Loss: 1.8126, batch time: 0.53, accuracy:  33.60%\n",
      "Epoch [25/100], Step [55/60], Loss: 1.8243, batch time: 0.54, accuracy:  33.00%\n",
      "Epoch [25/100], Step [56/60], Loss: 1.8546, batch time: 0.51, accuracy:  31.70%\n",
      "Epoch [25/100], Step [57/60], Loss: 1.8783, batch time: 0.44, accuracy:  30.10%\n",
      "Epoch [25/100], Step [58/60], Loss: 1.8147, batch time: 0.44, accuracy:  35.00%\n",
      "Epoch [25/100], Step [59/60], Loss: 1.8608, batch time: 0.43, accuracy:  33.00%\n",
      "Epoch [25/100], Step [60/60], Loss: 1.7866, batch time: 0.44, accuracy:  34.70%\n",
      "Epoch [26/100], Step [1/60], Loss: 1.8466, batch time: 0.47, accuracy:  31.70%\n",
      "Epoch [26/100], Step [2/60], Loss: 1.8057, batch time: 0.43, accuracy:  36.80%\n",
      "Epoch [26/100], Step [3/60], Loss: 1.8764, batch time: 0.45, accuracy:  30.70%\n",
      "Epoch [26/100], Step [4/60], Loss: 1.8143, batch time: 0.44, accuracy:  35.50%\n",
      "Epoch [26/100], Step [5/60], Loss: 1.7359, batch time: 0.43, accuracy:  36.50%\n",
      "Epoch [26/100], Step [6/60], Loss: 1.8510, batch time: 0.47, accuracy:  34.40%\n",
      "Epoch [26/100], Step [7/60], Loss: 1.8273, batch time: 0.50, accuracy:  34.60%\n",
      "Epoch [26/100], Step [8/60], Loss: 1.8829, batch time: 0.44, accuracy:  28.50%\n",
      "Epoch [26/100], Step [9/60], Loss: 1.8353, batch time: 0.44, accuracy:  31.90%\n",
      "Epoch [26/100], Step [10/60], Loss: 1.8249, batch time: 0.44, accuracy:  35.30%\n",
      "Epoch [26/100], Step [11/60], Loss: 1.8902, batch time: 0.43, accuracy:  30.50%\n",
      "Epoch [26/100], Step [12/60], Loss: 1.8285, batch time: 0.44, accuracy:  33.60%\n",
      "Epoch [26/100], Step [13/60], Loss: 1.8741, batch time: 0.44, accuracy:  31.90%\n",
      "Epoch [26/100], Step [14/60], Loss: 1.8667, batch time: 0.44, accuracy:  30.30%\n",
      "Epoch [26/100], Step [15/60], Loss: 1.8367, batch time: 0.47, accuracy:  31.80%\n",
      "Epoch [26/100], Step [16/60], Loss: 1.8157, batch time: 0.44, accuracy:  34.40%\n",
      "Epoch [26/100], Step [17/60], Loss: 1.8251, batch time: 0.45, accuracy:  37.40%\n",
      "Epoch [26/100], Step [18/60], Loss: 1.8829, batch time: 0.45, accuracy:  32.60%\n",
      "Epoch [26/100], Step [19/60], Loss: 1.8388, batch time: 0.45, accuracy:  34.80%\n",
      "Epoch [26/100], Step [20/60], Loss: 1.8156, batch time: 0.48, accuracy:  33.80%\n",
      "Epoch [26/100], Step [21/60], Loss: 1.8603, batch time: 0.52, accuracy:  33.20%\n",
      "Epoch [26/100], Step [22/60], Loss: 1.8187, batch time: 0.55, accuracy:  34.60%\n",
      "Epoch [26/100], Step [23/60], Loss: 1.8608, batch time: 0.52, accuracy:  33.30%\n",
      "Epoch [26/100], Step [24/60], Loss: 1.8781, batch time: 0.56, accuracy:  30.70%\n",
      "Epoch [26/100], Step [25/60], Loss: 1.8213, batch time: 0.55, accuracy:  33.70%\n",
      "Epoch [26/100], Step [26/60], Loss: 1.8367, batch time: 0.43, accuracy:  31.80%\n",
      "Epoch [26/100], Step [27/60], Loss: 1.8475, batch time: 0.45, accuracy:  31.60%\n",
      "Epoch [26/100], Step [28/60], Loss: 1.9024, batch time: 0.43, accuracy:  29.80%\n",
      "Epoch [26/100], Step [29/60], Loss: 1.8164, batch time: 0.43, accuracy:  35.50%\n",
      "Epoch [26/100], Step [30/60], Loss: 1.8216, batch time: 0.45, accuracy:  34.30%\n",
      "Epoch [26/100], Step [31/60], Loss: 1.7765, batch time: 0.43, accuracy:  35.10%\n",
      "Epoch [26/100], Step [32/60], Loss: 1.8642, batch time: 0.44, accuracy:  32.70%\n",
      "Epoch [26/100], Step [33/60], Loss: 1.8061, batch time: 0.47, accuracy:  33.90%\n",
      "Epoch [26/100], Step [34/60], Loss: 1.8242, batch time: 0.43, accuracy:  33.00%\n",
      "Epoch [26/100], Step [35/60], Loss: 1.8430, batch time: 0.44, accuracy:  35.10%\n",
      "Epoch [26/100], Step [36/60], Loss: 1.8111, batch time: 0.45, accuracy:  33.10%\n",
      "Epoch [26/100], Step [37/60], Loss: 1.8468, batch time: 0.43, accuracy:  32.30%\n",
      "Epoch [26/100], Step [38/60], Loss: 1.8473, batch time: 0.44, accuracy:  32.30%\n",
      "Epoch [26/100], Step [39/60], Loss: 1.8207, batch time: 0.45, accuracy:  32.90%\n",
      "Epoch [26/100], Step [40/60], Loss: 1.8008, batch time: 0.44, accuracy:  33.30%\n",
      "Epoch [26/100], Step [41/60], Loss: 1.7906, batch time: 0.44, accuracy:  35.50%\n",
      "Epoch [26/100], Step [42/60], Loss: 1.8066, batch time: 0.47, accuracy:  33.40%\n",
      "Epoch [26/100], Step [43/60], Loss: 1.8258, batch time: 0.44, accuracy:  32.60%\n",
      "Epoch [26/100], Step [44/60], Loss: 1.8468, batch time: 0.46, accuracy:  31.70%\n",
      "Epoch [26/100], Step [45/60], Loss: 1.8445, batch time: 0.43, accuracy:  33.20%\n",
      "Epoch [26/100], Step [46/60], Loss: 1.7851, batch time: 0.44, accuracy:  34.30%\n",
      "Epoch [26/100], Step [47/60], Loss: 1.8550, batch time: 0.46, accuracy:  32.80%\n",
      "Epoch [26/100], Step [48/60], Loss: 1.8253, batch time: 0.45, accuracy:  32.70%\n",
      "Epoch [26/100], Step [49/60], Loss: 1.8308, batch time: 0.56, accuracy:  34.90%\n",
      "Epoch [26/100], Step [50/60], Loss: 1.8105, batch time: 0.53, accuracy:  34.20%\n",
      "Epoch [26/100], Step [51/60], Loss: 1.8382, batch time: 0.56, accuracy:  34.40%\n",
      "Epoch [26/100], Step [52/60], Loss: 1.8048, batch time: 0.54, accuracy:  35.40%\n",
      "Epoch [26/100], Step [53/60], Loss: 1.8611, batch time: 0.52, accuracy:  30.70%\n",
      "Epoch [26/100], Step [54/60], Loss: 1.8374, batch time: 0.55, accuracy:  33.20%\n",
      "Epoch [26/100], Step [55/60], Loss: 1.8815, batch time: 0.52, accuracy:  31.80%\n",
      "Epoch [26/100], Step [56/60], Loss: 1.8015, batch time: 0.53, accuracy:  36.10%\n",
      "Epoch [26/100], Step [57/60], Loss: 1.8235, batch time: 0.54, accuracy:  34.50%\n",
      "Epoch [26/100], Step [58/60], Loss: 1.8416, batch time: 0.53, accuracy:  33.20%\n",
      "Epoch [26/100], Step [59/60], Loss: 1.8125, batch time: 0.46, accuracy:  34.20%\n",
      "Epoch [26/100], Step [60/60], Loss: 1.8266, batch time: 0.43, accuracy:  33.70%\n",
      "Epoch [27/100], Step [1/60], Loss: 1.8209, batch time: 0.46, accuracy:  33.40%\n",
      "Epoch [27/100], Step [2/60], Loss: 1.8638, batch time: 0.45, accuracy:  32.10%\n",
      "Epoch [27/100], Step [3/60], Loss: 1.7873, batch time: 0.43, accuracy:  34.90%\n",
      "Epoch [27/100], Step [4/60], Loss: 1.7820, batch time: 0.45, accuracy:  35.40%\n",
      "Epoch [27/100], Step [5/60], Loss: 1.7637, batch time: 0.44, accuracy:  36.40%\n",
      "Epoch [27/100], Step [6/60], Loss: 1.8597, batch time: 0.43, accuracy:  32.40%\n",
      "Epoch [27/100], Step [7/60], Loss: 1.8016, batch time: 0.45, accuracy:  32.40%\n",
      "Epoch [27/100], Step [8/60], Loss: 1.8358, batch time: 0.46, accuracy:  33.80%\n",
      "Epoch [27/100], Step [9/60], Loss: 1.8739, batch time: 0.44, accuracy:  32.70%\n",
      "Epoch [27/100], Step [10/60], Loss: 1.8628, batch time: 0.45, accuracy:  33.50%\n",
      "Epoch [27/100], Step [11/60], Loss: 1.8409, batch time: 0.43, accuracy:  34.60%\n",
      "Epoch [27/100], Step [12/60], Loss: 1.8356, batch time: 0.44, accuracy:  32.40%\n",
      "Epoch [27/100], Step [13/60], Loss: 1.8195, batch time: 0.45, accuracy:  31.20%\n",
      "Epoch [27/100], Step [14/60], Loss: 1.8066, batch time: 0.44, accuracy:  35.50%\n",
      "Epoch [27/100], Step [15/60], Loss: 1.8092, batch time: 0.44, accuracy:  33.80%\n",
      "Epoch [27/100], Step [16/60], Loss: 1.8265, batch time: 0.45, accuracy:  33.20%\n",
      "Epoch [27/100], Step [17/60], Loss: 1.8361, batch time: 0.46, accuracy:  32.60%\n",
      "Epoch [27/100], Step [18/60], Loss: 1.8192, batch time: 0.44, accuracy:  34.90%\n",
      "Epoch [27/100], Step [19/60], Loss: 1.8403, batch time: 0.45, accuracy:  31.70%\n",
      "Epoch [27/100], Step [20/60], Loss: 1.7688, batch time: 0.44, accuracy:  34.90%\n",
      "Epoch [27/100], Step [21/60], Loss: 1.8352, batch time: 0.46, accuracy:  30.80%\n",
      "Epoch [27/100], Step [22/60], Loss: 1.7906, batch time: 0.45, accuracy:  34.80%\n",
      "Epoch [27/100], Step [23/60], Loss: 1.8137, batch time: 0.53, accuracy:  34.00%\n",
      "Epoch [27/100], Step [24/60], Loss: 1.8496, batch time: 0.54, accuracy:  33.30%\n",
      "Epoch [27/100], Step [25/60], Loss: 1.8144, batch time: 0.59, accuracy:  33.70%\n",
      "Epoch [27/100], Step [26/60], Loss: 1.8558, batch time: 0.55, accuracy:  31.20%\n",
      "Epoch [27/100], Step [27/60], Loss: 1.8520, batch time: 0.54, accuracy:  31.20%\n",
      "Epoch [27/100], Step [28/60], Loss: 1.8593, batch time: 0.53, accuracy:  31.10%\n",
      "Epoch [27/100], Step [29/60], Loss: 1.8332, batch time: 0.53, accuracy:  34.80%\n",
      "Epoch [27/100], Step [30/60], Loss: 1.8291, batch time: 0.53, accuracy:  33.80%\n",
      "Epoch [27/100], Step [31/60], Loss: 1.7606, batch time: 0.53, accuracy:  36.90%\n",
      "Epoch [27/100], Step [32/60], Loss: 1.8354, batch time: 0.45, accuracy:  32.50%\n",
      "Epoch [27/100], Step [33/60], Loss: 1.8411, batch time: 0.43, accuracy:  32.30%\n",
      "Epoch [27/100], Step [34/60], Loss: 1.8803, batch time: 0.46, accuracy:  30.70%\n",
      "Epoch [27/100], Step [35/60], Loss: 1.8386, batch time: 0.44, accuracy:  32.80%\n",
      "Epoch [27/100], Step [36/60], Loss: 1.7936, batch time: 0.44, accuracy:  34.60%\n",
      "Epoch [27/100], Step [37/60], Loss: 1.8167, batch time: 0.44, accuracy:  34.50%\n",
      "Epoch [27/100], Step [38/60], Loss: 1.8018, batch time: 0.44, accuracy:  34.00%\n",
      "Epoch [27/100], Step [39/60], Loss: 1.7669, batch time: 0.44, accuracy:  36.60%\n",
      "Epoch [27/100], Step [40/60], Loss: 1.7941, batch time: 0.44, accuracy:  36.00%\n",
      "Epoch [27/100], Step [41/60], Loss: 1.8005, batch time: 0.44, accuracy:  35.60%\n",
      "Epoch [27/100], Step [42/60], Loss: 1.8041, batch time: 0.44, accuracy:  33.70%\n",
      "Epoch [27/100], Step [43/60], Loss: 1.7835, batch time: 0.46, accuracy:  33.80%\n",
      "Epoch [27/100], Step [44/60], Loss: 1.8306, batch time: 0.44, accuracy:  34.60%\n",
      "Epoch [27/100], Step [45/60], Loss: 1.8235, batch time: 0.44, accuracy:  33.20%\n",
      "Epoch [27/100], Step [46/60], Loss: 1.8464, batch time: 0.44, accuracy:  31.70%\n",
      "Epoch [27/100], Step [47/60], Loss: 1.8327, batch time: 0.44, accuracy:  32.60%\n",
      "Epoch [27/100], Step [48/60], Loss: 1.7845, batch time: 0.44, accuracy:  35.80%\n",
      "Epoch [27/100], Step [49/60], Loss: 1.8028, batch time: 0.44, accuracy:  36.20%\n",
      "Epoch [27/100], Step [50/60], Loss: 1.7955, batch time: 0.44, accuracy:  34.30%\n",
      "Epoch [27/100], Step [51/60], Loss: 1.8116, batch time: 0.44, accuracy:  33.40%\n",
      "Epoch [27/100], Step [52/60], Loss: 1.7957, batch time: 0.45, accuracy:  34.10%\n",
      "Epoch [27/100], Step [53/60], Loss: 1.7949, batch time: 0.45, accuracy:  33.00%\n",
      "Epoch [27/100], Step [54/60], Loss: 1.7986, batch time: 0.45, accuracy:  36.20%\n",
      "Epoch [27/100], Step [55/60], Loss: 1.8200, batch time: 0.57, accuracy:  35.50%\n",
      "Epoch [27/100], Step [56/60], Loss: 1.8385, batch time: 1.38, accuracy:  33.30%\n",
      "Epoch [27/100], Step [57/60], Loss: 1.8445, batch time: 1.92, accuracy:  31.50%\n",
      "Epoch [27/100], Step [58/60], Loss: 1.8455, batch time: 0.92, accuracy:  31.40%\n",
      "Epoch [27/100], Step [59/60], Loss: 1.8070, batch time: 0.76, accuracy:  33.30%\n",
      "Epoch [27/100], Step [60/60], Loss: 1.7495, batch time: 0.56, accuracy:  36.20%\n",
      "Epoch [28/100], Step [1/60], Loss: 1.8028, batch time: 0.70, accuracy:  35.40%\n",
      "Epoch [28/100], Step [2/60], Loss: 1.8107, batch time: 0.72, accuracy:  34.10%\n",
      "Epoch [28/100], Step [3/60], Loss: 1.8056, batch time: 0.69, accuracy:  34.90%\n",
      "Epoch [28/100], Step [4/60], Loss: 1.8081, batch time: 0.57, accuracy:  35.80%\n",
      "Epoch [28/100], Step [5/60], Loss: 1.8393, batch time: 0.61, accuracy:  33.40%\n",
      "Epoch [28/100], Step [6/60], Loss: 1.7803, batch time: 0.64, accuracy:  35.20%\n",
      "Epoch [28/100], Step [7/60], Loss: 1.8088, batch time: 0.52, accuracy:  34.80%\n",
      "Epoch [28/100], Step [8/60], Loss: 1.8274, batch time: 0.69, accuracy:  34.30%\n",
      "Epoch [28/100], Step [9/60], Loss: 1.8556, batch time: 0.46, accuracy:  32.90%\n",
      "Epoch [28/100], Step [10/60], Loss: 1.8248, batch time: 0.55, accuracy:  32.70%\n",
      "Epoch [28/100], Step [11/60], Loss: 1.8213, batch time: 0.73, accuracy:  34.90%\n",
      "Epoch [28/100], Step [12/60], Loss: 1.8403, batch time: 0.69, accuracy:  31.60%\n",
      "Epoch [28/100], Step [13/60], Loss: 1.8375, batch time: 0.73, accuracy:  32.90%\n",
      "Epoch [28/100], Step [14/60], Loss: 1.7930, batch time: 0.78, accuracy:  35.20%\n",
      "Epoch [28/100], Step [15/60], Loss: 1.7835, batch time: 0.86, accuracy:  33.80%\n",
      "Epoch [28/100], Step [16/60], Loss: 1.8325, batch time: 0.65, accuracy:  34.10%\n",
      "Epoch [28/100], Step [17/60], Loss: 1.8271, batch time: 0.71, accuracy:  34.70%\n",
      "Epoch [28/100], Step [18/60], Loss: 1.8462, batch time: 0.70, accuracy:  31.70%\n",
      "Epoch [28/100], Step [19/60], Loss: 1.7896, batch time: 0.64, accuracy:  35.60%\n",
      "Epoch [28/100], Step [20/60], Loss: 1.8113, batch time: 0.68, accuracy:  34.90%\n",
      "Epoch [28/100], Step [21/60], Loss: 1.7948, batch time: 0.69, accuracy:  34.90%\n",
      "Epoch [28/100], Step [22/60], Loss: 1.7573, batch time: 0.69, accuracy:  35.30%\n",
      "Epoch [28/100], Step [23/60], Loss: 1.7827, batch time: 0.68, accuracy:  35.60%\n",
      "Epoch [28/100], Step [24/60], Loss: 1.8224, batch time: 0.69, accuracy:  32.70%\n",
      "Epoch [28/100], Step [25/60], Loss: 1.8229, batch time: 0.69, accuracy:  32.30%\n",
      "Epoch [28/100], Step [26/60], Loss: 1.8117, batch time: 0.70, accuracy:  34.30%\n",
      "Epoch [28/100], Step [27/60], Loss: 1.7951, batch time: 0.74, accuracy:  36.60%\n",
      "Epoch [28/100], Step [28/60], Loss: 1.7848, batch time: 0.74, accuracy:  34.10%\n",
      "Epoch [28/100], Step [29/60], Loss: 1.8012, batch time: 0.74, accuracy:  33.00%\n",
      "Epoch [28/100], Step [30/60], Loss: 1.8488, batch time: 0.74, accuracy:  31.90%\n",
      "Epoch [28/100], Step [31/60], Loss: 1.7867, batch time: 0.74, accuracy:  35.10%\n",
      "Epoch [28/100], Step [32/60], Loss: 1.8003, batch time: 0.74, accuracy:  34.10%\n",
      "Epoch [28/100], Step [33/60], Loss: 1.8520, batch time: 0.65, accuracy:  33.40%\n",
      "Epoch [28/100], Step [34/60], Loss: 1.8084, batch time: 0.72, accuracy:  33.50%\n",
      "Epoch [28/100], Step [35/60], Loss: 1.8001, batch time: 0.84, accuracy:  34.80%\n",
      "Epoch [28/100], Step [36/60], Loss: 1.8032, batch time: 0.92, accuracy:  33.80%\n",
      "Epoch [28/100], Step [37/60], Loss: 1.8293, batch time: 1.03, accuracy:  32.70%\n",
      "Epoch [28/100], Step [38/60], Loss: 1.7851, batch time: 0.83, accuracy:  35.30%\n",
      "Epoch [28/100], Step [39/60], Loss: 1.8390, batch time: 0.81, accuracy:  35.20%\n",
      "Epoch [28/100], Step [40/60], Loss: 1.8528, batch time: 0.64, accuracy:  33.40%\n",
      "Epoch [28/100], Step [41/60], Loss: 1.7986, batch time: 0.65, accuracy:  33.90%\n",
      "Epoch [28/100], Step [42/60], Loss: 1.8226, batch time: 0.65, accuracy:  33.30%\n",
      "Epoch [28/100], Step [43/60], Loss: 1.7978, batch time: 0.65, accuracy:  33.90%\n",
      "Epoch [28/100], Step [44/60], Loss: 1.7997, batch time: 0.66, accuracy:  35.20%\n",
      "Epoch [28/100], Step [45/60], Loss: 1.8203, batch time: 1.02, accuracy:  34.10%\n",
      "Epoch [28/100], Step [46/60], Loss: 1.7417, batch time: 1.53, accuracy:  36.30%\n",
      "Epoch [28/100], Step [47/60], Loss: 1.8047, batch time: 1.03, accuracy:  34.00%\n",
      "Epoch [28/100], Step [48/60], Loss: 1.8246, batch time: 0.77, accuracy:  33.50%\n",
      "Epoch [28/100], Step [49/60], Loss: 1.8126, batch time: 0.73, accuracy:  33.50%\n",
      "Epoch [28/100], Step [50/60], Loss: 1.8205, batch time: 0.92, accuracy:  33.80%\n",
      "Epoch [28/100], Step [51/60], Loss: 1.7722, batch time: 1.00, accuracy:  35.10%\n",
      "Epoch [28/100], Step [52/60], Loss: 1.8422, batch time: 1.06, accuracy:  32.10%\n",
      "Epoch [28/100], Step [53/60], Loss: 1.8135, batch time: 1.35, accuracy:  32.60%\n",
      "Epoch [28/100], Step [54/60], Loss: 1.7837, batch time: 1.10, accuracy:  34.20%\n",
      "Epoch [28/100], Step [55/60], Loss: 1.8119, batch time: 1.33, accuracy:  33.60%\n",
      "Epoch [28/100], Step [56/60], Loss: 1.7676, batch time: 1.17, accuracy:  36.10%\n",
      "Epoch [28/100], Step [57/60], Loss: 1.7711, batch time: 0.86, accuracy:  35.00%\n",
      "Epoch [28/100], Step [58/60], Loss: 1.8343, batch time: 0.81, accuracy:  33.50%\n",
      "Epoch [28/100], Step [59/60], Loss: 1.8221, batch time: 0.94, accuracy:  33.50%\n",
      "Epoch [28/100], Step [60/60], Loss: 1.8164, batch time: 0.86, accuracy:  33.50%\n",
      "Epoch [29/100], Step [1/60], Loss: 1.8368, batch time: 0.92, accuracy:  32.80%\n",
      "Epoch [29/100], Step [2/60], Loss: 1.8288, batch time: 0.85, accuracy:  33.50%\n",
      "Epoch [29/100], Step [3/60], Loss: 1.8182, batch time: 1.06, accuracy:  34.40%\n",
      "Epoch [29/100], Step [4/60], Loss: 1.7850, batch time: 0.82, accuracy:  34.30%\n",
      "Epoch [29/100], Step [5/60], Loss: 1.7871, batch time: 1.05, accuracy:  36.50%\n",
      "Epoch [29/100], Step [6/60], Loss: 1.8246, batch time: 0.79, accuracy:  32.60%\n",
      "Epoch [29/100], Step [7/60], Loss: 1.8165, batch time: 0.79, accuracy:  34.50%\n",
      "Epoch [29/100], Step [8/60], Loss: 1.8035, batch time: 0.87, accuracy:  35.40%\n",
      "Epoch [29/100], Step [9/60], Loss: 1.7739, batch time: 0.96, accuracy:  35.60%\n",
      "Epoch [29/100], Step [10/60], Loss: 1.7867, batch time: 1.16, accuracy:  37.30%\n",
      "Epoch [29/100], Step [11/60], Loss: 1.7648, batch time: 1.10, accuracy:  34.90%\n",
      "Epoch [29/100], Step [12/60], Loss: 1.7954, batch time: 1.02, accuracy:  35.30%\n",
      "Epoch [29/100], Step [13/60], Loss: 1.7577, batch time: 0.87, accuracy:  37.30%\n",
      "Epoch [29/100], Step [14/60], Loss: 1.7676, batch time: 0.83, accuracy:  36.10%\n",
      "Epoch [29/100], Step [15/60], Loss: 1.8263, batch time: 0.67, accuracy:  33.30%\n",
      "Epoch [29/100], Step [16/60], Loss: 1.7731, batch time: 0.65, accuracy:  34.30%\n",
      "Epoch [29/100], Step [17/60], Loss: 1.7833, batch time: 0.71, accuracy:  35.20%\n",
      "Epoch [29/100], Step [18/60], Loss: 1.7592, batch time: 0.68, accuracy:  34.70%\n",
      "Epoch [29/100], Step [19/60], Loss: 1.7620, batch time: 0.69, accuracy:  36.70%\n",
      "Epoch [29/100], Step [20/60], Loss: 1.7846, batch time: 0.78, accuracy:  34.40%\n",
      "Epoch [29/100], Step [21/60], Loss: 1.7747, batch time: 0.89, accuracy:  33.70%\n",
      "Epoch [29/100], Step [22/60], Loss: 1.7983, batch time: 0.76, accuracy:  35.90%\n",
      "Epoch [29/100], Step [23/60], Loss: 1.8093, batch time: 0.76, accuracy:  33.00%\n",
      "Epoch [29/100], Step [24/60], Loss: 1.7940, batch time: 1.14, accuracy:  35.20%\n",
      "Epoch [29/100], Step [25/60], Loss: 1.7337, batch time: 1.01, accuracy:  37.30%\n",
      "Epoch [29/100], Step [26/60], Loss: 1.7656, batch time: 0.84, accuracy:  35.10%\n",
      "Epoch [29/100], Step [27/60], Loss: 1.8299, batch time: 0.83, accuracy:  35.30%\n",
      "Epoch [29/100], Step [28/60], Loss: 1.7880, batch time: 1.03, accuracy:  33.00%\n",
      "Epoch [29/100], Step [29/60], Loss: 1.7942, batch time: 1.05, accuracy:  33.20%\n",
      "Epoch [29/100], Step [30/60], Loss: 1.8002, batch time: 0.99, accuracy:  34.60%\n",
      "Epoch [29/100], Step [31/60], Loss: 1.7840, batch time: 0.68, accuracy:  35.50%\n",
      "Epoch [29/100], Step [32/60], Loss: 1.7337, batch time: 0.79, accuracy:  36.80%\n",
      "Epoch [29/100], Step [33/60], Loss: 1.7918, batch time: 0.70, accuracy:  32.40%\n",
      "Epoch [29/100], Step [34/60], Loss: 1.8016, batch time: 0.98, accuracy:  34.20%\n",
      "Epoch [29/100], Step [35/60], Loss: 1.7711, batch time: 0.79, accuracy:  34.60%\n",
      "Epoch [29/100], Step [36/60], Loss: 1.7576, batch time: 0.76, accuracy:  37.00%\n",
      "Epoch [29/100], Step [37/60], Loss: 1.8035, batch time: 0.72, accuracy:  35.70%\n",
      "Epoch [29/100], Step [38/60], Loss: 1.8259, batch time: 0.70, accuracy:  32.60%\n",
      "Epoch [29/100], Step [39/60], Loss: 1.7888, batch time: 0.81, accuracy:  33.20%\n",
      "Epoch [29/100], Step [40/60], Loss: 1.7848, batch time: 0.84, accuracy:  32.70%\n",
      "Epoch [29/100], Step [41/60], Loss: 1.7865, batch time: 0.84, accuracy:  32.50%\n",
      "Epoch [29/100], Step [42/60], Loss: 1.7946, batch time: 0.72, accuracy:  34.10%\n",
      "Epoch [29/100], Step [43/60], Loss: 1.7922, batch time: 0.72, accuracy:  34.30%\n",
      "Epoch [29/100], Step [44/60], Loss: 1.8481, batch time: 0.77, accuracy:  31.90%\n",
      "Epoch [29/100], Step [45/60], Loss: 1.7510, batch time: 0.70, accuracy:  36.80%\n",
      "Epoch [29/100], Step [46/60], Loss: 1.7924, batch time: 0.47, accuracy:  35.90%\n",
      "Epoch [29/100], Step [47/60], Loss: 1.7907, batch time: 0.54, accuracy:  33.80%\n",
      "Epoch [29/100], Step [48/60], Loss: 1.7833, batch time: 0.67, accuracy:  35.20%\n",
      "Epoch [29/100], Step [49/60], Loss: 1.7705, batch time: 0.45, accuracy:  35.60%\n",
      "Epoch [29/100], Step [50/60], Loss: 1.7988, batch time: 0.61, accuracy:  34.00%\n",
      "Epoch [29/100], Step [51/60], Loss: 1.7958, batch time: 0.62, accuracy:  32.90%\n",
      "Epoch [29/100], Step [52/60], Loss: 1.8297, batch time: 0.71, accuracy:  34.30%\n",
      "Epoch [29/100], Step [53/60], Loss: 1.8028, batch time: 0.61, accuracy:  33.90%\n",
      "Epoch [29/100], Step [54/60], Loss: 1.7722, batch time: 0.71, accuracy:  34.00%\n",
      "Epoch [29/100], Step [55/60], Loss: 1.8490, batch time: 0.71, accuracy:  31.70%\n",
      "Epoch [29/100], Step [56/60], Loss: 1.8077, batch time: 0.66, accuracy:  33.80%\n",
      "Epoch [29/100], Step [57/60], Loss: 1.8040, batch time: 0.71, accuracy:  33.40%\n",
      "Epoch [29/100], Step [58/60], Loss: 1.8114, batch time: 0.71, accuracy:  32.60%\n",
      "Epoch [29/100], Step [59/60], Loss: 1.7584, batch time: 0.70, accuracy:  35.10%\n",
      "Epoch [29/100], Step [60/60], Loss: 1.7834, batch time: 0.73, accuracy:  33.10%\n",
      "Epoch [30/100], Step [1/60], Loss: 1.7987, batch time: 0.65, accuracy:  34.50%\n",
      "Epoch [30/100], Step [2/60], Loss: 1.8119, batch time: 0.75, accuracy:  33.70%\n",
      "Epoch [30/100], Step [3/60], Loss: 1.8108, batch time: 0.64, accuracy:  33.70%\n",
      "Epoch [30/100], Step [4/60], Loss: 1.8002, batch time: 0.49, accuracy:  34.10%\n",
      "Epoch [30/100], Step [5/60], Loss: 1.7879, batch time: 0.61, accuracy:  34.70%\n",
      "Epoch [30/100], Step [6/60], Loss: 1.7953, batch time: 0.57, accuracy:  33.20%\n",
      "Epoch [30/100], Step [7/60], Loss: 1.8270, batch time: 0.55, accuracy:  32.50%\n",
      "Epoch [30/100], Step [8/60], Loss: 1.7748, batch time: 0.55, accuracy:  35.50%\n",
      "Epoch [30/100], Step [9/60], Loss: 1.7498, batch time: 0.54, accuracy:  36.30%\n",
      "Epoch [30/100], Step [10/60], Loss: 1.7440, batch time: 0.56, accuracy:  37.00%\n",
      "Epoch [30/100], Step [11/60], Loss: 1.8313, batch time: 0.54, accuracy:  34.90%\n",
      "Epoch [30/100], Step [12/60], Loss: 1.7729, batch time: 0.55, accuracy:  35.40%\n",
      "Epoch [30/100], Step [13/60], Loss: 1.7672, batch time: 0.54, accuracy:  36.10%\n",
      "Epoch [30/100], Step [14/60], Loss: 1.7672, batch time: 0.54, accuracy:  37.30%\n",
      "Epoch [30/100], Step [15/60], Loss: 1.8188, batch time: 0.54, accuracy:  32.10%\n",
      "Epoch [30/100], Step [16/60], Loss: 1.7960, batch time: 0.54, accuracy:  36.50%\n",
      "Epoch [30/100], Step [17/60], Loss: 1.7887, batch time: 0.54, accuracy:  36.40%\n",
      "Epoch [30/100], Step [18/60], Loss: 1.8132, batch time: 0.56, accuracy:  34.30%\n",
      "Epoch [30/100], Step [19/60], Loss: 1.7786, batch time: 0.54, accuracy:  36.00%\n",
      "Epoch [30/100], Step [20/60], Loss: 1.8253, batch time: 0.54, accuracy:  31.90%\n",
      "Epoch [30/100], Step [21/60], Loss: 1.7710, batch time: 0.54, accuracy:  35.20%\n",
      "Epoch [30/100], Step [22/60], Loss: 1.7742, batch time: 0.54, accuracy:  35.20%\n",
      "Epoch [30/100], Step [23/60], Loss: 1.7311, batch time: 0.54, accuracy:  37.40%\n",
      "Epoch [30/100], Step [24/60], Loss: 1.7705, batch time: 0.55, accuracy:  37.20%\n",
      "Epoch [30/100], Step [25/60], Loss: 1.7778, batch time: 0.55, accuracy:  34.60%\n",
      "Epoch [30/100], Step [26/60], Loss: 1.7750, batch time: 0.55, accuracy:  34.80%\n",
      "Epoch [30/100], Step [27/60], Loss: 1.7906, batch time: 0.49, accuracy:  34.70%\n",
      "Epoch [30/100], Step [28/60], Loss: 1.7928, batch time: 0.44, accuracy:  33.50%\n",
      "Epoch [30/100], Step [29/60], Loss: 1.7704, batch time: 0.44, accuracy:  36.40%\n",
      "Epoch [30/100], Step [30/60], Loss: 1.7754, batch time: 0.44, accuracy:  35.00%\n",
      "Epoch [30/100], Step [31/60], Loss: 1.7924, batch time: 0.44, accuracy:  35.10%\n",
      "Epoch [30/100], Step [32/60], Loss: 1.7544, batch time: 0.45, accuracy:  34.00%\n",
      "Epoch [30/100], Step [33/60], Loss: 1.7948, batch time: 0.44, accuracy:  34.80%\n",
      "Epoch [30/100], Step [34/60], Loss: 1.7892, batch time: 0.45, accuracy:  32.70%\n",
      "Epoch [30/100], Step [35/60], Loss: 1.7414, batch time: 0.45, accuracy:  35.50%\n",
      "Epoch [30/100], Step [36/60], Loss: 1.8133, batch time: 0.45, accuracy:  34.70%\n",
      "Epoch [30/100], Step [37/60], Loss: 1.7264, batch time: 0.45, accuracy:  37.50%\n",
      "Epoch [30/100], Step [38/60], Loss: 1.7908, batch time: 0.45, accuracy:  35.80%\n",
      "Epoch [30/100], Step [39/60], Loss: 1.7599, batch time: 0.45, accuracy:  37.30%\n",
      "Epoch [30/100], Step [40/60], Loss: 1.8216, batch time: 0.45, accuracy:  33.30%\n",
      "Epoch [30/100], Step [41/60], Loss: 1.7194, batch time: 0.45, accuracy:  36.40%\n",
      "Epoch [30/100], Step [42/60], Loss: 1.8078, batch time: 0.45, accuracy:  35.70%\n",
      "Epoch [30/100], Step [43/60], Loss: 1.8066, batch time: 0.45, accuracy:  32.90%\n",
      "Epoch [30/100], Step [44/60], Loss: 1.7903, batch time: 0.46, accuracy:  33.70%\n",
      "Epoch [30/100], Step [45/60], Loss: 1.7106, batch time: 0.45, accuracy:  35.50%\n",
      "Epoch [30/100], Step [46/60], Loss: 1.8011, batch time: 0.45, accuracy:  36.00%\n",
      "Epoch [30/100], Step [47/60], Loss: 1.7581, batch time: 0.45, accuracy:  36.40%\n",
      "Epoch [30/100], Step [48/60], Loss: 1.7623, batch time: 0.45, accuracy:  35.90%\n",
      "Epoch [30/100], Step [49/60], Loss: 1.7572, batch time: 0.46, accuracy:  35.80%\n",
      "Epoch [30/100], Step [50/60], Loss: 1.7617, batch time: 0.46, accuracy:  35.90%\n",
      "Epoch [30/100], Step [51/60], Loss: 1.7794, batch time: 0.51, accuracy:  34.50%\n",
      "Epoch [30/100], Step [52/60], Loss: 1.7977, batch time: 0.55, accuracy:  35.50%\n",
      "Epoch [30/100], Step [53/60], Loss: 1.8151, batch time: 0.53, accuracy:  32.00%\n",
      "Epoch [30/100], Step [54/60], Loss: 1.7985, batch time: 0.61, accuracy:  33.50%\n",
      "Epoch [30/100], Step [55/60], Loss: 1.7860, batch time: 0.54, accuracy:  36.10%\n",
      "Epoch [30/100], Step [56/60], Loss: 1.8078, batch time: 0.54, accuracy:  34.60%\n",
      "Epoch [30/100], Step [57/60], Loss: 1.7749, batch time: 0.54, accuracy:  33.20%\n",
      "Epoch [30/100], Step [58/60], Loss: 1.7853, batch time: 0.54, accuracy:  34.30%\n",
      "Epoch [30/100], Step [59/60], Loss: 1.8221, batch time: 0.54, accuracy:  31.80%\n",
      "Epoch [30/100], Step [60/60], Loss: 1.7370, batch time: 0.52, accuracy:  38.00%\n",
      "Epoch [31/100], Step [1/60], Loss: 1.7781, batch time: 0.47, accuracy:  35.70%\n",
      "Epoch [31/100], Step [2/60], Loss: 1.7790, batch time: 0.45, accuracy:  36.60%\n",
      "Epoch [31/100], Step [3/60], Loss: 1.8349, batch time: 0.45, accuracy:  32.10%\n",
      "Epoch [31/100], Step [4/60], Loss: 1.7466, batch time: 0.45, accuracy:  35.60%\n",
      "Epoch [31/100], Step [5/60], Loss: 1.8143, batch time: 0.45, accuracy:  32.00%\n",
      "Epoch [31/100], Step [6/60], Loss: 1.7615, batch time: 0.45, accuracy:  35.50%\n",
      "Epoch [31/100], Step [7/60], Loss: 1.8107, batch time: 0.46, accuracy:  33.60%\n",
      "Epoch [31/100], Step [8/60], Loss: 1.7521, batch time: 0.44, accuracy:  35.90%\n",
      "Epoch [31/100], Step [9/60], Loss: 1.8085, batch time: 0.47, accuracy:  31.60%\n",
      "Epoch [31/100], Step [10/60], Loss: 1.7622, batch time: 0.46, accuracy:  36.70%\n",
      "Epoch [31/100], Step [11/60], Loss: 1.7431, batch time: 0.45, accuracy:  35.60%\n",
      "Epoch [31/100], Step [12/60], Loss: 1.7861, batch time: 0.45, accuracy:  36.10%\n",
      "Epoch [31/100], Step [13/60], Loss: 1.7792, batch time: 0.45, accuracy:  35.30%\n",
      "Epoch [31/100], Step [14/60], Loss: 1.7664, batch time: 0.45, accuracy:  35.90%\n",
      "Epoch [31/100], Step [15/60], Loss: 1.7757, batch time: 0.45, accuracy:  36.10%\n",
      "Epoch [31/100], Step [16/60], Loss: 1.7387, batch time: 0.46, accuracy:  36.70%\n",
      "Epoch [31/100], Step [17/60], Loss: 1.7871, batch time: 0.45, accuracy:  35.10%\n",
      "Epoch [31/100], Step [18/60], Loss: 1.8045, batch time: 0.51, accuracy:  32.40%\n",
      "Epoch [31/100], Step [19/60], Loss: 1.7323, batch time: 0.60, accuracy:  37.20%\n",
      "Epoch [31/100], Step [20/60], Loss: 1.7494, batch time: 0.73, accuracy:  35.90%\n",
      "Epoch [31/100], Step [21/60], Loss: 1.8082, batch time: 0.72, accuracy:  36.30%\n",
      "Epoch [31/100], Step [22/60], Loss: 1.7112, batch time: 0.81, accuracy:  37.50%\n",
      "Epoch [31/100], Step [23/60], Loss: 1.6980, batch time: 0.96, accuracy:  38.70%\n",
      "Epoch [31/100], Step [24/60], Loss: 1.7736, batch time: 0.61, accuracy:  34.60%\n",
      "Epoch [31/100], Step [25/60], Loss: 1.8270, batch time: 0.70, accuracy:  31.90%\n",
      "Epoch [31/100], Step [26/60], Loss: 1.8006, batch time: 0.60, accuracy:  34.10%\n",
      "Epoch [31/100], Step [27/60], Loss: 1.7513, batch time: 0.77, accuracy:  35.70%\n",
      "Epoch [31/100], Step [28/60], Loss: 1.7927, batch time: 0.71, accuracy:  33.60%\n",
      "Epoch [31/100], Step [29/60], Loss: 1.7635, batch time: 0.70, accuracy:  34.80%\n",
      "Epoch [31/100], Step [30/60], Loss: 1.7689, batch time: 0.70, accuracy:  34.70%\n",
      "Epoch [31/100], Step [31/60], Loss: 1.7576, batch time: 0.71, accuracy:  35.20%\n",
      "Epoch [31/100], Step [32/60], Loss: 1.7254, batch time: 0.70, accuracy:  39.00%\n",
      "Epoch [31/100], Step [33/60], Loss: 1.7911, batch time: 0.70, accuracy:  34.50%\n",
      "Epoch [31/100], Step [34/60], Loss: 1.7536, batch time: 0.70, accuracy:  37.60%\n",
      "Epoch [31/100], Step [35/60], Loss: 1.7227, batch time: 0.61, accuracy:  36.30%\n",
      "Epoch [31/100], Step [36/60], Loss: 1.7533, batch time: 0.74, accuracy:  36.10%\n",
      "Epoch [31/100], Step [37/60], Loss: 1.7780, batch time: 0.71, accuracy:  34.20%\n",
      "Epoch [31/100], Step [38/60], Loss: 1.7954, batch time: 0.73, accuracy:  34.00%\n",
      "Epoch [31/100], Step [39/60], Loss: 1.7357, batch time: 0.83, accuracy:  36.10%\n",
      "Epoch [31/100], Step [40/60], Loss: 1.7384, batch time: 0.83, accuracy:  35.40%\n",
      "Epoch [31/100], Step [41/60], Loss: 1.7854, batch time: 0.83, accuracy:  33.70%\n",
      "Epoch [31/100], Step [42/60], Loss: 1.7270, batch time: 0.85, accuracy:  36.70%\n",
      "Epoch [31/100], Step [43/60], Loss: 1.7467, batch time: 0.79, accuracy:  35.70%\n",
      "Epoch [31/100], Step [44/60], Loss: 1.7320, batch time: 1.19, accuracy:  36.90%\n",
      "Epoch [31/100], Step [45/60], Loss: 1.7700, batch time: 0.93, accuracy:  35.30%\n",
      "Epoch [31/100], Step [46/60], Loss: 1.7768, batch time: 0.55, accuracy:  32.90%\n",
      "Epoch [31/100], Step [47/60], Loss: 1.7745, batch time: 0.79, accuracy:  37.10%\n",
      "Epoch [31/100], Step [48/60], Loss: 1.7721, batch time: 0.71, accuracy:  37.70%\n",
      "Epoch [31/100], Step [49/60], Loss: 1.7429, batch time: 0.62, accuracy:  36.70%\n",
      "Epoch [31/100], Step [50/60], Loss: 1.8282, batch time: 0.63, accuracy:  34.40%\n",
      "Epoch [31/100], Step [51/60], Loss: 1.8061, batch time: 0.63, accuracy:  34.30%\n",
      "Epoch [31/100], Step [52/60], Loss: 1.7621, batch time: 0.70, accuracy:  39.40%\n",
      "Epoch [31/100], Step [53/60], Loss: 1.7179, batch time: 0.69, accuracy:  36.30%\n",
      "Epoch [31/100], Step [54/60], Loss: 1.7489, batch time: 0.69, accuracy:  34.80%\n",
      "Epoch [31/100], Step [55/60], Loss: 1.6931, batch time: 0.70, accuracy:  37.00%\n",
      "Epoch [31/100], Step [56/60], Loss: 1.7291, batch time: 0.71, accuracy:  37.40%\n",
      "Epoch [31/100], Step [57/60], Loss: 1.7547, batch time: 0.81, accuracy:  35.10%\n",
      "Epoch [31/100], Step [58/60], Loss: 1.7757, batch time: 0.83, accuracy:  34.00%\n",
      "Epoch [31/100], Step [59/60], Loss: 1.7168, batch time: 0.83, accuracy:  36.10%\n",
      "Epoch [31/100], Step [60/60], Loss: 1.7532, batch time: 0.83, accuracy:  35.90%\n",
      "Epoch [32/100], Step [1/60], Loss: 1.7552, batch time: 0.83, accuracy:  35.10%\n",
      "Epoch [32/100], Step [2/60], Loss: 1.7699, batch time: 0.83, accuracy:  35.40%\n",
      "Epoch [32/100], Step [3/60], Loss: 1.7431, batch time: 0.83, accuracy:  34.10%\n",
      "Epoch [32/100], Step [4/60], Loss: 1.7681, batch time: 0.83, accuracy:  34.50%\n",
      "Epoch [32/100], Step [5/60], Loss: 1.8215, batch time: 0.83, accuracy:  32.90%\n",
      "Epoch [32/100], Step [6/60], Loss: 1.7545, batch time: 0.83, accuracy:  35.60%\n",
      "Epoch [32/100], Step [7/60], Loss: 1.7674, batch time: 0.82, accuracy:  36.30%\n",
      "Epoch [32/100], Step [8/60], Loss: 1.7431, batch time: 0.69, accuracy:  35.90%\n",
      "Epoch [32/100], Step [9/60], Loss: 1.7907, batch time: 0.76, accuracy:  34.60%\n",
      "Epoch [32/100], Step [10/60], Loss: 1.7607, batch time: 0.60, accuracy:  36.10%\n",
      "Epoch [32/100], Step [11/60], Loss: 1.7522, batch time: 0.69, accuracy:  35.70%\n",
      "Epoch [32/100], Step [12/60], Loss: 1.7302, batch time: 0.58, accuracy:  35.20%\n",
      "Epoch [32/100], Step [13/60], Loss: 1.6890, batch time: 0.69, accuracy:  38.70%\n",
      "Epoch [32/100], Step [14/60], Loss: 1.7847, batch time: 0.69, accuracy:  34.70%\n",
      "Epoch [32/100], Step [15/60], Loss: 1.7529, batch time: 0.69, accuracy:  36.40%\n",
      "Epoch [32/100], Step [16/60], Loss: 1.7305, batch time: 0.69, accuracy:  38.50%\n",
      "Epoch [32/100], Step [17/60], Loss: 1.7484, batch time: 0.69, accuracy:  35.00%\n",
      "Epoch [32/100], Step [18/60], Loss: 1.7587, batch time: 0.68, accuracy:  35.60%\n",
      "Epoch [32/100], Step [19/60], Loss: 1.7701, batch time: 0.69, accuracy:  35.60%\n",
      "Epoch [32/100], Step [20/60], Loss: 1.8018, batch time: 0.69, accuracy:  33.40%\n",
      "Epoch [32/100], Step [21/60], Loss: 1.7357, batch time: 0.72, accuracy:  36.60%\n",
      "Epoch [32/100], Step [22/60], Loss: 1.7132, batch time: 0.72, accuracy:  38.50%\n",
      "Epoch [32/100], Step [23/60], Loss: 1.7266, batch time: 0.75, accuracy:  36.70%\n",
      "Epoch [32/100], Step [24/60], Loss: 1.7460, batch time: 0.73, accuracy:  36.60%\n",
      "Epoch [32/100], Step [25/60], Loss: 1.7245, batch time: 0.72, accuracy:  35.20%\n",
      "Epoch [32/100], Step [26/60], Loss: 1.7485, batch time: 0.84, accuracy:  36.40%\n",
      "Epoch [32/100], Step [27/60], Loss: 1.7514, batch time: 0.83, accuracy:  36.30%\n",
      "Epoch [32/100], Step [28/60], Loss: 1.8037, batch time: 0.70, accuracy:  32.20%\n",
      "Epoch [32/100], Step [29/60], Loss: 1.7239, batch time: 0.69, accuracy:  36.80%\n",
      "Epoch [32/100], Step [30/60], Loss: 1.7430, batch time: 0.69, accuracy:  36.60%\n",
      "Epoch [32/100], Step [31/60], Loss: 1.7546, batch time: 0.70, accuracy:  37.00%\n",
      "Epoch [32/100], Step [32/60], Loss: 1.7152, batch time: 0.69, accuracy:  36.70%\n",
      "Epoch [32/100], Step [33/60], Loss: 1.7409, batch time: 0.69, accuracy:  36.70%\n",
      "Epoch [32/100], Step [34/60], Loss: 1.7196, batch time: 0.69, accuracy:  37.10%\n",
      "Epoch [32/100], Step [35/60], Loss: 1.7654, batch time: 0.71, accuracy:  35.90%\n",
      "Epoch [32/100], Step [36/60], Loss: 1.7319, batch time: 0.69, accuracy:  37.20%\n",
      "Epoch [32/100], Step [37/60], Loss: 1.7828, batch time: 0.64, accuracy:  33.20%\n",
      "Epoch [32/100], Step [38/60], Loss: 1.7920, batch time: 0.70, accuracy:  34.30%\n",
      "Epoch [32/100], Step [39/60], Loss: 1.7385, batch time: 0.69, accuracy:  35.60%\n",
      "Epoch [32/100], Step [40/60], Loss: 1.7413, batch time: 0.74, accuracy:  35.40%\n",
      "Epoch [32/100], Step [41/60], Loss: 1.7385, batch time: 0.74, accuracy:  37.20%\n",
      "Epoch [32/100], Step [42/60], Loss: 1.7253, batch time: 0.75, accuracy:  36.80%\n",
      "Epoch [32/100], Step [43/60], Loss: 1.7206, batch time: 0.74, accuracy:  36.60%\n",
      "Epoch [32/100], Step [44/60], Loss: 1.7898, batch time: 0.75, accuracy:  33.80%\n",
      "Epoch [32/100], Step [45/60], Loss: 1.7159, batch time: 0.64, accuracy:  38.10%\n",
      "Epoch [32/100], Step [46/60], Loss: 1.7549, batch time: 0.75, accuracy:  34.90%\n",
      "Epoch [32/100], Step [47/60], Loss: 1.7129, batch time: 0.75, accuracy:  35.90%\n",
      "Epoch [32/100], Step [48/60], Loss: 1.7557, batch time: 0.74, accuracy:  36.80%\n",
      "Epoch [32/100], Step [49/60], Loss: 1.7315, batch time: 0.74, accuracy:  36.60%\n",
      "Epoch [32/100], Step [50/60], Loss: 1.7396, batch time: 0.73, accuracy:  36.00%\n",
      "Epoch [32/100], Step [51/60], Loss: 1.7432, batch time: 0.74, accuracy:  36.50%\n",
      "Epoch [32/100], Step [52/60], Loss: 1.7730, batch time: 0.68, accuracy:  34.60%\n",
      "Epoch [32/100], Step [53/60], Loss: 1.7117, batch time: 0.73, accuracy:  37.00%\n",
      "Epoch [32/100], Step [54/60], Loss: 1.7596, batch time: 0.76, accuracy:  35.90%\n",
      "Epoch [32/100], Step [55/60], Loss: 1.7226, batch time: 0.76, accuracy:  38.00%\n",
      "Epoch [32/100], Step [56/60], Loss: 1.7661, batch time: 0.86, accuracy:  36.80%\n",
      "Epoch [32/100], Step [57/60], Loss: 1.7592, batch time: 0.87, accuracy:  36.50%\n",
      "Epoch [32/100], Step [58/60], Loss: 1.7232, batch time: 0.83, accuracy:  36.90%\n",
      "Epoch [32/100], Step [59/60], Loss: 1.7679, batch time: 0.75, accuracy:  36.60%\n",
      "Epoch [32/100], Step [60/60], Loss: 1.7211, batch time: 0.85, accuracy:  36.90%\n",
      "Epoch [33/100], Step [1/60], Loss: 1.7135, batch time: 0.81, accuracy:  38.00%\n",
      "Epoch [33/100], Step [2/60], Loss: 1.7695, batch time: 0.62, accuracy:  35.60%\n",
      "Epoch [33/100], Step [3/60], Loss: 1.7692, batch time: 0.69, accuracy:  35.00%\n",
      "Epoch [33/100], Step [4/60], Loss: 1.7829, batch time: 0.69, accuracy:  36.30%\n",
      "Epoch [33/100], Step [5/60], Loss: 1.7447, batch time: 0.70, accuracy:  36.20%\n",
      "Epoch [33/100], Step [6/60], Loss: 1.7256, batch time: 0.70, accuracy:  36.90%\n",
      "Epoch [33/100], Step [7/60], Loss: 1.7459, batch time: 0.67, accuracy:  37.20%\n",
      "Epoch [33/100], Step [8/60], Loss: 1.7051, batch time: 0.49, accuracy:  37.10%\n",
      "Epoch [33/100], Step [9/60], Loss: 1.7497, batch time: 0.44, accuracy:  34.80%\n",
      "Epoch [33/100], Step [10/60], Loss: 1.7303, batch time: 0.67, accuracy:  35.10%\n",
      "Epoch [33/100], Step [11/60], Loss: 1.7715, batch time: 0.70, accuracy:  31.40%\n",
      "Epoch [33/100], Step [12/60], Loss: 1.6971, batch time: 0.70, accuracy:  39.40%\n",
      "Epoch [33/100], Step [13/60], Loss: 1.7711, batch time: 0.70, accuracy:  36.40%\n",
      "Epoch [33/100], Step [14/60], Loss: 1.7415, batch time: 0.71, accuracy:  37.40%\n",
      "Epoch [33/100], Step [15/60], Loss: 1.7236, batch time: 0.62, accuracy:  36.70%\n",
      "Epoch [33/100], Step [16/60], Loss: 1.7701, batch time: 0.64, accuracy:  37.10%\n",
      "Epoch [33/100], Step [17/60], Loss: 1.7547, batch time: 0.75, accuracy:  34.80%\n",
      "Epoch [33/100], Step [18/60], Loss: 1.7601, batch time: 0.73, accuracy:  35.40%\n",
      "Epoch [33/100], Step [19/60], Loss: 1.7349, batch time: 0.73, accuracy:  36.40%\n",
      "Epoch [33/100], Step [20/60], Loss: 1.7245, batch time: 0.73, accuracy:  37.80%\n",
      "Epoch [33/100], Step [21/60], Loss: 1.7530, batch time: 0.73, accuracy:  34.80%\n",
      "Epoch [33/100], Step [22/60], Loss: 1.7189, batch time: 0.82, accuracy:  36.50%\n",
      "Epoch [33/100], Step [23/60], Loss: 1.7253, batch time: 0.74, accuracy:  36.50%\n",
      "Epoch [33/100], Step [24/60], Loss: 1.7397, batch time: 0.78, accuracy:  37.00%\n",
      "Epoch [33/100], Step [25/60], Loss: 1.6986, batch time: 0.77, accuracy:  36.80%\n",
      "Epoch [33/100], Step [26/60], Loss: 1.7484, batch time: 0.73, accuracy:  35.80%\n",
      "Epoch [33/100], Step [27/60], Loss: 1.7598, batch time: 0.84, accuracy:  38.60%\n",
      "Epoch [33/100], Step [28/60], Loss: 1.7489, batch time: 0.70, accuracy:  35.00%\n",
      "Epoch [33/100], Step [29/60], Loss: 1.7599, batch time: 0.69, accuracy:  36.80%\n",
      "Epoch [33/100], Step [30/60], Loss: 1.7303, batch time: 0.67, accuracy:  36.20%\n",
      "Epoch [33/100], Step [31/60], Loss: 1.7434, batch time: 0.56, accuracy:  37.00%\n",
      "Epoch [33/100], Step [32/60], Loss: 1.7182, batch time: 0.68, accuracy:  38.70%\n",
      "Epoch [33/100], Step [33/60], Loss: 1.7451, batch time: 0.62, accuracy:  36.20%\n",
      "Epoch [33/100], Step [34/60], Loss: 1.7291, batch time: 0.70, accuracy:  36.90%\n",
      "Epoch [33/100], Step [35/60], Loss: 1.7142, batch time: 0.55, accuracy:  38.20%\n",
      "Epoch [33/100], Step [36/60], Loss: 1.7537, batch time: 0.54, accuracy:  34.30%\n",
      "Epoch [33/100], Step [37/60], Loss: 1.7842, batch time: 0.63, accuracy:  34.70%\n",
      "Epoch [33/100], Step [38/60], Loss: 1.7255, batch time: 0.67, accuracy:  37.50%\n",
      "Epoch [33/100], Step [39/60], Loss: 1.7220, batch time: 0.54, accuracy:  36.40%\n",
      "Epoch [33/100], Step [40/60], Loss: 1.7041, batch time: 0.67, accuracy:  37.70%\n",
      "Epoch [33/100], Step [41/60], Loss: 1.7244, batch time: 0.46, accuracy:  35.80%\n",
      "Epoch [33/100], Step [42/60], Loss: 1.7226, batch time: 0.72, accuracy:  36.30%\n",
      "Epoch [33/100], Step [43/60], Loss: 1.7154, batch time: 0.71, accuracy:  37.00%\n",
      "Epoch [33/100], Step [44/60], Loss: 1.7181, batch time: 0.68, accuracy:  37.60%\n",
      "Epoch [33/100], Step [45/60], Loss: 1.7170, batch time: 0.71, accuracy:  37.30%\n",
      "Epoch [33/100], Step [46/60], Loss: 1.7803, batch time: 0.61, accuracy:  34.80%\n",
      "Epoch [33/100], Step [47/60], Loss: 1.7353, batch time: 0.63, accuracy:  37.40%\n",
      "Epoch [33/100], Step [48/60], Loss: 1.7816, batch time: 0.72, accuracy:  34.70%\n",
      "Epoch [33/100], Step [49/60], Loss: 1.7289, batch time: 0.73, accuracy:  37.10%\n",
      "Epoch [33/100], Step [50/60], Loss: 1.7007, batch time: 0.50, accuracy:  36.90%\n",
      "Epoch [33/100], Step [51/60], Loss: 1.7241, batch time: 0.47, accuracy:  36.20%\n",
      "Epoch [33/100], Step [52/60], Loss: 1.7589, batch time: 0.69, accuracy:  38.30%\n",
      "Epoch [33/100], Step [53/60], Loss: 1.7062, batch time: 0.52, accuracy:  39.50%\n",
      "Epoch [33/100], Step [54/60], Loss: 1.6866, batch time: 0.45, accuracy:  38.70%\n",
      "Epoch [33/100], Step [55/60], Loss: 1.7183, batch time: 0.47, accuracy:  34.60%\n",
      "Epoch [33/100], Step [56/60], Loss: 1.6860, batch time: 0.46, accuracy:  39.30%\n",
      "Epoch [33/100], Step [57/60], Loss: 1.7363, batch time: 0.46, accuracy:  38.10%\n",
      "Epoch [33/100], Step [58/60], Loss: 1.7497, batch time: 0.46, accuracy:  34.40%\n",
      "Epoch [33/100], Step [59/60], Loss: 1.7381, batch time: 0.46, accuracy:  35.90%\n",
      "Epoch [33/100], Step [60/60], Loss: 1.7194, batch time: 0.46, accuracy:  35.10%\n",
      "Epoch [34/100], Step [1/60], Loss: 1.7956, batch time: 0.49, accuracy:  33.10%\n",
      "Epoch [34/100], Step [2/60], Loss: 1.7873, batch time: 0.69, accuracy:  34.40%\n",
      "Epoch [34/100], Step [3/60], Loss: 1.7275, batch time: 0.73, accuracy:  35.90%\n",
      "Epoch [34/100], Step [4/60], Loss: 1.7206, batch time: 0.57, accuracy:  36.90%\n",
      "Epoch [34/100], Step [5/60], Loss: 1.6722, batch time: 0.74, accuracy:  40.10%\n",
      "Epoch [34/100], Step [6/60], Loss: 1.7201, batch time: 0.74, accuracy:  35.80%\n",
      "Epoch [34/100], Step [7/60], Loss: 1.7611, batch time: 0.81, accuracy:  35.90%\n",
      "Epoch [34/100], Step [8/60], Loss: 1.7462, batch time: 0.74, accuracy:  36.90%\n",
      "Epoch [34/100], Step [9/60], Loss: 1.6922, batch time: 0.72, accuracy:  38.50%\n",
      "Epoch [34/100], Step [10/60], Loss: 1.7152, batch time: 0.71, accuracy:  36.50%\n",
      "Epoch [34/100], Step [11/60], Loss: 1.7053, batch time: 0.58, accuracy:  38.00%\n",
      "Epoch [34/100], Step [12/60], Loss: 1.7334, batch time: 0.69, accuracy:  37.20%\n",
      "Epoch [34/100], Step [13/60], Loss: 1.6874, batch time: 0.74, accuracy:  37.40%\n",
      "Epoch [34/100], Step [14/60], Loss: 1.7344, batch time: 0.72, accuracy:  35.00%\n",
      "Epoch [34/100], Step [15/60], Loss: 1.7427, batch time: 0.82, accuracy:  36.20%\n",
      "Epoch [34/100], Step [16/60], Loss: 1.7170, batch time: 0.71, accuracy:  36.40%\n",
      "Epoch [34/100], Step [17/60], Loss: 1.7084, batch time: 0.65, accuracy:  37.80%\n",
      "Epoch [34/100], Step [18/60], Loss: 1.7531, batch time: 0.63, accuracy:  34.70%\n",
      "Epoch [34/100], Step [19/60], Loss: 1.7572, batch time: 0.59, accuracy:  35.70%\n",
      "Epoch [34/100], Step [20/60], Loss: 1.7175, batch time: 0.49, accuracy:  37.60%\n",
      "Epoch [34/100], Step [21/60], Loss: 1.6941, batch time: 0.50, accuracy:  37.80%\n",
      "Epoch [34/100], Step [22/60], Loss: 1.7249, batch time: 0.67, accuracy:  39.10%\n",
      "Epoch [34/100], Step [23/60], Loss: 1.6890, batch time: 0.72, accuracy:  37.90%\n",
      "Epoch [34/100], Step [24/60], Loss: 1.7504, batch time: 0.67, accuracy:  36.60%\n",
      "Epoch [34/100], Step [25/60], Loss: 1.7330, batch time: 0.73, accuracy:  35.50%\n",
      "Epoch [34/100], Step [26/60], Loss: 1.7508, batch time: 0.71, accuracy:  36.30%\n",
      "Epoch [34/100], Step [27/60], Loss: 1.7360, batch time: 0.73, accuracy:  36.70%\n",
      "Epoch [34/100], Step [28/60], Loss: 1.7436, batch time: 0.72, accuracy:  35.90%\n",
      "Epoch [34/100], Step [29/60], Loss: 1.6875, batch time: 0.71, accuracy:  38.70%\n",
      "Epoch [34/100], Step [30/60], Loss: 1.7160, batch time: 0.73, accuracy:  37.60%\n",
      "Epoch [34/100], Step [31/60], Loss: 1.7368, batch time: 0.74, accuracy:  38.00%\n",
      "Epoch [34/100], Step [32/60], Loss: 1.6884, batch time: 0.73, accuracy:  38.90%\n",
      "Epoch [34/100], Step [33/60], Loss: 1.6854, batch time: 0.85, accuracy:  40.00%\n",
      "Epoch [34/100], Step [34/60], Loss: 1.7372, batch time: 0.87, accuracy:  35.90%\n",
      "Epoch [34/100], Step [35/60], Loss: 1.6545, batch time: 0.88, accuracy:  39.60%\n",
      "Epoch [34/100], Step [36/60], Loss: 1.7653, batch time: 0.87, accuracy:  36.50%\n",
      "Epoch [34/100], Step [37/60], Loss: 1.7073, batch time: 0.88, accuracy:  37.70%\n",
      "Epoch [34/100], Step [38/60], Loss: 1.6952, batch time: 0.87, accuracy:  38.60%\n",
      "Epoch [34/100], Step [39/60], Loss: 1.6907, batch time: 0.63, accuracy:  39.50%\n",
      "Epoch [34/100], Step [40/60], Loss: 1.7615, batch time: 0.69, accuracy:  36.20%\n",
      "Epoch [34/100], Step [41/60], Loss: 1.7473, batch time: 0.62, accuracy:  35.20%\n",
      "Epoch [34/100], Step [42/60], Loss: 1.6821, batch time: 0.69, accuracy:  39.10%\n",
      "Epoch [34/100], Step [43/60], Loss: 1.7175, batch time: 0.62, accuracy:  36.70%\n",
      "Epoch [34/100], Step [44/60], Loss: 1.7375, batch time: 0.69, accuracy:  35.30%\n",
      "Epoch [34/100], Step [45/60], Loss: 1.7001, batch time: 0.62, accuracy:  37.00%\n",
      "Epoch [34/100], Step [46/60], Loss: 1.7145, batch time: 0.69, accuracy:  37.60%\n",
      "Epoch [34/100], Step [47/60], Loss: 1.7110, batch time: 0.72, accuracy:  36.20%\n",
      "Epoch [34/100], Step [48/60], Loss: 1.7072, batch time: 0.65, accuracy:  37.50%\n",
      "Epoch [34/100], Step [49/60], Loss: 1.7181, batch time: 0.77, accuracy:  37.00%\n",
      "Epoch [34/100], Step [50/60], Loss: 1.7398, batch time: 0.63, accuracy:  37.70%\n",
      "Epoch [34/100], Step [51/60], Loss: 1.7226, batch time: 0.71, accuracy:  35.00%\n",
      "Epoch [34/100], Step [52/60], Loss: 1.7264, batch time: 0.70, accuracy:  36.80%\n",
      "Epoch [34/100], Step [53/60], Loss: 1.6836, batch time: 0.72, accuracy:  37.60%\n",
      "Epoch [34/100], Step [54/60], Loss: 1.7069, batch time: 0.62, accuracy:  37.40%\n",
      "Epoch [34/100], Step [55/60], Loss: 1.6868, batch time: 0.62, accuracy:  38.10%\n",
      "Epoch [34/100], Step [56/60], Loss: 1.7361, batch time: 0.72, accuracy:  37.00%\n",
      "Epoch [34/100], Step [57/60], Loss: 1.7216, batch time: 0.42, accuracy:  35.90%\n",
      "Epoch [34/100], Step [58/60], Loss: 1.7125, batch time: 0.44, accuracy:  39.20%\n",
      "Epoch [34/100], Step [59/60], Loss: 1.6991, batch time: 0.42, accuracy:  37.10%\n",
      "Epoch [34/100], Step [60/60], Loss: 1.7577, batch time: 0.42, accuracy:  34.50%\n",
      "Epoch [35/100], Step [1/60], Loss: 1.7079, batch time: 0.48, accuracy:  38.30%\n",
      "Epoch [35/100], Step [2/60], Loss: 1.7295, batch time: 0.73, accuracy:  36.50%\n",
      "Epoch [35/100], Step [3/60], Loss: 1.6898, batch time: 0.44, accuracy:  38.40%\n",
      "Epoch [35/100], Step [4/60], Loss: 1.7097, batch time: 0.44, accuracy:  38.70%\n",
      "Epoch [35/100], Step [5/60], Loss: 1.6957, batch time: 0.43, accuracy:  38.30%\n",
      "Epoch [35/100], Step [6/60], Loss: 1.6942, batch time: 0.44, accuracy:  38.40%\n",
      "Epoch [35/100], Step [7/60], Loss: 1.7316, batch time: 0.42, accuracy:  38.10%\n",
      "Epoch [35/100], Step [8/60], Loss: 1.7203, batch time: 0.43, accuracy:  36.10%\n",
      "Epoch [35/100], Step [9/60], Loss: 1.7104, batch time: 0.43, accuracy:  37.10%\n",
      "Epoch [35/100], Step [10/60], Loss: 1.6535, batch time: 0.42, accuracy:  41.90%\n",
      "Epoch [35/100], Step [11/60], Loss: 1.7471, batch time: 0.43, accuracy:  37.70%\n",
      "Epoch [35/100], Step [12/60], Loss: 1.7721, batch time: 0.43, accuracy:  37.50%\n",
      "Epoch [35/100], Step [13/60], Loss: 1.7726, batch time: 0.43, accuracy:  35.70%\n",
      "Epoch [35/100], Step [14/60], Loss: 1.7405, batch time: 0.47, accuracy:  34.60%\n",
      "Epoch [35/100], Step [15/60], Loss: 1.7310, batch time: 0.46, accuracy:  36.90%\n",
      "Epoch [35/100], Step [16/60], Loss: 1.7095, batch time: 0.45, accuracy:  36.40%\n",
      "Epoch [35/100], Step [17/60], Loss: 1.7631, batch time: 0.47, accuracy:  34.20%\n",
      "Epoch [35/100], Step [18/60], Loss: 1.7013, batch time: 0.46, accuracy:  38.40%\n",
      "Epoch [35/100], Step [19/60], Loss: 1.7627, batch time: 0.46, accuracy:  37.20%\n",
      "Epoch [35/100], Step [20/60], Loss: 1.7253, batch time: 0.46, accuracy:  36.40%\n",
      "Epoch [35/100], Step [21/60], Loss: 1.6882, batch time: 0.46, accuracy:  37.90%\n",
      "Epoch [35/100], Step [22/60], Loss: 1.7186, batch time: 0.49, accuracy:  35.20%\n",
      "Epoch [35/100], Step [23/60], Loss: 1.7152, batch time: 0.47, accuracy:  37.80%\n",
      "Epoch [35/100], Step [24/60], Loss: 1.6742, batch time: 0.46, accuracy:  40.40%\n",
      "Epoch [35/100], Step [25/60], Loss: 1.7279, batch time: 0.53, accuracy:  37.40%\n",
      "Epoch [35/100], Step [26/60], Loss: 1.6944, batch time: 0.47, accuracy:  36.00%\n",
      "Epoch [35/100], Step [27/60], Loss: 1.7382, batch time: 0.46, accuracy:  37.40%\n",
      "Epoch [35/100], Step [28/60], Loss: 1.7013, batch time: 0.47, accuracy:  34.90%\n",
      "Epoch [35/100], Step [29/60], Loss: 1.7276, batch time: 0.46, accuracy:  35.80%\n",
      "Epoch [35/100], Step [30/60], Loss: 1.6582, batch time: 0.46, accuracy:  40.10%\n",
      "Epoch [35/100], Step [31/60], Loss: 1.6970, batch time: 0.49, accuracy:  37.20%\n",
      "Epoch [35/100], Step [32/60], Loss: 1.7014, batch time: 0.46, accuracy:  38.00%\n",
      "Epoch [35/100], Step [33/60], Loss: 1.7518, batch time: 0.47, accuracy:  35.50%\n",
      "Epoch [35/100], Step [34/60], Loss: 1.7430, batch time: 0.46, accuracy:  35.30%\n",
      "Epoch [35/100], Step [35/60], Loss: 1.6586, batch time: 0.46, accuracy:  39.40%\n",
      "Epoch [35/100], Step [36/60], Loss: 1.6975, batch time: 0.48, accuracy:  38.00%\n",
      "Epoch [35/100], Step [37/60], Loss: 1.6973, batch time: 0.46, accuracy:  36.70%\n",
      "Epoch [35/100], Step [38/60], Loss: 1.7317, batch time: 0.46, accuracy:  35.50%\n",
      "Epoch [35/100], Step [39/60], Loss: 1.7484, batch time: 0.46, accuracy:  34.50%\n",
      "Epoch [35/100], Step [40/60], Loss: 1.7380, batch time: 0.49, accuracy:  35.10%\n",
      "Epoch [35/100], Step [41/60], Loss: 1.6770, batch time: 0.46, accuracy:  37.50%\n",
      "Epoch [35/100], Step [42/60], Loss: 1.6540, batch time: 0.48, accuracy:  41.00%\n",
      "Epoch [35/100], Step [43/60], Loss: 1.6634, batch time: 0.45, accuracy:  39.50%\n",
      "Epoch [35/100], Step [44/60], Loss: 1.6955, batch time: 0.47, accuracy:  36.10%\n",
      "Epoch [35/100], Step [45/60], Loss: 1.7288, batch time: 0.46, accuracy:  38.20%\n",
      "Epoch [35/100], Step [46/60], Loss: 1.7088, batch time: 0.45, accuracy:  37.70%\n",
      "Epoch [35/100], Step [47/60], Loss: 1.6968, batch time: 0.47, accuracy:  39.60%\n",
      "Epoch [35/100], Step [48/60], Loss: 1.6786, batch time: 0.46, accuracy:  40.50%\n",
      "Epoch [35/100], Step [49/60], Loss: 1.6609, batch time: 0.49, accuracy:  39.90%\n",
      "Epoch [35/100], Step [50/60], Loss: 1.6946, batch time: 0.47, accuracy:  39.10%\n",
      "Epoch [35/100], Step [51/60], Loss: 1.7285, batch time: 0.49, accuracy:  37.30%\n",
      "Epoch [35/100], Step [52/60], Loss: 1.6310, batch time: 0.55, accuracy:  39.20%\n",
      "Epoch [35/100], Step [53/60], Loss: 1.6775, batch time: 0.53, accuracy:  38.10%\n",
      "Epoch [35/100], Step [54/60], Loss: 1.6668, batch time: 0.54, accuracy:  38.70%\n",
      "Epoch [35/100], Step [55/60], Loss: 1.7169, batch time: 0.43, accuracy:  36.80%\n",
      "Epoch [35/100], Step [56/60], Loss: 1.7233, batch time: 0.42, accuracy:  35.80%\n",
      "Epoch [35/100], Step [57/60], Loss: 1.6778, batch time: 0.43, accuracy:  38.20%\n",
      "Epoch [35/100], Step [58/60], Loss: 1.7158, batch time: 0.44, accuracy:  37.20%\n",
      "Epoch [35/100], Step [59/60], Loss: 1.7282, batch time: 0.42, accuracy:  37.20%\n",
      "Epoch [35/100], Step [60/60], Loss: 1.7400, batch time: 0.43, accuracy:  36.80%\n",
      "Epoch [36/100], Step [1/60], Loss: 1.7033, batch time: 0.70, accuracy:  38.20%\n",
      "Epoch [36/100], Step [2/60], Loss: 1.7184, batch time: 0.70, accuracy:  36.50%\n",
      "Epoch [36/100], Step [3/60], Loss: 1.6949, batch time: 0.69, accuracy:  38.90%\n",
      "Epoch [36/100], Step [4/60], Loss: 1.6525, batch time: 0.70, accuracy:  38.90%\n",
      "Epoch [36/100], Step [5/60], Loss: 1.7035, batch time: 0.70, accuracy:  38.20%\n",
      "Epoch [36/100], Step [6/60], Loss: 1.7048, batch time: 0.70, accuracy:  38.00%\n",
      "Epoch [36/100], Step [7/60], Loss: 1.6848, batch time: 0.70, accuracy:  39.20%\n",
      "Epoch [36/100], Step [8/60], Loss: 1.6666, batch time: 0.70, accuracy:  40.00%\n",
      "Epoch [36/100], Step [9/60], Loss: 1.6915, batch time: 0.74, accuracy:  37.50%\n",
      "Epoch [36/100], Step [10/60], Loss: 1.6977, batch time: 0.75, accuracy:  39.50%\n",
      "Epoch [36/100], Step [11/60], Loss: 1.7154, batch time: 0.75, accuracy:  37.40%\n",
      "Epoch [36/100], Step [12/60], Loss: 1.6451, batch time: 0.75, accuracy:  38.10%\n",
      "Epoch [36/100], Step [13/60], Loss: 1.6950, batch time: 0.75, accuracy:  38.80%\n",
      "Epoch [36/100], Step [14/60], Loss: 1.7430, batch time: 0.92, accuracy:  36.50%\n",
      "Epoch [36/100], Step [15/60], Loss: 1.6845, batch time: 0.87, accuracy:  39.50%\n",
      "Epoch [36/100], Step [16/60], Loss: 1.6881, batch time: 0.88, accuracy:  37.10%\n",
      "Epoch [36/100], Step [17/60], Loss: 1.6812, batch time: 0.85, accuracy:  39.40%\n",
      "Epoch [36/100], Step [18/60], Loss: 1.6435, batch time: 0.85, accuracy:  39.20%\n",
      "Epoch [36/100], Step [19/60], Loss: 1.7153, batch time: 0.71, accuracy:  38.50%\n",
      "Epoch [36/100], Step [20/60], Loss: 1.6767, batch time: 0.69, accuracy:  39.20%\n",
      "Epoch [36/100], Step [21/60], Loss: 1.6955, batch time: 0.71, accuracy:  38.70%\n",
      "Epoch [36/100], Step [22/60], Loss: 1.7060, batch time: 0.69, accuracy:  36.40%\n",
      "Epoch [36/100], Step [23/60], Loss: 1.7525, batch time: 0.70, accuracy:  36.50%\n",
      "Epoch [36/100], Step [24/60], Loss: 1.6892, batch time: 0.45, accuracy:  37.60%\n",
      "Epoch [36/100], Step [25/60], Loss: 1.7004, batch time: 0.46, accuracy:  38.00%\n",
      "Epoch [36/100], Step [26/60], Loss: 1.6506, batch time: 0.45, accuracy:  39.70%\n",
      "Epoch [36/100], Step [27/60], Loss: 1.7168, batch time: 0.45, accuracy:  37.70%\n",
      "Epoch [36/100], Step [28/60], Loss: 1.6538, batch time: 0.48, accuracy:  37.70%\n",
      "Epoch [36/100], Step [29/60], Loss: 1.7557, batch time: 0.45, accuracy:  35.80%\n",
      "Epoch [36/100], Step [30/60], Loss: 1.7273, batch time: 0.45, accuracy:  36.70%\n",
      "Epoch [36/100], Step [31/60], Loss: 1.7849, batch time: 0.51, accuracy:  34.80%\n",
      "Epoch [36/100], Step [32/60], Loss: 1.6822, batch time: 0.64, accuracy:  39.50%\n",
      "Epoch [36/100], Step [33/60], Loss: 1.6630, batch time: 0.68, accuracy:  38.30%\n",
      "Epoch [36/100], Step [34/60], Loss: 1.6884, batch time: 0.72, accuracy:  37.30%\n",
      "Epoch [36/100], Step [35/60], Loss: 1.6693, batch time: 0.72, accuracy:  40.70%\n",
      "Epoch [36/100], Step [36/60], Loss: 1.7031, batch time: 0.72, accuracy:  36.60%\n",
      "Epoch [36/100], Step [37/60], Loss: 1.7180, batch time: 0.66, accuracy:  37.40%\n",
      "Epoch [36/100], Step [38/60], Loss: 1.6580, batch time: 0.55, accuracy:  40.60%\n",
      "Epoch [36/100], Step [39/60], Loss: 1.7082, batch time: 0.68, accuracy:  37.70%\n",
      "Epoch [36/100], Step [40/60], Loss: 1.7119, batch time: 0.65, accuracy:  37.30%\n",
      "Epoch [36/100], Step [41/60], Loss: 1.7147, batch time: 0.87, accuracy:  37.30%\n",
      "Epoch [36/100], Step [42/60], Loss: 1.6452, batch time: 0.69, accuracy:  41.30%\n",
      "Epoch [36/100], Step [43/60], Loss: 1.6814, batch time: 0.69, accuracy:  40.50%\n",
      "Epoch [36/100], Step [44/60], Loss: 1.6959, batch time: 0.67, accuracy:  39.10%\n",
      "Epoch [36/100], Step [45/60], Loss: 1.6945, batch time: 0.68, accuracy:  36.20%\n",
      "Epoch [36/100], Step [46/60], Loss: 1.7181, batch time: 0.66, accuracy:  36.30%\n",
      "Epoch [36/100], Step [47/60], Loss: 1.6666, batch time: 0.74, accuracy:  41.10%\n",
      "Epoch [36/100], Step [48/60], Loss: 1.6486, batch time: 0.66, accuracy:  40.00%\n",
      "Epoch [36/100], Step [49/60], Loss: 1.6988, batch time: 0.63, accuracy:  37.40%\n",
      "Epoch [36/100], Step [50/60], Loss: 1.7339, batch time: 0.58, accuracy:  36.20%\n",
      "Epoch [36/100], Step [51/60], Loss: 1.6937, batch time: 0.71, accuracy:  36.80%\n",
      "Epoch [36/100], Step [52/60], Loss: 1.7008, batch time: 0.64, accuracy:  36.50%\n",
      "Epoch [36/100], Step [53/60], Loss: 1.6843, batch time: 0.72, accuracy:  39.10%\n",
      "Epoch [36/100], Step [54/60], Loss: 1.6255, batch time: 0.68, accuracy:  42.50%\n",
      "Epoch [36/100], Step [55/60], Loss: 1.6810, batch time: 0.59, accuracy:  39.50%\n",
      "Epoch [36/100], Step [56/60], Loss: 1.6527, batch time: 0.46, accuracy:  40.00%\n",
      "Epoch [36/100], Step [57/60], Loss: 1.7292, batch time: 0.46, accuracy:  35.20%\n",
      "Epoch [36/100], Step [58/60], Loss: 1.7547, batch time: 0.48, accuracy:  35.00%\n",
      "Epoch [36/100], Step [59/60], Loss: 1.6615, batch time: 0.53, accuracy:  42.10%\n",
      "Epoch [36/100], Step [60/60], Loss: 1.7172, batch time: 0.54, accuracy:  37.40%\n",
      "Epoch [37/100], Step [1/60], Loss: 1.7036, batch time: 0.58, accuracy:  39.50%\n",
      "Epoch [37/100], Step [2/60], Loss: 1.6275, batch time: 0.53, accuracy:  41.10%\n",
      "Epoch [37/100], Step [3/60], Loss: 1.7343, batch time: 0.55, accuracy:  37.60%\n",
      "Epoch [37/100], Step [4/60], Loss: 1.6754, batch time: 0.53, accuracy:  40.60%\n",
      "Epoch [37/100], Step [5/60], Loss: 1.7009, batch time: 0.55, accuracy:  38.60%\n",
      "Epoch [37/100], Step [6/60], Loss: 1.6919, batch time: 0.53, accuracy:  38.80%\n",
      "Epoch [37/100], Step [7/60], Loss: 1.6668, batch time: 0.54, accuracy:  39.30%\n",
      "Epoch [37/100], Step [8/60], Loss: 1.7113, batch time: 0.53, accuracy:  38.90%\n",
      "Epoch [37/100], Step [9/60], Loss: 1.6850, batch time: 0.55, accuracy:  37.40%\n",
      "Epoch [37/100], Step [10/60], Loss: 1.6646, batch time: 0.55, accuracy:  39.60%\n",
      "Epoch [37/100], Step [11/60], Loss: 1.6841, batch time: 0.53, accuracy:  38.60%\n",
      "Epoch [37/100], Step [12/60], Loss: 1.6621, batch time: 0.55, accuracy:  40.20%\n",
      "Epoch [37/100], Step [13/60], Loss: 1.7551, batch time: 0.53, accuracy:  35.30%\n",
      "Epoch [37/100], Step [14/60], Loss: 1.6489, batch time: 0.45, accuracy:  39.20%\n",
      "Epoch [37/100], Step [15/60], Loss: 1.7233, batch time: 0.44, accuracy:  38.90%\n",
      "Epoch [37/100], Step [16/60], Loss: 1.7161, batch time: 0.44, accuracy:  36.70%\n",
      "Epoch [37/100], Step [17/60], Loss: 1.6922, batch time: 0.48, accuracy:  38.10%\n",
      "Epoch [37/100], Step [18/60], Loss: 1.6407, batch time: 0.44, accuracy:  39.60%\n",
      "Epoch [37/100], Step [19/60], Loss: 1.6979, batch time: 0.45, accuracy:  39.20%\n",
      "Epoch [37/100], Step [20/60], Loss: 1.6566, batch time: 0.45, accuracy:  39.60%\n",
      "Epoch [37/100], Step [21/60], Loss: 1.6658, batch time: 0.44, accuracy:  37.90%\n",
      "Epoch [37/100], Step [22/60], Loss: 1.7077, batch time: 0.45, accuracy:  38.10%\n",
      "Epoch [37/100], Step [23/60], Loss: 1.6834, batch time: 0.45, accuracy:  36.90%\n",
      "Epoch [37/100], Step [24/60], Loss: 1.6582, batch time: 0.44, accuracy:  39.70%\n",
      "Epoch [37/100], Step [25/60], Loss: 1.7000, batch time: 0.45, accuracy:  38.10%\n",
      "Epoch [37/100], Step [26/60], Loss: 1.6967, batch time: 0.47, accuracy:  36.70%\n",
      "Epoch [37/100], Step [27/60], Loss: 1.7208, batch time: 0.44, accuracy:  36.80%\n",
      "Epoch [37/100], Step [28/60], Loss: 1.6655, batch time: 0.45, accuracy:  38.20%\n",
      "Epoch [37/100], Step [29/60], Loss: 1.6706, batch time: 0.50, accuracy:  38.00%\n",
      "Epoch [37/100], Step [30/60], Loss: 1.6766, batch time: 0.44, accuracy:  40.20%\n",
      "Epoch [37/100], Step [31/60], Loss: 1.6944, batch time: 0.47, accuracy:  37.60%\n",
      "Epoch [37/100], Step [32/60], Loss: 1.7011, batch time: 0.44, accuracy:  35.40%\n",
      "Epoch [37/100], Step [33/60], Loss: 1.7112, batch time: 0.45, accuracy:  36.40%\n",
      "Epoch [37/100], Step [34/60], Loss: 1.6304, batch time: 0.45, accuracy:  41.00%\n",
      "Epoch [37/100], Step [35/60], Loss: 1.7118, batch time: 0.47, accuracy:  37.20%\n",
      "Epoch [37/100], Step [36/60], Loss: 1.6724, batch time: 0.46, accuracy:  39.30%\n",
      "Epoch [37/100], Step [37/60], Loss: 1.6944, batch time: 0.47, accuracy:  39.40%\n",
      "Epoch [37/100], Step [38/60], Loss: 1.6835, batch time: 0.53, accuracy:  39.10%\n",
      "Epoch [37/100], Step [39/60], Loss: 1.6953, batch time: 0.54, accuracy:  37.40%\n",
      "Epoch [37/100], Step [40/60], Loss: 1.6275, batch time: 0.53, accuracy:  42.30%\n",
      "Epoch [37/100], Step [41/60], Loss: 1.6777, batch time: 0.54, accuracy:  36.60%\n",
      "Epoch [37/100], Step [42/60], Loss: 1.6793, batch time: 0.53, accuracy:  38.30%\n",
      "Epoch [37/100], Step [43/60], Loss: 1.6471, batch time: 0.57, accuracy:  40.60%\n",
      "Epoch [37/100], Step [44/60], Loss: 1.6891, batch time: 0.54, accuracy:  39.00%\n",
      "Epoch [37/100], Step [45/60], Loss: 1.6500, batch time: 0.53, accuracy:  41.00%\n",
      "Epoch [37/100], Step [46/60], Loss: 1.6680, batch time: 0.55, accuracy:  38.80%\n",
      "Epoch [37/100], Step [47/60], Loss: 1.6768, batch time: 0.52, accuracy:  37.80%\n",
      "Epoch [37/100], Step [48/60], Loss: 1.6726, batch time: 0.54, accuracy:  36.80%\n",
      "Epoch [37/100], Step [49/60], Loss: 1.6381, batch time: 0.68, accuracy:  40.00%\n",
      "Epoch [37/100], Step [50/60], Loss: 1.6576, batch time: 0.80, accuracy:  39.90%\n",
      "Epoch [37/100], Step [51/60], Loss: 1.6895, batch time: 0.78, accuracy:  38.70%\n",
      "Epoch [37/100], Step [52/60], Loss: 1.6523, batch time: 0.65, accuracy:  39.20%\n",
      "Epoch [37/100], Step [53/60], Loss: 1.6560, batch time: 0.67, accuracy:  38.80%\n",
      "Epoch [37/100], Step [54/60], Loss: 1.6966, batch time: 0.67, accuracy:  38.70%\n",
      "Epoch [37/100], Step [55/60], Loss: 1.6853, batch time: 0.71, accuracy:  41.50%\n",
      "Epoch [37/100], Step [56/60], Loss: 1.6311, batch time: 0.71, accuracy:  41.20%\n",
      "Epoch [37/100], Step [57/60], Loss: 1.6617, batch time: 0.65, accuracy:  41.00%\n",
      "Epoch [37/100], Step [58/60], Loss: 1.6399, batch time: 0.68, accuracy:  40.20%\n",
      "Epoch [37/100], Step [59/60], Loss: 1.6701, batch time: 0.60, accuracy:  39.10%\n",
      "Epoch [37/100], Step [60/60], Loss: 1.6922, batch time: 0.67, accuracy:  37.40%\n",
      "Epoch [38/100], Step [1/60], Loss: 1.6503, batch time: 0.58, accuracy:  39.70%\n",
      "Epoch [38/100], Step [2/60], Loss: 1.6967, batch time: 0.63, accuracy:  37.50%\n",
      "Epoch [38/100], Step [3/60], Loss: 1.6750, batch time: 0.58, accuracy:  39.90%\n",
      "Epoch [38/100], Step [4/60], Loss: 1.6882, batch time: 0.69, accuracy:  39.70%\n",
      "Epoch [38/100], Step [5/60], Loss: 1.6744, batch time: 0.79, accuracy:  38.30%\n",
      "Epoch [38/100], Step [6/60], Loss: 1.7025, batch time: 0.73, accuracy:  38.40%\n",
      "Epoch [38/100], Step [7/60], Loss: 1.6490, batch time: 0.72, accuracy:  40.20%\n",
      "Epoch [38/100], Step [8/60], Loss: 1.7412, batch time: 0.74, accuracy:  38.50%\n",
      "Epoch [38/100], Step [9/60], Loss: 1.6885, batch time: 0.85, accuracy:  38.40%\n",
      "Epoch [38/100], Step [10/60], Loss: 1.6495, batch time: 0.88, accuracy:  38.60%\n",
      "Epoch [38/100], Step [11/60], Loss: 1.6492, batch time: 0.69, accuracy:  40.70%\n",
      "Epoch [38/100], Step [12/60], Loss: 1.6721, batch time: 0.66, accuracy:  36.80%\n",
      "Epoch [38/100], Step [13/60], Loss: 1.6948, batch time: 0.69, accuracy:  37.50%\n",
      "Epoch [38/100], Step [14/60], Loss: 1.6714, batch time: 0.68, accuracy:  38.40%\n",
      "Epoch [38/100], Step [15/60], Loss: 1.6590, batch time: 0.70, accuracy:  40.20%\n",
      "Epoch [38/100], Step [16/60], Loss: 1.6812, batch time: 0.68, accuracy:  39.10%\n",
      "Epoch [38/100], Step [17/60], Loss: 1.7261, batch time: 0.69, accuracy:  36.60%\n",
      "Epoch [38/100], Step [18/60], Loss: 1.7337, batch time: 0.71, accuracy:  36.60%\n",
      "Epoch [38/100], Step [19/60], Loss: 1.6749, batch time: 0.69, accuracy:  40.50%\n",
      "Epoch [38/100], Step [20/60], Loss: 1.6681, batch time: 0.71, accuracy:  41.00%\n",
      "Epoch [38/100], Step [21/60], Loss: 1.6609, batch time: 0.71, accuracy:  37.70%\n",
      "Epoch [38/100], Step [22/60], Loss: 1.6631, batch time: 0.72, accuracy:  39.30%\n",
      "Epoch [38/100], Step [23/60], Loss: 1.6515, batch time: 0.72, accuracy:  40.60%\n",
      "Epoch [38/100], Step [24/60], Loss: 1.6863, batch time: 0.74, accuracy:  37.80%\n",
      "Epoch [38/100], Step [25/60], Loss: 1.6781, batch time: 0.74, accuracy:  39.90%\n",
      "Epoch [38/100], Step [26/60], Loss: 1.6774, batch time: 0.86, accuracy:  37.60%\n",
      "Epoch [38/100], Step [27/60], Loss: 1.6786, batch time: 0.87, accuracy:  38.10%\n",
      "Epoch [38/100], Step [28/60], Loss: 1.6125, batch time: 0.86, accuracy:  42.70%\n",
      "Epoch [38/100], Step [29/60], Loss: 1.6998, batch time: 0.86, accuracy:  37.10%\n",
      "Epoch [38/100], Step [30/60], Loss: 1.6172, batch time: 0.87, accuracy:  41.60%\n",
      "Epoch [38/100], Step [31/60], Loss: 1.6309, batch time: 0.87, accuracy:  41.90%\n",
      "Epoch [38/100], Step [32/60], Loss: 1.6490, batch time: 0.86, accuracy:  40.10%\n",
      "Epoch [38/100], Step [33/60], Loss: 1.6966, batch time: 0.86, accuracy:  37.30%\n",
      "Epoch [38/100], Step [34/60], Loss: 1.6831, batch time: 0.80, accuracy:  36.20%\n",
      "Epoch [38/100], Step [35/60], Loss: 1.6258, batch time: 0.71, accuracy:  42.40%\n",
      "Epoch [38/100], Step [36/60], Loss: 1.6297, batch time: 0.71, accuracy:  41.30%\n",
      "Epoch [38/100], Step [37/60], Loss: 1.6683, batch time: 0.71, accuracy:  39.10%\n",
      "Epoch [38/100], Step [38/60], Loss: 1.5864, batch time: 0.71, accuracy:  42.20%\n",
      "Epoch [38/100], Step [39/60], Loss: 1.5684, batch time: 0.62, accuracy:  42.00%\n",
      "Epoch [38/100], Step [40/60], Loss: 1.6958, batch time: 0.59, accuracy:  37.70%\n",
      "Epoch [38/100], Step [41/60], Loss: 1.6783, batch time: 0.60, accuracy:  39.00%\n",
      "Epoch [38/100], Step [42/60], Loss: 1.6765, batch time: 0.68, accuracy:  37.70%\n",
      "Epoch [38/100], Step [43/60], Loss: 1.6715, batch time: 0.59, accuracy:  38.70%\n",
      "Epoch [38/100], Step [44/60], Loss: 1.6906, batch time: 0.68, accuracy:  39.30%\n",
      "Epoch [38/100], Step [45/60], Loss: 1.6454, batch time: 0.59, accuracy:  39.80%\n",
      "Epoch [38/100], Step [46/60], Loss: 1.6457, batch time: 0.58, accuracy:  40.60%\n",
      "Epoch [38/100], Step [47/60], Loss: 1.7134, batch time: 0.68, accuracy:  35.50%\n",
      "Epoch [38/100], Step [48/60], Loss: 1.6992, batch time: 0.61, accuracy:  38.20%\n",
      "Epoch [38/100], Step [49/60], Loss: 1.7215, batch time: 0.70, accuracy:  37.90%\n",
      "Epoch [38/100], Step [50/60], Loss: 1.6894, batch time: 0.71, accuracy:  39.80%\n",
      "Epoch [38/100], Step [51/60], Loss: 1.6146, batch time: 0.73, accuracy:  42.30%\n",
      "Epoch [38/100], Step [52/60], Loss: 1.6427, batch time: 0.72, accuracy:  40.00%\n",
      "Epoch [38/100], Step [53/60], Loss: 1.6810, batch time: 0.71, accuracy:  39.00%\n",
      "Epoch [38/100], Step [54/60], Loss: 1.6904, batch time: 0.65, accuracy:  39.50%\n",
      "Epoch [38/100], Step [55/60], Loss: 1.6405, batch time: 0.62, accuracy:  40.20%\n",
      "Epoch [38/100], Step [56/60], Loss: 1.6114, batch time: 0.59, accuracy:  39.70%\n",
      "Epoch [38/100], Step [57/60], Loss: 1.6546, batch time: 0.69, accuracy:  40.30%\n",
      "Epoch [38/100], Step [58/60], Loss: 1.6488, batch time: 0.68, accuracy:  37.80%\n",
      "Epoch [38/100], Step [59/60], Loss: 1.6491, batch time: 0.67, accuracy:  38.40%\n",
      "Epoch [38/100], Step [60/60], Loss: 1.6420, batch time: 0.68, accuracy:  40.80%\n",
      "Epoch [39/100], Step [1/60], Loss: 1.6069, batch time: 0.67, accuracy:  41.10%\n",
      "Epoch [39/100], Step [2/60], Loss: 1.6670, batch time: 0.68, accuracy:  40.00%\n",
      "Epoch [39/100], Step [3/60], Loss: 1.6439, batch time: 0.68, accuracy:  39.30%\n",
      "Epoch [39/100], Step [4/60], Loss: 1.6269, batch time: 0.68, accuracy:  41.10%\n",
      "Epoch [39/100], Step [5/60], Loss: 1.7030, batch time: 0.68, accuracy:  38.90%\n",
      "Epoch [39/100], Step [6/60], Loss: 1.6246, batch time: 0.68, accuracy:  40.30%\n",
      "Epoch [39/100], Step [7/60], Loss: 1.6911, batch time: 0.69, accuracy:  36.40%\n",
      "Epoch [39/100], Step [8/60], Loss: 1.6650, batch time: 0.69, accuracy:  39.40%\n",
      "Epoch [39/100], Step [9/60], Loss: 1.6820, batch time: 0.81, accuracy:  40.20%\n",
      "Epoch [39/100], Step [10/60], Loss: 1.6033, batch time: 0.85, accuracy:  39.40%\n",
      "Epoch [39/100], Step [11/60], Loss: 1.6384, batch time: 0.84, accuracy:  40.00%\n",
      "Epoch [39/100], Step [12/60], Loss: 1.6819, batch time: 0.85, accuracy:  37.70%\n",
      "Epoch [39/100], Step [13/60], Loss: 1.5838, batch time: 0.83, accuracy:  43.00%\n",
      "Epoch [39/100], Step [14/60], Loss: 1.6907, batch time: 0.83, accuracy:  37.70%\n",
      "Epoch [39/100], Step [15/60], Loss: 1.6405, batch time: 0.85, accuracy:  40.00%\n",
      "Epoch [39/100], Step [16/60], Loss: 1.5886, batch time: 0.84, accuracy:  43.50%\n",
      "Epoch [39/100], Step [17/60], Loss: 1.6780, batch time: 0.67, accuracy:  37.80%\n",
      "Epoch [39/100], Step [18/60], Loss: 1.6741, batch time: 0.67, accuracy:  40.70%\n",
      "Epoch [39/100], Step [19/60], Loss: 1.6980, batch time: 0.67, accuracy:  38.80%\n",
      "Epoch [39/100], Step [20/60], Loss: 1.6327, batch time: 0.67, accuracy:  40.70%\n",
      "Epoch [39/100], Step [21/60], Loss: 1.6811, batch time: 0.67, accuracy:  39.70%\n",
      "Epoch [39/100], Step [22/60], Loss: 1.6478, batch time: 0.68, accuracy:  40.50%\n",
      "Epoch [39/100], Step [23/60], Loss: 1.6601, batch time: 0.67, accuracy:  41.30%\n",
      "Epoch [39/100], Step [24/60], Loss: 1.6568, batch time: 0.68, accuracy:  40.30%\n",
      "Epoch [39/100], Step [25/60], Loss: 1.6260, batch time: 0.68, accuracy:  41.60%\n",
      "Epoch [39/100], Step [26/60], Loss: 1.7174, batch time: 0.68, accuracy:  35.50%\n",
      "Epoch [39/100], Step [27/60], Loss: 1.6590, batch time: 0.76, accuracy:  39.80%\n",
      "Epoch [39/100], Step [28/60], Loss: 1.6548, batch time: 0.68, accuracy:  39.90%\n",
      "Epoch [39/100], Step [29/60], Loss: 1.6146, batch time: 0.68, accuracy:  42.20%\n",
      "Epoch [39/100], Step [30/60], Loss: 1.6268, batch time: 0.68, accuracy:  43.20%\n",
      "Epoch [39/100], Step [31/60], Loss: 1.6096, batch time: 0.70, accuracy:  41.70%\n",
      "Epoch [39/100], Step [32/60], Loss: 1.6602, batch time: 0.73, accuracy:  39.10%\n",
      "Epoch [39/100], Step [33/60], Loss: 1.6577, batch time: 0.81, accuracy:  38.50%\n",
      "Epoch [39/100], Step [34/60], Loss: 1.6784, batch time: 0.82, accuracy:  39.10%\n",
      "Epoch [39/100], Step [35/60], Loss: 1.6923, batch time: 0.82, accuracy:  37.90%\n",
      "Epoch [39/100], Step [36/60], Loss: 1.6674, batch time: 0.81, accuracy:  38.60%\n",
      "Epoch [39/100], Step [37/60], Loss: 1.7154, batch time: 0.67, accuracy:  39.50%\n",
      "Epoch [39/100], Step [38/60], Loss: 1.6554, batch time: 0.68, accuracy:  42.60%\n",
      "Epoch [39/100], Step [39/60], Loss: 1.6254, batch time: 0.68, accuracy:  40.60%\n",
      "Epoch [39/100], Step [40/60], Loss: 1.6318, batch time: 0.67, accuracy:  38.60%\n",
      "Epoch [39/100], Step [41/60], Loss: 1.6462, batch time: 0.69, accuracy:  40.80%\n",
      "Epoch [39/100], Step [42/60], Loss: 1.6816, batch time: 0.68, accuracy:  38.60%\n",
      "Epoch [39/100], Step [43/60], Loss: 1.6719, batch time: 0.69, accuracy:  38.10%\n",
      "Epoch [39/100], Step [44/60], Loss: 1.6782, batch time: 0.69, accuracy:  39.20%\n",
      "Epoch [39/100], Step [45/60], Loss: 1.6395, batch time: 0.69, accuracy:  42.60%\n",
      "Epoch [39/100], Step [46/60], Loss: 1.6500, batch time: 0.68, accuracy:  40.50%\n",
      "Epoch [39/100], Step [47/60], Loss: 1.6543, batch time: 0.63, accuracy:  39.20%\n",
      "Epoch [39/100], Step [48/60], Loss: 1.6124, batch time: 0.68, accuracy:  42.40%\n",
      "Epoch [39/100], Step [49/60], Loss: 1.6491, batch time: 0.68, accuracy:  39.30%\n",
      "Epoch [39/100], Step [50/60], Loss: 1.6531, batch time: 0.72, accuracy:  39.00%\n",
      "Epoch [39/100], Step [51/60], Loss: 1.6393, batch time: 0.74, accuracy:  38.80%\n",
      "Epoch [39/100], Step [52/60], Loss: 1.6315, batch time: 0.82, accuracy:  41.20%\n",
      "Epoch [39/100], Step [53/60], Loss: 1.6391, batch time: 0.82, accuracy:  38.80%\n",
      "Epoch [39/100], Step [54/60], Loss: 1.6513, batch time: 0.86, accuracy:  39.00%\n",
      "Epoch [39/100], Step [55/60], Loss: 1.6647, batch time: 0.85, accuracy:  39.10%\n",
      "Epoch [39/100], Step [56/60], Loss: 1.6352, batch time: 0.84, accuracy:  39.30%\n",
      "Epoch [39/100], Step [57/60], Loss: 1.6107, batch time: 0.83, accuracy:  40.10%\n",
      "Epoch [39/100], Step [58/60], Loss: 1.5774, batch time: 0.82, accuracy:  40.50%\n",
      "Epoch [39/100], Step [59/60], Loss: 1.7043, batch time: 0.81, accuracy:  38.10%\n",
      "Epoch [39/100], Step [60/60], Loss: 1.6550, batch time: 0.81, accuracy:  39.50%\n",
      "Epoch [40/100], Step [1/60], Loss: 1.6385, batch time: 0.55, accuracy:  40.60%\n",
      "Epoch [40/100], Step [2/60], Loss: 1.6283, batch time: 0.59, accuracy:  40.80%\n",
      "Epoch [40/100], Step [3/60], Loss: 1.6765, batch time: 0.67, accuracy:  38.20%\n",
      "Epoch [40/100], Step [4/60], Loss: 1.6274, batch time: 0.67, accuracy:  41.00%\n",
      "Epoch [40/100], Step [5/60], Loss: 1.6650, batch time: 0.67, accuracy:  38.70%\n",
      "Epoch [40/100], Step [6/60], Loss: 1.6362, batch time: 0.67, accuracy:  41.30%\n",
      "Epoch [40/100], Step [7/60], Loss: 1.5913, batch time: 0.67, accuracy:  42.90%\n",
      "Epoch [40/100], Step [8/60], Loss: 1.5962, batch time: 0.68, accuracy:  39.90%\n",
      "Epoch [40/100], Step [9/60], Loss: 1.6471, batch time: 0.75, accuracy:  40.60%\n",
      "Epoch [40/100], Step [10/60], Loss: 1.6425, batch time: 0.67, accuracy:  40.10%\n",
      "Epoch [40/100], Step [11/60], Loss: 1.6197, batch time: 0.61, accuracy:  42.60%\n",
      "Epoch [40/100], Step [12/60], Loss: 1.5789, batch time: 0.69, accuracy:  42.90%\n",
      "Epoch [40/100], Step [13/60], Loss: 1.5741, batch time: 0.58, accuracy:  41.10%\n",
      "Epoch [40/100], Step [14/60], Loss: 1.6820, batch time: 0.55, accuracy:  39.10%\n",
      "Epoch [40/100], Step [15/60], Loss: 1.5601, batch time: 0.70, accuracy:  44.80%\n",
      "Epoch [40/100], Step [16/60], Loss: 1.7029, batch time: 0.73, accuracy:  37.20%\n",
      "Epoch [40/100], Step [17/60], Loss: 1.6563, batch time: 0.75, accuracy:  40.60%\n",
      "Epoch [40/100], Step [18/60], Loss: 1.6114, batch time: 0.86, accuracy:  39.80%\n",
      "Epoch [40/100], Step [19/60], Loss: 1.6360, batch time: 0.89, accuracy:  40.50%\n",
      "Epoch [40/100], Step [20/60], Loss: 1.6410, batch time: 0.62, accuracy:  43.00%\n",
      "Epoch [40/100], Step [21/60], Loss: 1.6789, batch time: 0.56, accuracy:  38.50%\n",
      "Epoch [40/100], Step [22/60], Loss: 1.5980, batch time: 0.58, accuracy:  41.80%\n",
      "Epoch [40/100], Step [23/60], Loss: 1.6025, batch time: 0.42, accuracy:  43.30%\n",
      "Epoch [40/100], Step [24/60], Loss: 1.6642, batch time: 0.41, accuracy:  40.30%\n",
      "Epoch [40/100], Step [25/60], Loss: 1.6827, batch time: 0.50, accuracy:  38.70%\n",
      "Epoch [40/100], Step [26/60], Loss: 1.6095, batch time: 0.43, accuracy:  41.40%\n",
      "Epoch [40/100], Step [27/60], Loss: 1.6369, batch time: 0.42, accuracy:  39.40%\n",
      "Epoch [40/100], Step [28/60], Loss: 1.6237, batch time: 0.63, accuracy:  40.20%\n",
      "Epoch [40/100], Step [29/60], Loss: 1.6464, batch time: 0.70, accuracy:  40.80%\n",
      "Epoch [40/100], Step [30/60], Loss: 1.6510, batch time: 0.71, accuracy:  40.40%\n",
      "Epoch [40/100], Step [31/60], Loss: 1.6682, batch time: 0.70, accuracy:  38.50%\n",
      "Epoch [40/100], Step [32/60], Loss: 1.7048, batch time: 0.60, accuracy:  37.10%\n",
      "Epoch [40/100], Step [33/60], Loss: 1.7086, batch time: 0.69, accuracy:  35.80%\n",
      "Epoch [40/100], Step [34/60], Loss: 1.5716, batch time: 0.46, accuracy:  42.10%\n",
      "Epoch [40/100], Step [35/60], Loss: 1.6479, batch time: 0.47, accuracy:  38.60%\n",
      "Epoch [40/100], Step [36/60], Loss: 1.6695, batch time: 0.46, accuracy:  40.40%\n",
      "Epoch [40/100], Step [37/60], Loss: 1.6632, batch time: 0.46, accuracy:  40.40%\n",
      "Epoch [40/100], Step [38/60], Loss: 1.6474, batch time: 0.45, accuracy:  41.10%\n",
      "Epoch [40/100], Step [39/60], Loss: 1.5876, batch time: 0.51, accuracy:  41.90%\n",
      "Epoch [40/100], Step [40/60], Loss: 1.6409, batch time: 0.54, accuracy:  39.00%\n",
      "Epoch [40/100], Step [41/60], Loss: 1.7229, batch time: 0.54, accuracy:  38.50%\n",
      "Epoch [40/100], Step [42/60], Loss: 1.6473, batch time: 0.54, accuracy:  39.70%\n",
      "Epoch [40/100], Step [43/60], Loss: 1.6715, batch time: 0.56, accuracy:  39.50%\n",
      "Epoch [40/100], Step [44/60], Loss: 1.7318, batch time: 0.55, accuracy:  35.10%\n",
      "Epoch [40/100], Step [45/60], Loss: 1.6467, batch time: 0.59, accuracy:  40.60%\n",
      "Epoch [40/100], Step [46/60], Loss: 1.6649, batch time: 0.56, accuracy:  38.20%\n",
      "Epoch [40/100], Step [47/60], Loss: 1.6539, batch time: 0.53, accuracy:  39.40%\n",
      "Epoch [40/100], Step [48/60], Loss: 1.6134, batch time: 0.55, accuracy:  40.50%\n",
      "Epoch [40/100], Step [49/60], Loss: 1.6253, batch time: 0.54, accuracy:  40.70%\n",
      "Epoch [40/100], Step [50/60], Loss: 1.7210, batch time: 0.56, accuracy:  36.50%\n",
      "Epoch [40/100], Step [51/60], Loss: 1.6747, batch time: 0.54, accuracy:  39.60%\n",
      "Epoch [40/100], Step [52/60], Loss: 1.6381, batch time: 0.53, accuracy:  39.90%\n",
      "Epoch [40/100], Step [53/60], Loss: 1.6399, batch time: 0.55, accuracy:  39.70%\n",
      "Epoch [40/100], Step [54/60], Loss: 1.6187, batch time: 0.53, accuracy:  41.90%\n",
      "Epoch [40/100], Step [55/60], Loss: 1.6510, batch time: 0.55, accuracy:  42.90%\n",
      "Epoch [40/100], Step [56/60], Loss: 1.6322, batch time: 0.53, accuracy:  40.40%\n",
      "Epoch [40/100], Step [57/60], Loss: 1.5867, batch time: 0.51, accuracy:  41.80%\n",
      "Epoch [40/100], Step [58/60], Loss: 1.6223, batch time: 0.47, accuracy:  39.50%\n",
      "Epoch [40/100], Step [59/60], Loss: 1.6133, batch time: 0.44, accuracy:  42.50%\n",
      "Epoch [40/100], Step [60/60], Loss: 1.6339, batch time: 0.46, accuracy:  41.30%\n",
      "Epoch [41/100], Step [1/60], Loss: 1.6466, batch time: 0.46, accuracy:  37.70%\n",
      "Epoch [41/100], Step [2/60], Loss: 1.7094, batch time: 0.44, accuracy:  37.60%\n",
      "Epoch [41/100], Step [3/60], Loss: 1.6232, batch time: 0.45, accuracy:  39.90%\n",
      "Epoch [41/100], Step [4/60], Loss: 1.6432, batch time: 0.45, accuracy:  40.20%\n",
      "Epoch [41/100], Step [5/60], Loss: 1.6712, batch time: 0.44, accuracy:  37.50%\n",
      "Epoch [41/100], Step [6/60], Loss: 1.6274, batch time: 0.46, accuracy:  42.50%\n",
      "Epoch [41/100], Step [7/60], Loss: 1.6236, batch time: 0.45, accuracy:  40.70%\n",
      "Epoch [41/100], Step [8/60], Loss: 1.6172, batch time: 0.45, accuracy:  42.20%\n",
      "Epoch [41/100], Step [9/60], Loss: 1.6229, batch time: 0.46, accuracy:  39.10%\n",
      "Epoch [41/100], Step [10/60], Loss: 1.6231, batch time: 0.44, accuracy:  40.60%\n",
      "Epoch [41/100], Step [11/60], Loss: 1.6628, batch time: 0.45, accuracy:  40.90%\n",
      "Epoch [41/100], Step [12/60], Loss: 1.6346, batch time: 0.45, accuracy:  41.00%\n",
      "Epoch [41/100], Step [13/60], Loss: 1.6051, batch time: 0.44, accuracy:  42.60%\n",
      "Epoch [41/100], Step [14/60], Loss: 1.6513, batch time: 0.45, accuracy:  40.20%\n",
      "Epoch [41/100], Step [15/60], Loss: 1.6536, batch time: 0.46, accuracy:  41.30%\n",
      "Epoch [41/100], Step [16/60], Loss: 1.6265, batch time: 0.44, accuracy:  41.30%\n",
      "Epoch [41/100], Step [17/60], Loss: 1.6425, batch time: 0.47, accuracy:  40.00%\n",
      "Epoch [41/100], Step [18/60], Loss: 1.6405, batch time: 0.45, accuracy:  38.60%\n",
      "Epoch [41/100], Step [19/60], Loss: 1.5905, batch time: 0.44, accuracy:  41.50%\n",
      "Epoch [41/100], Step [20/60], Loss: 1.5814, batch time: 0.46, accuracy:  43.20%\n",
      "Epoch [41/100], Step [21/60], Loss: 1.5964, batch time: 0.73, accuracy:  40.30%\n",
      "Epoch [41/100], Step [22/60], Loss: 1.6679, batch time: 0.82, accuracy:  37.90%\n",
      "Epoch [41/100], Step [23/60], Loss: 1.6185, batch time: 0.73, accuracy:  42.00%\n",
      "Epoch [41/100], Step [24/60], Loss: 1.6486, batch time: 0.86, accuracy:  39.60%\n",
      "Epoch [41/100], Step [25/60], Loss: 1.6016, batch time: 0.69, accuracy:  41.60%\n",
      "Epoch [41/100], Step [26/60], Loss: 1.6748, batch time: 0.69, accuracy:  37.80%\n",
      "Epoch [41/100], Step [27/60], Loss: 1.6383, batch time: 0.57, accuracy:  40.80%\n",
      "Epoch [41/100], Step [28/60], Loss: 1.5991, batch time: 0.68, accuracy:  42.00%\n",
      "Epoch [41/100], Step [29/60], Loss: 1.6728, batch time: 0.69, accuracy:  38.90%\n",
      "Epoch [41/100], Step [30/60], Loss: 1.6448, batch time: 0.70, accuracy:  40.30%\n",
      "Epoch [41/100], Step [31/60], Loss: 1.5672, batch time: 0.70, accuracy:  43.20%\n",
      "Epoch [41/100], Step [32/60], Loss: 1.6109, batch time: 0.62, accuracy:  40.50%\n",
      "Epoch [41/100], Step [33/60], Loss: 1.6302, batch time: 0.70, accuracy:  40.60%\n",
      "Epoch [41/100], Step [34/60], Loss: 1.6008, batch time: 0.77, accuracy:  41.60%\n",
      "Epoch [41/100], Step [35/60], Loss: 1.5884, batch time: 0.69, accuracy:  43.10%\n",
      "Epoch [41/100], Step [36/60], Loss: 1.6255, batch time: 0.69, accuracy:  39.70%\n",
      "Epoch [41/100], Step [37/60], Loss: 1.6633, batch time: 0.72, accuracy:  40.00%\n",
      "Epoch [41/100], Step [38/60], Loss: 1.6503, batch time: 0.71, accuracy:  40.80%\n",
      "Epoch [41/100], Step [39/60], Loss: 1.6393, batch time: 0.68, accuracy:  40.50%\n",
      "Epoch [41/100], Step [40/60], Loss: 1.6501, batch time: 0.84, accuracy:  42.50%\n",
      "Epoch [41/100], Step [41/60], Loss: 1.5962, batch time: 0.88, accuracy:  41.20%\n",
      "Epoch [41/100], Step [42/60], Loss: 1.6118, batch time: 0.86, accuracy:  41.20%\n",
      "Epoch [41/100], Step [43/60], Loss: 1.5843, batch time: 0.86, accuracy:  42.10%\n",
      "Epoch [41/100], Step [44/60], Loss: 1.6200, batch time: 0.72, accuracy:  41.10%\n",
      "Epoch [41/100], Step [45/60], Loss: 1.6609, batch time: 0.68, accuracy:  39.60%\n",
      "Epoch [41/100], Step [46/60], Loss: 1.6252, batch time: 0.72, accuracy:  40.70%\n",
      "Epoch [41/100], Step [47/60], Loss: 1.6444, batch time: 0.72, accuracy:  39.50%\n",
      "Epoch [41/100], Step [48/60], Loss: 1.6600, batch time: 0.72, accuracy:  39.70%\n",
      "Epoch [41/100], Step [49/60], Loss: 1.6064, batch time: 0.73, accuracy:  41.40%\n",
      "Epoch [41/100], Step [50/60], Loss: 1.6617, batch time: 0.72, accuracy:  40.60%\n",
      "Epoch [41/100], Step [51/60], Loss: 1.6585, batch time: 0.72, accuracy:  38.70%\n",
      "Epoch [41/100], Step [52/60], Loss: 1.6467, batch time: 0.72, accuracy:  40.90%\n",
      "Epoch [41/100], Step [53/60], Loss: 1.6323, batch time: 0.72, accuracy:  40.90%\n",
      "Epoch [41/100], Step [54/60], Loss: 1.6444, batch time: 0.72, accuracy:  41.80%\n",
      "Epoch [41/100], Step [55/60], Loss: 1.6328, batch time: 0.71, accuracy:  40.90%\n",
      "Epoch [41/100], Step [56/60], Loss: 1.6450, batch time: 0.72, accuracy:  40.90%\n",
      "Epoch [41/100], Step [57/60], Loss: 1.6123, batch time: 0.72, accuracy:  39.40%\n",
      "Epoch [41/100], Step [58/60], Loss: 1.6097, batch time: 0.78, accuracy:  43.50%\n",
      "Epoch [41/100], Step [59/60], Loss: 1.6331, batch time: 0.87, accuracy:  40.60%\n",
      "Epoch [41/100], Step [60/60], Loss: 1.6305, batch time: 0.85, accuracy:  41.70%\n",
      "Epoch [42/100], Step [1/60], Loss: 1.6352, batch time: 0.88, accuracy:  40.60%\n",
      "Epoch [42/100], Step [2/60], Loss: 1.5807, batch time: 0.84, accuracy:  42.50%\n",
      "Epoch [42/100], Step [3/60], Loss: 1.5627, batch time: 0.68, accuracy:  43.20%\n",
      "Epoch [42/100], Step [4/60], Loss: 1.6734, batch time: 0.71, accuracy:  38.90%\n",
      "Epoch [42/100], Step [5/60], Loss: 1.6045, batch time: 0.69, accuracy:  42.30%\n",
      "Epoch [42/100], Step [6/60], Loss: 1.6256, batch time: 0.70, accuracy:  40.90%\n",
      "Epoch [42/100], Step [7/60], Loss: 1.5834, batch time: 0.72, accuracy:  43.90%\n",
      "Epoch [42/100], Step [8/60], Loss: 1.6236, batch time: 0.69, accuracy:  40.40%\n",
      "Epoch [42/100], Step [9/60], Loss: 1.5947, batch time: 0.72, accuracy:  42.00%\n",
      "Epoch [42/100], Step [10/60], Loss: 1.6257, batch time: 0.69, accuracy:  40.20%\n",
      "Epoch [42/100], Step [11/60], Loss: 1.5572, batch time: 0.72, accuracy:  44.60%\n",
      "Epoch [42/100], Step [12/60], Loss: 1.6310, batch time: 0.69, accuracy:  40.80%\n",
      "Epoch [42/100], Step [13/60], Loss: 1.5731, batch time: 0.59, accuracy:  42.30%\n",
      "Epoch [42/100], Step [14/60], Loss: 1.6611, batch time: 0.70, accuracy:  38.80%\n",
      "Epoch [42/100], Step [15/60], Loss: 1.6842, batch time: 0.73, accuracy:  37.80%\n",
      "Epoch [42/100], Step [16/60], Loss: 1.5799, batch time: 0.73, accuracy:  43.30%\n",
      "Epoch [42/100], Step [17/60], Loss: 1.6463, batch time: 0.73, accuracy:  39.60%\n",
      "Epoch [42/100], Step [18/60], Loss: 1.6065, batch time: 0.83, accuracy:  39.80%\n",
      "Epoch [42/100], Step [19/60], Loss: 1.6562, batch time: 0.83, accuracy:  40.80%\n",
      "Epoch [42/100], Step [20/60], Loss: 1.6504, batch time: 0.83, accuracy:  40.10%\n",
      "Epoch [42/100], Step [21/60], Loss: 1.5900, batch time: 0.83, accuracy:  42.20%\n",
      "Epoch [42/100], Step [22/60], Loss: 1.6107, batch time: 0.83, accuracy:  41.20%\n",
      "Epoch [42/100], Step [23/60], Loss: 1.6036, batch time: 0.83, accuracy:  41.40%\n",
      "Epoch [42/100], Step [24/60], Loss: 1.6679, batch time: 0.82, accuracy:  40.40%\n",
      "Epoch [42/100], Step [25/60], Loss: 1.5902, batch time: 0.83, accuracy:  43.20%\n",
      "Epoch [42/100], Step [26/60], Loss: 1.6341, batch time: 0.83, accuracy:  41.00%\n",
      "Epoch [42/100], Step [27/60], Loss: 1.6329, batch time: 0.82, accuracy:  39.20%\n",
      "Epoch [42/100], Step [28/60], Loss: 1.6171, batch time: 0.82, accuracy:  41.10%\n",
      "Epoch [42/100], Step [29/60], Loss: 1.5976, batch time: 0.80, accuracy:  43.00%\n",
      "Epoch [42/100], Step [30/60], Loss: 1.6346, batch time: 0.68, accuracy:  39.10%\n",
      "Epoch [42/100], Step [31/60], Loss: 1.6026, batch time: 0.68, accuracy:  41.90%\n",
      "Epoch [42/100], Step [32/60], Loss: 1.6537, batch time: 0.68, accuracy:  39.20%\n",
      "Epoch [42/100], Step [33/60], Loss: 1.6064, batch time: 0.68, accuracy:  42.30%\n",
      "Epoch [42/100], Step [34/60], Loss: 1.5700, batch time: 0.68, accuracy:  42.20%\n",
      "Epoch [42/100], Step [35/60], Loss: 1.6593, batch time: 0.68, accuracy:  39.80%\n",
      "Epoch [42/100], Step [36/60], Loss: 1.6044, batch time: 0.68, accuracy:  42.60%\n",
      "Epoch [42/100], Step [37/60], Loss: 1.6303, batch time: 0.68, accuracy:  40.60%\n",
      "Epoch [42/100], Step [38/60], Loss: 1.6226, batch time: 0.68, accuracy:  41.50%\n",
      "Epoch [42/100], Step [39/60], Loss: 1.6036, batch time: 0.68, accuracy:  43.20%\n",
      "Epoch [42/100], Step [40/60], Loss: 1.6138, batch time: 0.69, accuracy:  40.20%\n",
      "Epoch [42/100], Step [41/60], Loss: 1.5990, batch time: 0.69, accuracy:  39.70%\n",
      "Epoch [42/100], Step [42/60], Loss: 1.6893, batch time: 0.68, accuracy:  37.60%\n",
      "Epoch [42/100], Step [43/60], Loss: 1.6235, batch time: 0.69, accuracy:  43.30%\n",
      "Epoch [42/100], Step [44/60], Loss: 1.5718, batch time: 0.70, accuracy:  41.40%\n",
      "Epoch [42/100], Step [45/60], Loss: 1.6436, batch time: 0.77, accuracy:  41.70%\n",
      "Epoch [42/100], Step [46/60], Loss: 1.5886, batch time: 0.82, accuracy:  41.10%\n",
      "Epoch [42/100], Step [47/60], Loss: 1.5816, batch time: 0.87, accuracy:  42.70%\n",
      "Epoch [42/100], Step [48/60], Loss: 1.6201, batch time: 0.68, accuracy:  40.90%\n",
      "Epoch [42/100], Step [49/60], Loss: 1.6346, batch time: 0.77, accuracy:  39.30%\n",
      "Epoch [42/100], Step [50/60], Loss: 1.6278, batch time: 0.69, accuracy:  39.10%\n",
      "Epoch [42/100], Step [51/60], Loss: 1.6619, batch time: 0.69, accuracy:  39.40%\n",
      "Epoch [42/100], Step [52/60], Loss: 1.6225, batch time: 0.70, accuracy:  38.80%\n",
      "Epoch [42/100], Step [53/60], Loss: 1.6040, batch time: 0.65, accuracy:  42.80%\n",
      "Epoch [42/100], Step [54/60], Loss: 1.6204, batch time: 0.70, accuracy:  40.40%\n",
      "Epoch [42/100], Step [55/60], Loss: 1.6052, batch time: 0.69, accuracy:  39.80%\n",
      "Epoch [42/100], Step [56/60], Loss: 1.6061, batch time: 0.69, accuracy:  42.40%\n",
      "Epoch [42/100], Step [57/60], Loss: 1.6236, batch time: 0.70, accuracy:  39.60%\n",
      "Epoch [42/100], Step [58/60], Loss: 1.6282, batch time: 0.67, accuracy:  41.50%\n",
      "Epoch [42/100], Step [59/60], Loss: 1.6094, batch time: 0.48, accuracy:  42.10%\n",
      "Epoch [42/100], Step [60/60], Loss: 1.6361, batch time: 0.46, accuracy:  41.30%\n",
      "Epoch [43/100], Step [1/60], Loss: 1.5897, batch time: 0.48, accuracy:  44.80%\n",
      "Epoch [43/100], Step [2/60], Loss: 1.6381, batch time: 0.46, accuracy:  41.60%\n",
      "Epoch [43/100], Step [3/60], Loss: 1.6319, batch time: 0.45, accuracy:  40.10%\n",
      "Epoch [43/100], Step [4/60], Loss: 1.6099, batch time: 0.50, accuracy:  42.00%\n",
      "Epoch [43/100], Step [5/60], Loss: 1.5882, batch time: 0.54, accuracy:  43.60%\n",
      "Epoch [43/100], Step [6/60], Loss: 1.6391, batch time: 0.54, accuracy:  39.70%\n",
      "Epoch [43/100], Step [7/60], Loss: 1.6135, batch time: 0.54, accuracy:  41.00%\n",
      "Epoch [43/100], Step [8/60], Loss: 1.6744, batch time: 0.56, accuracy:  39.30%\n",
      "Epoch [43/100], Step [9/60], Loss: 1.6400, batch time: 0.56, accuracy:  41.20%\n",
      "Epoch [43/100], Step [10/60], Loss: 1.5478, batch time: 0.53, accuracy:  45.60%\n",
      "Epoch [43/100], Step [11/60], Loss: 1.5967, batch time: 0.55, accuracy:  41.20%\n",
      "Epoch [43/100], Step [12/60], Loss: 1.6265, batch time: 0.53, accuracy:  42.60%\n",
      "Epoch [43/100], Step [13/60], Loss: 1.6214, batch time: 0.55, accuracy:  41.80%\n",
      "Epoch [43/100], Step [14/60], Loss: 1.6587, batch time: 0.54, accuracy:  39.70%\n",
      "Epoch [43/100], Step [15/60], Loss: 1.6223, batch time: 0.53, accuracy:  41.30%\n",
      "Epoch [43/100], Step [16/60], Loss: 1.5929, batch time: 0.56, accuracy:  44.00%\n",
      "Epoch [43/100], Step [17/60], Loss: 1.5884, batch time: 0.53, accuracy:  42.50%\n",
      "Epoch [43/100], Step [18/60], Loss: 1.6072, batch time: 0.54, accuracy:  41.90%\n",
      "Epoch [43/100], Step [19/60], Loss: 1.5773, batch time: 0.53, accuracy:  43.00%\n",
      "Epoch [43/100], Step [20/60], Loss: 1.5979, batch time: 0.54, accuracy:  43.50%\n",
      "Epoch [43/100], Step [21/60], Loss: 1.6163, batch time: 0.48, accuracy:  40.60%\n",
      "Epoch [43/100], Step [22/60], Loss: 1.6032, batch time: 0.43, accuracy:  42.50%\n",
      "Epoch [43/100], Step [23/60], Loss: 1.5976, batch time: 0.45, accuracy:  40.10%\n",
      "Epoch [43/100], Step [24/60], Loss: 1.5826, batch time: 0.45, accuracy:  41.70%\n",
      "Epoch [43/100], Step [25/60], Loss: 1.6311, batch time: 0.50, accuracy:  40.80%\n",
      "Epoch [43/100], Step [26/60], Loss: 1.5990, batch time: 0.46, accuracy:  40.90%\n",
      "Epoch [43/100], Step [27/60], Loss: 1.6173, batch time: 0.44, accuracy:  42.20%\n",
      "Epoch [43/100], Step [28/60], Loss: 1.5787, batch time: 0.44, accuracy:  42.10%\n",
      "Epoch [43/100], Step [29/60], Loss: 1.6024, batch time: 0.46, accuracy:  40.00%\n",
      "Epoch [43/100], Step [30/60], Loss: 1.5809, batch time: 0.44, accuracy:  41.00%\n",
      "Epoch [43/100], Step [31/60], Loss: 1.6246, batch time: 0.45, accuracy:  40.00%\n",
      "Epoch [43/100], Step [32/60], Loss: 1.6315, batch time: 0.45, accuracy:  39.20%\n",
      "Epoch [43/100], Step [33/60], Loss: 1.5751, batch time: 0.46, accuracy:  43.50%\n",
      "Epoch [43/100], Step [34/60], Loss: 1.5405, batch time: 0.44, accuracy:  44.90%\n",
      "Epoch [43/100], Step [35/60], Loss: 1.6085, batch time: 0.44, accuracy:  40.30%\n",
      "Epoch [43/100], Step [36/60], Loss: 1.6513, batch time: 0.44, accuracy:  38.30%\n",
      "Epoch [43/100], Step [37/60], Loss: 1.5632, batch time: 0.45, accuracy:  43.60%\n",
      "Epoch [43/100], Step [38/60], Loss: 1.6252, batch time: 0.44, accuracy:  42.50%\n",
      "Epoch [43/100], Step [39/60], Loss: 1.5801, batch time: 0.45, accuracy:  42.10%\n",
      "Epoch [43/100], Step [40/60], Loss: 1.5799, batch time: 0.46, accuracy:  41.80%\n",
      "Epoch [43/100], Step [41/60], Loss: 1.6103, batch time: 0.44, accuracy:  40.60%\n",
      "Epoch [43/100], Step [42/60], Loss: 1.6530, batch time: 0.48, accuracy:  39.30%\n",
      "Epoch [43/100], Step [43/60], Loss: 1.5989, batch time: 0.45, accuracy:  40.50%\n",
      "Epoch [43/100], Step [44/60], Loss: 1.6155, batch time: 0.45, accuracy:  39.80%\n",
      "Epoch [43/100], Step [45/60], Loss: 1.5870, batch time: 0.52, accuracy:  40.70%\n",
      "Epoch [43/100], Step [46/60], Loss: 1.6627, batch time: 0.52, accuracy:  39.90%\n",
      "Epoch [43/100], Step [47/60], Loss: 1.5737, batch time: 0.53, accuracy:  42.50%\n",
      "Epoch [43/100], Step [48/60], Loss: 1.5606, batch time: 0.53, accuracy:  43.50%\n",
      "Epoch [43/100], Step [49/60], Loss: 1.5772, batch time: 0.53, accuracy:  40.30%\n",
      "Epoch [43/100], Step [50/60], Loss: 1.6033, batch time: 0.57, accuracy:  44.00%\n",
      "Epoch [43/100], Step [51/60], Loss: 1.6506, batch time: 0.53, accuracy:  40.30%\n",
      "Epoch [43/100], Step [52/60], Loss: 1.6395, batch time: 0.55, accuracy:  40.20%\n",
      "Epoch [43/100], Step [53/60], Loss: 1.6068, batch time: 0.53, accuracy:  41.80%\n",
      "Epoch [43/100], Step [54/60], Loss: 1.5412, batch time: 0.52, accuracy:  42.10%\n",
      "Epoch [43/100], Step [55/60], Loss: 1.6311, batch time: 0.44, accuracy:  41.00%\n",
      "Epoch [43/100], Step [56/60], Loss: 1.6101, batch time: 0.43, accuracy:  41.50%\n",
      "Epoch [43/100], Step [57/60], Loss: 1.5763, batch time: 0.45, accuracy:  42.00%\n",
      "Epoch [43/100], Step [58/60], Loss: 1.5725, batch time: 0.45, accuracy:  42.10%\n",
      "Epoch [43/100], Step [59/60], Loss: 1.5731, batch time: 0.45, accuracy:  44.30%\n",
      "Epoch [43/100], Step [60/60], Loss: 1.5742, batch time: 0.46, accuracy:  42.60%\n",
      "Epoch [44/100], Step [1/60], Loss: 1.6623, batch time: 0.45, accuracy:  37.60%\n",
      "Epoch [44/100], Step [2/60], Loss: 1.5487, batch time: 0.44, accuracy:  43.60%\n",
      "Epoch [44/100], Step [3/60], Loss: 1.5287, batch time: 0.46, accuracy:  44.10%\n",
      "Epoch [44/100], Step [4/60], Loss: 1.5897, batch time: 0.44, accuracy:  42.30%\n",
      "Epoch [44/100], Step [5/60], Loss: 1.6055, batch time: 0.44, accuracy:  40.80%\n",
      "Epoch [44/100], Step [6/60], Loss: 1.5461, batch time: 0.45, accuracy:  46.30%\n",
      "Epoch [44/100], Step [7/60], Loss: 1.5808, batch time: 0.44, accuracy:  43.80%\n",
      "Epoch [44/100], Step [8/60], Loss: 1.5793, batch time: 0.47, accuracy:  42.20%\n",
      "Epoch [44/100], Step [9/60], Loss: 1.6153, batch time: 0.45, accuracy:  40.70%\n",
      "Epoch [44/100], Step [10/60], Loss: 1.6171, batch time: 0.44, accuracy:  40.80%\n",
      "Epoch [44/100], Step [11/60], Loss: 1.6087, batch time: 0.45, accuracy:  43.40%\n",
      "Epoch [44/100], Step [12/60], Loss: 1.6361, batch time: 0.45, accuracy:  41.50%\n",
      "Epoch [44/100], Step [13/60], Loss: 1.6392, batch time: 0.44, accuracy:  40.40%\n",
      "Epoch [44/100], Step [14/60], Loss: 1.5629, batch time: 0.52, accuracy:  44.10%\n",
      "Epoch [44/100], Step [15/60], Loss: 1.6402, batch time: 0.44, accuracy:  41.10%\n",
      "Epoch [44/100], Step [16/60], Loss: 1.5257, batch time: 0.44, accuracy:  44.60%\n",
      "Epoch [44/100], Step [17/60], Loss: 1.5893, batch time: 0.49, accuracy:  44.20%\n",
      "Epoch [44/100], Step [18/60], Loss: 1.5996, batch time: 0.50, accuracy:  43.80%\n",
      "Epoch [44/100], Step [19/60], Loss: 1.6083, batch time: 0.55, accuracy:  42.30%\n",
      "Epoch [44/100], Step [20/60], Loss: 1.6028, batch time: 0.53, accuracy:  42.50%\n",
      "Epoch [44/100], Step [21/60], Loss: 1.5615, batch time: 0.53, accuracy:  44.60%\n",
      "Epoch [44/100], Step [22/60], Loss: 1.6470, batch time: 0.54, accuracy:  38.50%\n",
      "Epoch [44/100], Step [23/60], Loss: 1.6543, batch time: 0.53, accuracy:  41.20%\n",
      "Epoch [44/100], Step [24/60], Loss: 1.5574, batch time: 0.55, accuracy:  43.30%\n",
      "Epoch [44/100], Step [25/60], Loss: 1.6272, batch time: 0.55, accuracy:  39.30%\n",
      "Epoch [44/100], Step [26/60], Loss: 1.5673, batch time: 0.55, accuracy:  43.60%\n",
      "Epoch [44/100], Step [27/60], Loss: 1.6043, batch time: 0.75, accuracy:  40.90%\n",
      "Epoch [44/100], Step [28/60], Loss: 1.6076, batch time: 0.45, accuracy:  40.80%\n",
      "Epoch [44/100], Step [29/60], Loss: 1.5346, batch time: 0.43, accuracy:  44.30%\n",
      "Epoch [44/100], Step [30/60], Loss: 1.6103, batch time: 0.44, accuracy:  42.00%\n",
      "Epoch [44/100], Step [31/60], Loss: 1.5264, batch time: 0.46, accuracy:  43.80%\n",
      "Epoch [44/100], Step [32/60], Loss: 1.5993, batch time: 0.44, accuracy:  40.70%\n",
      "Epoch [44/100], Step [33/60], Loss: 1.5882, batch time: 0.47, accuracy:  42.60%\n",
      "Epoch [44/100], Step [34/60], Loss: 1.5838, batch time: 0.45, accuracy:  42.50%\n",
      "Epoch [44/100], Step [35/60], Loss: 1.5485, batch time: 0.44, accuracy:  43.80%\n",
      "Epoch [44/100], Step [36/60], Loss: 1.6089, batch time: 0.45, accuracy:  42.20%\n",
      "Epoch [44/100], Step [37/60], Loss: 1.5709, batch time: 0.46, accuracy:  43.40%\n",
      "Epoch [44/100], Step [38/60], Loss: 1.6437, batch time: 0.44, accuracy:  41.30%\n",
      "Epoch [44/100], Step [39/60], Loss: 1.5715, batch time: 0.44, accuracy:  42.40%\n",
      "Epoch [44/100], Step [40/60], Loss: 1.5989, batch time: 0.44, accuracy:  44.60%\n",
      "Epoch [44/100], Step [41/60], Loss: 1.6004, batch time: 0.44, accuracy:  42.60%\n",
      "Epoch [44/100], Step [42/60], Loss: 1.6727, batch time: 0.46, accuracy:  39.30%\n",
      "Epoch [44/100], Step [43/60], Loss: 1.6058, batch time: 0.44, accuracy:  40.10%\n",
      "Epoch [44/100], Step [44/60], Loss: 1.5380, batch time: 0.45, accuracy:  43.40%\n",
      "Epoch [44/100], Step [45/60], Loss: 1.6075, batch time: 0.46, accuracy:  43.60%\n",
      "Epoch [44/100], Step [46/60], Loss: 1.5774, batch time: 0.44, accuracy:  43.60%\n",
      "Epoch [44/100], Step [47/60], Loss: 1.5558, batch time: 0.50, accuracy:  44.60%\n",
      "Epoch [44/100], Step [48/60], Loss: 1.6074, batch time: 0.46, accuracy:  42.30%\n",
      "Epoch [44/100], Step [49/60], Loss: 1.6060, batch time: 0.45, accuracy:  41.00%\n",
      "Epoch [44/100], Step [50/60], Loss: 1.5586, batch time: 0.46, accuracy:  43.30%\n",
      "Epoch [44/100], Step [51/60], Loss: 1.5938, batch time: 0.56, accuracy:  40.90%\n",
      "Epoch [44/100], Step [52/60], Loss: 1.5777, batch time: 0.53, accuracy:  41.90%\n",
      "Epoch [44/100], Step [53/60], Loss: 1.5246, batch time: 0.55, accuracy:  42.30%\n",
      "Epoch [44/100], Step [54/60], Loss: 1.6336, batch time: 0.53, accuracy:  42.30%\n",
      "Epoch [44/100], Step [55/60], Loss: 1.5833, batch time: 0.54, accuracy:  43.60%\n",
      "Epoch [44/100], Step [56/60], Loss: 1.5991, batch time: 0.54, accuracy:  42.90%\n",
      "Epoch [44/100], Step [57/60], Loss: 1.6469, batch time: 0.53, accuracy:  39.40%\n",
      "Epoch [44/100], Step [58/60], Loss: 1.5346, batch time: 0.54, accuracy:  42.40%\n",
      "Epoch [44/100], Step [59/60], Loss: 1.6028, batch time: 0.56, accuracy:  40.40%\n",
      "Epoch [44/100], Step [60/60], Loss: 1.5923, batch time: 0.49, accuracy:  42.70%\n",
      "Epoch [45/100], Step [1/60], Loss: 1.6291, batch time: 0.46, accuracy:  38.50%\n",
      "Epoch [45/100], Step [2/60], Loss: 1.5332, batch time: 0.44, accuracy:  43.80%\n",
      "Epoch [45/100], Step [3/60], Loss: 1.5501, batch time: 0.45, accuracy:  43.40%\n",
      "Epoch [45/100], Step [4/60], Loss: 1.6108, batch time: 0.44, accuracy:  39.70%\n",
      "Epoch [45/100], Step [5/60], Loss: 1.5746, batch time: 0.44, accuracy:  42.50%\n",
      "Epoch [45/100], Step [6/60], Loss: 1.6013, batch time: 0.45, accuracy:  42.30%\n",
      "Epoch [45/100], Step [7/60], Loss: 1.5807, batch time: 0.44, accuracy:  42.50%\n",
      "Epoch [45/100], Step [8/60], Loss: 1.5471, batch time: 0.47, accuracy:  43.80%\n",
      "Epoch [45/100], Step [9/60], Loss: 1.5748, batch time: 0.45, accuracy:  42.90%\n",
      "Epoch [45/100], Step [10/60], Loss: 1.5815, batch time: 0.44, accuracy:  44.20%\n",
      "Epoch [45/100], Step [11/60], Loss: 1.5700, batch time: 0.45, accuracy:  41.80%\n",
      "Epoch [45/100], Step [12/60], Loss: 1.5633, batch time: 0.44, accuracy:  45.00%\n",
      "Epoch [45/100], Step [13/60], Loss: 1.5146, batch time: 0.44, accuracy:  43.90%\n",
      "Epoch [45/100], Step [14/60], Loss: 1.5630, batch time: 0.45, accuracy:  43.70%\n",
      "Epoch [45/100], Step [15/60], Loss: 1.6069, batch time: 0.44, accuracy:  43.60%\n",
      "Epoch [45/100], Step [16/60], Loss: 1.5675, batch time: 0.44, accuracy:  43.30%\n",
      "Epoch [45/100], Step [17/60], Loss: 1.6140, batch time: 0.48, accuracy:  44.50%\n",
      "Epoch [45/100], Step [18/60], Loss: 1.5460, batch time: 0.44, accuracy:  42.50%\n",
      "Epoch [45/100], Step [19/60], Loss: 1.5556, batch time: 0.45, accuracy:  43.10%\n",
      "Epoch [45/100], Step [20/60], Loss: 1.5807, batch time: 0.45, accuracy:  41.80%\n",
      "Epoch [45/100], Step [21/60], Loss: 1.5869, batch time: 0.44, accuracy:  43.00%\n",
      "Epoch [45/100], Step [22/60], Loss: 1.5542, batch time: 0.46, accuracy:  43.80%\n",
      "Epoch [45/100], Step [23/60], Loss: 1.5461, batch time: 0.45, accuracy:  45.20%\n",
      "Epoch [45/100], Step [24/60], Loss: 1.5305, batch time: 0.51, accuracy:  44.60%\n",
      "Epoch [45/100], Step [25/60], Loss: 1.5673, batch time: 0.55, accuracy:  45.00%\n",
      "Epoch [45/100], Step [26/60], Loss: 1.6197, batch time: 0.56, accuracy:  42.50%\n",
      "Epoch [45/100], Step [27/60], Loss: 1.6197, batch time: 0.54, accuracy:  40.60%\n",
      "Epoch [45/100], Step [28/60], Loss: 1.5973, batch time: 0.53, accuracy:  41.40%\n",
      "Epoch [45/100], Step [29/60], Loss: 1.5880, batch time: 0.60, accuracy:  42.30%\n",
      "Epoch [45/100], Step [30/60], Loss: 1.6021, batch time: 0.54, accuracy:  43.40%\n",
      "Epoch [45/100], Step [31/60], Loss: 1.5348, batch time: 0.53, accuracy:  43.70%\n",
      "Epoch [45/100], Step [32/60], Loss: 1.5590, batch time: 0.45, accuracy:  44.00%\n",
      "Epoch [45/100], Step [33/60], Loss: 1.5642, batch time: 0.45, accuracy:  41.90%\n",
      "Epoch [45/100], Step [34/60], Loss: 1.5598, batch time: 0.46, accuracy:  43.30%\n",
      "Epoch [45/100], Step [35/60], Loss: 1.6474, batch time: 0.44, accuracy:  40.70%\n",
      "Epoch [45/100], Step [36/60], Loss: 1.6061, batch time: 0.45, accuracy:  42.40%\n",
      "Epoch [45/100], Step [37/60], Loss: 1.6159, batch time: 0.45, accuracy:  40.60%\n",
      "Epoch [45/100], Step [38/60], Loss: 1.5974, batch time: 0.45, accuracy:  42.70%\n",
      "Epoch [45/100], Step [39/60], Loss: 1.5517, batch time: 0.44, accuracy:  42.40%\n",
      "Epoch [45/100], Step [40/60], Loss: 1.5687, batch time: 0.45, accuracy:  44.40%\n",
      "Epoch [45/100], Step [41/60], Loss: 1.5929, batch time: 0.45, accuracy:  42.80%\n",
      "Epoch [45/100], Step [42/60], Loss: 1.5608, batch time: 0.44, accuracy:  44.10%\n",
      "Epoch [45/100], Step [43/60], Loss: 1.5898, batch time: 0.48, accuracy:  42.80%\n",
      "Epoch [45/100], Step [44/60], Loss: 1.5494, batch time: 0.44, accuracy:  44.50%\n",
      "Epoch [45/100], Step [45/60], Loss: 1.5628, batch time: 0.44, accuracy:  42.80%\n",
      "Epoch [45/100], Step [46/60], Loss: 1.6167, batch time: 0.47, accuracy:  39.60%\n",
      "Epoch [45/100], Step [47/60], Loss: 1.5926, batch time: 0.44, accuracy:  43.50%\n",
      "Epoch [45/100], Step [48/60], Loss: 1.5732, batch time: 0.54, accuracy:  41.60%\n",
      "Epoch [45/100], Step [49/60], Loss: 1.5627, batch time: 0.45, accuracy:  42.50%\n",
      "Epoch [45/100], Step [50/60], Loss: 1.5952, batch time: 0.44, accuracy:  42.30%\n",
      "Epoch [45/100], Step [51/60], Loss: 1.5541, batch time: 0.46, accuracy:  43.70%\n",
      "Epoch [45/100], Step [52/60], Loss: 1.5672, batch time: 0.46, accuracy:  43.10%\n",
      "Epoch [45/100], Step [53/60], Loss: 1.5771, batch time: 0.45, accuracy:  43.50%\n",
      "Epoch [45/100], Step [54/60], Loss: 1.5709, batch time: 0.47, accuracy:  42.60%\n",
      "Epoch [45/100], Step [55/60], Loss: 1.5676, batch time: 0.48, accuracy:  44.60%\n",
      "Epoch [45/100], Step [56/60], Loss: 1.6108, batch time: 0.54, accuracy:  42.60%\n",
      "Epoch [45/100], Step [57/60], Loss: 1.5447, batch time: 0.54, accuracy:  43.60%\n",
      "Epoch [45/100], Step [58/60], Loss: 1.5625, batch time: 0.53, accuracy:  43.10%\n",
      "Epoch [45/100], Step [59/60], Loss: 1.5389, batch time: 0.55, accuracy:  45.40%\n",
      "Epoch [45/100], Step [60/60], Loss: 1.6093, batch time: 0.54, accuracy:  43.00%\n",
      "Epoch [46/100], Step [1/60], Loss: 1.6267, batch time: 0.55, accuracy:  40.70%\n",
      "Epoch [46/100], Step [2/60], Loss: 1.5312, batch time: 0.90, accuracy:  46.00%\n",
      "Epoch [46/100], Step [3/60], Loss: 1.5822, batch time: 0.69, accuracy:  41.50%\n",
      "Epoch [46/100], Step [4/60], Loss: 1.5758, batch time: 0.68, accuracy:  43.70%\n",
      "Epoch [46/100], Step [5/60], Loss: 1.5362, batch time: 0.76, accuracy:  45.50%\n",
      "Epoch [46/100], Step [6/60], Loss: 1.5845, batch time: 0.69, accuracy:  43.30%\n",
      "Epoch [46/100], Step [7/60], Loss: 1.5368, batch time: 0.69, accuracy:  43.30%\n",
      "Epoch [46/100], Step [8/60], Loss: 1.5352, batch time: 0.57, accuracy:  43.90%\n",
      "Epoch [46/100], Step [9/60], Loss: 1.5463, batch time: 0.68, accuracy:  45.00%\n",
      "Epoch [46/100], Step [10/60], Loss: 1.5383, batch time: 0.70, accuracy:  44.80%\n",
      "Epoch [46/100], Step [11/60], Loss: 1.5686, batch time: 0.69, accuracy:  42.90%\n",
      "Epoch [46/100], Step [12/60], Loss: 1.5475, batch time: 0.70, accuracy:  43.90%\n",
      "Epoch [46/100], Step [13/60], Loss: 1.5610, batch time: 0.69, accuracy:  44.30%\n",
      "Epoch [46/100], Step [14/60], Loss: 1.5187, batch time: 0.69, accuracy:  44.70%\n",
      "Epoch [46/100], Step [15/60], Loss: 1.6159, batch time: 0.71, accuracy:  41.40%\n",
      "Epoch [46/100], Step [16/60], Loss: 1.5913, batch time: 0.73, accuracy:  44.10%\n",
      "Epoch [46/100], Step [17/60], Loss: 1.5717, batch time: 0.61, accuracy:  45.40%\n",
      "Epoch [46/100], Step [18/60], Loss: 1.5198, batch time: 0.82, accuracy:  44.90%\n",
      "Epoch [46/100], Step [19/60], Loss: 1.5489, batch time: 0.83, accuracy:  44.10%\n",
      "Epoch [46/100], Step [20/60], Loss: 1.5353, batch time: 0.85, accuracy:  46.40%\n",
      "Epoch [46/100], Step [21/60], Loss: 1.5810, batch time: 0.78, accuracy:  42.60%\n",
      "Epoch [46/100], Step [22/60], Loss: 1.5404, batch time: 0.69, accuracy:  45.30%\n",
      "Epoch [46/100], Step [23/60], Loss: 1.5676, batch time: 0.69, accuracy:  44.90%\n",
      "Epoch [46/100], Step [24/60], Loss: 1.5328, batch time: 0.69, accuracy:  44.10%\n",
      "Epoch [46/100], Step [25/60], Loss: 1.5920, batch time: 0.69, accuracy:  41.90%\n",
      "Epoch [46/100], Step [26/60], Loss: 1.5617, batch time: 0.68, accuracy:  43.50%\n",
      "Epoch [46/100], Step [27/60], Loss: 1.5137, batch time: 0.69, accuracy:  44.70%\n",
      "Epoch [46/100], Step [28/60], Loss: 1.5950, batch time: 0.69, accuracy:  42.20%\n",
      "Epoch [46/100], Step [29/60], Loss: 1.5713, batch time: 0.69, accuracy:  41.70%\n",
      "Epoch [46/100], Step [30/60], Loss: 1.5707, batch time: 0.70, accuracy:  45.00%\n",
      "Epoch [46/100], Step [31/60], Loss: 1.5390, batch time: 0.70, accuracy:  44.70%\n",
      "Epoch [46/100], Step [32/60], Loss: 1.5896, batch time: 0.69, accuracy:  40.80%\n",
      "Epoch [46/100], Step [33/60], Loss: 1.5100, batch time: 0.69, accuracy:  43.30%\n",
      "Epoch [46/100], Step [34/60], Loss: 1.5721, batch time: 0.73, accuracy:  43.30%\n",
      "Epoch [46/100], Step [35/60], Loss: 1.5859, batch time: 0.72, accuracy:  42.60%\n",
      "Epoch [46/100], Step [36/60], Loss: 1.5502, batch time: 0.73, accuracy:  43.80%\n",
      "Epoch [46/100], Step [37/60], Loss: 1.5199, batch time: 0.75, accuracy:  44.70%\n",
      "Epoch [46/100], Step [38/60], Loss: 1.5473, batch time: 0.93, accuracy:  42.60%\n",
      "Epoch [46/100], Step [39/60], Loss: 1.6002, batch time: 0.69, accuracy:  43.10%\n",
      "Epoch [46/100], Step [40/60], Loss: 1.5257, batch time: 0.65, accuracy:  44.40%\n",
      "Epoch [46/100], Step [41/60], Loss: 1.6404, batch time: 0.61, accuracy:  39.40%\n",
      "Epoch [46/100], Step [42/60], Loss: 1.5683, batch time: 0.65, accuracy:  42.80%\n",
      "Epoch [46/100], Step [43/60], Loss: 1.5659, batch time: 0.45, accuracy:  43.30%\n",
      "Epoch [46/100], Step [44/60], Loss: 1.5607, batch time: 0.67, accuracy:  42.50%\n",
      "Epoch [46/100], Step [45/60], Loss: 1.5617, batch time: 0.70, accuracy:  42.90%\n",
      "Epoch [46/100], Step [46/60], Loss: 1.6049, batch time: 0.70, accuracy:  41.80%\n",
      "Epoch [46/100], Step [47/60], Loss: 1.5563, batch time: 0.70, accuracy:  42.30%\n",
      "Epoch [46/100], Step [48/60], Loss: 1.5139, batch time: 0.69, accuracy:  47.40%\n",
      "Epoch [46/100], Step [49/60], Loss: 1.5996, batch time: 0.59, accuracy:  41.70%\n",
      "Epoch [46/100], Step [50/60], Loss: 1.5899, batch time: 0.73, accuracy:  44.50%\n",
      "Epoch [46/100], Step [51/60], Loss: 1.5415, batch time: 0.72, accuracy:  42.20%\n",
      "Epoch [46/100], Step [52/60], Loss: 1.5143, batch time: 0.73, accuracy:  44.90%\n",
      "Epoch [46/100], Step [53/60], Loss: 1.5780, batch time: 0.73, accuracy:  42.40%\n",
      "Epoch [46/100], Step [54/60], Loss: 1.5824, batch time: 0.87, accuracy:  45.10%\n",
      "Epoch [46/100], Step [55/60], Loss: 1.5777, batch time: 0.54, accuracy:  42.40%\n",
      "Epoch [46/100], Step [56/60], Loss: 1.5865, batch time: 0.53, accuracy:  44.50%\n",
      "Epoch [46/100], Step [57/60], Loss: 1.5649, batch time: 0.57, accuracy:  43.80%\n",
      "Epoch [46/100], Step [58/60], Loss: 1.5732, batch time: 0.53, accuracy:  41.80%\n",
      "Epoch [46/100], Step [59/60], Loss: 1.5524, batch time: 0.81, accuracy:  43.70%\n",
      "Epoch [46/100], Step [60/60], Loss: 1.5489, batch time: 0.84, accuracy:  45.10%\n",
      "Epoch [47/100], Step [1/60], Loss: 1.5530, batch time: 0.66, accuracy:  46.40%\n",
      "Epoch [47/100], Step [2/60], Loss: 1.5612, batch time: 0.68, accuracy:  44.10%\n",
      "Epoch [47/100], Step [3/60], Loss: 1.5689, batch time: 0.66, accuracy:  41.70%\n",
      "Epoch [47/100], Step [4/60], Loss: 1.4666, batch time: 0.66, accuracy:  48.20%\n",
      "Epoch [47/100], Step [5/60], Loss: 1.5400, batch time: 0.66, accuracy:  43.80%\n",
      "Epoch [47/100], Step [6/60], Loss: 1.5377, batch time: 0.71, accuracy:  44.50%\n",
      "Epoch [47/100], Step [7/60], Loss: 1.5427, batch time: 0.66, accuracy:  42.10%\n",
      "Epoch [47/100], Step [8/60], Loss: 1.5316, batch time: 0.66, accuracy:  47.60%\n",
      "Epoch [47/100], Step [9/60], Loss: 1.5367, batch time: 0.69, accuracy:  44.30%\n",
      "Epoch [47/100], Step [10/60], Loss: 1.5662, batch time: 0.67, accuracy:  43.20%\n",
      "Epoch [47/100], Step [11/60], Loss: 1.5277, batch time: 0.69, accuracy:  43.30%\n",
      "Epoch [47/100], Step [12/60], Loss: 1.6002, batch time: 0.66, accuracy:  42.30%\n",
      "Epoch [47/100], Step [13/60], Loss: 1.4992, batch time: 0.70, accuracy:  46.60%\n",
      "Epoch [47/100], Step [14/60], Loss: 1.5650, batch time: 0.62, accuracy:  43.40%\n",
      "Epoch [47/100], Step [15/60], Loss: 1.5739, batch time: 0.71, accuracy:  41.90%\n",
      "Epoch [47/100], Step [16/60], Loss: 1.5338, batch time: 0.71, accuracy:  45.30%\n",
      "Epoch [47/100], Step [17/60], Loss: 1.5399, batch time: 0.63, accuracy:  44.30%\n",
      "Epoch [47/100], Step [18/60], Loss: 1.5437, batch time: 0.83, accuracy:  44.50%\n",
      "Epoch [47/100], Step [19/60], Loss: 1.5191, batch time: 0.84, accuracy:  44.60%\n",
      "Epoch [47/100], Step [20/60], Loss: 1.5525, batch time: 0.87, accuracy:  43.40%\n",
      "Epoch [47/100], Step [21/60], Loss: 1.4919, batch time: 0.59, accuracy:  44.00%\n",
      "Epoch [47/100], Step [22/60], Loss: 1.5383, batch time: 0.62, accuracy:  42.40%\n",
      "Epoch [47/100], Step [23/60], Loss: 1.5897, batch time: 0.61, accuracy:  41.60%\n",
      "Epoch [47/100], Step [24/60], Loss: 1.5551, batch time: 0.54, accuracy:  45.40%\n",
      "Epoch [47/100], Step [25/60], Loss: 1.5381, batch time: 0.57, accuracy:  46.10%\n",
      "Epoch [47/100], Step [26/60], Loss: 1.5792, batch time: 0.61, accuracy:  42.00%\n",
      "Epoch [47/100], Step [27/60], Loss: 1.5175, batch time: 0.72, accuracy:  46.70%\n",
      "Epoch [47/100], Step [28/60], Loss: 1.5405, batch time: 0.61, accuracy:  43.90%\n",
      "Epoch [47/100], Step [29/60], Loss: 1.5132, batch time: 0.70, accuracy:  45.60%\n",
      "Epoch [47/100], Step [30/60], Loss: 1.5269, batch time: 0.71, accuracy:  43.90%\n",
      "Epoch [47/100], Step [31/60], Loss: 1.5495, batch time: 0.65, accuracy:  42.30%\n",
      "Epoch [47/100], Step [32/60], Loss: 1.5159, batch time: 0.65, accuracy:  44.70%\n",
      "Epoch [47/100], Step [33/60], Loss: 1.5779, batch time: 0.69, accuracy:  44.00%\n",
      "Epoch [47/100], Step [34/60], Loss: 1.5419, batch time: 0.70, accuracy:  44.70%\n",
      "Epoch [47/100], Step [35/60], Loss: 1.5473, batch time: 0.73, accuracy:  45.70%\n",
      "Epoch [47/100], Step [36/60], Loss: 1.5769, batch time: 0.64, accuracy:  44.80%\n",
      "Epoch [47/100], Step [37/60], Loss: 1.5652, batch time: 0.84, accuracy:  43.30%\n",
      "Epoch [47/100], Step [38/60], Loss: 1.5763, batch time: 0.75, accuracy:  44.90%\n",
      "Epoch [47/100], Step [39/60], Loss: 1.5795, batch time: 0.54, accuracy:  42.00%\n",
      "Epoch [47/100], Step [40/60], Loss: 1.5215, batch time: 0.53, accuracy:  43.30%\n",
      "Epoch [47/100], Step [41/60], Loss: 1.5279, batch time: 0.54, accuracy:  45.10%\n",
      "Epoch [47/100], Step [42/60], Loss: 1.5730, batch time: 0.53, accuracy:  45.10%\n",
      "Epoch [47/100], Step [43/60], Loss: 1.6062, batch time: 0.44, accuracy:  42.30%\n",
      "Epoch [47/100], Step [44/60], Loss: 1.5542, batch time: 0.43, accuracy:  43.40%\n",
      "Epoch [47/100], Step [45/60], Loss: 1.5326, batch time: 0.43, accuracy:  47.20%\n",
      "Epoch [47/100], Step [46/60], Loss: 1.4958, batch time: 0.43, accuracy:  44.90%\n",
      "Epoch [47/100], Step [47/60], Loss: 1.5763, batch time: 0.42, accuracy:  43.50%\n",
      "Epoch [47/100], Step [48/60], Loss: 1.5010, batch time: 0.42, accuracy:  46.20%\n",
      "Epoch [47/100], Step [49/60], Loss: 1.6122, batch time: 0.42, accuracy:  41.00%\n",
      "Epoch [47/100], Step [50/60], Loss: 1.5700, batch time: 0.43, accuracy:  44.20%\n",
      "Epoch [47/100], Step [51/60], Loss: 1.5363, batch time: 0.42, accuracy:  44.80%\n",
      "Epoch [47/100], Step [52/60], Loss: 1.5736, batch time: 0.44, accuracy:  43.70%\n",
      "Epoch [47/100], Step [53/60], Loss: 1.5814, batch time: 0.44, accuracy:  44.80%\n",
      "Epoch [47/100], Step [54/60], Loss: 1.5587, batch time: 0.42, accuracy:  44.30%\n",
      "Epoch [47/100], Step [55/60], Loss: 1.5208, batch time: 0.57, accuracy:  46.20%\n",
      "Epoch [47/100], Step [56/60], Loss: 1.5381, batch time: 0.70, accuracy:  45.00%\n",
      "Epoch [47/100], Step [57/60], Loss: 1.5070, batch time: 0.66, accuracy:  45.70%\n",
      "Epoch [47/100], Step [58/60], Loss: 1.5641, batch time: 0.70, accuracy:  42.40%\n",
      "Epoch [47/100], Step [59/60], Loss: 1.5668, batch time: 0.71, accuracy:  42.10%\n",
      "Epoch [47/100], Step [60/60], Loss: 1.5882, batch time: 0.72, accuracy:  41.70%\n",
      "Epoch [48/100], Step [1/60], Loss: 1.5743, batch time: 0.71, accuracy:  44.60%\n",
      "Epoch [48/100], Step [2/60], Loss: 1.5234, batch time: 0.72, accuracy:  43.90%\n",
      "Epoch [48/100], Step [3/60], Loss: 1.5179, batch time: 0.73, accuracy:  43.10%\n",
      "Epoch [48/100], Step [4/60], Loss: 1.5171, batch time: 0.73, accuracy:  46.10%\n",
      "Epoch [48/100], Step [5/60], Loss: 1.5535, batch time: 0.70, accuracy:  44.00%\n",
      "Epoch [48/100], Step [6/60], Loss: 1.5501, batch time: 0.74, accuracy:  43.00%\n",
      "Epoch [48/100], Step [7/60], Loss: 1.5791, batch time: 0.78, accuracy:  42.80%\n",
      "Epoch [48/100], Step [8/60], Loss: 1.5430, batch time: 0.86, accuracy:  45.50%\n",
      "Epoch [48/100], Step [9/60], Loss: 1.5053, batch time: 0.89, accuracy:  45.40%\n",
      "Epoch [48/100], Step [10/60], Loss: 1.5408, batch time: 0.70, accuracy:  43.30%\n",
      "Epoch [48/100], Step [11/60], Loss: 1.5305, batch time: 0.70, accuracy:  44.10%\n",
      "Epoch [48/100], Step [12/60], Loss: 1.5006, batch time: 0.68, accuracy:  46.10%\n",
      "Epoch [48/100], Step [13/60], Loss: 1.5453, batch time: 0.70, accuracy:  46.80%\n",
      "Epoch [48/100], Step [14/60], Loss: 1.5336, batch time: 0.66, accuracy:  43.90%\n",
      "Epoch [48/100], Step [15/60], Loss: 1.4545, batch time: 0.67, accuracy:  49.60%\n",
      "Epoch [48/100], Step [16/60], Loss: 1.5585, batch time: 0.70, accuracy:  44.20%\n",
      "Epoch [48/100], Step [17/60], Loss: 1.5460, batch time: 0.66, accuracy:  44.00%\n",
      "Epoch [48/100], Step [18/60], Loss: 1.5553, batch time: 0.70, accuracy:  43.60%\n",
      "Epoch [48/100], Step [19/60], Loss: 1.6129, batch time: 0.67, accuracy:  43.10%\n",
      "Epoch [48/100], Step [20/60], Loss: 1.5252, batch time: 0.70, accuracy:  45.90%\n",
      "Epoch [48/100], Step [21/60], Loss: 1.5132, batch time: 0.70, accuracy:  45.30%\n",
      "Epoch [48/100], Step [22/60], Loss: 1.5543, batch time: 0.70, accuracy:  43.80%\n",
      "Epoch [48/100], Step [23/60], Loss: 1.4983, batch time: 0.73, accuracy:  45.20%\n",
      "Epoch [48/100], Step [24/60], Loss: 1.5569, batch time: 0.72, accuracy:  44.50%\n",
      "Epoch [48/100], Step [25/60], Loss: 1.5306, batch time: 0.74, accuracy:  44.40%\n",
      "Epoch [48/100], Step [26/60], Loss: 1.5245, batch time: 0.72, accuracy:  46.70%\n",
      "Epoch [48/100], Step [27/60], Loss: 1.5901, batch time: 0.73, accuracy:  43.20%\n",
      "Epoch [48/100], Step [28/60], Loss: 1.5518, batch time: 0.71, accuracy:  43.50%\n",
      "Epoch [48/100], Step [29/60], Loss: 1.4920, batch time: 0.78, accuracy:  46.30%\n",
      "Epoch [48/100], Step [30/60], Loss: 1.5830, batch time: 0.83, accuracy:  44.10%\n",
      "Epoch [48/100], Step [31/60], Loss: 1.5445, batch time: 0.82, accuracy:  46.00%\n",
      "Epoch [48/100], Step [32/60], Loss: 1.4809, batch time: 0.82, accuracy:  46.70%\n",
      "Epoch [48/100], Step [33/60], Loss: 1.5608, batch time: 0.77, accuracy:  42.90%\n",
      "Epoch [48/100], Step [34/60], Loss: 1.5588, batch time: 0.64, accuracy:  44.40%\n",
      "Epoch [48/100], Step [35/60], Loss: 1.5613, batch time: 0.65, accuracy:  43.20%\n",
      "Epoch [48/100], Step [36/60], Loss: 1.5523, batch time: 0.65, accuracy:  44.30%\n",
      "Epoch [48/100], Step [37/60], Loss: 1.5359, batch time: 0.65, accuracy:  45.70%\n",
      "Epoch [48/100], Step [38/60], Loss: 1.4935, batch time: 0.60, accuracy:  46.10%\n",
      "Epoch [48/100], Step [39/60], Loss: 1.5185, batch time: 0.65, accuracy:  45.30%\n",
      "Epoch [48/100], Step [40/60], Loss: 1.6060, batch time: 0.65, accuracy:  42.30%\n",
      "Epoch [48/100], Step [41/60], Loss: 1.5711, batch time: 0.65, accuracy:  43.50%\n",
      "Epoch [48/100], Step [42/60], Loss: 1.5473, batch time: 0.65, accuracy:  45.10%\n",
      "Epoch [48/100], Step [43/60], Loss: 1.5300, batch time: 0.65, accuracy:  45.60%\n",
      "Epoch [48/100], Step [44/60], Loss: 1.5213, batch time: 0.66, accuracy:  43.90%\n",
      "Epoch [48/100], Step [45/60], Loss: 1.6022, batch time: 0.74, accuracy:  42.30%\n",
      "Epoch [48/100], Step [46/60], Loss: 1.5773, batch time: 0.70, accuracy:  41.80%\n",
      "Epoch [48/100], Step [47/60], Loss: 1.5123, batch time: 0.71, accuracy:  46.30%\n",
      "Epoch [48/100], Step [48/60], Loss: 1.5129, batch time: 0.70, accuracy:  48.40%\n",
      "Epoch [48/100], Step [49/60], Loss: 1.5343, batch time: 0.70, accuracy:  45.40%\n",
      "Epoch [48/100], Step [50/60], Loss: 1.5564, batch time: 0.71, accuracy:  44.10%\n",
      "Epoch [48/100], Step [51/60], Loss: 1.5301, batch time: 0.70, accuracy:  43.80%\n",
      "Epoch [48/100], Step [52/60], Loss: 1.5290, batch time: 0.70, accuracy:  44.20%\n",
      "Epoch [48/100], Step [53/60], Loss: 1.5614, batch time: 0.82, accuracy:  46.70%\n",
      "Epoch [48/100], Step [54/60], Loss: 1.5230, batch time: 0.82, accuracy:  45.00%\n",
      "Epoch [48/100], Step [55/60], Loss: 1.4792, batch time: 0.82, accuracy:  47.80%\n",
      "Epoch [48/100], Step [56/60], Loss: 1.4706, batch time: 0.82, accuracy:  47.40%\n",
      "Epoch [48/100], Step [57/60], Loss: 1.5608, batch time: 0.70, accuracy:  44.00%\n",
      "Epoch [48/100], Step [58/60], Loss: 1.5170, batch time: 0.65, accuracy:  47.10%\n",
      "Epoch [48/100], Step [59/60], Loss: 1.5516, batch time: 0.65, accuracy:  45.10%\n",
      "Epoch [48/100], Step [60/60], Loss: 1.4543, batch time: 0.65, accuracy:  49.40%\n",
      "Epoch [49/100], Step [1/60], Loss: 1.5199, batch time: 0.65, accuracy:  46.10%\n",
      "Epoch [49/100], Step [2/60], Loss: 1.4932, batch time: 0.65, accuracy:  45.80%\n",
      "Epoch [49/100], Step [3/60], Loss: 1.5094, batch time: 0.65, accuracy:  46.20%\n",
      "Epoch [49/100], Step [4/60], Loss: 1.5037, batch time: 0.65, accuracy:  48.00%\n",
      "Epoch [49/100], Step [5/60], Loss: 1.5224, batch time: 0.66, accuracy:  46.10%\n",
      "Epoch [49/100], Step [6/60], Loss: 1.5046, batch time: 0.65, accuracy:  47.00%\n",
      "Epoch [49/100], Step [7/60], Loss: 1.4993, batch time: 0.65, accuracy:  44.90%\n",
      "Epoch [49/100], Step [8/60], Loss: 1.4997, batch time: 0.67, accuracy:  44.10%\n",
      "Epoch [49/100], Step [9/60], Loss: 1.5373, batch time: 0.70, accuracy:  43.70%\n",
      "Epoch [49/100], Step [10/60], Loss: 1.5237, batch time: 0.70, accuracy:  46.20%\n",
      "Epoch [49/100], Step [11/60], Loss: 1.5230, batch time: 0.73, accuracy:  45.40%\n",
      "Epoch [49/100], Step [12/60], Loss: 1.5221, batch time: 0.73, accuracy:  44.90%\n",
      "Epoch [49/100], Step [13/60], Loss: 1.5476, batch time: 0.71, accuracy:  44.60%\n",
      "Epoch [49/100], Step [14/60], Loss: 1.5314, batch time: 0.74, accuracy:  44.70%\n",
      "Epoch [49/100], Step [15/60], Loss: 1.5297, batch time: 0.79, accuracy:  46.60%\n",
      "Epoch [49/100], Step [16/60], Loss: 1.4693, batch time: 0.82, accuracy:  46.70%\n",
      "Epoch [49/100], Step [17/60], Loss: 1.5795, batch time: 0.82, accuracy:  42.00%\n",
      "Epoch [49/100], Step [18/60], Loss: 1.4956, batch time: 0.82, accuracy:  45.30%\n",
      "Epoch [49/100], Step [19/60], Loss: 1.5368, batch time: 0.76, accuracy:  46.10%\n",
      "Epoch [49/100], Step [20/60], Loss: 1.5566, batch time: 0.65, accuracy:  45.00%\n",
      "Epoch [49/100], Step [21/60], Loss: 1.5225, batch time: 0.65, accuracy:  46.30%\n",
      "Epoch [49/100], Step [22/60], Loss: 1.5090, batch time: 0.67, accuracy:  47.30%\n",
      "Epoch [49/100], Step [23/60], Loss: 1.4874, batch time: 0.68, accuracy:  45.70%\n",
      "Epoch [49/100], Step [24/60], Loss: 1.4693, batch time: 0.67, accuracy:  47.40%\n",
      "Epoch [49/100], Step [25/60], Loss: 1.4415, batch time: 0.55, accuracy:  48.30%\n",
      "Epoch [49/100], Step [26/60], Loss: 1.5668, batch time: 0.70, accuracy:  46.50%\n",
      "Epoch [49/100], Step [27/60], Loss: 1.6089, batch time: 0.55, accuracy:  41.60%\n",
      "Epoch [49/100], Step [28/60], Loss: 1.4915, batch time: 0.70, accuracy:  45.70%\n",
      "Epoch [49/100], Step [29/60], Loss: 1.4756, batch time: 0.54, accuracy:  44.50%\n",
      "Epoch [49/100], Step [30/60], Loss: 1.5174, batch time: 0.70, accuracy:  45.80%\n",
      "Epoch [49/100], Step [31/60], Loss: 1.5474, batch time: 0.54, accuracy:  43.90%\n",
      "Epoch [49/100], Step [32/60], Loss: 1.5315, batch time: 0.70, accuracy:  45.10%\n",
      "Epoch [49/100], Step [33/60], Loss: 1.5279, batch time: 0.70, accuracy:  44.50%\n",
      "Epoch [49/100], Step [34/60], Loss: 1.5518, batch time: 0.65, accuracy:  44.40%\n",
      "Epoch [49/100], Step [35/60], Loss: 1.5043, batch time: 0.73, accuracy:  48.60%\n",
      "Epoch [49/100], Step [36/60], Loss: 1.4879, batch time: 0.77, accuracy:  47.50%\n",
      "Epoch [49/100], Step [37/60], Loss: 1.5088, batch time: 0.79, accuracy:  46.20%\n",
      "Epoch [49/100], Step [38/60], Loss: 1.5543, batch time: 0.59, accuracy:  45.50%\n",
      "Epoch [49/100], Step [39/60], Loss: 1.5269, batch time: 0.63, accuracy:  45.10%\n",
      "Epoch [49/100], Step [40/60], Loss: 1.5400, batch time: 0.66, accuracy:  43.80%\n",
      "Epoch [49/100], Step [41/60], Loss: 1.4301, batch time: 0.66, accuracy:  48.40%\n",
      "Epoch [49/100], Step [42/60], Loss: 1.5562, batch time: 0.66, accuracy:  46.30%\n",
      "Epoch [49/100], Step [43/60], Loss: 1.5545, batch time: 0.66, accuracy:  46.30%\n",
      "Epoch [49/100], Step [44/60], Loss: 1.5534, batch time: 0.66, accuracy:  42.90%\n",
      "Epoch [49/100], Step [45/60], Loss: 1.5308, batch time: 0.66, accuracy:  45.70%\n",
      "Epoch [49/100], Step [46/60], Loss: 1.5394, batch time: 0.67, accuracy:  44.70%\n",
      "Epoch [49/100], Step [47/60], Loss: 1.5669, batch time: 0.67, accuracy:  43.00%\n",
      "Epoch [49/100], Step [48/60], Loss: 1.5744, batch time: 0.71, accuracy:  42.90%\n",
      "Epoch [49/100], Step [49/60], Loss: 1.5488, batch time: 0.66, accuracy:  44.80%\n",
      "Epoch [49/100], Step [50/60], Loss: 1.4950, batch time: 0.71, accuracy:  48.00%\n",
      "Epoch [49/100], Step [51/60], Loss: 1.5012, batch time: 0.61, accuracy:  49.00%\n",
      "Epoch [49/100], Step [52/60], Loss: 1.5025, batch time: 0.74, accuracy:  44.20%\n",
      "Epoch [49/100], Step [53/60], Loss: 1.5848, batch time: 0.71, accuracy:  42.60%\n",
      "Epoch [49/100], Step [54/60], Loss: 1.5358, batch time: 0.74, accuracy:  43.50%\n",
      "Epoch [49/100], Step [55/60], Loss: 1.4633, batch time: 0.74, accuracy:  47.70%\n",
      "Epoch [49/100], Step [56/60], Loss: 1.4923, batch time: 0.74, accuracy:  48.40%\n",
      "Epoch [49/100], Step [57/60], Loss: 1.4939, batch time: 0.80, accuracy:  49.30%\n",
      "Epoch [49/100], Step [58/60], Loss: 1.4553, batch time: 0.85, accuracy:  47.80%\n",
      "Epoch [49/100], Step [59/60], Loss: 1.5035, batch time: 0.87, accuracy:  45.70%\n",
      "Epoch [49/100], Step [60/60], Loss: 1.4592, batch time: 0.86, accuracy:  47.50%\n",
      "Epoch [50/100], Step [1/60], Loss: 1.4454, batch time: 0.75, accuracy:  50.40%\n",
      "Epoch [50/100], Step [2/60], Loss: 1.5002, batch time: 0.70, accuracy:  47.10%\n",
      "Epoch [50/100], Step [3/60], Loss: 1.5717, batch time: 0.70, accuracy:  44.30%\n",
      "Epoch [50/100], Step [4/60], Loss: 1.5433, batch time: 0.68, accuracy:  45.90%\n",
      "Epoch [50/100], Step [5/60], Loss: 1.4854, batch time: 0.70, accuracy:  45.30%\n",
      "Epoch [50/100], Step [6/60], Loss: 1.5120, batch time: 0.67, accuracy:  45.50%\n",
      "Epoch [50/100], Step [7/60], Loss: 1.5303, batch time: 0.77, accuracy:  45.60%\n",
      "Epoch [50/100], Step [8/60], Loss: 1.4505, batch time: 0.67, accuracy:  47.90%\n",
      "Epoch [50/100], Step [9/60], Loss: 1.5814, batch time: 0.71, accuracy:  43.20%\n",
      "Epoch [50/100], Step [10/60], Loss: 1.5182, batch time: 0.68, accuracy:  45.20%\n",
      "Epoch [50/100], Step [11/60], Loss: 1.4673, batch time: 0.71, accuracy:  47.80%\n",
      "Epoch [50/100], Step [12/60], Loss: 1.5378, batch time: 0.71, accuracy:  47.10%\n",
      "Epoch [50/100], Step [13/60], Loss: 1.4958, batch time: 0.69, accuracy:  45.10%\n",
      "Epoch [50/100], Step [14/60], Loss: 1.4892, batch time: 0.72, accuracy:  47.30%\n",
      "Epoch [50/100], Step [15/60], Loss: 1.5327, batch time: 0.57, accuracy:  45.60%\n",
      "Epoch [50/100], Step [16/60], Loss: 1.4580, batch time: 0.74, accuracy:  47.40%\n",
      "Epoch [50/100], Step [17/60], Loss: 1.4391, batch time: 0.73, accuracy:  48.30%\n",
      "Epoch [50/100], Step [18/60], Loss: 1.4888, batch time: 0.71, accuracy:  46.20%\n",
      "Epoch [50/100], Step [19/60], Loss: 1.4916, batch time: 0.74, accuracy:  46.20%\n",
      "Epoch [50/100], Step [20/60], Loss: 1.4959, batch time: 0.75, accuracy:  45.80%\n",
      "Epoch [50/100], Step [21/60], Loss: 1.4927, batch time: 0.81, accuracy:  43.60%\n",
      "Epoch [50/100], Step [22/60], Loss: 1.5426, batch time: 0.85, accuracy:  43.20%\n",
      "Epoch [50/100], Step [23/60], Loss: 1.4781, batch time: 0.85, accuracy:  46.60%\n",
      "Epoch [50/100], Step [24/60], Loss: 1.4953, batch time: 0.88, accuracy:  46.10%\n",
      "Epoch [50/100], Step [25/60], Loss: 1.5067, batch time: 0.77, accuracy:  44.30%\n",
      "Epoch [50/100], Step [26/60], Loss: 1.4824, batch time: 0.77, accuracy:  46.60%\n",
      "Epoch [50/100], Step [27/60], Loss: 1.5340, batch time: 0.70, accuracy:  46.30%\n",
      "Epoch [50/100], Step [28/60], Loss: 1.5191, batch time: 0.54, accuracy:  45.30%\n",
      "Epoch [50/100], Step [29/60], Loss: 1.5009, batch time: 0.71, accuracy:  47.20%\n",
      "Epoch [50/100], Step [30/60], Loss: 1.5001, batch time: 0.70, accuracy:  46.60%\n",
      "Epoch [50/100], Step [31/60], Loss: 1.5420, batch time: 0.72, accuracy:  46.40%\n",
      "Epoch [50/100], Step [32/60], Loss: 1.5276, batch time: 0.64, accuracy:  45.10%\n",
      "Epoch [50/100], Step [33/60], Loss: 1.4723, batch time: 0.45, accuracy:  46.80%\n",
      "Epoch [50/100], Step [34/60], Loss: 1.4951, batch time: 0.44, accuracy:  48.20%\n",
      "Epoch [50/100], Step [35/60], Loss: 1.4886, batch time: 0.54, accuracy:  46.10%\n",
      "Epoch [50/100], Step [36/60], Loss: 1.4928, batch time: 0.45, accuracy:  46.80%\n",
      "Epoch [50/100], Step [37/60], Loss: 1.4986, batch time: 0.48, accuracy:  46.30%\n",
      "Epoch [50/100], Step [38/60], Loss: 1.5168, batch time: 0.70, accuracy:  45.50%\n",
      "Epoch [50/100], Step [39/60], Loss: 1.5266, batch time: 0.69, accuracy:  47.50%\n",
      "Epoch [50/100], Step [40/60], Loss: 1.4895, batch time: 0.69, accuracy:  46.70%\n",
      "Epoch [50/100], Step [41/60], Loss: 1.5311, batch time: 0.73, accuracy:  44.70%\n",
      "Epoch [50/100], Step [42/60], Loss: 1.4709, batch time: 0.72, accuracy:  46.10%\n",
      "Epoch [50/100], Step [43/60], Loss: 1.5051, batch time: 0.62, accuracy:  48.80%\n",
      "Epoch [50/100], Step [44/60], Loss: 1.4429, batch time: 0.83, accuracy:  49.20%\n",
      "Epoch [50/100], Step [45/60], Loss: 1.5224, batch time: 0.82, accuracy:  45.70%\n",
      "Epoch [50/100], Step [46/60], Loss: 1.4476, batch time: 0.86, accuracy:  49.00%\n",
      "Epoch [50/100], Step [47/60], Loss: 1.4947, batch time: 0.86, accuracy:  48.30%\n",
      "Epoch [50/100], Step [48/60], Loss: 1.5025, batch time: 0.85, accuracy:  47.20%\n",
      "Epoch [50/100], Step [49/60], Loss: 1.4904, batch time: 0.91, accuracy:  45.90%\n",
      "Epoch [50/100], Step [50/60], Loss: 1.4845, batch time: 0.83, accuracy:  48.10%\n",
      "Epoch [50/100], Step [51/60], Loss: 1.4888, batch time: 0.53, accuracy:  46.10%\n",
      "Epoch [50/100], Step [52/60], Loss: 1.4679, batch time: 0.53, accuracy:  48.20%\n",
      "Epoch [50/100], Step [53/60], Loss: 1.5274, batch time: 0.54, accuracy:  46.10%\n",
      "Epoch [50/100], Step [54/60], Loss: 1.5463, batch time: 0.69, accuracy:  46.80%\n",
      "Epoch [50/100], Step [55/60], Loss: 1.4606, batch time: 0.61, accuracy:  48.30%\n",
      "Epoch [50/100], Step [56/60], Loss: 1.4904, batch time: 0.65, accuracy:  47.90%\n",
      "Epoch [50/100], Step [57/60], Loss: 1.5940, batch time: 0.53, accuracy:  42.50%\n",
      "Epoch [50/100], Step [58/60], Loss: 1.5306, batch time: 0.70, accuracy:  45.60%\n",
      "Epoch [50/100], Step [59/60], Loss: 1.4328, batch time: 0.68, accuracy:  49.70%\n",
      "Epoch [50/100], Step [60/60], Loss: 1.5234, batch time: 0.59, accuracy:  48.60%\n",
      "Epoch [51/100], Step [1/60], Loss: 1.5634, batch time: 0.69, accuracy:  45.40%\n",
      "Epoch [51/100], Step [2/60], Loss: 1.5506, batch time: 0.71, accuracy:  46.00%\n",
      "Epoch [51/100], Step [3/60], Loss: 1.4621, batch time: 0.60, accuracy:  47.50%\n",
      "Epoch [51/100], Step [4/60], Loss: 1.5332, batch time: 0.68, accuracy:  47.40%\n",
      "Epoch [51/100], Step [5/60], Loss: 1.4732, batch time: 0.60, accuracy:  48.50%\n",
      "Epoch [51/100], Step [6/60], Loss: 1.4678, batch time: 0.68, accuracy:  47.70%\n",
      "Epoch [51/100], Step [7/60], Loss: 1.4561, batch time: 0.61, accuracy:  47.60%\n",
      "Epoch [51/100], Step [8/60], Loss: 1.5240, batch time: 0.59, accuracy:  47.40%\n",
      "Epoch [51/100], Step [9/60], Loss: 1.5142, batch time: 0.64, accuracy:  48.20%\n",
      "Epoch [51/100], Step [10/60], Loss: 1.5041, batch time: 0.64, accuracy:  48.90%\n",
      "Epoch [51/100], Step [11/60], Loss: 1.4834, batch time: 0.66, accuracy:  47.80%\n",
      "Epoch [51/100], Step [12/60], Loss: 1.5216, batch time: 0.84, accuracy:  45.30%\n",
      "Epoch [51/100], Step [13/60], Loss: 1.4683, batch time: 0.83, accuracy:  48.60%\n",
      "Epoch [51/100], Step [14/60], Loss: 1.4977, batch time: 0.72, accuracy:  44.70%\n",
      "Epoch [51/100], Step [15/60], Loss: 1.5328, batch time: 0.72, accuracy:  46.60%\n",
      "Epoch [51/100], Step [16/60], Loss: 1.5150, batch time: 0.60, accuracy:  47.20%\n",
      "Epoch [51/100], Step [17/60], Loss: 1.4856, batch time: 0.69, accuracy:  46.80%\n",
      "Epoch [51/100], Step [18/60], Loss: 1.4287, batch time: 0.62, accuracy:  47.60%\n",
      "Epoch [51/100], Step [19/60], Loss: 1.5312, batch time: 0.71, accuracy:  46.80%\n",
      "Epoch [51/100], Step [20/60], Loss: 1.4894, batch time: 0.72, accuracy:  47.10%\n",
      "Epoch [51/100], Step [21/60], Loss: 1.4937, batch time: 0.72, accuracy:  46.60%\n",
      "Epoch [51/100], Step [22/60], Loss: 1.5212, batch time: 0.71, accuracy:  45.60%\n",
      "Epoch [51/100], Step [23/60], Loss: 1.4926, batch time: 0.70, accuracy:  45.90%\n",
      "Epoch [51/100], Step [24/60], Loss: 1.4475, batch time: 0.70, accuracy:  47.50%\n",
      "Epoch [51/100], Step [25/60], Loss: 1.4817, batch time: 0.80, accuracy:  46.70%\n",
      "Epoch [51/100], Step [26/60], Loss: 1.4902, batch time: 0.73, accuracy:  49.60%\n",
      "Epoch [51/100], Step [27/60], Loss: 1.5185, batch time: 0.73, accuracy:  47.00%\n",
      "Epoch [51/100], Step [28/60], Loss: 1.4664, batch time: 0.67, accuracy:  46.60%\n",
      "Epoch [51/100], Step [29/60], Loss: 1.4428, batch time: 0.73, accuracy:  48.30%\n",
      "Epoch [51/100], Step [30/60], Loss: 1.4647, batch time: 0.70, accuracy:  51.80%\n",
      "Epoch [51/100], Step [31/60], Loss: 1.5277, batch time: 0.73, accuracy:  46.60%\n",
      "Epoch [51/100], Step [32/60], Loss: 1.4998, batch time: 0.70, accuracy:  45.20%\n",
      "Epoch [51/100], Step [33/60], Loss: 1.5254, batch time: 0.80, accuracy:  44.50%\n",
      "Epoch [51/100], Step [34/60], Loss: 1.4403, batch time: 0.83, accuracy:  47.10%\n",
      "Epoch [51/100], Step [35/60], Loss: 1.4621, batch time: 0.80, accuracy:  47.40%\n",
      "Epoch [51/100], Step [36/60], Loss: 1.5119, batch time: 0.65, accuracy:  45.60%\n",
      "Epoch [51/100], Step [37/60], Loss: 1.4969, batch time: 0.68, accuracy:  49.10%\n",
      "Epoch [51/100], Step [38/60], Loss: 1.5036, batch time: 0.65, accuracy:  47.10%\n",
      "Epoch [51/100], Step [39/60], Loss: 1.4690, batch time: 0.61, accuracy:  49.30%\n",
      "Epoch [51/100], Step [40/60], Loss: 1.4861, batch time: 0.66, accuracy:  46.90%\n",
      "Epoch [51/100], Step [41/60], Loss: 1.4460, batch time: 0.62, accuracy:  50.10%\n",
      "Epoch [51/100], Step [42/60], Loss: 1.4404, batch time: 0.66, accuracy:  48.70%\n",
      "Epoch [51/100], Step [43/60], Loss: 1.4558, batch time: 0.70, accuracy:  51.30%\n",
      "Epoch [51/100], Step [44/60], Loss: 1.4640, batch time: 0.70, accuracy:  49.30%\n",
      "Epoch [51/100], Step [45/60], Loss: 1.4578, batch time: 0.70, accuracy:  49.90%\n",
      "Epoch [51/100], Step [46/60], Loss: 1.5266, batch time: 0.71, accuracy:  47.40%\n",
      "Epoch [51/100], Step [47/60], Loss: 1.5240, batch time: 0.66, accuracy:  44.60%\n",
      "Epoch [51/100], Step [48/60], Loss: 1.4178, batch time: 0.71, accuracy:  50.30%\n",
      "Epoch [51/100], Step [49/60], Loss: 1.5131, batch time: 0.67, accuracy:  47.70%\n",
      "Epoch [51/100], Step [50/60], Loss: 1.4622, batch time: 0.66, accuracy:  47.00%\n",
      "Epoch [51/100], Step [51/60], Loss: 1.4792, batch time: 0.73, accuracy:  46.80%\n",
      "Epoch [51/100], Step [52/60], Loss: 1.4621, batch time: 0.76, accuracy:  47.30%\n",
      "Epoch [51/100], Step [53/60], Loss: 1.4928, batch time: 0.86, accuracy:  45.60%\n",
      "Epoch [51/100], Step [54/60], Loss: 1.4807, batch time: 0.68, accuracy:  46.40%\n",
      "Epoch [51/100], Step [55/60], Loss: 1.4765, batch time: 0.79, accuracy:  47.10%\n",
      "Epoch [51/100], Step [56/60], Loss: 1.4895, batch time: 0.85, accuracy:  46.20%\n",
      "Epoch [51/100], Step [57/60], Loss: 1.4837, batch time: 0.84, accuracy:  47.20%\n",
      "Epoch [51/100], Step [58/60], Loss: 1.4633, batch time: 0.84, accuracy:  48.50%\n",
      "Epoch [51/100], Step [59/60], Loss: 1.5301, batch time: 0.69, accuracy:  45.20%\n",
      "Epoch [51/100], Step [60/60], Loss: 1.4785, batch time: 0.69, accuracy:  49.00%\n",
      "Epoch [52/100], Step [1/60], Loss: 1.4548, batch time: 0.62, accuracy:  48.50%\n",
      "Epoch [52/100], Step [2/60], Loss: 1.4696, batch time: 0.70, accuracy:  49.90%\n",
      "Epoch [52/100], Step [3/60], Loss: 1.5129, batch time: 0.69, accuracy:  48.10%\n",
      "Epoch [52/100], Step [4/60], Loss: 1.4588, batch time: 0.69, accuracy:  47.80%\n",
      "Epoch [52/100], Step [5/60], Loss: 1.5038, batch time: 0.69, accuracy:  46.20%\n",
      "Epoch [52/100], Step [6/60], Loss: 1.4636, batch time: 0.69, accuracy:  51.50%\n",
      "Epoch [52/100], Step [7/60], Loss: 1.5212, batch time: 0.69, accuracy:  46.00%\n",
      "Epoch [52/100], Step [8/60], Loss: 1.5052, batch time: 0.69, accuracy:  46.10%\n",
      "Epoch [52/100], Step [9/60], Loss: 1.4486, batch time: 0.69, accuracy:  50.50%\n",
      "Epoch [52/100], Step [10/60], Loss: 1.4864, batch time: 0.69, accuracy:  49.40%\n",
      "Epoch [52/100], Step [11/60], Loss: 1.4607, batch time: 0.69, accuracy:  49.10%\n",
      "Epoch [52/100], Step [12/60], Loss: 1.4251, batch time: 0.69, accuracy:  49.00%\n",
      "Epoch [52/100], Step [13/60], Loss: 1.3832, batch time: 0.71, accuracy:  49.00%\n",
      "Epoch [52/100], Step [14/60], Loss: 1.4763, batch time: 0.79, accuracy:  46.10%\n",
      "Epoch [52/100], Step [15/60], Loss: 1.4611, batch time: 0.77, accuracy:  49.40%\n",
      "Epoch [52/100], Step [16/60], Loss: 1.5263, batch time: 0.83, accuracy:  46.40%\n",
      "Epoch [52/100], Step [17/60], Loss: 1.4294, batch time: 0.83, accuracy:  48.70%\n",
      "Epoch [52/100], Step [18/60], Loss: 1.4425, batch time: 0.83, accuracy:  49.00%\n",
      "Epoch [52/100], Step [19/60], Loss: 1.4335, batch time: 0.83, accuracy:  48.00%\n",
      "Epoch [52/100], Step [20/60], Loss: 1.4738, batch time: 0.83, accuracy:  46.70%\n",
      "Epoch [52/100], Step [21/60], Loss: 1.4567, batch time: 0.83, accuracy:  47.80%\n",
      "Epoch [52/100], Step [22/60], Loss: 1.4907, batch time: 0.83, accuracy:  48.40%\n",
      "Epoch [52/100], Step [23/60], Loss: 1.4478, batch time: 0.83, accuracy:  48.40%\n",
      "Epoch [52/100], Step [24/60], Loss: 1.4501, batch time: 0.80, accuracy:  48.30%\n",
      "Epoch [52/100], Step [25/60], Loss: 1.5017, batch time: 0.78, accuracy:  47.40%\n",
      "Epoch [52/100], Step [26/60], Loss: 1.5198, batch time: 0.74, accuracy:  44.50%\n",
      "Epoch [52/100], Step [27/60], Loss: 1.5236, batch time: 0.72, accuracy:  46.60%\n",
      "Epoch [52/100], Step [28/60], Loss: 1.4347, batch time: 0.61, accuracy:  49.00%\n",
      "Epoch [52/100], Step [29/60], Loss: 1.3716, batch time: 0.67, accuracy:  51.00%\n",
      "Epoch [52/100], Step [30/60], Loss: 1.4845, batch time: 0.68, accuracy:  47.80%\n",
      "Epoch [52/100], Step [31/60], Loss: 1.4798, batch time: 0.67, accuracy:  49.10%\n",
      "Epoch [52/100], Step [32/60], Loss: 1.4885, batch time: 0.68, accuracy:  47.30%\n",
      "Epoch [52/100], Step [33/60], Loss: 1.4467, batch time: 0.68, accuracy:  49.90%\n",
      "Epoch [52/100], Step [34/60], Loss: 1.4521, batch time: 0.68, accuracy:  48.50%\n",
      "Epoch [52/100], Step [35/60], Loss: 1.4628, batch time: 0.68, accuracy:  47.10%\n",
      "Epoch [52/100], Step [36/60], Loss: 1.4856, batch time: 0.68, accuracy:  48.80%\n",
      "Epoch [52/100], Step [37/60], Loss: 1.4724, batch time: 0.68, accuracy:  49.90%\n",
      "Epoch [52/100], Step [38/60], Loss: 1.4947, batch time: 0.69, accuracy:  46.60%\n",
      "Epoch [52/100], Step [39/60], Loss: 1.4965, batch time: 0.68, accuracy:  48.30%\n",
      "Epoch [52/100], Step [40/60], Loss: 1.5008, batch time: 0.70, accuracy:  46.20%\n",
      "Epoch [52/100], Step [41/60], Loss: 1.5324, batch time: 0.70, accuracy:  46.10%\n",
      "Epoch [52/100], Step [42/60], Loss: 1.4763, batch time: 0.72, accuracy:  47.00%\n",
      "Epoch [52/100], Step [43/60], Loss: 1.5082, batch time: 0.68, accuracy:  50.30%\n",
      "Epoch [52/100], Step [44/60], Loss: 1.4867, batch time: 0.72, accuracy:  46.10%\n",
      "Epoch [52/100], Step [45/60], Loss: 1.4661, batch time: 0.82, accuracy:  49.10%\n",
      "Epoch [52/100], Step [46/60], Loss: 1.5011, batch time: 0.83, accuracy:  48.90%\n",
      "Epoch [52/100], Step [47/60], Loss: 1.5126, batch time: 0.91, accuracy:  48.00%\n",
      "Epoch [52/100], Step [48/60], Loss: 1.4678, batch time: 0.82, accuracy:  48.40%\n",
      "Epoch [52/100], Step [49/60], Loss: 1.4873, batch time: 0.84, accuracy:  46.00%\n",
      "Epoch [52/100], Step [50/60], Loss: 1.4357, batch time: 0.82, accuracy:  49.40%\n",
      "Epoch [52/100], Step [51/60], Loss: 1.5009, batch time: 0.75, accuracy:  48.00%\n",
      "Epoch [52/100], Step [52/60], Loss: 1.4710, batch time: 0.68, accuracy:  47.30%\n",
      "Epoch [52/100], Step [53/60], Loss: 1.4453, batch time: 0.69, accuracy:  48.20%\n",
      "Epoch [52/100], Step [54/60], Loss: 1.4542, batch time: 0.67, accuracy:  47.30%\n",
      "Epoch [52/100], Step [55/60], Loss: 1.4722, batch time: 0.67, accuracy:  47.30%\n",
      "Epoch [52/100], Step [56/60], Loss: 1.4676, batch time: 0.67, accuracy:  47.90%\n",
      "Epoch [52/100], Step [57/60], Loss: 1.4434, batch time: 0.67, accuracy:  49.30%\n",
      "Epoch [52/100], Step [58/60], Loss: 1.4422, batch time: 0.68, accuracy:  49.90%\n",
      "Epoch [52/100], Step [59/60], Loss: 1.4602, batch time: 0.67, accuracy:  48.10%\n",
      "Epoch [52/100], Step [60/60], Loss: 1.4500, batch time: 0.68, accuracy:  51.10%\n",
      "Epoch [53/100], Step [1/60], Loss: 1.4718, batch time: 0.69, accuracy:  50.70%\n",
      "Epoch [53/100], Step [2/60], Loss: 1.4665, batch time: 0.68, accuracy:  48.20%\n",
      "Epoch [53/100], Step [3/60], Loss: 1.4092, batch time: 0.67, accuracy:  50.70%\n",
      "Epoch [53/100], Step [4/60], Loss: 1.4043, batch time: 0.68, accuracy:  53.70%\n",
      "Epoch [53/100], Step [5/60], Loss: 1.4761, batch time: 0.63, accuracy:  48.90%\n",
      "Epoch [53/100], Step [6/60], Loss: 1.4909, batch time: 0.73, accuracy:  46.40%\n",
      "Epoch [53/100], Step [7/60], Loss: 1.4645, batch time: 0.83, accuracy:  49.10%\n",
      "Epoch [53/100], Step [8/60], Loss: 1.4282, batch time: 0.86, accuracy:  51.40%\n",
      "Epoch [53/100], Step [9/60], Loss: 1.4722, batch time: 0.86, accuracy:  48.40%\n",
      "Epoch [53/100], Step [10/60], Loss: 1.4227, batch time: 0.87, accuracy:  50.80%\n",
      "Epoch [53/100], Step [11/60], Loss: 1.4337, batch time: 0.85, accuracy:  47.40%\n",
      "Epoch [53/100], Step [12/60], Loss: 1.4775, batch time: 0.84, accuracy:  46.60%\n",
      "Epoch [53/100], Step [13/60], Loss: 1.4535, batch time: 0.85, accuracy:  47.20%\n",
      "Epoch [53/100], Step [14/60], Loss: 1.4572, batch time: 0.63, accuracy:  47.50%\n",
      "Epoch [53/100], Step [15/60], Loss: 1.4412, batch time: 0.70, accuracy:  48.50%\n",
      "Epoch [53/100], Step [16/60], Loss: 1.5445, batch time: 0.71, accuracy:  44.90%\n",
      "Epoch [53/100], Step [17/60], Loss: 1.4191, batch time: 0.68, accuracy:  51.30%\n",
      "Epoch [53/100], Step [18/60], Loss: 1.4485, batch time: 0.71, accuracy:  49.20%\n",
      "Epoch [53/100], Step [19/60], Loss: 1.4269, batch time: 0.68, accuracy:  49.70%\n",
      "Epoch [53/100], Step [20/60], Loss: 1.4893, batch time: 0.72, accuracy:  46.60%\n",
      "Epoch [53/100], Step [21/60], Loss: 1.5105, batch time: 0.68, accuracy:  46.60%\n",
      "Epoch [53/100], Step [22/60], Loss: 1.4674, batch time: 0.70, accuracy:  47.50%\n",
      "Epoch [53/100], Step [23/60], Loss: 1.4488, batch time: 0.70, accuracy:  48.90%\n",
      "Epoch [53/100], Step [24/60], Loss: 1.4908, batch time: 0.68, accuracy:  48.30%\n",
      "Epoch [53/100], Step [25/60], Loss: 1.4295, batch time: 0.71, accuracy:  48.90%\n",
      "Epoch [53/100], Step [26/60], Loss: 1.3863, batch time: 0.69, accuracy:  54.70%\n",
      "Epoch [53/100], Step [27/60], Loss: 1.4942, batch time: 0.73, accuracy:  47.60%\n",
      "Epoch [53/100], Step [28/60], Loss: 1.4048, batch time: 0.74, accuracy:  51.20%\n",
      "Epoch [53/100], Step [29/60], Loss: 1.4707, batch time: 0.92, accuracy:  50.70%\n",
      "Epoch [53/100], Step [30/60], Loss: 1.3892, batch time: 0.87, accuracy:  51.20%\n",
      "Epoch [53/100], Step [31/60], Loss: 1.5198, batch time: 0.87, accuracy:  45.10%\n",
      "Epoch [53/100], Step [32/60], Loss: 1.4641, batch time: 0.87, accuracy:  50.90%\n",
      "Epoch [53/100], Step [33/60], Loss: 1.4343, batch time: 0.87, accuracy:  48.80%\n",
      "Epoch [53/100], Step [34/60], Loss: 1.4848, batch time: 0.87, accuracy:  49.40%\n",
      "Epoch [53/100], Step [35/60], Loss: 1.4584, batch time: 0.71, accuracy:  49.60%\n",
      "Epoch [53/100], Step [36/60], Loss: 1.4991, batch time: 0.71, accuracy:  47.70%\n",
      "Epoch [53/100], Step [37/60], Loss: 1.4367, batch time: 0.71, accuracy:  49.00%\n",
      "Epoch [53/100], Step [38/60], Loss: 1.4395, batch time: 0.71, accuracy:  50.60%\n",
      "Epoch [53/100], Step [39/60], Loss: 1.4376, batch time: 0.71, accuracy:  51.60%\n",
      "Epoch [53/100], Step [40/60], Loss: 1.4781, batch time: 0.71, accuracy:  49.70%\n",
      "Epoch [53/100], Step [41/60], Loss: 1.4289, batch time: 0.71, accuracy:  50.60%\n",
      "Epoch [53/100], Step [42/60], Loss: 1.4983, batch time: 0.71, accuracy:  48.50%\n",
      "Epoch [53/100], Step [43/60], Loss: 1.3929, batch time: 0.71, accuracy:  51.50%\n",
      "Epoch [53/100], Step [44/60], Loss: 1.4495, batch time: 0.72, accuracy:  50.10%\n",
      "Epoch [53/100], Step [45/60], Loss: 1.4394, batch time: 0.72, accuracy:  51.60%\n",
      "Epoch [53/100], Step [46/60], Loss: 1.4247, batch time: 0.72, accuracy:  49.40%\n",
      "Epoch [53/100], Step [47/60], Loss: 1.4591, batch time: 0.72, accuracy:  48.00%\n",
      "Epoch [53/100], Step [48/60], Loss: 1.4035, batch time: 0.74, accuracy:  51.00%\n",
      "Epoch [53/100], Step [49/60], Loss: 1.4105, batch time: 0.74, accuracy:  49.90%\n",
      "Epoch [53/100], Step [50/60], Loss: 1.4303, batch time: 0.74, accuracy:  48.50%\n",
      "Epoch [53/100], Step [51/60], Loss: 1.4480, batch time: 0.86, accuracy:  48.20%\n",
      "Epoch [53/100], Step [52/60], Loss: 1.4635, batch time: 0.86, accuracy:  47.80%\n",
      "Epoch [53/100], Step [53/60], Loss: 1.4736, batch time: 0.87, accuracy:  46.60%\n",
      "Epoch [53/100], Step [54/60], Loss: 1.4751, batch time: 0.87, accuracy:  48.90%\n",
      "Epoch [53/100], Step [55/60], Loss: 1.4590, batch time: 0.86, accuracy:  48.20%\n",
      "Epoch [53/100], Step [56/60], Loss: 1.4746, batch time: 0.86, accuracy:  50.10%\n",
      "Epoch [53/100], Step [57/60], Loss: 1.4671, batch time: 0.86, accuracy:  49.70%\n",
      "Epoch [53/100], Step [58/60], Loss: 1.4045, batch time: 0.82, accuracy:  51.60%\n",
      "Epoch [53/100], Step [59/60], Loss: 1.4515, batch time: 0.70, accuracy:  49.10%\n",
      "Epoch [53/100], Step [60/60], Loss: 1.4792, batch time: 0.71, accuracy:  47.90%\n",
      "Epoch [54/100], Step [1/60], Loss: 1.5009, batch time: 0.44, accuracy:  48.80%\n",
      "Epoch [54/100], Step [2/60], Loss: 1.5081, batch time: 0.55, accuracy:  45.90%\n",
      "Epoch [54/100], Step [3/60], Loss: 1.4325, batch time: 0.67, accuracy:  50.40%\n",
      "Epoch [54/100], Step [4/60], Loss: 1.4547, batch time: 0.68, accuracy:  49.90%\n",
      "Epoch [54/100], Step [5/60], Loss: 1.4673, batch time: 0.77, accuracy:  48.60%\n",
      "Epoch [54/100], Step [6/60], Loss: 1.4575, batch time: 0.65, accuracy:  48.70%\n",
      "Epoch [54/100], Step [7/60], Loss: 1.3951, batch time: 0.70, accuracy:  50.40%\n",
      "Epoch [54/100], Step [8/60], Loss: 1.4865, batch time: 0.70, accuracy:  47.40%\n",
      "Epoch [54/100], Step [9/60], Loss: 1.4368, batch time: 0.71, accuracy:  48.20%\n",
      "Epoch [54/100], Step [10/60], Loss: 1.4865, batch time: 0.68, accuracy:  48.90%\n",
      "Epoch [54/100], Step [11/60], Loss: 1.4845, batch time: 0.73, accuracy:  49.40%\n",
      "Epoch [54/100], Step [12/60], Loss: 1.3992, batch time: 0.71, accuracy:  52.50%\n",
      "Epoch [54/100], Step [13/60], Loss: 1.4067, batch time: 0.61, accuracy:  51.80%\n",
      "Epoch [54/100], Step [14/60], Loss: 1.3927, batch time: 0.74, accuracy:  51.10%\n",
      "Epoch [54/100], Step [15/60], Loss: 1.4261, batch time: 0.78, accuracy:  49.60%\n",
      "Epoch [54/100], Step [16/60], Loss: 1.3796, batch time: 0.87, accuracy:  50.50%\n",
      "Epoch [54/100], Step [17/60], Loss: 1.4066, batch time: 0.68, accuracy:  50.30%\n",
      "Epoch [54/100], Step [18/60], Loss: 1.4868, batch time: 0.54, accuracy:  48.20%\n",
      "Epoch [54/100], Step [19/60], Loss: 1.4263, batch time: 0.44, accuracy:  51.40%\n",
      "Epoch [54/100], Step [20/60], Loss: 1.4103, batch time: 0.43, accuracy:  50.90%\n",
      "Epoch [54/100], Step [21/60], Loss: 1.3763, batch time: 0.44, accuracy:  52.40%\n",
      "Epoch [54/100], Step [22/60], Loss: 1.4693, batch time: 0.45, accuracy:  50.40%\n",
      "Epoch [54/100], Step [23/60], Loss: 1.4632, batch time: 0.45, accuracy:  48.70%\n",
      "Epoch [54/100], Step [24/60], Loss: 1.4594, batch time: 0.46, accuracy:  49.30%\n",
      "Epoch [54/100], Step [25/60], Loss: 1.4334, batch time: 0.44, accuracy:  48.60%\n",
      "Epoch [54/100], Step [26/60], Loss: 1.4746, batch time: 0.44, accuracy:  48.10%\n",
      "Epoch [54/100], Step [27/60], Loss: 1.3946, batch time: 0.46, accuracy:  49.20%\n",
      "Epoch [54/100], Step [28/60], Loss: 1.4389, batch time: 0.44, accuracy:  49.90%\n",
      "Epoch [54/100], Step [29/60], Loss: 1.4192, batch time: 0.44, accuracy:  51.90%\n",
      "Epoch [54/100], Step [30/60], Loss: 1.3949, batch time: 0.45, accuracy:  51.60%\n",
      "Epoch [54/100], Step [31/60], Loss: 1.4591, batch time: 0.44, accuracy:  49.60%\n",
      "Epoch [54/100], Step [32/60], Loss: 1.4196, batch time: 0.47, accuracy:  50.90%\n",
      "Epoch [54/100], Step [33/60], Loss: 1.4574, batch time: 0.45, accuracy:  48.10%\n",
      "Epoch [54/100], Step [34/60], Loss: 1.4750, batch time: 0.44, accuracy:  47.30%\n",
      "Epoch [54/100], Step [35/60], Loss: 1.4656, batch time: 0.45, accuracy:  52.20%\n",
      "Epoch [54/100], Step [36/60], Loss: 1.4080, batch time: 0.44, accuracy:  51.90%\n",
      "Epoch [54/100], Step [37/60], Loss: 1.5048, batch time: 0.45, accuracy:  45.70%\n",
      "Epoch [54/100], Step [38/60], Loss: 1.4152, batch time: 0.46, accuracy:  52.10%\n",
      "Epoch [54/100], Step [39/60], Loss: 1.3912, batch time: 0.48, accuracy:  50.80%\n",
      "Epoch [54/100], Step [40/60], Loss: 1.4899, batch time: 0.53, accuracy:  48.40%\n",
      "Epoch [54/100], Step [41/60], Loss: 1.4615, batch time: 0.57, accuracy:  52.70%\n",
      "Epoch [54/100], Step [42/60], Loss: 1.4178, batch time: 0.53, accuracy:  51.80%\n",
      "Epoch [54/100], Step [43/60], Loss: 1.4187, batch time: 0.54, accuracy:  51.00%\n",
      "Epoch [54/100], Step [44/60], Loss: 1.4510, batch time: 0.53, accuracy:  48.10%\n",
      "Epoch [54/100], Step [45/60], Loss: 1.4585, batch time: 0.44, accuracy:  50.60%\n",
      "Epoch [54/100], Step [46/60], Loss: 1.4111, batch time: 0.45, accuracy:  48.10%\n",
      "Epoch [54/100], Step [47/60], Loss: 1.4396, batch time: 0.43, accuracy:  50.00%\n",
      "Epoch [54/100], Step [48/60], Loss: 1.3987, batch time: 0.44, accuracy:  52.50%\n",
      "Epoch [54/100], Step [49/60], Loss: 1.4185, batch time: 0.46, accuracy:  48.80%\n",
      "Epoch [54/100], Step [50/60], Loss: 1.4465, batch time: 0.44, accuracy:  52.20%\n",
      "Epoch [54/100], Step [51/60], Loss: 1.4922, batch time: 0.46, accuracy:  51.10%\n",
      "Epoch [54/100], Step [52/60], Loss: 1.3783, batch time: 0.44, accuracy:  53.40%\n",
      "Epoch [54/100], Step [53/60], Loss: 1.4347, batch time: 0.44, accuracy:  50.20%\n",
      "Epoch [54/100], Step [54/60], Loss: 1.3831, batch time: 0.52, accuracy:  51.60%\n",
      "Epoch [54/100], Step [55/60], Loss: 1.4301, batch time: 0.44, accuracy:  50.00%\n",
      "Epoch [54/100], Step [56/60], Loss: 1.4544, batch time: 0.44, accuracy:  51.70%\n",
      "Epoch [54/100], Step [57/60], Loss: 1.4218, batch time: 0.45, accuracy:  52.20%\n",
      "Epoch [54/100], Step [58/60], Loss: 1.4429, batch time: 0.45, accuracy:  50.30%\n",
      "Epoch [54/100], Step [59/60], Loss: 1.4495, batch time: 0.45, accuracy:  48.30%\n",
      "Epoch [54/100], Step [60/60], Loss: 1.4143, batch time: 0.45, accuracy:  48.90%\n",
      "Epoch [55/100], Step [1/60], Loss: 1.4231, batch time: 0.70, accuracy:  52.90%\n",
      "Epoch [55/100], Step [2/60], Loss: 1.4445, batch time: 0.70, accuracy:  48.90%\n",
      "Epoch [55/100], Step [3/60], Loss: 1.4456, batch time: 0.69, accuracy:  50.00%\n",
      "Epoch [55/100], Step [4/60], Loss: 1.3980, batch time: 0.73, accuracy:  51.90%\n",
      "Epoch [55/100], Step [5/60], Loss: 1.4930, batch time: 0.69, accuracy:  49.40%\n",
      "Epoch [55/100], Step [6/60], Loss: 1.4591, batch time: 0.89, accuracy:  50.10%\n",
      "Epoch [55/100], Step [7/60], Loss: 1.4624, batch time: 0.69, accuracy:  49.10%\n",
      "Epoch [55/100], Step [8/60], Loss: 1.4319, batch time: 0.69, accuracy:  52.20%\n",
      "Epoch [55/100], Step [9/60], Loss: 1.4205, batch time: 0.69, accuracy:  49.70%\n",
      "Epoch [55/100], Step [10/60], Loss: 1.3950, batch time: 0.69, accuracy:  52.50%\n",
      "Epoch [55/100], Step [11/60], Loss: 1.4038, batch time: 0.69, accuracy:  51.60%\n",
      "Epoch [55/100], Step [12/60], Loss: 1.4464, batch time: 0.69, accuracy:  48.80%\n",
      "Epoch [55/100], Step [13/60], Loss: 1.4123, batch time: 0.69, accuracy:  50.60%\n",
      "Epoch [55/100], Step [14/60], Loss: 1.4904, batch time: 0.66, accuracy:  47.90%\n",
      "Epoch [55/100], Step [15/60], Loss: 1.3974, batch time: 0.63, accuracy:  50.70%\n",
      "Epoch [55/100], Step [16/60], Loss: 1.3964, batch time: 0.63, accuracy:  52.40%\n",
      "Epoch [55/100], Step [17/60], Loss: 1.4316, batch time: 0.62, accuracy:  49.20%\n",
      "Epoch [55/100], Step [18/60], Loss: 1.3876, batch time: 0.65, accuracy:  49.80%\n",
      "Epoch [55/100], Step [19/60], Loss: 1.4516, batch time: 0.70, accuracy:  50.00%\n",
      "Epoch [55/100], Step [20/60], Loss: 1.3757, batch time: 0.69, accuracy:  53.70%\n",
      "Epoch [55/100], Step [21/60], Loss: 1.4359, batch time: 0.71, accuracy:  51.80%\n",
      "Epoch [55/100], Step [22/60], Loss: 1.4560, batch time: 0.80, accuracy:  48.80%\n",
      "Epoch [55/100], Step [23/60], Loss: 1.4372, batch time: 0.83, accuracy:  51.70%\n",
      "Epoch [55/100], Step [24/60], Loss: 1.4442, batch time: 0.83, accuracy:  50.90%\n",
      "Epoch [55/100], Step [25/60], Loss: 1.4427, batch time: 0.83, accuracy:  50.00%\n",
      "Epoch [55/100], Step [26/60], Loss: 1.4302, batch time: 0.83, accuracy:  50.90%\n",
      "Epoch [55/100], Step [27/60], Loss: 1.4531, batch time: 0.91, accuracy:  49.80%\n",
      "Epoch [55/100], Step [28/60], Loss: 1.4579, batch time: 0.85, accuracy:  52.10%\n",
      "Epoch [55/100], Step [29/60], Loss: 1.4017, batch time: 0.83, accuracy:  52.50%\n",
      "Epoch [55/100], Step [30/60], Loss: 1.4052, batch time: 0.71, accuracy:  51.20%\n",
      "Epoch [55/100], Step [31/60], Loss: 1.4019, batch time: 0.68, accuracy:  51.80%\n",
      "Epoch [55/100], Step [32/60], Loss: 1.3924, batch time: 0.69, accuracy:  51.10%\n",
      "Epoch [55/100], Step [33/60], Loss: 1.4424, batch time: 0.69, accuracy:  53.10%\n",
      "Epoch [55/100], Step [34/60], Loss: 1.4058, batch time: 0.70, accuracy:  50.40%\n",
      "Epoch [55/100], Step [35/60], Loss: 1.4094, batch time: 0.62, accuracy:  53.30%\n",
      "Epoch [55/100], Step [36/60], Loss: 1.3912, batch time: 0.70, accuracy:  50.40%\n",
      "Epoch [55/100], Step [37/60], Loss: 1.4500, batch time: 0.62, accuracy:  50.50%\n",
      "Epoch [55/100], Step [38/60], Loss: 1.4166, batch time: 0.72, accuracy:  52.50%\n",
      "Epoch [55/100], Step [39/60], Loss: 1.3933, batch time: 0.70, accuracy:  50.10%\n",
      "Epoch [55/100], Step [40/60], Loss: 1.3808, batch time: 0.72, accuracy:  51.80%\n",
      "Epoch [55/100], Step [41/60], Loss: 1.3695, batch time: 0.70, accuracy:  52.40%\n",
      "Epoch [55/100], Step [42/60], Loss: 1.4419, batch time: 0.72, accuracy:  50.20%\n",
      "Epoch [55/100], Step [43/60], Loss: 1.4682, batch time: 0.73, accuracy:  49.50%\n",
      "Epoch [55/100], Step [44/60], Loss: 1.3970, batch time: 0.75, accuracy:  51.50%\n",
      "Epoch [55/100], Step [45/60], Loss: 1.3975, batch time: 0.76, accuracy:  50.40%\n",
      "Epoch [55/100], Step [46/60], Loss: 1.3952, batch time: 0.85, accuracy:  51.00%\n",
      "Epoch [55/100], Step [47/60], Loss: 1.4086, batch time: 0.85, accuracy:  50.00%\n",
      "Epoch [55/100], Step [48/60], Loss: 1.3612, batch time: 0.80, accuracy:  53.30%\n",
      "Epoch [55/100], Step [49/60], Loss: 1.4595, batch time: 0.54, accuracy:  50.90%\n",
      "Epoch [55/100], Step [50/60], Loss: 1.4200, batch time: 0.53, accuracy:  50.00%\n",
      "Epoch [55/100], Step [51/60], Loss: 1.4186, batch time: 0.60, accuracy:  50.90%\n",
      "Epoch [55/100], Step [52/60], Loss: 1.3763, batch time: 0.53, accuracy:  53.40%\n",
      "Epoch [55/100], Step [53/60], Loss: 1.3929, batch time: 0.82, accuracy:  51.90%\n",
      "Epoch [55/100], Step [54/60], Loss: 1.3884, batch time: 0.86, accuracy:  51.70%\n",
      "Epoch [55/100], Step [55/60], Loss: 1.4756, batch time: 0.70, accuracy:  51.70%\n",
      "Epoch [55/100], Step [56/60], Loss: 1.4306, batch time: 0.71, accuracy:  51.70%\n",
      "Epoch [55/100], Step [57/60], Loss: 1.3953, batch time: 0.70, accuracy:  50.00%\n",
      "Epoch [55/100], Step [58/60], Loss: 1.3862, batch time: 0.69, accuracy:  53.10%\n",
      "Epoch [55/100], Step [59/60], Loss: 1.4074, batch time: 0.70, accuracy:  50.90%\n",
      "Epoch [55/100], Step [60/60], Loss: 1.3816, batch time: 0.70, accuracy:  51.20%\n",
      "Epoch [56/100], Step [1/60], Loss: 1.4206, batch time: 0.70, accuracy:  52.50%\n",
      "Epoch [56/100], Step [2/60], Loss: 1.4108, batch time: 0.70, accuracy:  51.00%\n",
      "Epoch [56/100], Step [3/60], Loss: 1.3809, batch time: 0.69, accuracy:  51.60%\n",
      "Epoch [56/100], Step [4/60], Loss: 1.4303, batch time: 0.70, accuracy:  51.10%\n",
      "Epoch [56/100], Step [5/60], Loss: 1.3776, batch time: 0.69, accuracy:  51.70%\n",
      "Epoch [56/100], Step [6/60], Loss: 1.4367, batch time: 0.70, accuracy:  50.80%\n",
      "Epoch [56/100], Step [7/60], Loss: 1.4462, batch time: 0.70, accuracy:  48.80%\n",
      "Epoch [56/100], Step [8/60], Loss: 1.4313, batch time: 0.74, accuracy:  52.60%\n",
      "Epoch [56/100], Step [9/60], Loss: 1.3655, batch time: 0.74, accuracy:  54.00%\n",
      "Epoch [56/100], Step [10/60], Loss: 1.4037, batch time: 0.83, accuracy:  52.80%\n",
      "Epoch [56/100], Step [11/60], Loss: 1.4181, batch time: 0.84, accuracy:  50.30%\n",
      "Epoch [56/100], Step [12/60], Loss: 1.3893, batch time: 0.85, accuracy:  52.70%\n",
      "Epoch [56/100], Step [13/60], Loss: 1.4019, batch time: 0.74, accuracy:  52.70%\n",
      "Epoch [56/100], Step [14/60], Loss: 1.4030, batch time: 0.78, accuracy:  51.80%\n",
      "Epoch [56/100], Step [15/60], Loss: 1.3986, batch time: 0.68, accuracy:  50.60%\n",
      "Epoch [56/100], Step [16/60], Loss: 1.4328, batch time: 0.72, accuracy:  51.00%\n",
      "Epoch [56/100], Step [17/60], Loss: 1.4055, batch time: 0.69, accuracy:  50.40%\n",
      "Epoch [56/100], Step [18/60], Loss: 1.3777, batch time: 0.70, accuracy:  49.90%\n",
      "Epoch [56/100], Step [19/60], Loss: 1.3878, batch time: 0.70, accuracy:  53.50%\n",
      "Epoch [56/100], Step [20/60], Loss: 1.3779, batch time: 0.62, accuracy:  55.00%\n",
      "Epoch [56/100], Step [21/60], Loss: 1.4102, batch time: 0.69, accuracy:  53.90%\n",
      "Epoch [56/100], Step [22/60], Loss: 1.4251, batch time: 0.73, accuracy:  50.30%\n",
      "Epoch [56/100], Step [23/60], Loss: 1.3841, batch time: 0.69, accuracy:  51.80%\n",
      "Epoch [56/100], Step [24/60], Loss: 1.4018, batch time: 0.73, accuracy:  52.20%\n",
      "Epoch [56/100], Step [25/60], Loss: 1.4329, batch time: 0.70, accuracy:  50.40%\n",
      "Epoch [56/100], Step [26/60], Loss: 1.4494, batch time: 0.70, accuracy:  47.50%\n",
      "Epoch [56/100], Step [27/60], Loss: 1.4090, batch time: 0.61, accuracy:  52.60%\n",
      "Epoch [56/100], Step [28/60], Loss: 1.4526, batch time: 0.73, accuracy:  51.50%\n",
      "Epoch [56/100], Step [29/60], Loss: 1.3594, batch time: 0.79, accuracy:  53.70%\n",
      "Epoch [56/100], Step [30/60], Loss: 1.3706, batch time: 0.85, accuracy:  55.10%\n",
      "Epoch [56/100], Step [31/60], Loss: 1.3815, batch time: 0.93, accuracy:  51.70%\n",
      "Epoch [56/100], Step [32/60], Loss: 1.4164, batch time: 0.72, accuracy:  54.00%\n",
      "Epoch [56/100], Step [33/60], Loss: 1.3921, batch time: 0.69, accuracy:  50.40%\n",
      "Epoch [56/100], Step [34/60], Loss: 1.3511, batch time: 0.73, accuracy:  52.00%\n",
      "Epoch [56/100], Step [35/60], Loss: 1.3709, batch time: 0.69, accuracy:  53.00%\n",
      "Epoch [56/100], Step [36/60], Loss: 1.4390, batch time: 0.69, accuracy:  50.70%\n",
      "Epoch [56/100], Step [37/60], Loss: 1.4133, batch time: 0.72, accuracy:  51.00%\n",
      "Epoch [56/100], Step [38/60], Loss: 1.3184, batch time: 0.69, accuracy:  55.90%\n",
      "Epoch [56/100], Step [39/60], Loss: 1.4587, batch time: 0.72, accuracy:  50.50%\n",
      "Epoch [56/100], Step [40/60], Loss: 1.4028, batch time: 0.69, accuracy:  53.30%\n",
      "Epoch [56/100], Step [41/60], Loss: 1.3611, batch time: 0.69, accuracy:  51.20%\n",
      "Epoch [56/100], Step [42/60], Loss: 1.3933, batch time: 0.72, accuracy:  49.80%\n",
      "Epoch [56/100], Step [43/60], Loss: 1.3969, batch time: 0.73, accuracy:  52.00%\n",
      "Epoch [56/100], Step [44/60], Loss: 1.3501, batch time: 0.72, accuracy:  52.50%\n",
      "Epoch [56/100], Step [45/60], Loss: 1.3921, batch time: 0.82, accuracy:  51.40%\n",
      "Epoch [56/100], Step [46/60], Loss: 1.4059, batch time: 0.83, accuracy:  51.50%\n",
      "Epoch [56/100], Step [47/60], Loss: 1.4283, batch time: 0.85, accuracy:  52.50%\n",
      "Epoch [56/100], Step [48/60], Loss: 1.4076, batch time: 0.89, accuracy:  51.20%\n",
      "Epoch [56/100], Step [49/60], Loss: 1.4011, batch time: 0.73, accuracy:  51.80%\n",
      "Epoch [56/100], Step [50/60], Loss: 1.4511, batch time: 0.69, accuracy:  51.10%\n",
      "Epoch [56/100], Step [51/60], Loss: 1.3882, batch time: 0.71, accuracy:  52.50%\n",
      "Epoch [56/100], Step [52/60], Loss: 1.3873, batch time: 0.69, accuracy:  54.10%\n",
      "Epoch [56/100], Step [53/60], Loss: 1.3807, batch time: 0.71, accuracy:  52.40%\n",
      "Epoch [56/100], Step [54/60], Loss: 1.4158, batch time: 0.73, accuracy:  51.50%\n",
      "Epoch [56/100], Step [55/60], Loss: 1.4017, batch time: 0.72, accuracy:  49.60%\n",
      "Epoch [56/100], Step [56/60], Loss: 1.4510, batch time: 0.71, accuracy:  50.90%\n",
      "Epoch [56/100], Step [57/60], Loss: 1.4377, batch time: 0.71, accuracy:  53.00%\n",
      "Epoch [56/100], Step [58/60], Loss: 1.3709, batch time: 0.73, accuracy:  54.00%\n",
      "Epoch [56/100], Step [59/60], Loss: 1.3805, batch time: 0.73, accuracy:  54.10%\n",
      "Epoch [56/100], Step [60/60], Loss: 1.3961, batch time: 0.73, accuracy:  54.10%\n",
      "Epoch [57/100], Step [1/60], Loss: 1.4272, batch time: 0.74, accuracy:  48.80%\n",
      "Epoch [57/100], Step [2/60], Loss: 1.3647, batch time: 0.72, accuracy:  52.00%\n",
      "Epoch [57/100], Step [3/60], Loss: 1.3879, batch time: 0.75, accuracy:  53.40%\n",
      "Epoch [57/100], Step [4/60], Loss: 1.3850, batch time: 0.74, accuracy:  53.70%\n",
      "Epoch [57/100], Step [5/60], Loss: 1.3988, batch time: 0.70, accuracy:  53.00%\n",
      "Epoch [57/100], Step [6/60], Loss: 1.3909, batch time: 0.85, accuracy:  53.80%\n",
      "Epoch [57/100], Step [7/60], Loss: 1.3914, batch time: 0.84, accuracy:  55.30%\n",
      "Epoch [57/100], Step [8/60], Loss: 1.3939, batch time: 0.60, accuracy:  52.80%\n",
      "Epoch [57/100], Step [9/60], Loss: 1.3609, batch time: 0.84, accuracy:  53.20%\n",
      "Epoch [57/100], Step [10/60], Loss: 1.4038, batch time: 0.69, accuracy:  53.70%\n",
      "Epoch [57/100], Step [11/60], Loss: 1.3264, batch time: 0.72, accuracy:  53.40%\n",
      "Epoch [57/100], Step [12/60], Loss: 1.3687, batch time: 0.70, accuracy:  52.00%\n",
      "Epoch [57/100], Step [13/60], Loss: 1.3388, batch time: 0.70, accuracy:  53.50%\n",
      "Epoch [57/100], Step [14/60], Loss: 1.3857, batch time: 0.70, accuracy:  51.30%\n",
      "Epoch [57/100], Step [15/60], Loss: 1.4947, batch time: 0.70, accuracy:  51.30%\n",
      "Epoch [57/100], Step [16/60], Loss: 1.3511, batch time: 0.71, accuracy:  54.00%\n",
      "Epoch [57/100], Step [17/60], Loss: 1.4089, batch time: 0.70, accuracy:  49.70%\n",
      "Epoch [57/100], Step [18/60], Loss: 1.3437, batch time: 0.70, accuracy:  53.10%\n",
      "Epoch [57/100], Step [19/60], Loss: 1.3783, batch time: 0.71, accuracy:  52.80%\n",
      "Epoch [57/100], Step [20/60], Loss: 1.3440, batch time: 0.70, accuracy:  55.50%\n",
      "Epoch [57/100], Step [21/60], Loss: 1.4098, batch time: 0.71, accuracy:  52.90%\n",
      "Epoch [57/100], Step [22/60], Loss: 1.3711, batch time: 0.71, accuracy:  53.40%\n",
      "Epoch [57/100], Step [23/60], Loss: 1.3862, batch time: 0.70, accuracy:  51.70%\n",
      "Epoch [57/100], Step [24/60], Loss: 1.2960, batch time: 0.72, accuracy:  57.20%\n",
      "Epoch [57/100], Step [25/60], Loss: 1.3518, batch time: 0.74, accuracy:  54.20%\n",
      "Epoch [57/100], Step [26/60], Loss: 1.3531, batch time: 0.74, accuracy:  54.10%\n",
      "Epoch [57/100], Step [27/60], Loss: 1.3672, batch time: 0.74, accuracy:  54.10%\n",
      "Epoch [57/100], Step [28/60], Loss: 1.3715, batch time: 0.60, accuracy:  52.80%\n",
      "Epoch [57/100], Step [29/60], Loss: 1.3435, batch time: 0.79, accuracy:  54.70%\n",
      "Epoch [57/100], Step [30/60], Loss: 1.3336, batch time: 0.68, accuracy:  53.00%\n",
      "Epoch [57/100], Step [31/60], Loss: 1.4368, batch time: 0.73, accuracy:  48.00%\n",
      "Epoch [57/100], Step [32/60], Loss: 1.4609, batch time: 0.78, accuracy:  52.10%\n",
      "Epoch [57/100], Step [33/60], Loss: 1.3969, batch time: 0.53, accuracy:  54.30%\n",
      "Epoch [57/100], Step [34/60], Loss: 1.3658, batch time: 0.78, accuracy:  52.60%\n",
      "Epoch [57/100], Step [35/60], Loss: 1.3325, batch time: 0.70, accuracy:  53.80%\n",
      "Epoch [57/100], Step [36/60], Loss: 1.3491, batch time: 0.70, accuracy:  54.10%\n",
      "Epoch [57/100], Step [37/60], Loss: 1.3572, batch time: 0.69, accuracy:  54.40%\n",
      "Epoch [57/100], Step [38/60], Loss: 1.3551, batch time: 0.71, accuracy:  53.30%\n",
      "Epoch [57/100], Step [39/60], Loss: 1.3861, batch time: 0.70, accuracy:  51.60%\n",
      "Epoch [57/100], Step [40/60], Loss: 1.4172, batch time: 0.70, accuracy:  53.80%\n",
      "Epoch [57/100], Step [41/60], Loss: 1.3724, batch time: 0.70, accuracy:  53.20%\n",
      "Epoch [57/100], Step [42/60], Loss: 1.3878, batch time: 0.53, accuracy:  54.30%\n",
      "Epoch [57/100], Step [43/60], Loss: 1.4183, batch time: 0.68, accuracy:  51.50%\n",
      "Epoch [57/100], Step [44/60], Loss: 1.4122, batch time: 0.73, accuracy:  54.30%\n",
      "Epoch [57/100], Step [45/60], Loss: 1.3748, batch time: 0.73, accuracy:  52.30%\n",
      "Epoch [57/100], Step [46/60], Loss: 1.4652, batch time: 0.74, accuracy:  50.30%\n",
      "Epoch [57/100], Step [47/60], Loss: 1.3964, batch time: 0.73, accuracy:  52.40%\n",
      "Epoch [57/100], Step [48/60], Loss: 1.3372, batch time: 0.70, accuracy:  54.40%\n",
      "Epoch [57/100], Step [49/60], Loss: 1.3620, batch time: 0.71, accuracy:  54.80%\n",
      "Epoch [57/100], Step [50/60], Loss: 1.4222, batch time: 0.81, accuracy:  53.50%\n",
      "Epoch [57/100], Step [51/60], Loss: 1.3688, batch time: 0.82, accuracy:  52.60%\n",
      "Epoch [57/100], Step [52/60], Loss: 1.4224, batch time: 0.85, accuracy:  50.40%\n",
      "Epoch [57/100], Step [53/60], Loss: 1.3947, batch time: 0.72, accuracy:  54.60%\n",
      "Epoch [57/100], Step [54/60], Loss: 1.3990, batch time: 0.86, accuracy:  52.70%\n",
      "Epoch [57/100], Step [55/60], Loss: 1.3809, batch time: 0.71, accuracy:  51.30%\n",
      "Epoch [57/100], Step [56/60], Loss: 1.4070, batch time: 0.70, accuracy:  51.80%\n",
      "Epoch [57/100], Step [57/60], Loss: 1.3398, batch time: 0.68, accuracy:  54.00%\n",
      "Epoch [57/100], Step [58/60], Loss: 1.4138, batch time: 0.68, accuracy:  52.90%\n",
      "Epoch [57/100], Step [59/60], Loss: 1.3734, batch time: 0.69, accuracy:  51.70%\n",
      "Epoch [57/100], Step [60/60], Loss: 1.4248, batch time: 0.69, accuracy:  50.70%\n",
      "Epoch [58/100], Step [1/60], Loss: 1.3874, batch time: 0.69, accuracy:  53.90%\n",
      "Epoch [58/100], Step [2/60], Loss: 1.3458, batch time: 0.69, accuracy:  54.30%\n",
      "Epoch [58/100], Step [3/60], Loss: 1.3713, batch time: 0.69, accuracy:  52.50%\n",
      "Epoch [58/100], Step [4/60], Loss: 1.3775, batch time: 0.70, accuracy:  54.30%\n",
      "Epoch [58/100], Step [5/60], Loss: 1.3410, batch time: 0.69, accuracy:  54.70%\n",
      "Epoch [58/100], Step [6/60], Loss: 1.3568, batch time: 0.69, accuracy:  53.70%\n",
      "Epoch [58/100], Step [7/60], Loss: 1.3813, batch time: 0.71, accuracy:  52.90%\n",
      "Epoch [58/100], Step [8/60], Loss: 1.4026, batch time: 0.60, accuracy:  52.00%\n",
      "Epoch [58/100], Step [9/60], Loss: 1.4125, batch time: 0.71, accuracy:  54.10%\n",
      "Epoch [58/100], Step [10/60], Loss: 1.3263, batch time: 0.80, accuracy:  54.30%\n",
      "Epoch [58/100], Step [11/60], Loss: 1.3998, batch time: 0.83, accuracy:  52.40%\n",
      "Epoch [58/100], Step [12/60], Loss: 1.4271, batch time: 0.83, accuracy:  52.10%\n",
      "Epoch [58/100], Step [13/60], Loss: 1.3692, batch time: 0.68, accuracy:  54.50%\n",
      "Epoch [58/100], Step [14/60], Loss: 1.3649, batch time: 0.68, accuracy:  52.90%\n",
      "Epoch [58/100], Step [15/60], Loss: 1.3705, batch time: 0.69, accuracy:  53.30%\n",
      "Epoch [58/100], Step [16/60], Loss: 1.3406, batch time: 0.69, accuracy:  54.40%\n",
      "Epoch [58/100], Step [17/60], Loss: 1.3950, batch time: 0.69, accuracy:  51.80%\n",
      "Epoch [58/100], Step [18/60], Loss: 1.3302, batch time: 0.69, accuracy:  55.60%\n",
      "Epoch [58/100], Step [19/60], Loss: 1.4475, batch time: 0.69, accuracy:  50.70%\n",
      "Epoch [58/100], Step [20/60], Loss: 1.3905, batch time: 0.68, accuracy:  55.20%\n",
      "Epoch [58/100], Step [21/60], Loss: 1.3917, batch time: 0.68, accuracy:  53.00%\n",
      "Epoch [58/100], Step [22/60], Loss: 1.3472, batch time: 0.68, accuracy:  55.00%\n",
      "Epoch [58/100], Step [23/60], Loss: 1.3509, batch time: 0.68, accuracy:  54.00%\n",
      "Epoch [58/100], Step [24/60], Loss: 1.3918, batch time: 0.68, accuracy:  54.40%\n",
      "Epoch [58/100], Step [25/60], Loss: 1.3376, batch time: 0.67, accuracy:  54.40%\n",
      "Epoch [58/100], Step [26/60], Loss: 1.4029, batch time: 0.70, accuracy:  52.00%\n",
      "Epoch [58/100], Step [27/60], Loss: 1.3511, batch time: 0.72, accuracy:  53.60%\n",
      "Epoch [58/100], Step [28/60], Loss: 1.3467, batch time: 0.80, accuracy:  53.60%\n",
      "Epoch [58/100], Step [29/60], Loss: 1.3722, batch time: 0.82, accuracy:  53.80%\n",
      "Epoch [58/100], Step [30/60], Loss: 1.3120, batch time: 0.81, accuracy:  55.20%\n",
      "Epoch [58/100], Step [31/60], Loss: 1.3643, batch time: 0.82, accuracy:  54.70%\n",
      "Epoch [58/100], Step [32/60], Loss: 1.3589, batch time: 0.82, accuracy:  55.50%\n",
      "Epoch [58/100], Step [33/60], Loss: 1.3433, batch time: 0.81, accuracy:  54.50%\n",
      "Epoch [58/100], Step [34/60], Loss: 1.3427, batch time: 0.81, accuracy:  56.00%\n",
      "Epoch [58/100], Step [35/60], Loss: 1.3893, batch time: 0.84, accuracy:  55.00%\n",
      "Epoch [58/100], Step [36/60], Loss: 1.3719, batch time: 0.85, accuracy:  52.60%\n",
      "Epoch [58/100], Step [37/60], Loss: 1.3821, batch time: 0.69, accuracy:  51.80%\n",
      "Epoch [58/100], Step [38/60], Loss: 1.3515, batch time: 0.67, accuracy:  53.40%\n",
      "Epoch [58/100], Step [39/60], Loss: 1.3164, batch time: 0.51, accuracy:  54.60%\n",
      "Epoch [58/100], Step [40/60], Loss: 1.3458, batch time: 0.67, accuracy:  55.10%\n",
      "Epoch [58/100], Step [41/60], Loss: 1.3620, batch time: 0.67, accuracy:  52.70%\n",
      "Epoch [58/100], Step [42/60], Loss: 1.3481, batch time: 0.68, accuracy:  54.50%\n",
      "Epoch [58/100], Step [43/60], Loss: 1.4170, batch time: 0.67, accuracy:  53.50%\n",
      "Epoch [58/100], Step [44/60], Loss: 1.3446, batch time: 0.68, accuracy:  55.70%\n",
      "Epoch [58/100], Step [45/60], Loss: 1.3916, batch time: 0.67, accuracy:  52.10%\n",
      "Epoch [58/100], Step [46/60], Loss: 1.3714, batch time: 0.68, accuracy:  54.00%\n",
      "Epoch [58/100], Step [47/60], Loss: 1.2766, batch time: 0.68, accuracy:  55.80%\n",
      "Epoch [58/100], Step [48/60], Loss: 1.3309, batch time: 0.68, accuracy:  55.30%\n",
      "Epoch [58/100], Step [49/60], Loss: 1.3396, batch time: 0.79, accuracy:  54.50%\n",
      "Epoch [58/100], Step [50/60], Loss: 1.3325, batch time: 0.73, accuracy:  54.30%\n",
      "Epoch [58/100], Step [51/60], Loss: 1.3823, batch time: 0.74, accuracy:  52.20%\n",
      "Epoch [58/100], Step [52/60], Loss: 1.4092, batch time: 0.81, accuracy:  54.00%\n",
      "Epoch [58/100], Step [53/60], Loss: 1.3652, batch time: 0.87, accuracy:  56.70%\n",
      "Epoch [58/100], Step [54/60], Loss: 1.3515, batch time: 0.87, accuracy:  54.20%\n",
      "Epoch [58/100], Step [55/60], Loss: 1.3593, batch time: 0.87, accuracy:  54.60%\n",
      "Epoch [58/100], Step [56/60], Loss: 1.3168, batch time: 0.87, accuracy:  55.00%\n",
      "Epoch [58/100], Step [57/60], Loss: 1.4179, batch time: 0.87, accuracy:  51.80%\n",
      "Epoch [58/100], Step [58/60], Loss: 1.4121, batch time: 0.87, accuracy:  52.30%\n",
      "Epoch [58/100], Step [59/60], Loss: 1.3958, batch time: 0.87, accuracy:  53.90%\n",
      "Epoch [58/100], Step [60/60], Loss: 1.3450, batch time: 0.87, accuracy:  53.00%\n",
      "Epoch [59/100], Step [1/60], Loss: 1.2919, batch time: 0.72, accuracy:  54.90%\n",
      "Epoch [59/100], Step [2/60], Loss: 1.2866, batch time: 0.72, accuracy:  56.40%\n",
      "Epoch [59/100], Step [3/60], Loss: 1.2708, batch time: 0.71, accuracy:  56.10%\n",
      "Epoch [59/100], Step [4/60], Loss: 1.3376, batch time: 0.72, accuracy:  56.10%\n",
      "Epoch [59/100], Step [5/60], Loss: 1.3156, batch time: 0.72, accuracy:  54.20%\n",
      "Epoch [59/100], Step [6/60], Loss: 1.4145, batch time: 0.71, accuracy:  51.30%\n",
      "Epoch [59/100], Step [7/60], Loss: 1.3573, batch time: 0.72, accuracy:  54.60%\n",
      "Epoch [59/100], Step [8/60], Loss: 1.3430, batch time: 0.71, accuracy:  54.70%\n",
      "Epoch [59/100], Step [9/60], Loss: 1.3194, batch time: 0.72, accuracy:  54.70%\n",
      "Epoch [59/100], Step [10/60], Loss: 1.3433, batch time: 0.72, accuracy:  54.60%\n",
      "Epoch [59/100], Step [11/60], Loss: 1.3259, batch time: 0.72, accuracy:  53.50%\n",
      "Epoch [59/100], Step [12/60], Loss: 1.3911, batch time: 0.72, accuracy:  53.60%\n",
      "Epoch [59/100], Step [13/60], Loss: 1.3624, batch time: 0.72, accuracy:  53.90%\n",
      "Epoch [59/100], Step [14/60], Loss: 1.3075, batch time: 0.74, accuracy:  55.50%\n",
      "Epoch [59/100], Step [15/60], Loss: 1.3572, batch time: 0.73, accuracy:  55.10%\n",
      "Epoch [59/100], Step [16/60], Loss: 1.3743, batch time: 0.91, accuracy:  53.10%\n",
      "Epoch [59/100], Step [17/60], Loss: 1.3931, batch time: 0.72, accuracy:  52.10%\n",
      "Epoch [59/100], Step [18/60], Loss: 1.3335, batch time: 0.72, accuracy:  55.30%\n",
      "Epoch [59/100], Step [19/60], Loss: 1.3207, batch time: 0.72, accuracy:  54.20%\n",
      "Epoch [59/100], Step [20/60], Loss: 1.3793, batch time: 0.72, accuracy:  54.40%\n",
      "Epoch [59/100], Step [21/60], Loss: 1.3366, batch time: 0.72, accuracy:  55.40%\n",
      "Epoch [59/100], Step [22/60], Loss: 1.3290, batch time: 0.72, accuracy:  53.00%\n",
      "Epoch [59/100], Step [23/60], Loss: 1.3549, batch time: 0.72, accuracy:  53.30%\n",
      "Epoch [59/100], Step [24/60], Loss: 1.3353, batch time: 0.72, accuracy:  58.50%\n",
      "Epoch [59/100], Step [25/60], Loss: 1.3969, batch time: 0.80, accuracy:  51.80%\n",
      "Epoch [59/100], Step [26/60], Loss: 1.3496, batch time: 0.73, accuracy:  54.20%\n",
      "Epoch [59/100], Step [27/60], Loss: 1.3318, batch time: 0.72, accuracy:  56.00%\n",
      "Epoch [59/100], Step [28/60], Loss: 1.3590, batch time: 0.72, accuracy:  53.60%\n",
      "Epoch [59/100], Step [29/60], Loss: 1.3484, batch time: 0.73, accuracy:  55.10%\n",
      "Epoch [59/100], Step [30/60], Loss: 1.3910, batch time: 0.74, accuracy:  53.90%\n",
      "Epoch [59/100], Step [31/60], Loss: 1.3425, batch time: 0.83, accuracy:  55.10%\n",
      "Epoch [59/100], Step [32/60], Loss: 1.3650, batch time: 0.87, accuracy:  55.70%\n",
      "Epoch [59/100], Step [33/60], Loss: 1.2953, batch time: 0.84, accuracy:  56.20%\n",
      "Epoch [59/100], Step [34/60], Loss: 1.3317, batch time: 0.84, accuracy:  54.40%\n",
      "Epoch [59/100], Step [35/60], Loss: 1.3586, batch time: 0.74, accuracy:  55.30%\n",
      "Epoch [59/100], Step [36/60], Loss: 1.3065, batch time: 0.68, accuracy:  55.30%\n",
      "Epoch [59/100], Step [37/60], Loss: 1.3872, batch time: 0.67, accuracy:  52.40%\n",
      "Epoch [59/100], Step [38/60], Loss: 1.3422, batch time: 0.68, accuracy:  57.60%\n",
      "Epoch [59/100], Step [39/60], Loss: 1.3894, batch time: 0.65, accuracy:  50.60%\n",
      "Epoch [59/100], Step [40/60], Loss: 1.3624, batch time: 0.65, accuracy:  53.70%\n",
      "Epoch [59/100], Step [41/60], Loss: 1.3810, batch time: 0.58, accuracy:  54.20%\n",
      "Epoch [59/100], Step [42/60], Loss: 1.3976, batch time: 0.68, accuracy:  53.90%\n",
      "Epoch [59/100], Step [43/60], Loss: 1.2756, batch time: 0.66, accuracy:  56.10%\n",
      "Epoch [59/100], Step [44/60], Loss: 1.3826, batch time: 0.68, accuracy:  52.60%\n",
      "Epoch [59/100], Step [45/60], Loss: 1.3238, batch time: 0.66, accuracy:  56.30%\n",
      "Epoch [59/100], Step [46/60], Loss: 1.3857, batch time: 0.68, accuracy:  54.50%\n",
      "Epoch [59/100], Step [47/60], Loss: 1.3658, batch time: 0.69, accuracy:  53.90%\n",
      "Epoch [59/100], Step [48/60], Loss: 1.3977, batch time: 0.70, accuracy:  51.50%\n",
      "Epoch [59/100], Step [49/60], Loss: 1.2933, batch time: 0.72, accuracy:  56.60%\n",
      "Epoch [59/100], Step [50/60], Loss: 1.3333, batch time: 0.71, accuracy:  54.80%\n",
      "Epoch [59/100], Step [51/60], Loss: 1.3459, batch time: 0.88, accuracy:  54.90%\n",
      "Epoch [59/100], Step [52/60], Loss: 1.3517, batch time: 0.87, accuracy:  55.60%\n",
      "Epoch [59/100], Step [53/60], Loss: 1.4064, batch time: 0.46, accuracy:  54.60%\n",
      "Epoch [59/100], Step [54/60], Loss: 1.3232, batch time: 0.44, accuracy:  54.20%\n",
      "Epoch [59/100], Step [55/60], Loss: 1.3239, batch time: 0.61, accuracy:  58.80%\n",
      "Epoch [59/100], Step [56/60], Loss: 1.3881, batch time: 0.72, accuracy:  53.10%\n",
      "Epoch [59/100], Step [57/60], Loss: 1.3575, batch time: 0.73, accuracy:  54.00%\n",
      "Epoch [59/100], Step [58/60], Loss: 1.3530, batch time: 0.67, accuracy:  54.30%\n",
      "Epoch [59/100], Step [59/60], Loss: 1.3589, batch time: 0.72, accuracy:  55.80%\n",
      "Epoch [59/100], Step [60/60], Loss: 1.3599, batch time: 0.73, accuracy:  54.10%\n",
      "Epoch [60/100], Step [1/60], Loss: 1.3472, batch time: 0.69, accuracy:  55.60%\n",
      "Epoch [60/100], Step [2/60], Loss: 1.2828, batch time: 0.71, accuracy:  58.00%\n",
      "Epoch [60/100], Step [3/60], Loss: 1.3051, batch time: 0.69, accuracy:  55.70%\n",
      "Epoch [60/100], Step [4/60], Loss: 1.2497, batch time: 0.67, accuracy:  60.30%\n",
      "Epoch [60/100], Step [5/60], Loss: 1.3777, batch time: 0.63, accuracy:  54.70%\n",
      "Epoch [60/100], Step [6/60], Loss: 1.4236, batch time: 0.65, accuracy:  52.70%\n",
      "Epoch [60/100], Step [7/60], Loss: 1.3717, batch time: 0.68, accuracy:  52.60%\n",
      "Epoch [60/100], Step [8/60], Loss: 1.4044, batch time: 0.66, accuracy:  53.10%\n",
      "Epoch [60/100], Step [9/60], Loss: 1.3595, batch time: 0.79, accuracy:  54.50%\n",
      "Epoch [60/100], Step [10/60], Loss: 1.3332, batch time: 0.85, accuracy:  56.50%\n",
      "Epoch [60/100], Step [11/60], Loss: 1.3679, batch time: 0.82, accuracy:  54.80%\n",
      "Epoch [60/100], Step [12/60], Loss: 1.2740, batch time: 0.82, accuracy:  57.40%\n",
      "Epoch [60/100], Step [13/60], Loss: 1.3631, batch time: 0.85, accuracy:  55.40%\n",
      "Epoch [60/100], Step [14/60], Loss: 1.3131, batch time: 0.78, accuracy:  55.50%\n",
      "Epoch [60/100], Step [15/60], Loss: 1.3416, batch time: 0.76, accuracy:  56.00%\n",
      "Epoch [60/100], Step [16/60], Loss: 1.3385, batch time: 0.85, accuracy:  55.30%\n",
      "Epoch [60/100], Step [17/60], Loss: 1.3495, batch time: 0.82, accuracy:  57.60%\n",
      "Epoch [60/100], Step [18/60], Loss: 1.2614, batch time: 0.85, accuracy:  58.80%\n",
      "Epoch [60/100], Step [19/60], Loss: 1.3145, batch time: 0.81, accuracy:  56.50%\n",
      "Epoch [60/100], Step [20/60], Loss: 1.2933, batch time: 0.86, accuracy:  54.20%\n",
      "Epoch [60/100], Step [21/60], Loss: 1.3495, batch time: 0.77, accuracy:  56.00%\n",
      "Epoch [60/100], Step [22/60], Loss: 1.3153, batch time: 0.74, accuracy:  57.30%\n",
      "Epoch [60/100], Step [23/60], Loss: 1.3400, batch time: 0.65, accuracy:  53.30%\n",
      "Epoch [60/100], Step [24/60], Loss: 1.3681, batch time: 0.68, accuracy:  54.60%\n",
      "Epoch [60/100], Step [25/60], Loss: 1.3143, batch time: 0.54, accuracy:  54.30%\n",
      "Epoch [60/100], Step [26/60], Loss: 1.3161, batch time: 0.69, accuracy:  54.80%\n",
      "Epoch [60/100], Step [27/60], Loss: 1.3278, batch time: 0.70, accuracy:  55.00%\n",
      "Epoch [60/100], Step [28/60], Loss: 1.3667, batch time: 0.47, accuracy:  51.00%\n",
      "Epoch [60/100], Step [29/60], Loss: 1.3063, batch time: 0.44, accuracy:  56.90%\n",
      "Epoch [60/100], Step [30/60], Loss: 1.2965, batch time: 0.69, accuracy:  57.40%\n",
      "Epoch [60/100], Step [31/60], Loss: 1.3637, batch time: 0.69, accuracy:  57.00%\n",
      "Epoch [60/100], Step [32/60], Loss: 1.2927, batch time: 0.69, accuracy:  57.80%\n",
      "Epoch [60/100], Step [33/60], Loss: 1.3534, batch time: 0.69, accuracy:  53.60%\n",
      "Epoch [60/100], Step [34/60], Loss: 1.3424, batch time: 0.68, accuracy:  53.90%\n",
      "Epoch [60/100], Step [35/60], Loss: 1.3498, batch time: 0.69, accuracy:  53.40%\n",
      "Epoch [60/100], Step [36/60], Loss: 1.4008, batch time: 0.61, accuracy:  53.00%\n",
      "Epoch [60/100], Step [37/60], Loss: 1.2777, batch time: 0.63, accuracy:  53.70%\n",
      "Epoch [60/100], Step [38/60], Loss: 1.3245, batch time: 0.73, accuracy:  55.50%\n",
      "Epoch [60/100], Step [39/60], Loss: 1.3170, batch time: 0.74, accuracy:  56.50%\n",
      "Epoch [60/100], Step [40/60], Loss: 1.3629, batch time: 0.73, accuracy:  54.00%\n",
      "Epoch [60/100], Step [41/60], Loss: 1.2894, batch time: 0.86, accuracy:  55.30%\n",
      "Epoch [60/100], Step [42/60], Loss: 1.3005, batch time: 0.87, accuracy:  56.40%\n",
      "Epoch [60/100], Step [43/60], Loss: 1.3070, batch time: 0.72, accuracy:  56.00%\n",
      "Epoch [60/100], Step [44/60], Loss: 1.2998, batch time: 0.71, accuracy:  57.70%\n",
      "Epoch [60/100], Step [45/60], Loss: 1.3740, batch time: 0.73, accuracy:  54.20%\n",
      "Epoch [60/100], Step [46/60], Loss: 1.3503, batch time: 0.72, accuracy:  57.30%\n",
      "Epoch [60/100], Step [47/60], Loss: 1.3047, batch time: 0.63, accuracy:  55.80%\n",
      "Epoch [60/100], Step [48/60], Loss: 1.2835, batch time: 0.70, accuracy:  54.90%\n",
      "Epoch [60/100], Step [49/60], Loss: 1.3402, batch time: 0.65, accuracy:  56.10%\n",
      "Epoch [60/100], Step [50/60], Loss: 1.3549, batch time: 0.70, accuracy:  56.20%\n",
      "Epoch [60/100], Step [51/60], Loss: 1.4143, batch time: 0.67, accuracy:  52.40%\n",
      "Epoch [60/100], Step [52/60], Loss: 1.2970, batch time: 0.70, accuracy:  56.80%\n",
      "Epoch [60/100], Step [53/60], Loss: 1.3354, batch time: 0.70, accuracy:  54.20%\n",
      "Epoch [60/100], Step [54/60], Loss: 1.3253, batch time: 0.71, accuracy:  55.60%\n",
      "Epoch [60/100], Step [55/60], Loss: 1.3848, batch time: 0.72, accuracy:  53.80%\n",
      "Epoch [60/100], Step [56/60], Loss: 1.3571, batch time: 0.71, accuracy:  52.70%\n",
      "Epoch [60/100], Step [57/60], Loss: 1.3584, batch time: 0.72, accuracy:  56.50%\n",
      "Epoch [60/100], Step [58/60], Loss: 1.3669, batch time: 0.83, accuracy:  54.70%\n",
      "Epoch [60/100], Step [59/60], Loss: 1.3621, batch time: 0.57, accuracy:  54.40%\n",
      "Epoch [60/100], Step [60/60], Loss: 1.3053, batch time: 0.87, accuracy:  56.30%\n",
      "Epoch [61/100], Step [1/60], Loss: 1.3664, batch time: 0.64, accuracy:  57.10%\n",
      "Epoch [61/100], Step [2/60], Loss: 1.3813, batch time: 0.68, accuracy:  54.40%\n",
      "Epoch [61/100], Step [3/60], Loss: 1.3340, batch time: 0.69, accuracy:  55.70%\n",
      "Epoch [61/100], Step [4/60], Loss: 1.3325, batch time: 0.68, accuracy:  54.30%\n",
      "Epoch [61/100], Step [5/60], Loss: 1.2944, batch time: 0.68, accuracy:  55.90%\n",
      "Epoch [61/100], Step [6/60], Loss: 1.2673, batch time: 0.70, accuracy:  57.10%\n",
      "Epoch [61/100], Step [7/60], Loss: 1.3269, batch time: 0.70, accuracy:  54.30%\n",
      "Epoch [61/100], Step [8/60], Loss: 1.3488, batch time: 0.71, accuracy:  55.70%\n",
      "Epoch [61/100], Step [9/60], Loss: 1.3442, batch time: 0.73, accuracy:  57.60%\n",
      "Epoch [61/100], Step [10/60], Loss: 1.2962, batch time: 0.70, accuracy:  56.20%\n",
      "Epoch [61/100], Step [11/60], Loss: 1.4107, batch time: 0.45, accuracy:  52.60%\n",
      "Epoch [61/100], Step [12/60], Loss: 1.3217, batch time: 0.42, accuracy:  57.00%\n",
      "Epoch [61/100], Step [13/60], Loss: 1.3086, batch time: 0.66, accuracy:  58.20%\n",
      "Epoch [61/100], Step [14/60], Loss: 1.3488, batch time: 0.73, accuracy:  54.70%\n",
      "Epoch [61/100], Step [15/60], Loss: 1.2908, batch time: 0.73, accuracy:  56.00%\n",
      "Epoch [61/100], Step [16/60], Loss: 1.2935, batch time: 0.75, accuracy:  59.50%\n",
      "Epoch [61/100], Step [17/60], Loss: 1.2911, batch time: 0.78, accuracy:  58.20%\n",
      "Epoch [61/100], Step [18/60], Loss: 1.3550, batch time: 0.88, accuracy:  54.70%\n",
      "Epoch [61/100], Step [19/60], Loss: 1.3241, batch time: 0.87, accuracy:  56.70%\n",
      "Epoch [61/100], Step [20/60], Loss: 1.3509, batch time: 0.88, accuracy:  55.70%\n",
      "Epoch [61/100], Step [21/60], Loss: 1.3473, batch time: 0.88, accuracy:  55.30%\n",
      "Epoch [61/100], Step [22/60], Loss: 1.4147, batch time: 0.80, accuracy:  52.30%\n",
      "Epoch [61/100], Step [23/60], Loss: 1.3120, batch time: 0.61, accuracy:  55.50%\n",
      "Epoch [61/100], Step [24/60], Loss: 1.2997, batch time: 0.63, accuracy:  56.20%\n",
      "Epoch [61/100], Step [25/60], Loss: 1.2842, batch time: 0.45, accuracy:  56.50%\n",
      "Epoch [61/100], Step [26/60], Loss: 1.3114, batch time: 0.44, accuracy:  56.70%\n",
      "Epoch [61/100], Step [27/60], Loss: 1.3482, batch time: 0.46, accuracy:  56.40%\n",
      "Epoch [61/100], Step [28/60], Loss: 1.2537, batch time: 0.45, accuracy:  57.60%\n",
      "Epoch [61/100], Step [29/60], Loss: 1.2749, batch time: 0.45, accuracy:  58.40%\n",
      "Epoch [61/100], Step [30/60], Loss: 1.2924, batch time: 0.46, accuracy:  57.50%\n",
      "Epoch [61/100], Step [31/60], Loss: 1.3167, batch time: 0.45, accuracy:  56.20%\n",
      "Epoch [61/100], Step [32/60], Loss: 1.3101, batch time: 0.45, accuracy:  56.70%\n",
      "Epoch [61/100], Step [33/60], Loss: 1.3676, batch time: 0.45, accuracy:  55.00%\n",
      "Epoch [61/100], Step [34/60], Loss: 1.2937, batch time: 0.45, accuracy:  56.00%\n",
      "Epoch [61/100], Step [35/60], Loss: 1.3317, batch time: 0.45, accuracy:  56.20%\n",
      "Epoch [61/100], Step [36/60], Loss: 1.2980, batch time: 0.46, accuracy:  58.00%\n",
      "Epoch [61/100], Step [37/60], Loss: 1.3162, batch time: 0.44, accuracy:  56.20%\n",
      "Epoch [61/100], Step [38/60], Loss: 1.3441, batch time: 0.45, accuracy:  54.80%\n",
      "Epoch [61/100], Step [39/60], Loss: 1.2819, batch time: 0.47, accuracy:  58.00%\n",
      "Epoch [61/100], Step [40/60], Loss: 1.2966, batch time: 0.44, accuracy:  56.20%\n",
      "Epoch [61/100], Step [41/60], Loss: 1.3283, batch time: 0.45, accuracy:  56.90%\n",
      "Epoch [61/100], Step [42/60], Loss: 1.2694, batch time: 0.45, accuracy:  59.10%\n",
      "Epoch [61/100], Step [43/60], Loss: 1.2651, batch time: 0.45, accuracy:  56.40%\n",
      "Epoch [61/100], Step [44/60], Loss: 1.3010, batch time: 0.46, accuracy:  55.70%\n",
      "Epoch [61/100], Step [45/60], Loss: 1.3249, batch time: 0.53, accuracy:  57.60%\n",
      "Epoch [61/100], Step [46/60], Loss: 1.2828, batch time: 0.54, accuracy:  57.10%\n",
      "Epoch [61/100], Step [47/60], Loss: 1.2632, batch time: 0.56, accuracy:  57.60%\n",
      "Epoch [61/100], Step [48/60], Loss: 1.2959, batch time: 0.54, accuracy:  58.40%\n",
      "Epoch [61/100], Step [49/60], Loss: 1.3584, batch time: 0.54, accuracy:  57.70%\n",
      "Epoch [61/100], Step [50/60], Loss: 1.3241, batch time: 0.54, accuracy:  56.80%\n",
      "Epoch [61/100], Step [51/60], Loss: 1.2921, batch time: 0.55, accuracy:  55.80%\n",
      "Epoch [61/100], Step [52/60], Loss: 1.3717, batch time: 0.53, accuracy:  55.10%\n",
      "Epoch [61/100], Step [53/60], Loss: 1.3415, batch time: 0.55, accuracy:  55.90%\n",
      "Epoch [61/100], Step [54/60], Loss: 1.2482, batch time: 0.53, accuracy:  56.50%\n",
      "Epoch [61/100], Step [55/60], Loss: 1.2957, batch time: 0.57, accuracy:  58.20%\n",
      "Epoch [61/100], Step [56/60], Loss: 1.2827, batch time: 0.54, accuracy:  57.00%\n",
      "Epoch [61/100], Step [57/60], Loss: 1.2948, batch time: 0.54, accuracy:  57.10%\n",
      "Epoch [61/100], Step [58/60], Loss: 1.2668, batch time: 0.53, accuracy:  56.60%\n",
      "Epoch [61/100], Step [59/60], Loss: 1.2691, batch time: 0.43, accuracy:  57.10%\n",
      "Epoch [61/100], Step [60/60], Loss: 1.3456, batch time: 0.45, accuracy:  55.00%\n",
      "Epoch [62/100], Step [1/60], Loss: 1.2253, batch time: 0.45, accuracy:  59.90%\n",
      "Epoch [62/100], Step [2/60], Loss: 1.2919, batch time: 0.44, accuracy:  56.10%\n",
      "Epoch [62/100], Step [3/60], Loss: 1.2470, batch time: 0.48, accuracy:  58.40%\n",
      "Epoch [62/100], Step [4/60], Loss: 1.2623, batch time: 0.44, accuracy:  56.50%\n",
      "Epoch [62/100], Step [5/60], Loss: 1.2787, batch time: 0.45, accuracy:  59.70%\n",
      "Epoch [62/100], Step [6/60], Loss: 1.3027, batch time: 0.45, accuracy:  56.50%\n",
      "Epoch [62/100], Step [7/60], Loss: 1.2786, batch time: 0.44, accuracy:  57.40%\n",
      "Epoch [62/100], Step [8/60], Loss: 1.3345, batch time: 0.45, accuracy:  56.80%\n",
      "Epoch [62/100], Step [9/60], Loss: 1.2327, batch time: 0.45, accuracy:  60.00%\n",
      "Epoch [62/100], Step [10/60], Loss: 1.3209, batch time: 0.44, accuracy:  57.20%\n",
      "Epoch [62/100], Step [11/60], Loss: 1.3483, batch time: 0.45, accuracy:  56.30%\n",
      "Epoch [62/100], Step [12/60], Loss: 1.3042, batch time: 0.46, accuracy:  54.20%\n",
      "Epoch [62/100], Step [13/60], Loss: 1.3448, batch time: 0.45, accuracy:  54.80%\n",
      "Epoch [62/100], Step [14/60], Loss: 1.2982, batch time: 0.45, accuracy:  56.30%\n",
      "Epoch [62/100], Step [15/60], Loss: 1.3080, batch time: 0.45, accuracy:  53.60%\n",
      "Epoch [62/100], Step [16/60], Loss: 1.2726, batch time: 0.44, accuracy:  56.60%\n",
      "Epoch [62/100], Step [17/60], Loss: 1.3479, batch time: 0.45, accuracy:  55.70%\n",
      "Epoch [62/100], Step [18/60], Loss: 1.2891, batch time: 0.45, accuracy:  56.80%\n",
      "Epoch [62/100], Step [19/60], Loss: 1.3749, batch time: 0.44, accuracy:  56.40%\n",
      "Epoch [62/100], Step [20/60], Loss: 1.2995, batch time: 0.46, accuracy:  57.40%\n",
      "Epoch [62/100], Step [21/60], Loss: 1.2786, batch time: 0.46, accuracy:  56.70%\n",
      "Epoch [62/100], Step [22/60], Loss: 1.3541, batch time: 0.49, accuracy:  57.00%\n",
      "Epoch [62/100], Step [23/60], Loss: 1.3009, batch time: 0.55, accuracy:  57.60%\n",
      "Epoch [62/100], Step [24/60], Loss: 1.2637, batch time: 0.54, accuracy:  56.80%\n",
      "Epoch [62/100], Step [25/60], Loss: 1.2626, batch time: 0.54, accuracy:  58.90%\n",
      "Epoch [62/100], Step [26/60], Loss: 1.3691, batch time: 0.53, accuracy:  56.00%\n",
      "Epoch [62/100], Step [27/60], Loss: 1.2490, batch time: 0.54, accuracy:  58.10%\n",
      "Epoch [62/100], Step [28/60], Loss: 1.2496, batch time: 0.53, accuracy:  58.60%\n",
      "Epoch [62/100], Step [29/60], Loss: 1.2965, batch time: 0.55, accuracy:  56.50%\n",
      "Epoch [62/100], Step [30/60], Loss: 1.2558, batch time: 0.54, accuracy:  59.10%\n",
      "Epoch [62/100], Step [31/60], Loss: 1.2970, batch time: 0.54, accuracy:  59.10%\n",
      "Epoch [62/100], Step [32/60], Loss: 1.2836, batch time: 0.54, accuracy:  55.00%\n",
      "Epoch [62/100], Step [33/60], Loss: 1.3258, batch time: 0.53, accuracy:  55.10%\n",
      "Epoch [62/100], Step [34/60], Loss: 1.2589, batch time: 0.54, accuracy:  57.20%\n",
      "Epoch [62/100], Step [35/60], Loss: 1.3585, batch time: 0.54, accuracy:  55.70%\n",
      "Epoch [62/100], Step [36/60], Loss: 1.3458, batch time: 0.49, accuracy:  56.50%\n",
      "Epoch [62/100], Step [37/60], Loss: 1.2431, batch time: 0.47, accuracy:  59.80%\n",
      "Epoch [62/100], Step [38/60], Loss: 1.2751, batch time: 0.44, accuracy:  57.60%\n",
      "Epoch [62/100], Step [39/60], Loss: 1.3348, batch time: 0.45, accuracy:  57.60%\n",
      "Epoch [62/100], Step [40/60], Loss: 1.3277, batch time: 0.44, accuracy:  56.90%\n",
      "Epoch [62/100], Step [41/60], Loss: 1.2494, batch time: 0.44, accuracy:  59.30%\n",
      "Epoch [62/100], Step [42/60], Loss: 1.2886, batch time: 0.44, accuracy:  56.50%\n",
      "Epoch [62/100], Step [43/60], Loss: 1.2829, batch time: 0.44, accuracy:  57.60%\n",
      "Epoch [62/100], Step [44/60], Loss: 1.2968, batch time: 0.44, accuracy:  55.10%\n",
      "Epoch [62/100], Step [45/60], Loss: 1.3172, batch time: 0.45, accuracy:  57.60%\n",
      "Epoch [62/100], Step [46/60], Loss: 1.2965, batch time: 0.45, accuracy:  55.00%\n",
      "Epoch [62/100], Step [47/60], Loss: 1.3380, batch time: 0.46, accuracy:  53.50%\n",
      "Epoch [62/100], Step [48/60], Loss: 1.2956, batch time: 0.45, accuracy:  59.40%\n",
      "Epoch [62/100], Step [49/60], Loss: 1.3045, batch time: 0.44, accuracy:  55.00%\n",
      "Epoch [62/100], Step [50/60], Loss: 1.2992, batch time: 0.44, accuracy:  57.70%\n",
      "Epoch [62/100], Step [51/60], Loss: 1.3325, batch time: 0.45, accuracy:  55.60%\n",
      "Epoch [62/100], Step [52/60], Loss: 1.3099, batch time: 0.44, accuracy:  57.40%\n",
      "Epoch [62/100], Step [53/60], Loss: 1.3262, batch time: 0.44, accuracy:  55.90%\n",
      "Epoch [62/100], Step [54/60], Loss: 1.3170, batch time: 0.45, accuracy:  55.90%\n",
      "Epoch [62/100], Step [55/60], Loss: 1.2154, batch time: 0.44, accuracy:  58.90%\n",
      "Epoch [62/100], Step [56/60], Loss: 1.3809, batch time: 0.46, accuracy:  54.60%\n",
      "Epoch [62/100], Step [57/60], Loss: 1.2586, batch time: 0.46, accuracy:  58.00%\n",
      "Epoch [62/100], Step [58/60], Loss: 1.2630, batch time: 0.46, accuracy:  59.00%\n",
      "Epoch [62/100], Step [59/60], Loss: 1.3223, batch time: 0.45, accuracy:  55.40%\n",
      "Epoch [62/100], Step [60/60], Loss: 1.3271, batch time: 0.64, accuracy:  57.90%\n",
      "Epoch [63/100], Step [1/60], Loss: 1.3182, batch time: 0.73, accuracy:  57.50%\n",
      "Epoch [63/100], Step [2/60], Loss: 1.2850, batch time: 0.72, accuracy:  57.20%\n",
      "Epoch [63/100], Step [3/60], Loss: 1.3627, batch time: 0.72, accuracy:  56.40%\n",
      "Epoch [63/100], Step [4/60], Loss: 1.2828, batch time: 0.80, accuracy:  58.10%\n",
      "Epoch [63/100], Step [5/60], Loss: 1.2906, batch time: 0.74, accuracy:  55.90%\n",
      "Epoch [63/100], Step [6/60], Loss: 1.3256, batch time: 0.74, accuracy:  55.40%\n",
      "Epoch [63/100], Step [7/60], Loss: 1.2958, batch time: 0.74, accuracy:  58.00%\n",
      "Epoch [63/100], Step [8/60], Loss: 1.2869, batch time: 0.82, accuracy:  59.40%\n",
      "Epoch [63/100], Step [9/60], Loss: 1.2738, batch time: 0.82, accuracy:  58.40%\n",
      "Epoch [63/100], Step [10/60], Loss: 1.3043, batch time: 0.82, accuracy:  55.40%\n",
      "Epoch [63/100], Step [11/60], Loss: 1.2624, batch time: 0.81, accuracy:  59.30%\n",
      "Epoch [63/100], Step [12/60], Loss: 1.2296, batch time: 0.81, accuracy:  60.20%\n",
      "Epoch [63/100], Step [13/60], Loss: 1.2974, batch time: 0.70, accuracy:  56.90%\n",
      "Epoch [63/100], Step [14/60], Loss: 1.2702, batch time: 0.68, accuracy:  55.40%\n",
      "Epoch [63/100], Step [15/60], Loss: 1.3477, batch time: 0.68, accuracy:  55.10%\n",
      "Epoch [63/100], Step [16/60], Loss: 1.3075, batch time: 0.68, accuracy:  57.90%\n",
      "Epoch [63/100], Step [17/60], Loss: 1.2744, batch time: 0.68, accuracy:  59.60%\n",
      "Epoch [63/100], Step [18/60], Loss: 1.2320, batch time: 0.68, accuracy:  59.60%\n",
      "Epoch [63/100], Step [19/60], Loss: 1.3072, batch time: 0.68, accuracy:  58.60%\n",
      "Epoch [63/100], Step [20/60], Loss: 1.2382, batch time: 0.68, accuracy:  59.60%\n",
      "Epoch [63/100], Step [21/60], Loss: 1.2880, batch time: 0.68, accuracy:  57.40%\n",
      "Epoch [63/100], Step [22/60], Loss: 1.2777, batch time: 0.68, accuracy:  58.90%\n",
      "Epoch [63/100], Step [23/60], Loss: 1.2268, batch time: 0.68, accuracy:  60.00%\n",
      "Epoch [63/100], Step [24/60], Loss: 1.2524, batch time: 0.68, accuracy:  59.70%\n",
      "Epoch [63/100], Step [25/60], Loss: 1.3015, batch time: 0.68, accuracy:  57.00%\n",
      "Epoch [63/100], Step [26/60], Loss: 1.3669, batch time: 0.68, accuracy:  53.90%\n",
      "Epoch [63/100], Step [27/60], Loss: 1.3101, batch time: 0.70, accuracy:  56.30%\n",
      "Epoch [63/100], Step [28/60], Loss: 1.2936, batch time: 0.70, accuracy:  58.00%\n",
      "Epoch [63/100], Step [29/60], Loss: 1.2965, batch time: 0.81, accuracy:  56.90%\n",
      "Epoch [63/100], Step [30/60], Loss: 1.2849, batch time: 0.81, accuracy:  58.60%\n",
      "Epoch [63/100], Step [31/60], Loss: 1.2398, batch time: 0.81, accuracy:  58.50%\n",
      "Epoch [63/100], Step [32/60], Loss: 1.3072, batch time: 0.81, accuracy:  57.20%\n",
      "Epoch [63/100], Step [33/60], Loss: 1.3057, batch time: 0.81, accuracy:  56.20%\n",
      "Epoch [63/100], Step [34/60], Loss: 1.2972, batch time: 0.68, accuracy:  58.80%\n",
      "Epoch [63/100], Step [35/60], Loss: 1.2641, batch time: 0.68, accuracy:  60.20%\n",
      "Epoch [63/100], Step [36/60], Loss: 1.3053, batch time: 0.68, accuracy:  57.90%\n",
      "Epoch [63/100], Step [37/60], Loss: 1.3014, batch time: 0.70, accuracy:  57.80%\n",
      "Epoch [63/100], Step [38/60], Loss: 1.2512, batch time: 0.69, accuracy:  58.80%\n",
      "Epoch [63/100], Step [39/60], Loss: 1.2577, batch time: 0.68, accuracy:  57.50%\n",
      "Epoch [63/100], Step [40/60], Loss: 1.2653, batch time: 0.68, accuracy:  59.80%\n",
      "Epoch [63/100], Step [41/60], Loss: 1.2946, batch time: 0.68, accuracy:  55.30%\n",
      "Epoch [63/100], Step [42/60], Loss: 1.2598, batch time: 0.68, accuracy:  57.90%\n",
      "Epoch [63/100], Step [43/60], Loss: 1.2269, batch time: 0.68, accuracy:  60.70%\n",
      "Epoch [63/100], Step [44/60], Loss: 1.3338, batch time: 0.68, accuracy:  56.50%\n",
      "Epoch [63/100], Step [45/60], Loss: 1.2719, batch time: 0.69, accuracy:  58.00%\n",
      "Epoch [63/100], Step [46/60], Loss: 1.2626, batch time: 0.69, accuracy:  57.00%\n",
      "Epoch [63/100], Step [47/60], Loss: 1.3297, batch time: 0.69, accuracy:  54.70%\n",
      "Epoch [63/100], Step [48/60], Loss: 1.2986, batch time: 0.72, accuracy:  58.80%\n",
      "Epoch [63/100], Step [49/60], Loss: 1.2267, batch time: 0.81, accuracy:  59.10%\n",
      "Epoch [63/100], Step [50/60], Loss: 1.2706, batch time: 0.88, accuracy:  56.60%\n",
      "Epoch [63/100], Step [51/60], Loss: 1.2152, batch time: 0.89, accuracy:  58.40%\n",
      "Epoch [63/100], Step [52/60], Loss: 1.2474, batch time: 0.87, accuracy:  58.20%\n",
      "Epoch [63/100], Step [53/60], Loss: 1.2565, batch time: 0.73, accuracy:  59.70%\n",
      "Epoch [63/100], Step [54/60], Loss: 1.2585, batch time: 0.74, accuracy:  59.10%\n",
      "Epoch [63/100], Step [55/60], Loss: 1.2569, batch time: 0.73, accuracy:  58.10%\n",
      "Epoch [63/100], Step [56/60], Loss: 1.2533, batch time: 0.73, accuracy:  59.00%\n",
      "Epoch [63/100], Step [57/60], Loss: 1.2359, batch time: 0.74, accuracy:  59.50%\n",
      "Epoch [63/100], Step [58/60], Loss: 1.2926, batch time: 0.74, accuracy:  57.00%\n",
      "Epoch [63/100], Step [59/60], Loss: 1.2640, batch time: 0.73, accuracy:  57.80%\n",
      "Epoch [63/100], Step [60/60], Loss: 1.3016, batch time: 0.74, accuracy:  57.70%\n",
      "Epoch [64/100], Step [1/60], Loss: 1.2661, batch time: 0.75, accuracy:  56.90%\n",
      "Epoch [64/100], Step [2/60], Loss: 1.3349, batch time: 0.74, accuracy:  56.90%\n",
      "Epoch [64/100], Step [3/60], Loss: 1.2483, batch time: 0.74, accuracy:  56.40%\n",
      "Epoch [64/100], Step [4/60], Loss: 1.2874, batch time: 0.75, accuracy:  58.70%\n",
      "Epoch [64/100], Step [5/60], Loss: 1.1960, batch time: 0.77, accuracy:  59.00%\n",
      "Epoch [64/100], Step [6/60], Loss: 1.3258, batch time: 0.77, accuracy:  54.40%\n",
      "Epoch [64/100], Step [7/60], Loss: 1.2199, batch time: 0.83, accuracy:  60.40%\n",
      "Epoch [64/100], Step [8/60], Loss: 1.2944, batch time: 0.85, accuracy:  57.20%\n",
      "Epoch [64/100], Step [9/60], Loss: 1.2362, batch time: 0.77, accuracy:  59.60%\n",
      "Epoch [64/100], Step [10/60], Loss: 1.2384, batch time: 0.70, accuracy:  62.20%\n",
      "Epoch [64/100], Step [11/60], Loss: 1.2704, batch time: 0.62, accuracy:  55.80%\n",
      "Epoch [64/100], Step [12/60], Loss: 1.2586, batch time: 0.71, accuracy:  59.80%\n",
      "Epoch [64/100], Step [13/60], Loss: 1.2536, batch time: 0.71, accuracy:  58.20%\n",
      "Epoch [64/100], Step [14/60], Loss: 1.3059, batch time: 0.65, accuracy:  58.30%\n",
      "Epoch [64/100], Step [15/60], Loss: 1.2897, batch time: 0.69, accuracy:  55.90%\n",
      "Epoch [64/100], Step [16/60], Loss: 1.2653, batch time: 0.69, accuracy:  58.90%\n",
      "Epoch [64/100], Step [17/60], Loss: 1.2559, batch time: 0.69, accuracy:  61.60%\n",
      "Epoch [64/100], Step [18/60], Loss: 1.2868, batch time: 0.69, accuracy:  59.60%\n",
      "Epoch [64/100], Step [19/60], Loss: 1.1633, batch time: 0.69, accuracy:  62.90%\n",
      "Epoch [64/100], Step [20/60], Loss: 1.2099, batch time: 0.69, accuracy:  59.50%\n",
      "Epoch [64/100], Step [21/60], Loss: 1.2431, batch time: 0.69, accuracy:  58.80%\n",
      "Epoch [64/100], Step [22/60], Loss: 1.2816, batch time: 0.69, accuracy:  58.20%\n",
      "Epoch [64/100], Step [23/60], Loss: 1.2470, batch time: 0.69, accuracy:  58.70%\n",
      "Epoch [64/100], Step [24/60], Loss: 1.2417, batch time: 0.70, accuracy:  57.10%\n",
      "Epoch [64/100], Step [25/60], Loss: 1.2587, batch time: 0.74, accuracy:  57.70%\n",
      "Epoch [64/100], Step [26/60], Loss: 1.3093, batch time: 0.81, accuracy:  57.30%\n",
      "Epoch [64/100], Step [27/60], Loss: 1.2787, batch time: 0.81, accuracy:  57.10%\n",
      "Epoch [64/100], Step [28/60], Loss: 1.2840, batch time: 0.82, accuracy:  60.20%\n",
      "Epoch [64/100], Step [29/60], Loss: 1.2281, batch time: 0.81, accuracy:  56.90%\n",
      "Epoch [64/100], Step [30/60], Loss: 1.2514, batch time: 0.82, accuracy:  58.90%\n",
      "Epoch [64/100], Step [31/60], Loss: 1.3178, batch time: 0.81, accuracy:  56.60%\n",
      "Epoch [64/100], Step [32/60], Loss: 1.2522, batch time: 0.81, accuracy:  60.20%\n",
      "Epoch [64/100], Step [33/60], Loss: 1.2121, batch time: 0.82, accuracy:  61.10%\n",
      "Epoch [64/100], Step [34/60], Loss: 1.2917, batch time: 0.80, accuracy:  57.60%\n",
      "Epoch [64/100], Step [35/60], Loss: 1.2388, batch time: 0.68, accuracy:  59.10%\n",
      "Epoch [64/100], Step [36/60], Loss: 1.2162, batch time: 0.68, accuracy:  59.10%\n",
      "Epoch [64/100], Step [37/60], Loss: 1.2229, batch time: 0.68, accuracy:  60.50%\n",
      "Epoch [64/100], Step [38/60], Loss: 1.2926, batch time: 0.68, accuracy:  57.50%\n",
      "Epoch [64/100], Step [39/60], Loss: 1.2355, batch time: 0.68, accuracy:  59.40%\n",
      "Epoch [64/100], Step [40/60], Loss: 1.2666, batch time: 0.68, accuracy:  58.50%\n",
      "Epoch [64/100], Step [41/60], Loss: 1.2697, batch time: 0.64, accuracy:  58.90%\n",
      "Epoch [64/100], Step [42/60], Loss: 1.1947, batch time: 0.61, accuracy:  60.20%\n",
      "Epoch [64/100], Step [43/60], Loss: 1.3307, batch time: 0.61, accuracy:  55.50%\n",
      "Epoch [64/100], Step [44/60], Loss: 1.2945, batch time: 0.68, accuracy:  58.40%\n",
      "Epoch [64/100], Step [45/60], Loss: 1.2323, batch time: 0.67, accuracy:  61.20%\n",
      "Epoch [64/100], Step [46/60], Loss: 1.2313, batch time: 0.68, accuracy:  58.40%\n",
      "Epoch [64/100], Step [47/60], Loss: 1.2602, batch time: 0.68, accuracy:  59.30%\n",
      "Epoch [64/100], Step [48/60], Loss: 1.2552, batch time: 0.69, accuracy:  57.90%\n",
      "Epoch [64/100], Step [49/60], Loss: 1.2571, batch time: 0.70, accuracy:  57.80%\n",
      "Epoch [64/100], Step [50/60], Loss: 1.2888, batch time: 0.73, accuracy:  58.80%\n",
      "Epoch [64/100], Step [51/60], Loss: 1.2021, batch time: 0.82, accuracy:  59.30%\n",
      "Epoch [64/100], Step [52/60], Loss: 1.2088, batch time: 0.82, accuracy:  61.20%\n",
      "Epoch [64/100], Step [53/60], Loss: 1.3601, batch time: 0.81, accuracy:  55.60%\n",
      "Epoch [64/100], Step [54/60], Loss: 1.2540, batch time: 0.82, accuracy:  58.20%\n",
      "Epoch [64/100], Step [55/60], Loss: 1.2585, batch time: 0.81, accuracy:  60.10%\n",
      "Epoch [64/100], Step [56/60], Loss: 1.3345, batch time: 0.67, accuracy:  56.40%\n",
      "Epoch [64/100], Step [57/60], Loss: 1.3266, batch time: 0.67, accuracy:  57.30%\n",
      "Epoch [64/100], Step [58/60], Loss: 1.2518, batch time: 0.68, accuracy:  59.90%\n",
      "Epoch [64/100], Step [59/60], Loss: 1.1947, batch time: 0.67, accuracy:  63.30%\n",
      "Epoch [64/100], Step [60/60], Loss: 1.2793, batch time: 0.68, accuracy:  55.30%\n",
      "Epoch [65/100], Step [1/60], Loss: 1.2025, batch time: 0.68, accuracy:  58.80%\n",
      "Epoch [65/100], Step [2/60], Loss: 1.2734, batch time: 0.68, accuracy:  57.60%\n",
      "Epoch [65/100], Step [3/60], Loss: 1.2250, batch time: 0.68, accuracy:  62.10%\n",
      "Epoch [65/100], Step [4/60], Loss: 1.1903, batch time: 0.68, accuracy:  61.50%\n",
      "Epoch [65/100], Step [5/60], Loss: 1.2285, batch time: 0.68, accuracy:  57.90%\n",
      "Epoch [65/100], Step [6/60], Loss: 1.2441, batch time: 0.68, accuracy:  58.70%\n",
      "Epoch [65/100], Step [7/60], Loss: 1.2832, batch time: 0.68, accuracy:  57.60%\n",
      "Epoch [65/100], Step [8/60], Loss: 1.2637, batch time: 0.68, accuracy:  57.50%\n",
      "Epoch [65/100], Step [9/60], Loss: 1.2099, batch time: 0.69, accuracy:  59.40%\n",
      "Epoch [65/100], Step [10/60], Loss: 1.2556, batch time: 0.70, accuracy:  57.50%\n",
      "Epoch [65/100], Step [11/60], Loss: 1.3417, batch time: 0.75, accuracy:  58.60%\n",
      "Epoch [65/100], Step [12/60], Loss: 1.2380, batch time: 0.82, accuracy:  58.90%\n",
      "Epoch [65/100], Step [13/60], Loss: 1.2394, batch time: 0.82, accuracy:  58.90%\n",
      "Epoch [65/100], Step [14/60], Loss: 1.1722, batch time: 0.80, accuracy:  61.30%\n",
      "Epoch [65/100], Step [15/60], Loss: 1.2972, batch time: 0.68, accuracy:  57.80%\n",
      "Epoch [65/100], Step [16/60], Loss: 1.2339, batch time: 0.67, accuracy:  59.90%\n",
      "Epoch [65/100], Step [17/60], Loss: 1.3200, batch time: 0.68, accuracy:  56.80%\n",
      "Epoch [65/100], Step [18/60], Loss: 1.3132, batch time: 0.68, accuracy:  56.50%\n",
      "Epoch [65/100], Step [19/60], Loss: 1.2187, batch time: 0.68, accuracy:  57.70%\n",
      "Epoch [65/100], Step [20/60], Loss: 1.2305, batch time: 0.68, accuracy:  59.20%\n",
      "Epoch [65/100], Step [21/60], Loss: 1.2447, batch time: 0.68, accuracy:  58.30%\n",
      "Epoch [65/100], Step [22/60], Loss: 1.2809, batch time: 0.68, accuracy:  57.20%\n",
      "Epoch [65/100], Step [23/60], Loss: 1.3143, batch time: 0.68, accuracy:  57.20%\n",
      "Epoch [65/100], Step [24/60], Loss: 1.2405, batch time: 0.68, accuracy:  59.70%\n",
      "Epoch [65/100], Step [25/60], Loss: 1.2819, batch time: 0.68, accuracy:  60.40%\n",
      "Epoch [65/100], Step [26/60], Loss: 1.3204, batch time: 0.68, accuracy:  60.30%\n",
      "Epoch [65/100], Step [27/60], Loss: 1.2519, batch time: 0.68, accuracy:  60.10%\n",
      "Epoch [65/100], Step [28/60], Loss: 1.1955, batch time: 0.70, accuracy:  60.30%\n",
      "Epoch [65/100], Step [29/60], Loss: 1.1889, batch time: 0.70, accuracy:  59.90%\n",
      "Epoch [65/100], Step [30/60], Loss: 1.2590, batch time: 0.82, accuracy:  58.20%\n",
      "Epoch [65/100], Step [31/60], Loss: 1.2090, batch time: 0.82, accuracy:  60.40%\n",
      "Epoch [65/100], Step [32/60], Loss: 1.2458, batch time: 0.82, accuracy:  59.10%\n",
      "Epoch [65/100], Step [33/60], Loss: 1.1803, batch time: 0.82, accuracy:  61.00%\n",
      "Epoch [65/100], Step [34/60], Loss: 1.2091, batch time: 0.82, accuracy:  60.40%\n",
      "Epoch [65/100], Step [35/60], Loss: 1.2852, batch time: 0.82, accuracy:  58.90%\n",
      "Epoch [65/100], Step [36/60], Loss: 1.2993, batch time: 0.82, accuracy:  57.50%\n",
      "Epoch [65/100], Step [37/60], Loss: 1.2889, batch time: 0.82, accuracy:  55.50%\n",
      "Epoch [65/100], Step [38/60], Loss: 1.2017, batch time: 0.82, accuracy:  61.40%\n",
      "Epoch [65/100], Step [39/60], Loss: 1.2671, batch time: 0.69, accuracy:  59.00%\n",
      "Epoch [65/100], Step [40/60], Loss: 1.2642, batch time: 0.67, accuracy:  55.50%\n",
      "Epoch [65/100], Step [41/60], Loss: 1.2298, batch time: 0.67, accuracy:  60.90%\n",
      "Epoch [65/100], Step [42/60], Loss: 1.2678, batch time: 0.68, accuracy:  60.10%\n",
      "Epoch [65/100], Step [43/60], Loss: 1.2168, batch time: 0.67, accuracy:  60.00%\n",
      "Epoch [65/100], Step [44/60], Loss: 1.2558, batch time: 0.68, accuracy:  59.30%\n",
      "Epoch [65/100], Step [45/60], Loss: 1.2383, batch time: 0.68, accuracy:  60.20%\n",
      "Epoch [65/100], Step [46/60], Loss: 1.2678, batch time: 0.68, accuracy:  58.40%\n",
      "Epoch [65/100], Step [47/60], Loss: 1.2290, batch time: 0.68, accuracy:  59.60%\n",
      "Epoch [65/100], Step [48/60], Loss: 1.2181, batch time: 0.68, accuracy:  59.20%\n",
      "Epoch [65/100], Step [49/60], Loss: 1.3454, batch time: 0.68, accuracy:  58.00%\n",
      "Epoch [65/100], Step [50/60], Loss: 1.3147, batch time: 0.68, accuracy:  58.30%\n",
      "Epoch [65/100], Step [51/60], Loss: 1.2512, batch time: 0.68, accuracy:  58.90%\n",
      "Epoch [65/100], Step [52/60], Loss: 1.2157, batch time: 0.68, accuracy:  59.80%\n",
      "Epoch [65/100], Step [53/60], Loss: 1.1853, batch time: 0.70, accuracy:  60.20%\n",
      "Epoch [65/100], Step [54/60], Loss: 1.2634, batch time: 0.71, accuracy:  57.90%\n",
      "Epoch [65/100], Step [55/60], Loss: 1.2738, batch time: 0.81, accuracy:  58.40%\n",
      "Epoch [65/100], Step [56/60], Loss: 1.2530, batch time: 0.82, accuracy:  58.50%\n",
      "Epoch [65/100], Step [57/60], Loss: 1.3123, batch time: 0.82, accuracy:  56.60%\n",
      "Epoch [65/100], Step [58/60], Loss: 1.2772, batch time: 0.83, accuracy:  59.80%\n",
      "Epoch [65/100], Step [59/60], Loss: 1.2249, batch time: 0.67, accuracy:  60.40%\n",
      "Epoch [65/100], Step [60/60], Loss: 1.2430, batch time: 0.67, accuracy:  61.50%\n",
      "Epoch [66/100], Step [1/60], Loss: 1.2214, batch time: 0.68, accuracy:  60.00%\n",
      "Epoch [66/100], Step [2/60], Loss: 1.2182, batch time: 0.68, accuracy:  60.50%\n",
      "Epoch [66/100], Step [3/60], Loss: 1.2494, batch time: 0.68, accuracy:  59.50%\n",
      "Epoch [66/100], Step [4/60], Loss: 1.2545, batch time: 0.68, accuracy:  56.10%\n",
      "Epoch [66/100], Step [5/60], Loss: 1.2698, batch time: 0.68, accuracy:  57.90%\n",
      "Epoch [66/100], Step [6/60], Loss: 1.2869, batch time: 0.68, accuracy:  58.00%\n",
      "Epoch [66/100], Step [7/60], Loss: 1.1854, batch time: 0.68, accuracy:  63.10%\n",
      "Epoch [66/100], Step [8/60], Loss: 1.2275, batch time: 0.68, accuracy:  58.60%\n",
      "Epoch [66/100], Step [9/60], Loss: 1.2549, batch time: 0.69, accuracy:  59.90%\n",
      "Epoch [66/100], Step [10/60], Loss: 1.2023, batch time: 0.68, accuracy:  60.50%\n",
      "Epoch [66/100], Step [11/60], Loss: 1.2409, batch time: 0.68, accuracy:  59.30%\n",
      "Epoch [66/100], Step [12/60], Loss: 1.2282, batch time: 0.69, accuracy:  59.90%\n",
      "Epoch [66/100], Step [13/60], Loss: 1.2641, batch time: 0.70, accuracy:  60.30%\n",
      "Epoch [66/100], Step [14/60], Loss: 1.3192, batch time: 0.75, accuracy:  57.30%\n",
      "Epoch [66/100], Step [15/60], Loss: 1.2269, batch time: 0.82, accuracy:  61.20%\n",
      "Epoch [66/100], Step [16/60], Loss: 1.2190, batch time: 0.82, accuracy:  59.00%\n",
      "Epoch [66/100], Step [17/60], Loss: 1.2107, batch time: 0.82, accuracy:  60.70%\n",
      "Epoch [66/100], Step [18/60], Loss: 1.2797, batch time: 0.82, accuracy:  57.80%\n",
      "Epoch [66/100], Step [19/60], Loss: 1.2550, batch time: 0.81, accuracy:  57.90%\n",
      "Epoch [66/100], Step [20/60], Loss: 1.2229, batch time: 0.82, accuracy:  60.00%\n",
      "Epoch [66/100], Step [21/60], Loss: 1.1899, batch time: 0.82, accuracy:  62.30%\n",
      "Epoch [66/100], Step [22/60], Loss: 1.2039, batch time: 0.82, accuracy:  61.10%\n",
      "Epoch [66/100], Step [23/60], Loss: 1.2363, batch time: 0.76, accuracy:  60.20%\n",
      "Epoch [66/100], Step [24/60], Loss: 1.2467, batch time: 0.68, accuracy:  57.90%\n",
      "Epoch [66/100], Step [25/60], Loss: 1.2705, batch time: 0.69, accuracy:  59.60%\n",
      "Epoch [66/100], Step [26/60], Loss: 1.2529, batch time: 0.69, accuracy:  58.90%\n",
      "Epoch [66/100], Step [27/60], Loss: 1.2094, batch time: 0.69, accuracy:  61.80%\n",
      "Epoch [66/100], Step [28/60], Loss: 1.1670, batch time: 0.69, accuracy:  61.60%\n",
      "Epoch [66/100], Step [29/60], Loss: 1.1833, batch time: 0.69, accuracy:  62.10%\n",
      "Epoch [66/100], Step [30/60], Loss: 1.2711, batch time: 0.69, accuracy:  59.00%\n",
      "Epoch [66/100], Step [31/60], Loss: 1.2369, batch time: 0.68, accuracy:  58.40%\n",
      "Epoch [66/100], Step [32/60], Loss: 1.2891, batch time: 0.69, accuracy:  57.10%\n",
      "Epoch [66/100], Step [33/60], Loss: 1.2243, batch time: 0.70, accuracy:  59.20%\n",
      "Epoch [66/100], Step [34/60], Loss: 1.1674, batch time: 0.69, accuracy:  61.80%\n",
      "Epoch [66/100], Step [35/60], Loss: 1.1969, batch time: 0.69, accuracy:  62.10%\n",
      "Epoch [66/100], Step [36/60], Loss: 1.2577, batch time: 0.57, accuracy:  59.10%\n",
      "Epoch [66/100], Step [37/60], Loss: 1.2539, batch time: 0.73, accuracy:  62.10%\n",
      "Epoch [66/100], Step [38/60], Loss: 1.2076, batch time: 0.58, accuracy:  61.80%\n",
      "Epoch [66/100], Step [39/60], Loss: 1.1761, batch time: 0.75, accuracy:  62.30%\n",
      "Epoch [66/100], Step [40/60], Loss: 1.2181, batch time: 0.61, accuracy:  60.20%\n",
      "Epoch [66/100], Step [41/60], Loss: 1.1841, batch time: 0.73, accuracy:  61.30%\n",
      "Epoch [66/100], Step [42/60], Loss: 1.2646, batch time: 0.58, accuracy:  57.40%\n",
      "Epoch [66/100], Step [43/60], Loss: 1.2862, batch time: 0.85, accuracy:  57.10%\n",
      "Epoch [66/100], Step [44/60], Loss: 1.2547, batch time: 0.84, accuracy:  58.60%\n",
      "Epoch [66/100], Step [45/60], Loss: 1.2648, batch time: 0.78, accuracy:  59.50%\n",
      "Epoch [66/100], Step [46/60], Loss: 1.2533, batch time: 0.73, accuracy:  59.10%\n",
      "Epoch [66/100], Step [47/60], Loss: 1.2224, batch time: 0.69, accuracy:  59.20%\n",
      "Epoch [66/100], Step [48/60], Loss: 1.2251, batch time: 0.72, accuracy:  59.90%\n",
      "Epoch [66/100], Step [49/60], Loss: 1.1799, batch time: 0.68, accuracy:  62.20%\n",
      "Epoch [66/100], Step [50/60], Loss: 1.1813, batch time: 0.72, accuracy:  62.40%\n",
      "Epoch [66/100], Step [51/60], Loss: 1.2278, batch time: 0.68, accuracy:  59.60%\n",
      "Epoch [66/100], Step [52/60], Loss: 1.2367, batch time: 0.72, accuracy:  59.60%\n",
      "Epoch [66/100], Step [53/60], Loss: 1.2345, batch time: 0.66, accuracy:  59.10%\n",
      "Epoch [66/100], Step [54/60], Loss: 1.2110, batch time: 0.63, accuracy:  59.90%\n",
      "Epoch [66/100], Step [55/60], Loss: 1.3213, batch time: 0.69, accuracy:  57.80%\n",
      "Epoch [66/100], Step [56/60], Loss: 1.2617, batch time: 0.62, accuracy:  59.50%\n",
      "Epoch [66/100], Step [57/60], Loss: 1.2491, batch time: 0.61, accuracy:  59.80%\n",
      "Epoch [66/100], Step [58/60], Loss: 1.2229, batch time: 0.60, accuracy:  58.40%\n",
      "Epoch [66/100], Step [59/60], Loss: 1.2737, batch time: 0.66, accuracy:  60.10%\n",
      "Epoch [66/100], Step [60/60], Loss: 1.1668, batch time: 0.68, accuracy:  62.40%\n",
      "Epoch [67/100], Step [1/60], Loss: 1.2646, batch time: 0.65, accuracy:  58.50%\n",
      "Epoch [67/100], Step [2/60], Loss: 1.1784, batch time: 0.69, accuracy:  61.30%\n",
      "Epoch [67/100], Step [3/60], Loss: 1.1862, batch time: 0.69, accuracy:  60.40%\n",
      "Epoch [67/100], Step [4/60], Loss: 1.2203, batch time: 0.86, accuracy:  61.60%\n",
      "Epoch [67/100], Step [5/60], Loss: 1.2099, batch time: 0.81, accuracy:  58.70%\n",
      "Epoch [67/100], Step [6/60], Loss: 1.1784, batch time: 0.69, accuracy:  61.80%\n",
      "Epoch [67/100], Step [7/60], Loss: 1.2715, batch time: 0.59, accuracy:  58.40%\n",
      "Epoch [67/100], Step [8/60], Loss: 1.2434, batch time: 0.65, accuracy:  59.60%\n",
      "Epoch [67/100], Step [9/60], Loss: 1.2513, batch time: 0.70, accuracy:  59.80%\n",
      "Epoch [67/100], Step [10/60], Loss: 1.1872, batch time: 0.69, accuracy:  60.70%\n",
      "Epoch [67/100], Step [11/60], Loss: 1.2624, batch time: 0.69, accuracy:  58.10%\n",
      "Epoch [67/100], Step [12/60], Loss: 1.2133, batch time: 0.69, accuracy:  61.60%\n",
      "Epoch [67/100], Step [13/60], Loss: 1.2107, batch time: 0.70, accuracy:  61.10%\n",
      "Epoch [67/100], Step [14/60], Loss: 1.2288, batch time: 0.70, accuracy:  58.60%\n",
      "Epoch [67/100], Step [15/60], Loss: 1.1959, batch time: 0.71, accuracy:  62.10%\n",
      "Epoch [67/100], Step [16/60], Loss: 1.1936, batch time: 0.69, accuracy:  60.40%\n",
      "Epoch [67/100], Step [17/60], Loss: 1.1999, batch time: 0.71, accuracy:  60.20%\n",
      "Epoch [67/100], Step [18/60], Loss: 1.2827, batch time: 0.74, accuracy:  56.70%\n",
      "Epoch [67/100], Step [19/60], Loss: 1.2219, batch time: 0.73, accuracy:  60.70%\n",
      "Epoch [67/100], Step [20/60], Loss: 1.2824, batch time: 0.74, accuracy:  57.00%\n",
      "Epoch [67/100], Step [21/60], Loss: 1.1466, batch time: 0.74, accuracy:  62.90%\n",
      "Epoch [67/100], Step [22/60], Loss: 1.2413, batch time: 0.74, accuracy:  59.80%\n",
      "Epoch [67/100], Step [23/60], Loss: 1.2269, batch time: 0.74, accuracy:  59.80%\n",
      "Epoch [67/100], Step [24/60], Loss: 1.2418, batch time: 0.65, accuracy:  58.90%\n",
      "Epoch [67/100], Step [25/60], Loss: 1.2118, batch time: 0.70, accuracy:  60.90%\n",
      "Epoch [67/100], Step [26/60], Loss: 1.1908, batch time: 0.70, accuracy:  61.20%\n",
      "Epoch [67/100], Step [27/60], Loss: 1.2671, batch time: 0.70, accuracy:  61.20%\n",
      "Epoch [67/100], Step [28/60], Loss: 1.2514, batch time: 0.69, accuracy:  59.20%\n",
      "Epoch [67/100], Step [29/60], Loss: 1.2338, batch time: 0.69, accuracy:  60.00%\n",
      "Epoch [67/100], Step [30/60], Loss: 1.2691, batch time: 0.75, accuracy:  61.50%\n",
      "Epoch [67/100], Step [31/60], Loss: 1.2076, batch time: 0.70, accuracy:  61.50%\n",
      "Epoch [67/100], Step [32/60], Loss: 1.1935, batch time: 0.86, accuracy:  63.30%\n",
      "Epoch [67/100], Step [33/60], Loss: 1.2574, batch time: 0.82, accuracy:  58.20%\n",
      "Epoch [67/100], Step [34/60], Loss: 1.2504, batch time: 0.85, accuracy:  59.50%\n",
      "Epoch [67/100], Step [35/60], Loss: 1.2812, batch time: 0.69, accuracy:  59.10%\n",
      "Epoch [67/100], Step [36/60], Loss: 1.2410, batch time: 0.53, accuracy:  60.00%\n",
      "Epoch [67/100], Step [37/60], Loss: 1.2628, batch time: 0.42, accuracy:  60.10%\n",
      "Epoch [67/100], Step [38/60], Loss: 1.1711, batch time: 0.44, accuracy:  62.40%\n",
      "Epoch [67/100], Step [39/60], Loss: 1.2104, batch time: 0.44, accuracy:  60.40%\n",
      "Epoch [67/100], Step [40/60], Loss: 1.1549, batch time: 0.42, accuracy:  64.10%\n",
      "Epoch [67/100], Step [41/60], Loss: 1.2278, batch time: 0.42, accuracy:  58.80%\n",
      "Epoch [67/100], Step [42/60], Loss: 1.1964, batch time: 0.44, accuracy:  60.50%\n",
      "Epoch [67/100], Step [43/60], Loss: 1.1665, batch time: 0.42, accuracy:  62.20%\n",
      "Epoch [67/100], Step [44/60], Loss: 1.1912, batch time: 0.42, accuracy:  60.00%\n",
      "Epoch [67/100], Step [45/60], Loss: 1.1997, batch time: 0.44, accuracy:  60.10%\n",
      "Epoch [67/100], Step [46/60], Loss: 1.1356, batch time: 0.42, accuracy:  60.70%\n",
      "Epoch [67/100], Step [47/60], Loss: 1.1906, batch time: 0.42, accuracy:  60.50%\n",
      "Epoch [67/100], Step [48/60], Loss: 1.2005, batch time: 0.46, accuracy:  60.10%\n",
      "Epoch [67/100], Step [49/60], Loss: 1.1700, batch time: 0.42, accuracy:  61.80%\n",
      "Epoch [67/100], Step [50/60], Loss: 1.1745, batch time: 0.43, accuracy:  60.00%\n",
      "Epoch [67/100], Step [51/60], Loss: 1.1899, batch time: 0.43, accuracy:  59.80%\n",
      "Epoch [67/100], Step [52/60], Loss: 1.1874, batch time: 0.42, accuracy:  61.00%\n",
      "Epoch [67/100], Step [53/60], Loss: 1.1659, batch time: 0.45, accuracy:  62.80%\n",
      "Epoch [67/100], Step [54/60], Loss: 1.2545, batch time: 0.46, accuracy:  60.80%\n",
      "Epoch [67/100], Step [55/60], Loss: 1.2074, batch time: 0.62, accuracy:  60.90%\n",
      "Epoch [67/100], Step [56/60], Loss: 1.2096, batch time: 0.74, accuracy:  60.40%\n",
      "Epoch [67/100], Step [57/60], Loss: 1.2486, batch time: 0.80, accuracy:  58.50%\n",
      "Epoch [67/100], Step [58/60], Loss: 1.1776, batch time: 0.84, accuracy:  62.50%\n",
      "Epoch [67/100], Step [59/60], Loss: 1.2191, batch time: 0.87, accuracy:  60.90%\n",
      "Epoch [67/100], Step [60/60], Loss: 1.2771, batch time: 0.77, accuracy:  60.20%\n",
      "Epoch [68/100], Step [1/60], Loss: 1.1670, batch time: 0.69, accuracy:  61.90%\n",
      "Epoch [68/100], Step [2/60], Loss: 1.2998, batch time: 0.70, accuracy:  56.80%\n",
      "Epoch [68/100], Step [3/60], Loss: 1.2391, batch time: 0.69, accuracy:  60.80%\n",
      "Epoch [68/100], Step [4/60], Loss: 1.1961, batch time: 0.70, accuracy:  61.20%\n",
      "Epoch [68/100], Step [5/60], Loss: 1.2567, batch time: 0.69, accuracy:  58.50%\n",
      "Epoch [68/100], Step [6/60], Loss: 1.1886, batch time: 0.70, accuracy:  60.70%\n",
      "Epoch [68/100], Step [7/60], Loss: 1.2094, batch time: 0.70, accuracy:  59.80%\n",
      "Epoch [68/100], Step [8/60], Loss: 1.2267, batch time: 0.70, accuracy:  60.60%\n",
      "Epoch [68/100], Step [9/60], Loss: 1.1734, batch time: 0.62, accuracy:  62.40%\n",
      "Epoch [68/100], Step [10/60], Loss: 1.2739, batch time: 0.69, accuracy:  60.70%\n",
      "Epoch [68/100], Step [11/60], Loss: 1.1549, batch time: 0.70, accuracy:  62.30%\n",
      "Epoch [68/100], Step [12/60], Loss: 1.2053, batch time: 0.71, accuracy:  63.60%\n",
      "Epoch [68/100], Step [13/60], Loss: 1.2226, batch time: 0.75, accuracy:  60.30%\n",
      "Epoch [68/100], Step [14/60], Loss: 1.2841, batch time: 0.73, accuracy:  58.60%\n",
      "Epoch [68/100], Step [15/60], Loss: 1.2670, batch time: 0.77, accuracy:  58.90%\n",
      "Epoch [68/100], Step [16/60], Loss: 1.1728, batch time: 0.87, accuracy:  61.80%\n",
      "Epoch [68/100], Step [17/60], Loss: 1.2086, batch time: 0.86, accuracy:  62.10%\n",
      "Epoch [68/100], Step [18/60], Loss: 1.1830, batch time: 0.82, accuracy:  57.80%\n",
      "Epoch [68/100], Step [19/60], Loss: 1.2060, batch time: 0.69, accuracy:  61.40%\n",
      "Epoch [68/100], Step [20/60], Loss: 1.1595, batch time: 0.69, accuracy:  62.60%\n",
      "Epoch [68/100], Step [21/60], Loss: 1.1818, batch time: 0.70, accuracy:  60.20%\n",
      "Epoch [68/100], Step [22/60], Loss: 1.1915, batch time: 0.70, accuracy:  60.30%\n",
      "Epoch [68/100], Step [23/60], Loss: 1.1669, batch time: 0.69, accuracy:  60.80%\n",
      "Epoch [68/100], Step [24/60], Loss: 1.2151, batch time: 0.70, accuracy:  62.50%\n",
      "Epoch [68/100], Step [25/60], Loss: 1.2382, batch time: 0.69, accuracy:  60.10%\n",
      "Epoch [68/100], Step [26/60], Loss: 1.2385, batch time: 0.70, accuracy:  60.80%\n",
      "Epoch [68/100], Step [27/60], Loss: 1.1993, batch time: 0.70, accuracy:  62.20%\n",
      "Epoch [68/100], Step [28/60], Loss: 1.1813, batch time: 0.70, accuracy:  63.20%\n",
      "Epoch [68/100], Step [29/60], Loss: 1.2787, batch time: 0.69, accuracy:  57.10%\n",
      "Epoch [68/100], Step [30/60], Loss: 1.1454, batch time: 0.72, accuracy:  62.40%\n",
      "Epoch [68/100], Step [31/60], Loss: 1.1862, batch time: 0.72, accuracy:  60.10%\n",
      "Epoch [68/100], Step [32/60], Loss: 1.1907, batch time: 0.71, accuracy:  61.60%\n",
      "Epoch [68/100], Step [33/60], Loss: 1.1247, batch time: 0.79, accuracy:  64.10%\n",
      "Epoch [68/100], Step [34/60], Loss: 1.2310, batch time: 0.84, accuracy:  60.80%\n",
      "Epoch [68/100], Step [35/60], Loss: 1.2288, batch time: 0.84, accuracy:  58.70%\n",
      "Epoch [68/100], Step [36/60], Loss: 1.1672, batch time: 0.86, accuracy:  62.90%\n",
      "Epoch [68/100], Step [37/60], Loss: 1.2226, batch time: 0.84, accuracy:  61.00%\n",
      "Epoch [68/100], Step [38/60], Loss: 1.1576, batch time: 0.77, accuracy:  64.10%\n",
      "Epoch [68/100], Step [39/60], Loss: 1.1118, batch time: 0.51, accuracy:  64.00%\n",
      "Epoch [68/100], Step [40/60], Loss: 1.2042, batch time: 0.45, accuracy:  60.50%\n",
      "Epoch [68/100], Step [41/60], Loss: 1.1704, batch time: 0.44, accuracy:  61.10%\n",
      "Epoch [68/100], Step [42/60], Loss: 1.2279, batch time: 0.47, accuracy:  59.30%\n",
      "Epoch [68/100], Step [43/60], Loss: 1.2542, batch time: 0.45, accuracy:  59.10%\n",
      "Epoch [68/100], Step [44/60], Loss: 1.2233, batch time: 0.44, accuracy:  59.30%\n",
      "Epoch [68/100], Step [45/60], Loss: 1.2273, batch time: 0.46, accuracy:  60.30%\n",
      "Epoch [68/100], Step [46/60], Loss: 1.1698, batch time: 0.44, accuracy:  61.70%\n",
      "Epoch [68/100], Step [47/60], Loss: 1.1825, batch time: 0.44, accuracy:  60.70%\n",
      "Epoch [68/100], Step [48/60], Loss: 1.2144, batch time: 0.46, accuracy:  59.90%\n",
      "Epoch [68/100], Step [49/60], Loss: 1.1189, batch time: 0.44, accuracy:  62.10%\n",
      "Epoch [68/100], Step [50/60], Loss: 1.2096, batch time: 0.44, accuracy:  59.80%\n",
      "Epoch [68/100], Step [51/60], Loss: 1.2611, batch time: 0.48, accuracy:  56.90%\n",
      "Epoch [68/100], Step [52/60], Loss: 1.1489, batch time: 0.44, accuracy:  61.50%\n",
      "Epoch [68/100], Step [53/60], Loss: 1.1710, batch time: 0.45, accuracy:  61.60%\n",
      "Epoch [68/100], Step [54/60], Loss: 1.2755, batch time: 0.45, accuracy:  59.40%\n",
      "Epoch [68/100], Step [55/60], Loss: 1.1673, batch time: 0.44, accuracy:  63.50%\n",
      "Epoch [68/100], Step [56/60], Loss: 1.2301, batch time: 0.45, accuracy:  61.70%\n",
      "Epoch [68/100], Step [57/60], Loss: 1.1729, batch time: 0.45, accuracy:  59.80%\n",
      "Epoch [68/100], Step [58/60], Loss: 1.1709, batch time: 0.44, accuracy:  62.00%\n",
      "Epoch [68/100], Step [59/60], Loss: 1.1419, batch time: 0.45, accuracy:  62.90%\n",
      "Epoch [68/100], Step [60/60], Loss: 1.1919, batch time: 0.47, accuracy:  61.60%\n",
      "Epoch [69/100], Step [1/60], Loss: 1.1644, batch time: 0.71, accuracy:  60.80%\n",
      "Epoch [69/100], Step [2/60], Loss: 1.1935, batch time: 0.70, accuracy:  60.20%\n",
      "Epoch [69/100], Step [3/60], Loss: 1.1891, batch time: 0.72, accuracy:  61.10%\n",
      "Epoch [69/100], Step [4/60], Loss: 1.1922, batch time: 0.70, accuracy:  60.30%\n",
      "Epoch [69/100], Step [5/60], Loss: 1.2090, batch time: 0.71, accuracy:  60.50%\n",
      "Epoch [69/100], Step [6/60], Loss: 1.3384, batch time: 0.70, accuracy:  58.30%\n",
      "Epoch [69/100], Step [7/60], Loss: 1.2130, batch time: 0.70, accuracy:  60.50%\n",
      "Epoch [69/100], Step [8/60], Loss: 1.2292, batch time: 0.70, accuracy:  59.90%\n",
      "Epoch [69/100], Step [9/60], Loss: 1.1965, batch time: 0.70, accuracy:  61.60%\n",
      "Epoch [69/100], Step [10/60], Loss: 1.2238, batch time: 0.71, accuracy:  60.90%\n",
      "Epoch [69/100], Step [11/60], Loss: 1.1524, batch time: 0.75, accuracy:  63.50%\n",
      "Epoch [69/100], Step [12/60], Loss: 1.1781, batch time: 0.82, accuracy:  63.40%\n",
      "Epoch [69/100], Step [13/60], Loss: 1.1678, batch time: 0.82, accuracy:  62.70%\n",
      "Epoch [69/100], Step [14/60], Loss: 1.2049, batch time: 0.65, accuracy:  61.30%\n",
      "Epoch [69/100], Step [15/60], Loss: 1.1541, batch time: 0.65, accuracy:  61.60%\n",
      "Epoch [69/100], Step [16/60], Loss: 1.1592, batch time: 0.65, accuracy:  61.20%\n",
      "Epoch [69/100], Step [17/60], Loss: 1.1994, batch time: 0.65, accuracy:  61.60%\n",
      "Epoch [69/100], Step [18/60], Loss: 1.2112, batch time: 0.65, accuracy:  63.50%\n",
      "Epoch [69/100], Step [19/60], Loss: 1.2225, batch time: 0.65, accuracy:  60.00%\n",
      "Epoch [69/100], Step [20/60], Loss: 1.1082, batch time: 0.65, accuracy:  64.30%\n",
      "Epoch [69/100], Step [21/60], Loss: 1.1917, batch time: 0.65, accuracy:  61.80%\n",
      "Epoch [69/100], Step [22/60], Loss: 1.1828, batch time: 0.65, accuracy:  62.60%\n",
      "Epoch [69/100], Step [23/60], Loss: 1.3015, batch time: 0.65, accuracy:  59.00%\n",
      "Epoch [69/100], Step [24/60], Loss: 1.1892, batch time: 0.66, accuracy:  63.60%\n",
      "Epoch [69/100], Step [25/60], Loss: 1.1995, batch time: 0.67, accuracy:  59.70%\n",
      "Epoch [69/100], Step [26/60], Loss: 1.1322, batch time: 0.69, accuracy:  61.50%\n",
      "Epoch [69/100], Step [27/60], Loss: 1.1674, batch time: 0.71, accuracy:  60.50%\n",
      "Epoch [69/100], Step [28/60], Loss: 1.1601, batch time: 0.70, accuracy:  61.80%\n",
      "Epoch [69/100], Step [29/60], Loss: 1.1794, batch time: 0.70, accuracy:  62.30%\n",
      "Epoch [69/100], Step [30/60], Loss: 1.1747, batch time: 0.71, accuracy:  61.90%\n",
      "Epoch [69/100], Step [31/60], Loss: 1.1803, batch time: 0.70, accuracy:  60.80%\n",
      "Epoch [69/100], Step [32/60], Loss: 1.1423, batch time: 0.71, accuracy:  61.80%\n",
      "Epoch [69/100], Step [33/60], Loss: 1.1580, batch time: 0.71, accuracy:  61.80%\n",
      "Epoch [69/100], Step [34/60], Loss: 1.1612, batch time: 0.70, accuracy:  63.50%\n",
      "Epoch [69/100], Step [35/60], Loss: 1.1785, batch time: 0.71, accuracy:  61.40%\n",
      "Epoch [69/100], Step [36/60], Loss: 1.1934, batch time: 0.70, accuracy:  60.40%\n",
      "Epoch [69/100], Step [37/60], Loss: 1.1749, batch time: 0.71, accuracy:  62.60%\n",
      "Epoch [69/100], Step [38/60], Loss: 1.1599, batch time: 0.70, accuracy:  62.00%\n",
      "Epoch [69/100], Step [39/60], Loss: 1.2243, batch time: 0.71, accuracy:  59.60%\n",
      "Epoch [69/100], Step [40/60], Loss: 1.1946, batch time: 0.71, accuracy:  61.10%\n",
      "Epoch [69/100], Step [41/60], Loss: 1.2106, batch time: 0.70, accuracy:  60.50%\n",
      "Epoch [69/100], Step [42/60], Loss: 1.1057, batch time: 0.70, accuracy:  64.00%\n",
      "Epoch [69/100], Step [43/60], Loss: 1.1987, batch time: 0.66, accuracy:  59.20%\n",
      "Epoch [69/100], Step [44/60], Loss: 1.2613, batch time: 0.58, accuracy:  59.90%\n",
      "Epoch [69/100], Step [45/60], Loss: 1.1489, batch time: 0.56, accuracy:  62.30%\n",
      "Epoch [69/100], Step [46/60], Loss: 1.1031, batch time: 0.70, accuracy:  64.10%\n",
      "Epoch [69/100], Step [47/60], Loss: 1.2194, batch time: 0.86, accuracy:  62.00%\n",
      "Epoch [69/100], Step [48/60], Loss: 1.1197, batch time: 0.78, accuracy:  62.50%\n",
      "Epoch [69/100], Step [49/60], Loss: 1.1613, batch time: 0.87, accuracy:  62.90%\n",
      "Epoch [69/100], Step [50/60], Loss: 1.2449, batch time: 0.68, accuracy:  59.50%\n",
      "Epoch [69/100], Step [51/60], Loss: 1.1792, batch time: 0.67, accuracy:  62.20%\n",
      "Epoch [69/100], Step [52/60], Loss: 1.2042, batch time: 0.69, accuracy:  59.50%\n",
      "Epoch [69/100], Step [53/60], Loss: 1.2149, batch time: 0.69, accuracy:  62.90%\n",
      "Epoch [69/100], Step [54/60], Loss: 1.1926, batch time: 0.70, accuracy:  61.90%\n",
      "Epoch [69/100], Step [55/60], Loss: 1.1067, batch time: 0.54, accuracy:  63.00%\n",
      "Epoch [69/100], Step [56/60], Loss: 1.2308, batch time: 0.43, accuracy:  58.00%\n",
      "Epoch [69/100], Step [57/60], Loss: 1.1722, batch time: 0.42, accuracy:  61.50%\n",
      "Epoch [69/100], Step [58/60], Loss: 1.1479, batch time: 0.44, accuracy:  63.60%\n",
      "Epoch [69/100], Step [59/60], Loss: 1.1630, batch time: 0.43, accuracy:  61.60%\n",
      "Epoch [69/100], Step [60/60], Loss: 1.2111, batch time: 0.42, accuracy:  63.40%\n",
      "Epoch [70/100], Step [1/60], Loss: 1.1580, batch time: 0.45, accuracy:  64.80%\n",
      "Epoch [70/100], Step [2/60], Loss: 1.1467, batch time: 0.45, accuracy:  62.70%\n",
      "Epoch [70/100], Step [3/60], Loss: 1.1798, batch time: 0.47, accuracy:  61.00%\n",
      "Epoch [70/100], Step [4/60], Loss: 1.1138, batch time: 0.61, accuracy:  64.20%\n",
      "Epoch [70/100], Step [5/60], Loss: 1.2432, batch time: 0.42, accuracy:  59.10%\n",
      "Epoch [70/100], Step [6/60], Loss: 1.2155, batch time: 0.70, accuracy:  61.20%\n",
      "Epoch [70/100], Step [7/60], Loss: 1.1771, batch time: 0.73, accuracy:  62.70%\n",
      "Epoch [70/100], Step [8/60], Loss: 1.2307, batch time: 0.74, accuracy:  61.10%\n",
      "Epoch [70/100], Step [9/60], Loss: 1.1476, batch time: 0.76, accuracy:  62.90%\n",
      "Epoch [70/100], Step [10/60], Loss: 1.2725, batch time: 0.85, accuracy:  58.10%\n",
      "Epoch [70/100], Step [11/60], Loss: 1.1826, batch time: 0.87, accuracy:  60.90%\n",
      "Epoch [70/100], Step [12/60], Loss: 1.1994, batch time: 0.64, accuracy:  61.10%\n",
      "Epoch [70/100], Step [13/60], Loss: 1.1111, batch time: 0.54, accuracy:  64.20%\n",
      "Epoch [70/100], Step [14/60], Loss: 1.1874, batch time: 0.57, accuracy:  62.00%\n",
      "Epoch [70/100], Step [15/60], Loss: 1.1348, batch time: 0.54, accuracy:  64.10%\n",
      "Epoch [70/100], Step [16/60], Loss: 1.1900, batch time: 0.54, accuracy:  60.80%\n",
      "Epoch [70/100], Step [17/60], Loss: 1.1618, batch time: 0.53, accuracy:  64.10%\n",
      "Epoch [70/100], Step [18/60], Loss: 1.1843, batch time: 0.54, accuracy:  61.50%\n",
      "Epoch [70/100], Step [19/60], Loss: 1.1469, batch time: 0.54, accuracy:  60.10%\n",
      "Epoch [70/100], Step [20/60], Loss: 1.1705, batch time: 0.54, accuracy:  64.50%\n",
      "Epoch [70/100], Step [21/60], Loss: 1.1863, batch time: 0.54, accuracy:  60.70%\n",
      "Epoch [70/100], Step [22/60], Loss: 1.2263, batch time: 0.46, accuracy:  62.30%\n",
      "Epoch [70/100], Step [23/60], Loss: 1.1684, batch time: 0.45, accuracy:  61.40%\n",
      "Epoch [70/100], Step [24/60], Loss: 1.1859, batch time: 0.45, accuracy:  62.70%\n",
      "Epoch [70/100], Step [25/60], Loss: 1.2507, batch time: 0.45, accuracy:  60.00%\n",
      "Epoch [70/100], Step [26/60], Loss: 1.1738, batch time: 0.45, accuracy:  61.60%\n",
      "Epoch [70/100], Step [27/60], Loss: 1.1224, batch time: 0.45, accuracy:  61.60%\n",
      "Epoch [70/100], Step [28/60], Loss: 1.1446, batch time: 0.45, accuracy:  63.90%\n",
      "Epoch [70/100], Step [29/60], Loss: 1.1827, batch time: 0.45, accuracy:  60.50%\n",
      "Epoch [70/100], Step [30/60], Loss: 1.2380, batch time: 0.44, accuracy:  58.40%\n",
      "Epoch [70/100], Step [31/60], Loss: 1.2303, batch time: 0.47, accuracy:  60.20%\n",
      "Epoch [70/100], Step [32/60], Loss: 1.1464, batch time: 0.45, accuracy:  65.20%\n",
      "Epoch [70/100], Step [33/60], Loss: 1.1035, batch time: 0.44, accuracy:  64.50%\n",
      "Epoch [70/100], Step [34/60], Loss: 1.1826, batch time: 0.45, accuracy:  60.60%\n",
      "Epoch [70/100], Step [35/60], Loss: 1.1662, batch time: 0.45, accuracy:  60.40%\n",
      "Epoch [70/100], Step [36/60], Loss: 1.1298, batch time: 0.45, accuracy:  63.20%\n",
      "Epoch [70/100], Step [37/60], Loss: 1.1665, batch time: 0.45, accuracy:  62.80%\n",
      "Epoch [70/100], Step [38/60], Loss: 1.1813, batch time: 0.45, accuracy:  61.80%\n",
      "Epoch [70/100], Step [39/60], Loss: 1.2038, batch time: 0.45, accuracy:  60.40%\n",
      "Epoch [70/100], Step [40/60], Loss: 1.0898, batch time: 0.46, accuracy:  64.50%\n",
      "Epoch [70/100], Step [41/60], Loss: 1.1058, batch time: 0.45, accuracy:  64.00%\n",
      "Epoch [70/100], Step [42/60], Loss: 1.1912, batch time: 0.45, accuracy:  61.10%\n",
      "Epoch [70/100], Step [43/60], Loss: 1.0952, batch time: 0.45, accuracy:  65.20%\n",
      "Epoch [70/100], Step [44/60], Loss: 1.2221, batch time: 0.45, accuracy:  60.00%\n",
      "Epoch [70/100], Step [45/60], Loss: 1.1668, batch time: 0.48, accuracy:  61.00%\n",
      "Epoch [70/100], Step [46/60], Loss: 1.2620, batch time: 0.53, accuracy:  60.90%\n",
      "Epoch [70/100], Step [47/60], Loss: 1.1528, batch time: 0.54, accuracy:  63.90%\n",
      "Epoch [70/100], Step [48/60], Loss: 1.1686, batch time: 0.54, accuracy:  60.20%\n",
      "Epoch [70/100], Step [49/60], Loss: 1.1725, batch time: 0.56, accuracy:  63.10%\n",
      "Epoch [70/100], Step [50/60], Loss: 1.2119, batch time: 0.54, accuracy:  61.10%\n",
      "Epoch [70/100], Step [51/60], Loss: 1.2262, batch time: 0.53, accuracy:  59.60%\n",
      "Epoch [70/100], Step [52/60], Loss: 1.1749, batch time: 0.53, accuracy:  62.50%\n",
      "Epoch [70/100], Step [53/60], Loss: 1.1926, batch time: 0.52, accuracy:  61.40%\n",
      "Epoch [70/100], Step [54/60], Loss: 1.1400, batch time: 0.44, accuracy:  62.40%\n",
      "Epoch [70/100], Step [55/60], Loss: 1.0934, batch time: 0.44, accuracy:  63.30%\n",
      "Epoch [70/100], Step [56/60], Loss: 1.1517, batch time: 0.44, accuracy:  62.90%\n",
      "Epoch [70/100], Step [57/60], Loss: 1.1847, batch time: 0.47, accuracy:  62.30%\n",
      "Epoch [70/100], Step [58/60], Loss: 1.1882, batch time: 0.46, accuracy:  62.20%\n",
      "Epoch [70/100], Step [59/60], Loss: 1.1631, batch time: 0.65, accuracy:  62.50%\n",
      "Epoch [70/100], Step [60/60], Loss: 1.1369, batch time: 0.42, accuracy:  64.30%\n",
      "Epoch [71/100], Step [1/60], Loss: 1.1456, batch time: 0.44, accuracy:  62.00%\n",
      "Epoch [71/100], Step [2/60], Loss: 1.2141, batch time: 0.54, accuracy:  60.20%\n",
      "Epoch [71/100], Step [3/60], Loss: 1.1413, batch time: 0.69, accuracy:  63.40%\n",
      "Epoch [71/100], Step [4/60], Loss: 1.1215, batch time: 0.68, accuracy:  63.30%\n",
      "Epoch [71/100], Step [5/60], Loss: 1.1301, batch time: 0.69, accuracy:  63.70%\n",
      "Epoch [71/100], Step [6/60], Loss: 1.1768, batch time: 0.67, accuracy:  61.30%\n",
      "Epoch [71/100], Step [7/60], Loss: 1.1426, batch time: 0.70, accuracy:  62.60%\n",
      "Epoch [71/100], Step [8/60], Loss: 1.1986, batch time: 0.69, accuracy:  60.80%\n",
      "Epoch [71/100], Step [9/60], Loss: 1.1182, batch time: 0.70, accuracy:  64.30%\n",
      "Epoch [71/100], Step [10/60], Loss: 1.1124, batch time: 0.71, accuracy:  62.90%\n",
      "Epoch [71/100], Step [11/60], Loss: 1.1229, batch time: 0.72, accuracy:  63.70%\n",
      "Epoch [71/100], Step [12/60], Loss: 1.1688, batch time: 0.85, accuracy:  61.40%\n",
      "Epoch [71/100], Step [13/60], Loss: 1.1508, batch time: 0.84, accuracy:  62.20%\n",
      "Epoch [71/100], Step [14/60], Loss: 1.1571, batch time: 0.83, accuracy:  62.80%\n",
      "Epoch [71/100], Step [15/60], Loss: 1.1750, batch time: 0.86, accuracy:  61.50%\n",
      "Epoch [71/100], Step [16/60], Loss: 1.1763, batch time: 0.69, accuracy:  63.20%\n",
      "Epoch [71/100], Step [17/60], Loss: 1.1979, batch time: 0.69, accuracy:  60.80%\n",
      "Epoch [71/100], Step [18/60], Loss: 1.0865, batch time: 0.70, accuracy:  65.60%\n",
      "Epoch [71/100], Step [19/60], Loss: 1.1534, batch time: 0.70, accuracy:  65.00%\n",
      "Epoch [71/100], Step [20/60], Loss: 1.1744, batch time: 0.59, accuracy:  62.10%\n",
      "Epoch [71/100], Step [21/60], Loss: 1.1699, batch time: 0.65, accuracy:  64.00%\n",
      "Epoch [71/100], Step [22/60], Loss: 1.2118, batch time: 0.69, accuracy:  60.20%\n",
      "Epoch [71/100], Step [23/60], Loss: 1.1690, batch time: 0.69, accuracy:  61.60%\n",
      "Epoch [71/100], Step [24/60], Loss: 1.1868, batch time: 0.69, accuracy:  63.70%\n",
      "Epoch [71/100], Step [25/60], Loss: 1.1631, batch time: 0.69, accuracy:  61.10%\n",
      "Epoch [71/100], Step [26/60], Loss: 1.0956, batch time: 0.69, accuracy:  62.40%\n",
      "Epoch [71/100], Step [27/60], Loss: 1.1629, batch time: 0.69, accuracy:  61.50%\n",
      "Epoch [71/100], Step [28/60], Loss: 1.1532, batch time: 0.72, accuracy:  63.20%\n",
      "Epoch [71/100], Step [29/60], Loss: 1.1109, batch time: 0.71, accuracy:  64.50%\n",
      "Epoch [71/100], Step [30/60], Loss: 1.0980, batch time: 0.83, accuracy:  64.40%\n",
      "Epoch [71/100], Step [31/60], Loss: 1.1479, batch time: 0.83, accuracy:  64.30%\n",
      "Epoch [71/100], Step [32/60], Loss: 1.1853, batch time: 0.83, accuracy:  59.30%\n",
      "Epoch [71/100], Step [33/60], Loss: 1.1556, batch time: 0.84, accuracy:  61.50%\n",
      "Epoch [71/100], Step [34/60], Loss: 1.1535, batch time: 0.83, accuracy:  61.20%\n",
      "Epoch [71/100], Step [35/60], Loss: 1.2260, batch time: 0.83, accuracy:  59.70%\n",
      "Epoch [71/100], Step [36/60], Loss: 1.1800, batch time: 0.83, accuracy:  60.20%\n",
      "Epoch [71/100], Step [37/60], Loss: 1.1158, batch time: 0.83, accuracy:  64.00%\n",
      "Epoch [71/100], Step [38/60], Loss: 1.1867, batch time: 0.84, accuracy:  62.30%\n",
      "Epoch [71/100], Step [39/60], Loss: 1.2435, batch time: 0.68, accuracy:  63.40%\n",
      "Epoch [71/100], Step [40/60], Loss: 1.1424, batch time: 0.68, accuracy:  64.10%\n",
      "Epoch [71/100], Step [41/60], Loss: 1.1256, batch time: 0.68, accuracy:  61.60%\n",
      "Epoch [71/100], Step [42/60], Loss: 1.1630, batch time: 0.68, accuracy:  60.30%\n",
      "Epoch [71/100], Step [43/60], Loss: 1.2002, batch time: 0.68, accuracy:  61.20%\n",
      "Epoch [71/100], Step [44/60], Loss: 1.1798, batch time: 0.69, accuracy:  60.10%\n",
      "Epoch [71/100], Step [45/60], Loss: 1.1287, batch time: 0.69, accuracy:  61.90%\n",
      "Epoch [71/100], Step [46/60], Loss: 1.2014, batch time: 0.68, accuracy:  62.60%\n",
      "Epoch [71/100], Step [47/60], Loss: 1.1255, batch time: 0.69, accuracy:  61.10%\n",
      "Epoch [71/100], Step [48/60], Loss: 1.0603, batch time: 0.64, accuracy:  65.00%\n",
      "Epoch [71/100], Step [49/60], Loss: 1.1977, batch time: 0.61, accuracy:  61.00%\n",
      "Epoch [71/100], Step [50/60], Loss: 1.1453, batch time: 0.69, accuracy:  62.30%\n",
      "Epoch [71/100], Step [51/60], Loss: 1.2132, batch time: 0.61, accuracy:  61.40%\n",
      "Epoch [71/100], Step [52/60], Loss: 1.1754, batch time: 0.72, accuracy:  61.80%\n",
      "Epoch [71/100], Step [53/60], Loss: 1.1834, batch time: 0.73, accuracy:  61.60%\n",
      "Epoch [71/100], Step [54/60], Loss: 1.1803, batch time: 0.64, accuracy:  62.80%\n",
      "Epoch [71/100], Step [55/60], Loss: 1.1781, batch time: 0.78, accuracy:  62.80%\n",
      "Epoch [71/100], Step [56/60], Loss: 1.1767, batch time: 0.84, accuracy:  62.60%\n",
      "Epoch [71/100], Step [57/60], Loss: 1.2017, batch time: 0.73, accuracy:  63.70%\n",
      "Epoch [71/100], Step [58/60], Loss: 1.1823, batch time: 0.70, accuracy:  58.90%\n",
      "Epoch [71/100], Step [59/60], Loss: 1.1628, batch time: 0.68, accuracy:  62.80%\n",
      "Epoch [71/100], Step [60/60], Loss: 1.1879, batch time: 0.69, accuracy:  64.40%\n",
      "Epoch [72/100], Step [1/60], Loss: 1.1356, batch time: 0.70, accuracy:  63.60%\n",
      "Epoch [72/100], Step [2/60], Loss: 1.1183, batch time: 0.69, accuracy:  65.30%\n",
      "Epoch [72/100], Step [3/60], Loss: 1.1382, batch time: 0.68, accuracy:  64.80%\n",
      "Epoch [72/100], Step [4/60], Loss: 1.1659, batch time: 0.68, accuracy:  61.20%\n",
      "Epoch [72/100], Step [5/60], Loss: 1.1498, batch time: 0.69, accuracy:  64.10%\n",
      "Epoch [72/100], Step [6/60], Loss: 1.1506, batch time: 0.68, accuracy:  62.90%\n",
      "Epoch [72/100], Step [7/60], Loss: 1.1624, batch time: 0.68, accuracy:  62.70%\n",
      "Epoch [72/100], Step [8/60], Loss: 1.1520, batch time: 0.69, accuracy:  62.10%\n",
      "Epoch [72/100], Step [9/60], Loss: 1.0948, batch time: 0.68, accuracy:  62.70%\n",
      "Epoch [72/100], Step [10/60], Loss: 1.1279, batch time: 0.69, accuracy:  62.40%\n",
      "Epoch [72/100], Step [11/60], Loss: 1.1748, batch time: 0.69, accuracy:  63.00%\n",
      "Epoch [72/100], Step [12/60], Loss: 1.1707, batch time: 0.71, accuracy:  64.60%\n",
      "Epoch [72/100], Step [13/60], Loss: 1.1598, batch time: 0.78, accuracy:  63.50%\n",
      "Epoch [72/100], Step [14/60], Loss: 1.1611, batch time: 0.83, accuracy:  63.10%\n",
      "Epoch [72/100], Step [15/60], Loss: 1.0843, batch time: 0.83, accuracy:  65.50%\n",
      "Epoch [72/100], Step [16/60], Loss: 1.2153, batch time: 0.83, accuracy:  61.40%\n",
      "Epoch [72/100], Step [17/60], Loss: 1.1811, batch time: 0.83, accuracy:  60.10%\n",
      "Epoch [72/100], Step [18/60], Loss: 1.1522, batch time: 0.77, accuracy:  63.80%\n",
      "Epoch [72/100], Step [19/60], Loss: 1.1719, batch time: 0.68, accuracy:  64.40%\n",
      "Epoch [72/100], Step [20/60], Loss: 1.1213, batch time: 0.69, accuracy:  64.20%\n",
      "Epoch [72/100], Step [21/60], Loss: 1.1385, batch time: 0.69, accuracy:  61.60%\n",
      "Epoch [72/100], Step [22/60], Loss: 1.1240, batch time: 0.69, accuracy:  62.00%\n",
      "Epoch [72/100], Step [23/60], Loss: 1.1654, batch time: 0.70, accuracy:  61.40%\n",
      "Epoch [72/100], Step [24/60], Loss: 1.0772, batch time: 0.60, accuracy:  67.10%\n",
      "Epoch [72/100], Step [25/60], Loss: 1.1579, batch time: 0.70, accuracy:  61.70%\n",
      "Epoch [72/100], Step [26/60], Loss: 1.1504, batch time: 0.69, accuracy:  63.00%\n",
      "Epoch [72/100], Step [27/60], Loss: 1.0964, batch time: 0.69, accuracy:  65.00%\n",
      "Epoch [72/100], Step [28/60], Loss: 1.1585, batch time: 0.69, accuracy:  61.90%\n",
      "Epoch [72/100], Step [29/60], Loss: 1.2127, batch time: 0.69, accuracy:  62.90%\n",
      "Epoch [72/100], Step [30/60], Loss: 1.1697, batch time: 0.73, accuracy:  61.90%\n",
      "Epoch [72/100], Step [31/60], Loss: 1.1244, batch time: 0.67, accuracy:  63.90%\n",
      "Epoch [72/100], Step [32/60], Loss: 1.1301, batch time: 0.72, accuracy:  63.20%\n",
      "Epoch [72/100], Step [33/60], Loss: 1.1659, batch time: 0.62, accuracy:  60.90%\n",
      "Epoch [72/100], Step [34/60], Loss: 1.2205, batch time: 0.87, accuracy:  63.60%\n",
      "Epoch [72/100], Step [35/60], Loss: 1.1553, batch time: 0.73, accuracy:  63.70%\n",
      "Epoch [72/100], Step [36/60], Loss: 1.1798, batch time: 0.69, accuracy:  62.00%\n",
      "Epoch [72/100], Step [37/60], Loss: 1.1810, batch time: 0.69, accuracy:  61.30%\n",
      "Epoch [72/100], Step [38/60], Loss: 1.1551, batch time: 0.64, accuracy:  62.90%\n",
      "Epoch [72/100], Step [39/60], Loss: 1.1008, batch time: 0.69, accuracy:  66.30%\n",
      "Epoch [72/100], Step [40/60], Loss: 1.1849, batch time: 0.59, accuracy:  58.80%\n",
      "Epoch [72/100], Step [41/60], Loss: 1.1972, batch time: 0.45, accuracy:  64.30%\n",
      "Epoch [72/100], Step [42/60], Loss: 1.1333, batch time: 0.45, accuracy:  63.30%\n",
      "Epoch [72/100], Step [43/60], Loss: 1.1781, batch time: 0.48, accuracy:  62.90%\n",
      "Epoch [72/100], Step [44/60], Loss: 1.0877, batch time: 0.45, accuracy:  66.10%\n",
      "Epoch [72/100], Step [45/60], Loss: 1.1231, batch time: 0.45, accuracy:  62.70%\n",
      "Epoch [72/100], Step [46/60], Loss: 1.1527, batch time: 0.46, accuracy:  64.40%\n",
      "Epoch [72/100], Step [47/60], Loss: 1.1696, batch time: 0.45, accuracy:  61.40%\n",
      "Epoch [72/100], Step [48/60], Loss: 1.1489, batch time: 0.45, accuracy:  60.40%\n",
      "Epoch [72/100], Step [49/60], Loss: 1.1841, batch time: 0.45, accuracy:  63.50%\n",
      "Epoch [72/100], Step [50/60], Loss: 1.1807, batch time: 0.45, accuracy:  61.10%\n",
      "Epoch [72/100], Step [51/60], Loss: 1.1305, batch time: 0.46, accuracy:  63.70%\n",
      "Epoch [72/100], Step [52/60], Loss: 1.2075, batch time: 0.47, accuracy:  60.10%\n",
      "Epoch [72/100], Step [53/60], Loss: 1.1066, batch time: 0.44, accuracy:  66.20%\n",
      "Epoch [72/100], Step [54/60], Loss: 1.1921, batch time: 0.46, accuracy:  58.70%\n",
      "Epoch [72/100], Step [55/60], Loss: 1.1150, batch time: 0.49, accuracy:  64.00%\n",
      "Epoch [72/100], Step [56/60], Loss: 1.1966, batch time: 0.54, accuracy:  62.60%\n",
      "Epoch [72/100], Step [57/60], Loss: 1.1412, batch time: 0.53, accuracy:  64.30%\n",
      "Epoch [72/100], Step [58/60], Loss: 1.1277, batch time: 0.53, accuracy:  64.30%\n",
      "Epoch [72/100], Step [59/60], Loss: 1.0652, batch time: 0.54, accuracy:  66.10%\n",
      "Epoch [72/100], Step [60/60], Loss: 1.1139, batch time: 0.55, accuracy:  64.10%\n",
      "Epoch [73/100], Step [1/60], Loss: 1.1428, batch time: 0.87, accuracy:  62.00%\n",
      "Epoch [73/100], Step [2/60], Loss: 1.1362, batch time: 0.77, accuracy:  63.60%\n",
      "Epoch [73/100], Step [3/60], Loss: 1.1782, batch time: 0.54, accuracy:  64.20%\n",
      "Epoch [73/100], Step [4/60], Loss: 1.1592, batch time: 0.53, accuracy:  61.10%\n",
      "Epoch [73/100], Step [5/60], Loss: 1.0993, batch time: 0.54, accuracy:  66.30%\n",
      "Epoch [73/100], Step [6/60], Loss: 1.1670, batch time: 0.53, accuracy:  64.00%\n",
      "Epoch [73/100], Step [7/60], Loss: 1.1601, batch time: 0.56, accuracy:  61.40%\n",
      "Epoch [73/100], Step [8/60], Loss: 1.2075, batch time: 0.46, accuracy:  63.80%\n",
      "Epoch [73/100], Step [9/60], Loss: 1.1565, batch time: 0.44, accuracy:  64.10%\n",
      "Epoch [73/100], Step [10/60], Loss: 1.0687, batch time: 0.45, accuracy:  65.80%\n",
      "Epoch [73/100], Step [11/60], Loss: 1.1056, batch time: 0.44, accuracy:  65.00%\n",
      "Epoch [73/100], Step [12/60], Loss: 1.1030, batch time: 0.45, accuracy:  63.50%\n",
      "Epoch [73/100], Step [13/60], Loss: 1.2261, batch time: 0.45, accuracy:  59.90%\n",
      "Epoch [73/100], Step [14/60], Loss: 1.1877, batch time: 0.44, accuracy:  60.50%\n",
      "Epoch [73/100], Step [15/60], Loss: 1.1170, batch time: 0.45, accuracy:  62.40%\n",
      "Epoch [73/100], Step [16/60], Loss: 1.1232, batch time: 0.46, accuracy:  63.10%\n",
      "Epoch [73/100], Step [17/60], Loss: 1.1809, batch time: 0.44, accuracy:  62.50%\n",
      "Epoch [73/100], Step [18/60], Loss: 1.1649, batch time: 0.49, accuracy:  60.60%\n",
      "Epoch [73/100], Step [19/60], Loss: 1.0548, batch time: 0.68, accuracy:  65.80%\n",
      "Epoch [73/100], Step [20/60], Loss: 1.1656, batch time: 0.71, accuracy:  61.80%\n",
      "Epoch [73/100], Step [21/60], Loss: 1.1675, batch time: 0.72, accuracy:  62.90%\n",
      "Epoch [73/100], Step [22/60], Loss: 1.1022, batch time: 0.72, accuracy:  64.00%\n",
      "Epoch [73/100], Step [23/60], Loss: 1.1340, batch time: 0.72, accuracy:  63.70%\n",
      "Epoch [73/100], Step [24/60], Loss: 1.1420, batch time: 0.71, accuracy:  64.10%\n",
      "Epoch [73/100], Step [25/60], Loss: 1.1274, batch time: 0.73, accuracy:  64.90%\n",
      "Epoch [73/100], Step [26/60], Loss: 1.0962, batch time: 0.73, accuracy:  64.50%\n",
      "Epoch [73/100], Step [27/60], Loss: 1.1739, batch time: 0.85, accuracy:  62.00%\n",
      "Epoch [73/100], Step [28/60], Loss: 1.1153, batch time: 0.87, accuracy:  61.10%\n",
      "Epoch [73/100], Step [29/60], Loss: 1.1334, batch time: 0.85, accuracy:  60.90%\n",
      "Epoch [73/100], Step [30/60], Loss: 1.1359, batch time: 0.86, accuracy:  63.50%\n",
      "Epoch [73/100], Step [31/60], Loss: 1.2297, batch time: 0.70, accuracy:  60.70%\n",
      "Epoch [73/100], Step [32/60], Loss: 1.1251, batch time: 0.68, accuracy:  63.60%\n",
      "Epoch [73/100], Step [33/60], Loss: 1.1285, batch time: 0.72, accuracy:  64.10%\n",
      "Epoch [73/100], Step [34/60], Loss: 1.0824, batch time: 0.69, accuracy:  64.60%\n",
      "Epoch [73/100], Step [35/60], Loss: 1.0828, batch time: 0.68, accuracy:  65.40%\n",
      "Epoch [73/100], Step [36/60], Loss: 1.1168, batch time: 0.71, accuracy:  61.80%\n",
      "Epoch [73/100], Step [37/60], Loss: 1.1089, batch time: 0.69, accuracy:  65.40%\n",
      "Epoch [73/100], Step [38/60], Loss: 1.0846, batch time: 0.72, accuracy:  65.90%\n",
      "Epoch [73/100], Step [39/60], Loss: 1.1470, batch time: 0.72, accuracy:  63.30%\n",
      "Epoch [73/100], Step [40/60], Loss: 1.1253, batch time: 0.72, accuracy:  65.50%\n",
      "Epoch [73/100], Step [41/60], Loss: 1.1072, batch time: 0.66, accuracy:  63.70%\n",
      "Epoch [73/100], Step [42/60], Loss: 1.0895, batch time: 0.57, accuracy:  64.80%\n",
      "Epoch [73/100], Step [43/60], Loss: 1.1359, batch time: 0.48, accuracy:  62.40%\n",
      "Epoch [73/100], Step [44/60], Loss: 1.1926, batch time: 0.48, accuracy:  60.30%\n",
      "Epoch [73/100], Step [45/60], Loss: 1.0939, batch time: 0.69, accuracy:  64.90%\n",
      "Epoch [73/100], Step [46/60], Loss: 1.1266, batch time: 0.69, accuracy:  62.80%\n",
      "Epoch [73/100], Step [47/60], Loss: 1.1094, batch time: 0.78, accuracy:  63.80%\n",
      "Epoch [73/100], Step [48/60], Loss: 1.0955, batch time: 0.88, accuracy:  64.30%\n",
      "Epoch [73/100], Step [49/60], Loss: 1.1980, batch time: 0.88, accuracy:  61.90%\n",
      "Epoch [73/100], Step [50/60], Loss: 1.1498, batch time: 0.87, accuracy:  63.20%\n",
      "Epoch [73/100], Step [51/60], Loss: 1.1031, batch time: 0.88, accuracy:  63.20%\n",
      "Epoch [73/100], Step [52/60], Loss: 1.0915, batch time: 0.87, accuracy:  63.80%\n",
      "Epoch [73/100], Step [53/60], Loss: 1.1264, batch time: 0.72, accuracy:  65.10%\n",
      "Epoch [73/100], Step [54/60], Loss: 1.1340, batch time: 0.67, accuracy:  62.60%\n",
      "Epoch [73/100], Step [55/60], Loss: 1.1977, batch time: 0.71, accuracy:  63.00%\n",
      "Epoch [73/100], Step [56/60], Loss: 1.2032, batch time: 0.63, accuracy:  59.80%\n",
      "Epoch [73/100], Step [57/60], Loss: 1.0721, batch time: 0.71, accuracy:  68.30%\n",
      "Epoch [73/100], Step [58/60], Loss: 1.0815, batch time: 0.72, accuracy:  65.60%\n",
      "Epoch [73/100], Step [59/60], Loss: 1.0396, batch time: 0.71, accuracy:  66.90%\n",
      "Epoch [73/100], Step [60/60], Loss: 1.1527, batch time: 0.73, accuracy:  62.50%\n",
      "Epoch [74/100], Step [1/60], Loss: 1.1000, batch time: 0.73, accuracy:  63.20%\n",
      "Epoch [74/100], Step [2/60], Loss: 1.1096, batch time: 0.73, accuracy:  62.50%\n",
      "Epoch [74/100], Step [3/60], Loss: 1.0669, batch time: 0.73, accuracy:  65.00%\n",
      "Epoch [74/100], Step [4/60], Loss: 1.1093, batch time: 0.72, accuracy:  63.70%\n",
      "Epoch [74/100], Step [5/60], Loss: 1.1975, batch time: 0.75, accuracy:  62.40%\n",
      "Epoch [74/100], Step [6/60], Loss: 1.0875, batch time: 0.76, accuracy:  63.70%\n",
      "Epoch [74/100], Step [7/60], Loss: 1.0980, batch time: 0.73, accuracy:  66.20%\n",
      "Epoch [74/100], Step [8/60], Loss: 1.0925, batch time: 0.74, accuracy:  65.30%\n",
      "Epoch [74/100], Step [9/60], Loss: 1.0978, batch time: 0.82, accuracy:  65.10%\n",
      "Epoch [74/100], Step [10/60], Loss: 1.1155, batch time: 0.85, accuracy:  63.90%\n",
      "Epoch [74/100], Step [11/60], Loss: 1.1004, batch time: 0.85, accuracy:  64.60%\n",
      "Epoch [74/100], Step [12/60], Loss: 1.1900, batch time: 0.88, accuracy:  63.90%\n",
      "Epoch [74/100], Step [13/60], Loss: 1.1374, batch time: 0.69, accuracy:  63.60%\n",
      "Epoch [74/100], Step [14/60], Loss: 1.1241, batch time: 0.73, accuracy:  63.80%\n",
      "Epoch [74/100], Step [15/60], Loss: 1.0911, batch time: 0.70, accuracy:  64.80%\n",
      "Epoch [74/100], Step [16/60], Loss: 1.1307, batch time: 0.69, accuracy:  65.20%\n",
      "Epoch [74/100], Step [17/60], Loss: 1.0918, batch time: 0.72, accuracy:  63.10%\n",
      "Epoch [74/100], Step [18/60], Loss: 1.0832, batch time: 0.70, accuracy:  65.60%\n",
      "Epoch [74/100], Step [19/60], Loss: 1.1340, batch time: 0.70, accuracy:  64.70%\n",
      "Epoch [74/100], Step [20/60], Loss: 1.2173, batch time: 0.69, accuracy:  60.10%\n",
      "Epoch [74/100], Step [21/60], Loss: 1.1776, batch time: 0.74, accuracy:  60.60%\n",
      "Epoch [74/100], Step [22/60], Loss: 1.1140, batch time: 0.72, accuracy:  63.30%\n",
      "Epoch [74/100], Step [23/60], Loss: 1.1529, batch time: 0.69, accuracy:  62.90%\n",
      "Epoch [74/100], Step [24/60], Loss: 1.1458, batch time: 0.72, accuracy:  61.90%\n",
      "Epoch [74/100], Step [25/60], Loss: 1.1838, batch time: 0.72, accuracy:  61.60%\n",
      "Epoch [74/100], Step [26/60], Loss: 1.1441, batch time: 0.75, accuracy:  62.10%\n",
      "Epoch [74/100], Step [27/60], Loss: 1.1299, batch time: 0.76, accuracy:  62.80%\n",
      "Epoch [74/100], Step [28/60], Loss: 1.1625, batch time: 1.04, accuracy:  63.00%\n",
      "Epoch [74/100], Step [29/60], Loss: 1.1557, batch time: 0.73, accuracy:  60.80%\n",
      "Epoch [74/100], Step [30/60], Loss: 1.1265, batch time: 0.73, accuracy:  64.30%\n",
      "Epoch [74/100], Step [31/60], Loss: 1.0425, batch time: 0.73, accuracy:  65.50%\n",
      "Epoch [74/100], Step [32/60], Loss: 1.1075, batch time: 0.72, accuracy:  62.70%\n",
      "Epoch [74/100], Step [33/60], Loss: 1.1823, batch time: 0.73, accuracy:  63.40%\n",
      "Epoch [74/100], Step [34/60], Loss: 1.1960, batch time: 0.72, accuracy:  63.30%\n",
      "Epoch [74/100], Step [35/60], Loss: 1.1332, batch time: 0.71, accuracy:  63.00%\n",
      "Epoch [74/100], Step [36/60], Loss: 1.1683, batch time: 0.72, accuracy:  61.40%\n",
      "Epoch [74/100], Step [37/60], Loss: 1.0566, batch time: 0.71, accuracy:  65.40%\n",
      "Epoch [74/100], Step [38/60], Loss: 1.1095, batch time: 0.71, accuracy:  63.80%\n",
      "Epoch [74/100], Step [39/60], Loss: 1.2342, batch time: 0.69, accuracy:  62.80%\n",
      "Epoch [74/100], Step [40/60], Loss: 1.0413, batch time: 0.71, accuracy:  65.80%\n",
      "Epoch [74/100], Step [41/60], Loss: 1.1553, batch time: 0.74, accuracy:  63.00%\n",
      "Epoch [74/100], Step [42/60], Loss: 1.1842, batch time: 0.74, accuracy:  63.20%\n",
      "Epoch [74/100], Step [43/60], Loss: 1.1353, batch time: 0.73, accuracy:  64.20%\n",
      "Epoch [74/100], Step [44/60], Loss: 1.1864, batch time: 0.79, accuracy:  63.10%\n",
      "Epoch [74/100], Step [45/60], Loss: 1.0783, batch time: 0.83, accuracy:  64.20%\n",
      "Epoch [74/100], Step [46/60], Loss: 1.2146, batch time: 0.86, accuracy:  61.00%\n",
      "Epoch [74/100], Step [47/60], Loss: 1.1211, batch time: 0.70, accuracy:  63.90%\n",
      "Epoch [74/100], Step [48/60], Loss: 1.1255, batch time: 0.68, accuracy:  63.90%\n",
      "Epoch [74/100], Step [49/60], Loss: 1.1624, batch time: 0.70, accuracy:  60.90%\n",
      "Epoch [74/100], Step [50/60], Loss: 1.1237, batch time: 0.67, accuracy:  64.10%\n",
      "Epoch [74/100], Step [51/60], Loss: 1.1209, batch time: 0.69, accuracy:  65.80%\n",
      "Epoch [74/100], Step [52/60], Loss: 1.1577, batch time: 0.67, accuracy:  62.90%\n",
      "Epoch [74/100], Step [53/60], Loss: 1.1607, batch time: 0.67, accuracy:  61.70%\n",
      "Epoch [74/100], Step [54/60], Loss: 1.1275, batch time: 0.68, accuracy:  64.00%\n",
      "Epoch [74/100], Step [55/60], Loss: 1.1124, batch time: 0.67, accuracy:  63.00%\n",
      "Epoch [74/100], Step [56/60], Loss: 1.1605, batch time: 0.60, accuracy:  62.00%\n",
      "Epoch [74/100], Step [57/60], Loss: 1.0584, batch time: 0.68, accuracy:  66.10%\n",
      "Epoch [74/100], Step [58/60], Loss: 1.1384, batch time: 0.67, accuracy:  64.50%\n",
      "Epoch [74/100], Step [59/60], Loss: 1.1470, batch time: 0.71, accuracy:  64.80%\n",
      "Epoch [74/100], Step [60/60], Loss: 1.1079, batch time: 0.57, accuracy:  63.50%\n",
      "Epoch [75/100], Step [1/60], Loss: 1.1595, batch time: 0.74, accuracy:  63.10%\n",
      "Epoch [75/100], Step [2/60], Loss: 1.1424, batch time: 0.73, accuracy:  62.20%\n",
      "Epoch [75/100], Step [3/60], Loss: 1.1097, batch time: 0.82, accuracy:  63.70%\n",
      "Epoch [75/100], Step [4/60], Loss: 1.1339, batch time: 0.83, accuracy:  63.60%\n",
      "Epoch [75/100], Step [5/60], Loss: 1.1354, batch time: 0.84, accuracy:  61.90%\n",
      "Epoch [75/100], Step [6/60], Loss: 1.1461, batch time: 0.71, accuracy:  63.20%\n",
      "Epoch [75/100], Step [7/60], Loss: 1.0792, batch time: 0.71, accuracy:  67.20%\n",
      "Epoch [75/100], Step [8/60], Loss: 1.0308, batch time: 0.72, accuracy:  67.40%\n",
      "Epoch [75/100], Step [9/60], Loss: 1.1271, batch time: 0.66, accuracy:  64.10%\n",
      "Epoch [75/100], Step [10/60], Loss: 1.1610, batch time: 0.72, accuracy:  62.00%\n",
      "Epoch [75/100], Step [11/60], Loss: 1.1590, batch time: 0.68, accuracy:  62.90%\n",
      "Epoch [75/100], Step [12/60], Loss: 1.1120, batch time: 0.72, accuracy:  65.00%\n",
      "Epoch [75/100], Step [13/60], Loss: 1.1179, batch time: 0.66, accuracy:  62.00%\n",
      "Epoch [75/100], Step [14/60], Loss: 1.1431, batch time: 0.67, accuracy:  63.80%\n",
      "Epoch [75/100], Step [15/60], Loss: 1.0810, batch time: 0.67, accuracy:  63.00%\n",
      "Epoch [75/100], Step [16/60], Loss: 1.1502, batch time: 0.68, accuracy:  62.90%\n",
      "Epoch [75/100], Step [17/60], Loss: 1.1407, batch time: 0.73, accuracy:  64.60%\n",
      "Epoch [75/100], Step [18/60], Loss: 1.0307, batch time: 0.71, accuracy:  67.80%\n",
      "Epoch [75/100], Step [19/60], Loss: 1.1188, batch time: 0.73, accuracy:  61.70%\n",
      "Epoch [75/100], Step [20/60], Loss: 1.0519, batch time: 0.71, accuracy:  65.60%\n",
      "Epoch [75/100], Step [21/60], Loss: 1.1115, batch time: 0.71, accuracy:  64.80%\n",
      "Epoch [75/100], Step [22/60], Loss: 1.0715, batch time: 0.71, accuracy:  65.50%\n",
      "Epoch [75/100], Step [23/60], Loss: 1.0977, batch time: 0.71, accuracy:  66.20%\n",
      "Epoch [75/100], Step [24/60], Loss: 1.1807, batch time: 0.72, accuracy:  59.80%\n",
      "Epoch [75/100], Step [25/60], Loss: 1.1418, batch time: 0.71, accuracy:  62.10%\n",
      "Epoch [75/100], Step [26/60], Loss: 1.1884, batch time: 0.64, accuracy:  62.20%\n",
      "Epoch [75/100], Step [27/60], Loss: 1.0690, batch time: 0.85, accuracy:  65.00%\n",
      "Epoch [75/100], Step [28/60], Loss: 1.0744, batch time: 0.83, accuracy:  65.70%\n",
      "Epoch [75/100], Step [29/60], Loss: 1.0671, batch time: 0.82, accuracy:  65.90%\n",
      "Epoch [75/100], Step [30/60], Loss: 1.1474, batch time: 0.77, accuracy:  64.30%\n",
      "Epoch [75/100], Step [31/60], Loss: 1.1266, batch time: 0.57, accuracy:  64.40%\n",
      "Epoch [75/100], Step [32/60], Loss: 1.1953, batch time: 0.63, accuracy:  63.90%\n",
      "Epoch [75/100], Step [33/60], Loss: 1.1646, batch time: 0.65, accuracy:  62.90%\n",
      "Epoch [75/100], Step [34/60], Loss: 1.1377, batch time: 0.65, accuracy:  61.90%\n",
      "Epoch [75/100], Step [35/60], Loss: 1.1410, batch time: 0.68, accuracy:  62.60%\n",
      "Epoch [75/100], Step [36/60], Loss: 1.0629, batch time: 0.67, accuracy:  63.90%\n",
      "Epoch [75/100], Step [37/60], Loss: 1.0621, batch time: 0.70, accuracy:  65.50%\n",
      "Epoch [75/100], Step [38/60], Loss: 1.1343, batch time: 0.53, accuracy:  62.30%\n",
      "Epoch [75/100], Step [39/60], Loss: 1.0590, batch time: 0.69, accuracy:  64.80%\n",
      "Epoch [75/100], Step [40/60], Loss: 1.0977, batch time: 0.69, accuracy:  63.90%\n",
      "Epoch [75/100], Step [41/60], Loss: 1.1100, batch time: 0.70, accuracy:  63.90%\n",
      "Epoch [75/100], Step [42/60], Loss: 1.1091, batch time: 0.61, accuracy:  64.80%\n",
      "Epoch [75/100], Step [43/60], Loss: 1.0629, batch time: 0.69, accuracy:  65.40%\n",
      "Epoch [75/100], Step [44/60], Loss: 1.1241, batch time: 0.69, accuracy:  64.60%\n",
      "Epoch [75/100], Step [45/60], Loss: 1.1771, batch time: 0.69, accuracy:  64.70%\n",
      "Epoch [75/100], Step [46/60], Loss: 1.1057, batch time: 0.70, accuracy:  65.00%\n",
      "Epoch [75/100], Step [47/60], Loss: 1.0776, batch time: 0.74, accuracy:  64.60%\n",
      "Epoch [75/100], Step [48/60], Loss: 1.0591, batch time: 0.82, accuracy:  64.60%\n",
      "Epoch [75/100], Step [49/60], Loss: 1.1020, batch time: 0.57, accuracy:  62.70%\n",
      "Epoch [75/100], Step [50/60], Loss: 1.1137, batch time: 0.56, accuracy:  63.70%\n",
      "Epoch [75/100], Step [51/60], Loss: 1.0924, batch time: 0.43, accuracy:  64.50%\n",
      "Epoch [75/100], Step [52/60], Loss: 1.0905, batch time: 0.45, accuracy:  64.10%\n",
      "Epoch [75/100], Step [53/60], Loss: 1.0981, batch time: 0.42, accuracy:  65.00%\n",
      "Epoch [75/100], Step [54/60], Loss: 1.0423, batch time: 0.44, accuracy:  66.60%\n",
      "Epoch [75/100], Step [55/60], Loss: 1.1221, batch time: 0.43, accuracy:  64.80%\n",
      "Epoch [75/100], Step [56/60], Loss: 1.1174, batch time: 0.42, accuracy:  62.90%\n",
      "Epoch [75/100], Step [57/60], Loss: 1.0612, batch time: 0.43, accuracy:  66.00%\n",
      "Epoch [75/100], Step [58/60], Loss: 1.1355, batch time: 0.43, accuracy:  64.40%\n",
      "Epoch [75/100], Step [59/60], Loss: 1.1724, batch time: 0.42, accuracy:  62.90%\n",
      "Epoch [75/100], Step [60/60], Loss: 1.1549, batch time: 0.43, accuracy:  63.80%\n",
      "Epoch [76/100], Step [1/60], Loss: 1.0972, batch time: 0.45, accuracy:  66.40%\n",
      "Epoch [76/100], Step [2/60], Loss: 1.1106, batch time: 0.44, accuracy:  63.30%\n",
      "Epoch [76/100], Step [3/60], Loss: 1.1342, batch time: 0.43, accuracy:  63.60%\n",
      "Epoch [76/100], Step [4/60], Loss: 1.0969, batch time: 0.43, accuracy:  64.70%\n",
      "Epoch [76/100], Step [5/60], Loss: 1.1363, batch time: 0.42, accuracy:  65.20%\n",
      "Epoch [76/100], Step [6/60], Loss: 1.1194, batch time: 0.43, accuracy:  64.50%\n",
      "Epoch [76/100], Step [7/60], Loss: 1.1198, batch time: 0.43, accuracy:  63.70%\n",
      "Epoch [76/100], Step [8/60], Loss: 1.1233, batch time: 0.42, accuracy:  64.00%\n",
      "Epoch [76/100], Step [9/60], Loss: 1.0619, batch time: 0.44, accuracy:  65.20%\n",
      "Epoch [76/100], Step [10/60], Loss: 1.1215, batch time: 0.46, accuracy:  64.80%\n",
      "Epoch [76/100], Step [11/60], Loss: 1.0440, batch time: 0.48, accuracy:  65.70%\n",
      "Epoch [76/100], Step [12/60], Loss: 1.1688, batch time: 0.46, accuracy:  63.70%\n",
      "Epoch [76/100], Step [13/60], Loss: 1.0827, batch time: 0.46, accuracy:  63.30%\n",
      "Epoch [76/100], Step [14/60], Loss: 1.1415, batch time: 0.47, accuracy:  64.50%\n",
      "Epoch [76/100], Step [15/60], Loss: 1.0645, batch time: 0.47, accuracy:  66.70%\n",
      "Epoch [76/100], Step [16/60], Loss: 1.0758, batch time: 0.50, accuracy:  66.00%\n",
      "Epoch [76/100], Step [17/60], Loss: 1.1071, batch time: 0.49, accuracy:  65.20%\n",
      "Epoch [76/100], Step [18/60], Loss: 1.0958, batch time: 0.46, accuracy:  66.10%\n",
      "Epoch [76/100], Step [19/60], Loss: 1.0600, batch time: 0.46, accuracy:  63.50%\n",
      "Epoch [76/100], Step [20/60], Loss: 1.0924, batch time: 0.75, accuracy:  64.20%\n",
      "Epoch [76/100], Step [21/60], Loss: 1.0798, batch time: 0.73, accuracy:  66.40%\n",
      "Epoch [76/100], Step [22/60], Loss: 1.1871, batch time: 0.73, accuracy:  63.60%\n",
      "Epoch [76/100], Step [23/60], Loss: 1.0779, batch time: 0.80, accuracy:  66.70%\n",
      "Epoch [76/100], Step [24/60], Loss: 1.1095, batch time: 0.85, accuracy:  64.30%\n",
      "Epoch [76/100], Step [25/60], Loss: 1.0605, batch time: 0.85, accuracy:  66.40%\n",
      "Epoch [76/100], Step [26/60], Loss: 1.0499, batch time: 0.88, accuracy:  66.70%\n",
      "Epoch [76/100], Step [27/60], Loss: 1.1112, batch time: 0.69, accuracy:  62.10%\n",
      "Epoch [76/100], Step [28/60], Loss: 1.0892, batch time: 0.69, accuracy:  65.70%\n",
      "Epoch [76/100], Step [29/60], Loss: 1.1504, batch time: 0.59, accuracy:  65.20%\n",
      "Epoch [76/100], Step [30/60], Loss: 1.1180, batch time: 0.70, accuracy:  64.80%\n",
      "Epoch [76/100], Step [31/60], Loss: 1.0549, batch time: 0.70, accuracy:  67.40%\n",
      "Epoch [76/100], Step [32/60], Loss: 1.1187, batch time: 0.69, accuracy:  65.40%\n",
      "Epoch [76/100], Step [33/60], Loss: 1.0735, batch time: 0.71, accuracy:  65.60%\n",
      "Epoch [76/100], Step [34/60], Loss: 1.0931, batch time: 0.69, accuracy:  65.50%\n",
      "Epoch [76/100], Step [35/60], Loss: 1.0703, batch time: 0.70, accuracy:  65.90%\n",
      "Epoch [76/100], Step [36/60], Loss: 1.0810, batch time: 0.70, accuracy:  64.50%\n",
      "Epoch [76/100], Step [37/60], Loss: 1.1274, batch time: 0.70, accuracy:  61.20%\n",
      "Epoch [76/100], Step [38/60], Loss: 1.1057, batch time: 0.71, accuracy:  63.20%\n",
      "Epoch [76/100], Step [39/60], Loss: 1.0682, batch time: 0.71, accuracy:  63.80%\n",
      "Epoch [76/100], Step [40/60], Loss: 1.1652, batch time: 0.75, accuracy:  62.70%\n",
      "Epoch [76/100], Step [41/60], Loss: 1.0913, batch time: 0.75, accuracy:  65.00%\n",
      "Epoch [76/100], Step [42/60], Loss: 1.0770, batch time: 0.75, accuracy:  65.10%\n",
      "Epoch [76/100], Step [43/60], Loss: 1.1894, batch time: 0.76, accuracy:  62.50%\n",
      "Epoch [76/100], Step [44/60], Loss: 1.0725, batch time: 0.85, accuracy:  65.90%\n",
      "Epoch [76/100], Step [45/60], Loss: 1.1414, batch time: 0.87, accuracy:  64.00%\n",
      "Epoch [76/100], Step [46/60], Loss: 1.0981, batch time: 0.85, accuracy:  64.20%\n",
      "Epoch [76/100], Step [47/60], Loss: 1.0702, batch time: 0.69, accuracy:  65.00%\n",
      "Epoch [76/100], Step [48/60], Loss: 1.1315, batch time: 0.70, accuracy:  63.10%\n",
      "Epoch [76/100], Step [49/60], Loss: 1.1778, batch time: 0.69, accuracy:  62.50%\n",
      "Epoch [76/100], Step [50/60], Loss: 1.0455, batch time: 0.70, accuracy:  65.70%\n",
      "Epoch [76/100], Step [51/60], Loss: 1.0801, batch time: 0.69, accuracy:  62.90%\n",
      "Epoch [76/100], Step [52/60], Loss: 1.0975, batch time: 0.69, accuracy:  65.40%\n",
      "Epoch [76/100], Step [53/60], Loss: 1.0685, batch time: 0.70, accuracy:  63.20%\n",
      "Epoch [76/100], Step [54/60], Loss: 1.1363, batch time: 0.70, accuracy:  63.40%\n",
      "Epoch [76/100], Step [55/60], Loss: 1.1491, batch time: 0.70, accuracy:  63.20%\n",
      "Epoch [76/100], Step [56/60], Loss: 1.0890, batch time: 0.70, accuracy:  65.10%\n",
      "Epoch [76/100], Step [57/60], Loss: 1.1203, batch time: 0.70, accuracy:  62.40%\n",
      "Epoch [76/100], Step [58/60], Loss: 1.1226, batch time: 0.73, accuracy:  64.30%\n",
      "Epoch [76/100], Step [59/60], Loss: 1.1147, batch time: 0.75, accuracy:  64.40%\n",
      "Epoch [76/100], Step [60/60], Loss: 1.0098, batch time: 0.75, accuracy:  66.80%\n",
      "Epoch [77/100], Step [1/60], Loss: 1.0790, batch time: 0.75, accuracy:  65.80%\n",
      "Epoch [77/100], Step [2/60], Loss: 1.0813, batch time: 0.75, accuracy:  64.80%\n",
      "Epoch [77/100], Step [3/60], Loss: 1.0667, batch time: 0.75, accuracy:  65.40%\n",
      "Epoch [77/100], Step [4/60], Loss: 1.1256, batch time: 0.75, accuracy:  64.90%\n",
      "Epoch [77/100], Step [5/60], Loss: 1.0777, batch time: 0.75, accuracy:  66.50%\n",
      "Epoch [77/100], Step [6/60], Loss: 1.0766, batch time: 0.75, accuracy:  63.90%\n",
      "Epoch [77/100], Step [7/60], Loss: 1.1014, batch time: 0.75, accuracy:  66.20%\n",
      "Epoch [77/100], Step [8/60], Loss: 1.0715, batch time: 0.75, accuracy:  64.30%\n",
      "Epoch [77/100], Step [9/60], Loss: 1.0661, batch time: 0.78, accuracy:  65.00%\n",
      "Epoch [77/100], Step [10/60], Loss: 1.0822, batch time: 0.71, accuracy:  64.90%\n",
      "Epoch [77/100], Step [11/60], Loss: 1.0456, batch time: 0.82, accuracy:  65.90%\n",
      "Epoch [77/100], Step [12/60], Loss: 1.0739, batch time: 0.82, accuracy:  64.60%\n",
      "Epoch [77/100], Step [13/60], Loss: 1.1320, batch time: 0.81, accuracy:  64.60%\n",
      "Epoch [77/100], Step [14/60], Loss: 1.0416, batch time: 0.82, accuracy:  65.80%\n",
      "Epoch [77/100], Step [15/60], Loss: 1.0882, batch time: 0.82, accuracy:  63.50%\n",
      "Epoch [77/100], Step [16/60], Loss: 1.1472, batch time: 0.85, accuracy:  65.20%\n",
      "Epoch [77/100], Step [17/60], Loss: 1.1644, batch time: 0.83, accuracy:  64.80%\n",
      "Epoch [77/100], Step [18/60], Loss: 1.1128, batch time: 0.78, accuracy:  63.40%\n",
      "Epoch [77/100], Step [19/60], Loss: 1.1550, batch time: 0.68, accuracy:  61.40%\n",
      "Epoch [77/100], Step [20/60], Loss: 1.0949, batch time: 0.70, accuracy:  64.40%\n",
      "Epoch [77/100], Step [21/60], Loss: 1.1432, batch time: 0.63, accuracy:  63.10%\n",
      "Epoch [77/100], Step [22/60], Loss: 1.1103, batch time: 0.70, accuracy:  64.50%\n",
      "Epoch [77/100], Step [23/60], Loss: 1.0827, batch time: 0.59, accuracy:  64.40%\n",
      "Epoch [77/100], Step [24/60], Loss: 1.1086, batch time: 0.70, accuracy:  62.30%\n",
      "Epoch [77/100], Step [25/60], Loss: 1.0419, batch time: 0.56, accuracy:  66.10%\n",
      "Epoch [77/100], Step [26/60], Loss: 1.1530, batch time: 0.68, accuracy:  64.10%\n",
      "Epoch [77/100], Step [27/60], Loss: 1.0670, batch time: 0.54, accuracy:  66.60%\n",
      "Epoch [77/100], Step [28/60], Loss: 1.0913, batch time: 0.44, accuracy:  63.50%\n",
      "Epoch [77/100], Step [29/60], Loss: 1.0975, batch time: 0.45, accuracy:  67.00%\n",
      "Epoch [77/100], Step [30/60], Loss: 1.0441, batch time: 0.45, accuracy:  64.40%\n",
      "Epoch [77/100], Step [31/60], Loss: 1.0914, batch time: 0.44, accuracy:  64.00%\n",
      "Epoch [77/100], Step [32/60], Loss: 1.1745, batch time: 0.45, accuracy:  64.30%\n",
      "Epoch [77/100], Step [33/60], Loss: 1.0767, batch time: 0.44, accuracy:  66.70%\n",
      "Epoch [77/100], Step [34/60], Loss: 1.0406, batch time: 0.44, accuracy:  65.90%\n",
      "Epoch [77/100], Step [35/60], Loss: 1.0575, batch time: 0.45, accuracy:  64.20%\n",
      "Epoch [77/100], Step [36/60], Loss: 1.0992, batch time: 0.47, accuracy:  63.90%\n",
      "Epoch [77/100], Step [37/60], Loss: 1.1040, batch time: 0.47, accuracy:  63.30%\n",
      "Epoch [77/100], Step [38/60], Loss: 1.0861, batch time: 0.54, accuracy:  66.50%\n",
      "Epoch [77/100], Step [39/60], Loss: 1.0802, batch time: 0.53, accuracy:  64.80%\n",
      "Epoch [77/100], Step [40/60], Loss: 1.1004, batch time: 0.54, accuracy:  66.30%\n",
      "Epoch [77/100], Step [41/60], Loss: 1.1024, batch time: 0.55, accuracy:  65.30%\n",
      "Epoch [77/100], Step [42/60], Loss: 1.1474, batch time: 0.53, accuracy:  63.80%\n",
      "Epoch [77/100], Step [43/60], Loss: 1.1460, batch time: 0.54, accuracy:  62.20%\n",
      "Epoch [77/100], Step [44/60], Loss: 1.1010, batch time: 0.56, accuracy:  63.90%\n",
      "Epoch [77/100], Step [45/60], Loss: 1.1225, batch time: 0.55, accuracy:  63.50%\n",
      "Epoch [77/100], Step [46/60], Loss: 1.0710, batch time: 0.45, accuracy:  67.40%\n",
      "Epoch [77/100], Step [47/60], Loss: 1.0641, batch time: 0.43, accuracy:  64.40%\n",
      "Epoch [77/100], Step [48/60], Loss: 1.1146, batch time: 0.45, accuracy:  64.60%\n",
      "Epoch [77/100], Step [49/60], Loss: 1.0795, batch time: 0.45, accuracy:  63.40%\n",
      "Epoch [77/100], Step [50/60], Loss: 1.1139, batch time: 0.44, accuracy:  65.80%\n",
      "Epoch [77/100], Step [51/60], Loss: 1.0804, batch time: 0.44, accuracy:  66.10%\n",
      "Epoch [77/100], Step [52/60], Loss: 1.1629, batch time: 0.45, accuracy:  63.30%\n",
      "Epoch [77/100], Step [53/60], Loss: 1.0733, batch time: 0.45, accuracy:  66.00%\n",
      "Epoch [77/100], Step [54/60], Loss: 1.0790, batch time: 0.45, accuracy:  64.20%\n",
      "Epoch [77/100], Step [55/60], Loss: 1.1157, batch time: 0.44, accuracy:  65.90%\n",
      "Epoch [77/100], Step [56/60], Loss: 1.1142, batch time: 0.44, accuracy:  64.70%\n",
      "Epoch [77/100], Step [57/60], Loss: 1.0781, batch time: 0.45, accuracy:  65.80%\n",
      "Epoch [77/100], Step [58/60], Loss: 1.1280, batch time: 0.44, accuracy:  62.30%\n",
      "Epoch [77/100], Step [59/60], Loss: 1.0841, batch time: 0.44, accuracy:  66.80%\n",
      "Epoch [77/100], Step [60/60], Loss: 1.0579, batch time: 0.45, accuracy:  67.80%\n",
      "Epoch [78/100], Step [1/60], Loss: 1.1357, batch time: 0.61, accuracy:  64.10%\n",
      "Epoch [78/100], Step [2/60], Loss: 1.1288, batch time: 0.46, accuracy:  66.30%\n",
      "Epoch [78/100], Step [3/60], Loss: 1.0749, batch time: 0.44, accuracy:  66.90%\n",
      "Epoch [78/100], Step [4/60], Loss: 1.1508, batch time: 0.45, accuracy:  61.60%\n",
      "Epoch [78/100], Step [5/60], Loss: 1.0770, batch time: 0.45, accuracy:  65.10%\n",
      "Epoch [78/100], Step [6/60], Loss: 1.1166, batch time: 0.44, accuracy:  62.60%\n",
      "Epoch [78/100], Step [7/60], Loss: 1.0901, batch time: 0.46, accuracy:  63.40%\n",
      "Epoch [78/100], Step [8/60], Loss: 1.0798, batch time: 0.46, accuracy:  66.00%\n",
      "Epoch [78/100], Step [9/60], Loss: 1.1233, batch time: 0.52, accuracy:  64.20%\n",
      "Epoch [78/100], Step [10/60], Loss: 1.0979, batch time: 0.56, accuracy:  63.60%\n",
      "Epoch [78/100], Step [11/60], Loss: 1.0767, batch time: 0.53, accuracy:  65.10%\n",
      "Epoch [78/100], Step [12/60], Loss: 1.1055, batch time: 0.55, accuracy:  65.50%\n",
      "Epoch [78/100], Step [13/60], Loss: 1.0987, batch time: 0.53, accuracy:  64.90%\n",
      "Epoch [78/100], Step [14/60], Loss: 1.1329, batch time: 0.54, accuracy:  65.00%\n",
      "Epoch [78/100], Step [15/60], Loss: 1.0517, batch time: 0.53, accuracy:  65.20%\n",
      "Epoch [78/100], Step [16/60], Loss: 1.0867, batch time: 0.70, accuracy:  65.50%\n",
      "Epoch [78/100], Step [17/60], Loss: 1.0258, batch time: 0.44, accuracy:  67.00%\n",
      "Epoch [78/100], Step [18/60], Loss: 1.0528, batch time: 0.45, accuracy:  66.00%\n",
      "Epoch [78/100], Step [19/60], Loss: 1.0932, batch time: 0.45, accuracy:  64.90%\n",
      "Epoch [78/100], Step [20/60], Loss: 1.0274, batch time: 0.44, accuracy:  67.40%\n",
      "Epoch [78/100], Step [21/60], Loss: 1.0670, batch time: 0.44, accuracy:  66.30%\n",
      "Epoch [78/100], Step [22/60], Loss: 1.0753, batch time: 0.45, accuracy:  65.40%\n",
      "Epoch [78/100], Step [23/60], Loss: 1.1494, batch time: 0.44, accuracy:  64.80%\n",
      "Epoch [78/100], Step [24/60], Loss: 1.0605, batch time: 0.44, accuracy:  68.60%\n",
      "Epoch [78/100], Step [25/60], Loss: 1.0136, batch time: 0.45, accuracy:  67.00%\n",
      "Epoch [78/100], Step [26/60], Loss: 1.0835, batch time: 0.44, accuracy:  64.30%\n",
      "Epoch [78/100], Step [27/60], Loss: 1.1072, batch time: 0.47, accuracy:  63.40%\n",
      "Epoch [78/100], Step [28/60], Loss: 1.0583, batch time: 0.45, accuracy:  67.30%\n",
      "Epoch [78/100], Step [29/60], Loss: 1.0311, batch time: 0.44, accuracy:  67.40%\n",
      "Epoch [78/100], Step [30/60], Loss: 1.1262, batch time: 0.45, accuracy:  63.10%\n",
      "Epoch [78/100], Step [31/60], Loss: 1.1174, batch time: 0.45, accuracy:  63.50%\n",
      "Epoch [78/100], Step [32/60], Loss: 1.0818, batch time: 0.44, accuracy:  66.40%\n",
      "Epoch [78/100], Step [33/60], Loss: 1.0941, batch time: 0.44, accuracy:  65.40%\n",
      "Epoch [78/100], Step [34/60], Loss: 1.0675, batch time: 0.45, accuracy:  65.80%\n",
      "Epoch [78/100], Step [35/60], Loss: 1.0623, batch time: 0.44, accuracy:  66.30%\n",
      "Epoch [78/100], Step [36/60], Loss: 1.1414, batch time: 0.45, accuracy:  63.80%\n",
      "Epoch [78/100], Step [37/60], Loss: 1.0593, batch time: 0.46, accuracy:  64.80%\n",
      "Epoch [78/100], Step [38/60], Loss: 1.0174, batch time: 0.45, accuracy:  67.80%\n",
      "Epoch [78/100], Step [39/60], Loss: 1.1140, batch time: 0.46, accuracy:  66.80%\n",
      "Epoch [78/100], Step [40/60], Loss: 1.0222, batch time: 0.48, accuracy:  67.80%\n",
      "Epoch [78/100], Step [41/60], Loss: 1.0490, batch time: 0.54, accuracy:  66.10%\n",
      "Epoch [78/100], Step [42/60], Loss: 1.0445, batch time: 0.54, accuracy:  66.50%\n",
      "Epoch [78/100], Step [43/60], Loss: 1.0900, batch time: 0.54, accuracy:  66.30%\n",
      "Epoch [78/100], Step [44/60], Loss: 1.0683, batch time: 0.54, accuracy:  61.70%\n",
      "Epoch [78/100], Step [45/60], Loss: 1.1009, batch time: 0.57, accuracy:  64.30%\n",
      "Epoch [78/100], Step [46/60], Loss: 1.0749, batch time: 0.44, accuracy:  66.00%\n",
      "Epoch [78/100], Step [47/60], Loss: 1.0878, batch time: 0.45, accuracy:  65.60%\n",
      "Epoch [78/100], Step [48/60], Loss: 1.0935, batch time: 0.44, accuracy:  62.80%\n",
      "Epoch [78/100], Step [49/60], Loss: 1.0606, batch time: 0.45, accuracy:  66.90%\n",
      "Epoch [78/100], Step [50/60], Loss: 1.0370, batch time: 0.44, accuracy:  66.40%\n",
      "Epoch [78/100], Step [51/60], Loss: 1.0869, batch time: 0.44, accuracy:  63.60%\n",
      "Epoch [78/100], Step [52/60], Loss: 1.0657, batch time: 0.45, accuracy:  67.10%\n",
      "Epoch [78/100], Step [53/60], Loss: 1.1354, batch time: 0.44, accuracy:  62.80%\n",
      "Epoch [78/100], Step [54/60], Loss: 1.0153, batch time: 0.47, accuracy:  66.70%\n",
      "Epoch [78/100], Step [55/60], Loss: 1.1244, batch time: 0.45, accuracy:  65.80%\n",
      "Epoch [78/100], Step [56/60], Loss: 1.0962, batch time: 0.44, accuracy:  64.50%\n",
      "Epoch [78/100], Step [57/60], Loss: 1.0601, batch time: 0.45, accuracy:  66.10%\n",
      "Epoch [78/100], Step [58/60], Loss: 1.1161, batch time: 0.45, accuracy:  63.70%\n",
      "Epoch [78/100], Step [59/60], Loss: 1.1187, batch time: 0.44, accuracy:  66.20%\n",
      "Epoch [78/100], Step [60/60], Loss: 1.0800, batch time: 0.46, accuracy:  64.30%\n",
      "Epoch [79/100], Step [1/60], Loss: 1.1145, batch time: 0.47, accuracy:  63.70%\n",
      "Epoch [79/100], Step [2/60], Loss: 1.0797, batch time: 0.45, accuracy:  64.80%\n",
      "Epoch [79/100], Step [3/60], Loss: 1.0076, batch time: 0.47, accuracy:  67.60%\n",
      "Epoch [79/100], Step [4/60], Loss: 1.0103, batch time: 0.45, accuracy:  68.40%\n",
      "Epoch [79/100], Step [5/60], Loss: 1.0379, batch time: 0.45, accuracy:  67.60%\n",
      "Epoch [79/100], Step [6/60], Loss: 1.0587, batch time: 0.45, accuracy:  64.50%\n",
      "Epoch [79/100], Step [7/60], Loss: 1.0560, batch time: 0.45, accuracy:  66.80%\n",
      "Epoch [79/100], Step [8/60], Loss: 1.0788, batch time: 0.46, accuracy:  66.70%\n",
      "Epoch [79/100], Step [9/60], Loss: 1.0503, batch time: 0.53, accuracy:  66.60%\n",
      "Epoch [79/100], Step [10/60], Loss: 1.1233, batch time: 0.54, accuracy:  66.20%\n",
      "Epoch [79/100], Step [11/60], Loss: 1.0893, batch time: 0.54, accuracy:  66.40%\n",
      "Epoch [79/100], Step [12/60], Loss: 1.1240, batch time: 0.54, accuracy:  65.90%\n",
      "Epoch [79/100], Step [13/60], Loss: 1.1096, batch time: 0.55, accuracy:  63.10%\n",
      "Epoch [79/100], Step [14/60], Loss: 1.0600, batch time: 0.53, accuracy:  63.80%\n",
      "Epoch [79/100], Step [15/60], Loss: 1.0477, batch time: 0.54, accuracy:  66.60%\n",
      "Epoch [79/100], Step [16/60], Loss: 1.0496, batch time: 0.53, accuracy:  66.60%\n",
      "Epoch [79/100], Step [17/60], Loss: 1.0472, batch time: 0.54, accuracy:  66.90%\n",
      "Epoch [79/100], Step [18/60], Loss: 1.0894, batch time: 0.54, accuracy:  64.00%\n",
      "Epoch [79/100], Step [19/60], Loss: 1.0572, batch time: 0.56, accuracy:  65.70%\n",
      "Epoch [79/100], Step [20/60], Loss: 1.0587, batch time: 0.55, accuracy:  65.00%\n",
      "Epoch [79/100], Step [21/60], Loss: 1.0287, batch time: 0.53, accuracy:  70.00%\n",
      "Epoch [79/100], Step [22/60], Loss: 1.0284, batch time: 0.54, accuracy:  67.70%\n",
      "Epoch [79/100], Step [23/60], Loss: 1.1156, batch time: 0.53, accuracy:  64.10%\n",
      "Epoch [79/100], Step [24/60], Loss: 1.0292, batch time: 0.54, accuracy:  65.00%\n",
      "Epoch [79/100], Step [25/60], Loss: 1.0090, batch time: 0.53, accuracy:  66.10%\n",
      "Epoch [79/100], Step [26/60], Loss: 1.0766, batch time: 0.43, accuracy:  65.20%\n",
      "Epoch [79/100], Step [27/60], Loss: 1.1427, batch time: 0.47, accuracy:  63.70%\n",
      "Epoch [79/100], Step [28/60], Loss: 1.0919, batch time: 0.44, accuracy:  64.70%\n",
      "Epoch [79/100], Step [29/60], Loss: 1.0382, batch time: 0.44, accuracy:  67.20%\n",
      "Epoch [79/100], Step [30/60], Loss: 1.0518, batch time: 0.45, accuracy:  67.10%\n",
      "Epoch [79/100], Step [31/60], Loss: 1.0493, batch time: 0.43, accuracy:  66.50%\n",
      "Epoch [79/100], Step [32/60], Loss: 1.0053, batch time: 0.44, accuracy:  67.30%\n",
      "Epoch [79/100], Step [33/60], Loss: 0.9736, batch time: 0.44, accuracy:  68.30%\n",
      "Epoch [79/100], Step [34/60], Loss: 1.0271, batch time: 0.44, accuracy:  66.60%\n",
      "Epoch [79/100], Step [35/60], Loss: 1.0442, batch time: 0.45, accuracy:  66.30%\n",
      "Epoch [79/100], Step [36/60], Loss: 1.1441, batch time: 0.45, accuracy:  63.90%\n",
      "Epoch [79/100], Step [37/60], Loss: 1.0029, batch time: 0.44, accuracy:  67.20%\n",
      "Epoch [79/100], Step [38/60], Loss: 1.0295, batch time: 0.46, accuracy:  66.80%\n",
      "Epoch [79/100], Step [39/60], Loss: 1.1177, batch time: 0.44, accuracy:  64.70%\n",
      "Epoch [79/100], Step [40/60], Loss: 1.0594, batch time: 0.44, accuracy:  65.70%\n",
      "Epoch [79/100], Step [41/60], Loss: 1.1462, batch time: 0.45, accuracy:  64.70%\n",
      "Epoch [79/100], Step [42/60], Loss: 1.1144, batch time: 0.44, accuracy:  64.80%\n",
      "Epoch [79/100], Step [43/60], Loss: 1.0673, batch time: 0.44, accuracy:  64.90%\n",
      "Epoch [79/100], Step [44/60], Loss: 1.1717, batch time: 0.45, accuracy:  62.00%\n",
      "Epoch [79/100], Step [45/60], Loss: 1.0588, batch time: 0.44, accuracy:  65.90%\n",
      "Epoch [79/100], Step [46/60], Loss: 1.0707, batch time: 0.46, accuracy:  66.30%\n",
      "Epoch [79/100], Step [47/60], Loss: 1.0503, batch time: 0.45, accuracy:  65.10%\n",
      "Epoch [79/100], Step [48/60], Loss: 1.0915, batch time: 0.46, accuracy:  65.00%\n",
      "Epoch [79/100], Step [49/60], Loss: 1.0683, batch time: 0.46, accuracy:  66.20%\n",
      "Epoch [79/100], Step [50/60], Loss: 1.0683, batch time: 0.54, accuracy:  66.50%\n",
      "Epoch [79/100], Step [51/60], Loss: 1.1179, batch time: 0.52, accuracy:  65.40%\n",
      "Epoch [79/100], Step [52/60], Loss: 1.1228, batch time: 0.54, accuracy:  63.40%\n",
      "Epoch [79/100], Step [53/60], Loss: 1.0283, batch time: 0.54, accuracy:  66.90%\n",
      "Epoch [79/100], Step [54/60], Loss: 1.0807, batch time: 0.56, accuracy:  66.50%\n",
      "Epoch [79/100], Step [55/60], Loss: 1.0357, batch time: 0.54, accuracy:  65.60%\n",
      "Epoch [79/100], Step [56/60], Loss: 1.0716, batch time: 0.54, accuracy:  65.40%\n",
      "Epoch [79/100], Step [57/60], Loss: 1.1307, batch time: 0.54, accuracy:  64.40%\n",
      "Epoch [79/100], Step [58/60], Loss: 1.0640, batch time: 0.53, accuracy:  66.60%\n",
      "Epoch [79/100], Step [59/60], Loss: 1.1135, batch time: 0.53, accuracy:  64.90%\n",
      "Epoch [79/100], Step [60/60], Loss: 1.0795, batch time: 0.54, accuracy:  66.70%\n",
      "Epoch [80/100], Step [1/60], Loss: 1.0758, batch time: 0.73, accuracy:  64.70%\n",
      "Epoch [80/100], Step [2/60], Loss: 1.0506, batch time: 0.68, accuracy:  64.60%\n",
      "Epoch [80/100], Step [3/60], Loss: 1.0296, batch time: 0.71, accuracy:  66.80%\n",
      "Epoch [80/100], Step [4/60], Loss: 1.1056, batch time: 0.62, accuracy:  64.80%\n",
      "Epoch [80/100], Step [5/60], Loss: 1.0952, batch time: 0.63, accuracy:  67.60%\n",
      "Epoch [80/100], Step [6/60], Loss: 1.0785, batch time: 0.71, accuracy:  63.30%\n",
      "Epoch [80/100], Step [7/60], Loss: 1.0218, batch time: 0.71, accuracy:  67.50%\n",
      "Epoch [80/100], Step [8/60], Loss: 1.1073, batch time: 0.68, accuracy:  63.40%\n",
      "Epoch [80/100], Step [9/60], Loss: 1.0014, batch time: 0.68, accuracy:  68.20%\n",
      "Epoch [80/100], Step [10/60], Loss: 1.0548, batch time: 0.72, accuracy:  67.30%\n",
      "Epoch [80/100], Step [11/60], Loss: 1.0812, batch time: 0.68, accuracy:  65.60%\n",
      "Epoch [80/100], Step [12/60], Loss: 1.0699, batch time: 0.71, accuracy:  66.40%\n",
      "Epoch [80/100], Step [13/60], Loss: 1.1025, batch time: 0.70, accuracy:  64.90%\n",
      "Epoch [80/100], Step [14/60], Loss: 1.1295, batch time: 0.74, accuracy:  63.80%\n",
      "Epoch [80/100], Step [15/60], Loss: 1.0257, batch time: 0.58, accuracy:  67.80%\n",
      "Epoch [80/100], Step [16/60], Loss: 1.0376, batch time: 0.74, accuracy:  68.50%\n",
      "Epoch [80/100], Step [17/60], Loss: 1.0222, batch time: 0.84, accuracy:  67.30%\n",
      "Epoch [80/100], Step [18/60], Loss: 1.0633, batch time: 0.91, accuracy:  66.80%\n",
      "Epoch [80/100], Step [19/60], Loss: 1.0721, batch time: 0.72, accuracy:  66.40%\n",
      "Epoch [80/100], Step [20/60], Loss: 1.1109, batch time: 0.57, accuracy:  64.20%\n",
      "Epoch [80/100], Step [21/60], Loss: 1.0198, batch time: 0.56, accuracy:  68.10%\n",
      "Epoch [80/100], Step [22/60], Loss: 1.0549, batch time: 0.58, accuracy:  67.10%\n",
      "Epoch [80/100], Step [23/60], Loss: 0.9679, batch time: 0.68, accuracy:  68.60%\n",
      "Epoch [80/100], Step [24/60], Loss: 1.0620, batch time: 0.69, accuracy:  68.20%\n",
      "Epoch [80/100], Step [25/60], Loss: 1.1197, batch time: 0.72, accuracy:  64.10%\n",
      "Epoch [80/100], Step [26/60], Loss: 1.0772, batch time: 0.71, accuracy:  64.80%\n",
      "Epoch [80/100], Step [27/60], Loss: 1.0553, batch time: 0.69, accuracy:  65.90%\n",
      "Epoch [80/100], Step [28/60], Loss: 1.0498, batch time: 0.72, accuracy:  68.10%\n",
      "Epoch [80/100], Step [29/60], Loss: 1.0326, batch time: 0.73, accuracy:  65.60%\n",
      "Epoch [80/100], Step [30/60], Loss: 1.0124, batch time: 0.73, accuracy:  67.70%\n",
      "Epoch [80/100], Step [31/60], Loss: 1.0880, batch time: 0.74, accuracy:  67.70%\n",
      "Epoch [80/100], Step [32/60], Loss: 1.1450, batch time: 0.75, accuracy:  64.40%\n",
      "Epoch [80/100], Step [33/60], Loss: 1.0787, batch time: 0.83, accuracy:  64.70%\n",
      "Epoch [80/100], Step [34/60], Loss: 1.1661, batch time: 0.87, accuracy:  64.90%\n",
      "Epoch [80/100], Step [35/60], Loss: 1.0602, batch time: 0.83, accuracy:  65.60%\n",
      "Epoch [80/100], Step [36/60], Loss: 1.0383, batch time: 0.88, accuracy:  66.90%\n",
      "Epoch [80/100], Step [37/60], Loss: 1.0635, batch time: 0.88, accuracy:  66.10%\n",
      "Epoch [80/100], Step [38/60], Loss: 1.1042, batch time: 0.74, accuracy:  65.70%\n",
      "Epoch [80/100], Step [39/60], Loss: 1.0868, batch time: 0.72, accuracy:  64.10%\n",
      "Epoch [80/100], Step [40/60], Loss: 1.1167, batch time: 0.72, accuracy:  65.60%\n",
      "Epoch [80/100], Step [41/60], Loss: 1.0509, batch time: 0.73, accuracy:  67.00%\n",
      "Epoch [80/100], Step [42/60], Loss: 1.0311, batch time: 0.72, accuracy:  65.60%\n",
      "Epoch [80/100], Step [43/60], Loss: 1.1317, batch time: 0.72, accuracy:  64.20%\n",
      "Epoch [80/100], Step [44/60], Loss: 1.1252, batch time: 0.72, accuracy:  64.30%\n",
      "Epoch [80/100], Step [45/60], Loss: 1.0622, batch time: 0.72, accuracy:  65.10%\n",
      "Epoch [80/100], Step [46/60], Loss: 1.0541, batch time: 0.72, accuracy:  67.50%\n",
      "Epoch [80/100], Step [47/60], Loss: 1.0778, batch time: 0.73, accuracy:  65.60%\n",
      "Epoch [80/100], Step [48/60], Loss: 1.0606, batch time: 0.73, accuracy:  63.70%\n",
      "Epoch [80/100], Step [49/60], Loss: 1.0418, batch time: 0.73, accuracy:  64.10%\n",
      "Epoch [80/100], Step [50/60], Loss: 1.0272, batch time: 0.73, accuracy:  68.80%\n",
      "Epoch [80/100], Step [51/60], Loss: 1.0223, batch time: 0.66, accuracy:  67.80%\n",
      "Epoch [80/100], Step [52/60], Loss: 1.0291, batch time: 0.45, accuracy:  68.20%\n",
      "Epoch [80/100], Step [53/60], Loss: 1.0698, batch time: 0.65, accuracy:  68.10%\n",
      "Epoch [80/100], Step [54/60], Loss: 1.1172, batch time: 0.78, accuracy:  63.40%\n",
      "Epoch [80/100], Step [55/60], Loss: 1.0384, batch time: 0.87, accuracy:  66.50%\n",
      "Epoch [80/100], Step [56/60], Loss: 1.0187, batch time: 0.87, accuracy:  67.50%\n",
      "Epoch [80/100], Step [57/60], Loss: 1.0301, batch time: 0.86, accuracy:  67.30%\n",
      "Epoch [80/100], Step [58/60], Loss: 1.1053, batch time: 0.87, accuracy:  65.70%\n",
      "Epoch [80/100], Step [59/60], Loss: 1.0275, batch time: 0.84, accuracy:  68.20%\n",
      "Epoch [80/100], Step [60/60], Loss: 1.0686, batch time: 0.78, accuracy:  65.50%\n",
      "Epoch [81/100], Step [1/60], Loss: 1.0301, batch time: 0.68, accuracy:  66.40%\n",
      "Epoch [81/100], Step [2/60], Loss: 1.0986, batch time: 0.68, accuracy:  64.10%\n",
      "Epoch [81/100], Step [3/60], Loss: 1.0759, batch time: 0.64, accuracy:  65.70%\n",
      "Epoch [81/100], Step [4/60], Loss: 1.0239, batch time: 0.69, accuracy:  65.00%\n",
      "Epoch [81/100], Step [5/60], Loss: 1.1139, batch time: 0.69, accuracy:  63.90%\n",
      "Epoch [81/100], Step [6/60], Loss: 1.0425, batch time: 0.70, accuracy:  65.60%\n",
      "Epoch [81/100], Step [7/60], Loss: 1.1159, batch time: 0.69, accuracy:  65.80%\n",
      "Epoch [81/100], Step [8/60], Loss: 1.0241, batch time: 0.69, accuracy:  67.30%\n",
      "Epoch [81/100], Step [9/60], Loss: 1.0076, batch time: 0.70, accuracy:  68.50%\n",
      "Epoch [81/100], Step [10/60], Loss: 1.0760, batch time: 0.69, accuracy:  66.00%\n",
      "Epoch [81/100], Step [11/60], Loss: 1.1372, batch time: 0.69, accuracy:  65.30%\n",
      "Epoch [81/100], Step [12/60], Loss: 0.9994, batch time: 0.63, accuracy:  67.00%\n",
      "Epoch [81/100], Step [13/60], Loss: 1.0651, batch time: 0.72, accuracy:  66.80%\n",
      "Epoch [81/100], Step [14/60], Loss: 1.0289, batch time: 0.71, accuracy:  67.00%\n",
      "Epoch [81/100], Step [15/60], Loss: 1.1066, batch time: 0.74, accuracy:  65.60%\n",
      "Epoch [81/100], Step [16/60], Loss: 1.1428, batch time: 0.81, accuracy:  63.60%\n",
      "Epoch [81/100], Step [17/60], Loss: 1.0514, batch time: 0.72, accuracy:  65.20%\n",
      "Epoch [81/100], Step [18/60], Loss: 1.1623, batch time: 0.72, accuracy:  63.80%\n",
      "Epoch [81/100], Step [19/60], Loss: 1.1242, batch time: 0.59, accuracy:  63.90%\n",
      "Epoch [81/100], Step [20/60], Loss: 1.0504, batch time: 0.70, accuracy:  69.20%\n",
      "Epoch [81/100], Step [21/60], Loss: 1.0602, batch time: 0.69, accuracy:  65.90%\n",
      "Epoch [81/100], Step [22/60], Loss: 1.0915, batch time: 0.69, accuracy:  64.80%\n",
      "Epoch [81/100], Step [23/60], Loss: 1.0190, batch time: 0.69, accuracy:  68.30%\n",
      "Epoch [81/100], Step [24/60], Loss: 1.0602, batch time: 0.70, accuracy:  67.70%\n",
      "Epoch [81/100], Step [25/60], Loss: 1.0074, batch time: 0.70, accuracy:  66.20%\n",
      "Epoch [81/100], Step [26/60], Loss: 0.9932, batch time: 0.69, accuracy:  66.40%\n",
      "Epoch [81/100], Step [27/60], Loss: 1.0726, batch time: 0.69, accuracy:  65.40%\n",
      "Epoch [81/100], Step [28/60], Loss: 1.0417, batch time: 0.69, accuracy:  66.90%\n",
      "Epoch [81/100], Step [29/60], Loss: 1.0377, batch time: 0.72, accuracy:  66.50%\n",
      "Epoch [81/100], Step [30/60], Loss: 0.9882, batch time: 0.71, accuracy:  69.10%\n",
      "Epoch [81/100], Step [31/60], Loss: 1.0617, batch time: 0.72, accuracy:  66.00%\n",
      "Epoch [81/100], Step [32/60], Loss: 1.0632, batch time: 0.73, accuracy:  66.00%\n",
      "Epoch [81/100], Step [33/60], Loss: 1.0396, batch time: 0.80, accuracy:  67.20%\n",
      "Epoch [81/100], Step [34/60], Loss: 1.0673, batch time: 0.69, accuracy:  66.70%\n",
      "Epoch [81/100], Step [35/60], Loss: 1.0708, batch time: 0.85, accuracy:  65.20%\n",
      "Epoch [81/100], Step [36/60], Loss: 1.0365, batch time: 0.84, accuracy:  67.60%\n",
      "Epoch [81/100], Step [37/60], Loss: 1.0483, batch time: 0.74, accuracy:  66.50%\n",
      "Epoch [81/100], Step [38/60], Loss: 1.0015, batch time: 0.79, accuracy:  68.10%\n",
      "Epoch [81/100], Step [39/60], Loss: 1.0260, batch time: 0.67, accuracy:  68.30%\n",
      "Epoch [81/100], Step [40/60], Loss: 1.0054, batch time: 0.68, accuracy:  68.70%\n",
      "Epoch [81/100], Step [41/60], Loss: 1.0587, batch time: 0.64, accuracy:  67.00%\n",
      "Epoch [81/100], Step [42/60], Loss: 1.0427, batch time: 0.70, accuracy:  65.20%\n",
      "Epoch [81/100], Step [43/60], Loss: 0.9797, batch time: 0.69, accuracy:  67.60%\n",
      "Epoch [81/100], Step [44/60], Loss: 1.0606, batch time: 0.65, accuracy:  64.50%\n",
      "Epoch [81/100], Step [45/60], Loss: 1.0716, batch time: 0.58, accuracy:  66.00%\n",
      "Epoch [81/100], Step [46/60], Loss: 1.0490, batch time: 0.69, accuracy:  67.00%\n",
      "Epoch [81/100], Step [47/60], Loss: 1.0435, batch time: 0.69, accuracy:  68.20%\n",
      "Epoch [81/100], Step [48/60], Loss: 1.0590, batch time: 0.70, accuracy:  65.70%\n",
      "Epoch [81/100], Step [49/60], Loss: 0.9885, batch time: 0.69, accuracy:  66.70%\n",
      "Epoch [81/100], Step [50/60], Loss: 1.0043, batch time: 0.51, accuracy:  66.70%\n",
      "Epoch [81/100], Step [51/60], Loss: 1.1003, batch time: 0.57, accuracy:  67.70%\n",
      "Epoch [81/100], Step [52/60], Loss: 0.9905, batch time: 0.73, accuracy:  67.40%\n",
      "Epoch [81/100], Step [53/60], Loss: 1.1262, batch time: 0.62, accuracy:  62.90%\n",
      "Epoch [81/100], Step [54/60], Loss: 1.0282, batch time: 0.70, accuracy:  67.70%\n",
      "Epoch [81/100], Step [55/60], Loss: 1.0078, batch time: 0.73, accuracy:  67.10%\n",
      "Epoch [81/100], Step [56/60], Loss: 0.9551, batch time: 0.68, accuracy:  69.90%\n",
      "Epoch [81/100], Step [57/60], Loss: 1.0311, batch time: 0.82, accuracy:  67.10%\n",
      "Epoch [81/100], Step [58/60], Loss: 1.0395, batch time: 0.82, accuracy:  68.00%\n",
      "Epoch [81/100], Step [59/60], Loss: 1.0320, batch time: 0.83, accuracy:  67.10%\n",
      "Epoch [81/100], Step [60/60], Loss: 1.0084, batch time: 0.65, accuracy:  68.10%\n",
      "Epoch [82/100], Step [1/60], Loss: 1.0433, batch time: 0.65, accuracy:  67.50%\n",
      "Epoch [82/100], Step [2/60], Loss: 1.0725, batch time: 0.66, accuracy:  65.90%\n",
      "Epoch [82/100], Step [3/60], Loss: 1.0290, batch time: 0.63, accuracy:  66.90%\n",
      "Epoch [82/100], Step [4/60], Loss: 1.0989, batch time: 0.58, accuracy:  65.20%\n",
      "Epoch [82/100], Step [5/60], Loss: 0.9997, batch time: 0.59, accuracy:  68.90%\n",
      "Epoch [82/100], Step [6/60], Loss: 1.1259, batch time: 0.59, accuracy:  65.80%\n",
      "Epoch [82/100], Step [7/60], Loss: 1.1797, batch time: 0.60, accuracy:  62.90%\n",
      "Epoch [82/100], Step [8/60], Loss: 1.0606, batch time: 0.67, accuracy:  67.60%\n",
      "Epoch [82/100], Step [9/60], Loss: 1.0857, batch time: 0.66, accuracy:  66.90%\n",
      "Epoch [82/100], Step [10/60], Loss: 1.0974, batch time: 0.72, accuracy:  65.80%\n",
      "Epoch [82/100], Step [11/60], Loss: 1.0373, batch time: 0.69, accuracy:  67.20%\n",
      "Epoch [82/100], Step [12/60], Loss: 1.0340, batch time: 0.70, accuracy:  66.60%\n",
      "Epoch [82/100], Step [13/60], Loss: 1.0580, batch time: 0.67, accuracy:  65.70%\n",
      "Epoch [82/100], Step [14/60], Loss: 1.0493, batch time: 0.72, accuracy:  67.70%\n",
      "Epoch [82/100], Step [15/60], Loss: 1.0814, batch time: 0.73, accuracy:  65.50%\n",
      "Epoch [82/100], Step [16/60], Loss: 1.0531, batch time: 0.74, accuracy:  65.70%\n",
      "Epoch [82/100], Step [17/60], Loss: 1.1727, batch time: 0.72, accuracy:  64.40%\n",
      "Epoch [82/100], Step [18/60], Loss: 1.0950, batch time: 0.72, accuracy:  63.50%\n",
      "Epoch [82/100], Step [19/60], Loss: 1.0480, batch time: 0.72, accuracy:  66.30%\n",
      "Epoch [82/100], Step [20/60], Loss: 1.0446, batch time: 0.72, accuracy:  65.30%\n",
      "Epoch [82/100], Step [21/60], Loss: 0.9901, batch time: 0.72, accuracy:  68.80%\n",
      "Epoch [82/100], Step [22/60], Loss: 1.1036, batch time: 0.72, accuracy:  65.70%\n",
      "Epoch [82/100], Step [23/60], Loss: 1.0693, batch time: 0.72, accuracy:  66.20%\n",
      "Epoch [82/100], Step [24/60], Loss: 1.0373, batch time: 0.71, accuracy:  67.70%\n",
      "Epoch [82/100], Step [25/60], Loss: 1.0143, batch time: 0.72, accuracy:  68.00%\n",
      "Epoch [82/100], Step [26/60], Loss: 1.0786, batch time: 0.72, accuracy:  66.20%\n",
      "Epoch [82/100], Step [27/60], Loss: 0.9765, batch time: 0.47, accuracy:  67.70%\n",
      "Epoch [82/100], Step [28/60], Loss: 1.0033, batch time: 0.88, accuracy:  67.30%\n",
      "Epoch [82/100], Step [29/60], Loss: 1.1019, batch time: 0.85, accuracy:  62.40%\n",
      "Epoch [82/100], Step [30/60], Loss: 1.0497, batch time: 0.87, accuracy:  65.40%\n",
      "Epoch [82/100], Step [31/60], Loss: 1.0345, batch time: 0.85, accuracy:  66.60%\n",
      "Epoch [82/100], Step [32/60], Loss: 1.1070, batch time: 0.83, accuracy:  63.90%\n",
      "Epoch [82/100], Step [33/60], Loss: 0.9991, batch time: 0.86, accuracy:  67.60%\n",
      "Epoch [82/100], Step [34/60], Loss: 1.1097, batch time: 0.74, accuracy:  65.70%\n",
      "Epoch [82/100], Step [35/60], Loss: 1.0680, batch time: 0.70, accuracy:  66.20%\n",
      "Epoch [82/100], Step [36/60], Loss: 0.9951, batch time: 0.71, accuracy:  68.00%\n",
      "Epoch [82/100], Step [37/60], Loss: 0.9912, batch time: 0.72, accuracy:  68.60%\n",
      "Epoch [82/100], Step [38/60], Loss: 1.0306, batch time: 0.71, accuracy:  67.30%\n",
      "Epoch [82/100], Step [39/60], Loss: 1.0311, batch time: 0.70, accuracy:  66.50%\n",
      "Epoch [82/100], Step [40/60], Loss: 1.0864, batch time: 0.71, accuracy:  66.20%\n",
      "Epoch [82/100], Step [41/60], Loss: 1.0014, batch time: 0.63, accuracy:  67.90%\n",
      "Epoch [82/100], Step [42/60], Loss: 1.0117, batch time: 0.61, accuracy:  67.30%\n",
      "Epoch [82/100], Step [43/60], Loss: 1.0854, batch time: 0.69, accuracy:  66.00%\n",
      "Epoch [82/100], Step [44/60], Loss: 1.0273, batch time: 0.69, accuracy:  68.80%\n",
      "Epoch [82/100], Step [45/60], Loss: 1.1190, batch time: 0.56, accuracy:  63.90%\n",
      "Epoch [82/100], Step [46/60], Loss: 1.0353, batch time: 0.64, accuracy:  67.30%\n",
      "Epoch [82/100], Step [47/60], Loss: 1.0201, batch time: 0.73, accuracy:  67.50%\n",
      "Epoch [82/100], Step [48/60], Loss: 1.0514, batch time: 0.48, accuracy:  66.10%\n",
      "Epoch [82/100], Step [49/60], Loss: 1.0597, batch time: 0.47, accuracy:  66.60%\n",
      "Epoch [82/100], Step [50/60], Loss: 1.0498, batch time: 0.48, accuracy:  64.80%\n",
      "Epoch [82/100], Step [51/60], Loss: 1.0191, batch time: 0.47, accuracy:  66.00%\n",
      "Epoch [82/100], Step [52/60], Loss: 1.0553, batch time: 0.46, accuracy:  65.10%\n",
      "Epoch [82/100], Step [53/60], Loss: 1.0505, batch time: 0.47, accuracy:  65.60%\n",
      "Epoch [82/100], Step [54/60], Loss: 1.0290, batch time: 0.46, accuracy:  67.50%\n",
      "Epoch [82/100], Step [55/60], Loss: 0.9685, batch time: 0.46, accuracy:  68.90%\n",
      "Epoch [82/100], Step [56/60], Loss: 1.0201, batch time: 0.48, accuracy:  68.80%\n",
      "Epoch [82/100], Step [57/60], Loss: 1.0041, batch time: 0.47, accuracy:  68.70%\n",
      "Epoch [82/100], Step [58/60], Loss: 1.0536, batch time: 0.48, accuracy:  67.20%\n",
      "Epoch [82/100], Step [59/60], Loss: 0.9551, batch time: 0.46, accuracy:  69.70%\n",
      "Epoch [82/100], Step [60/60], Loss: 1.0604, batch time: 0.47, accuracy:  68.60%\n",
      "Epoch [83/100], Step [1/60], Loss: 1.0805, batch time: 0.49, accuracy:  68.20%\n",
      "Epoch [83/100], Step [2/60], Loss: 1.0294, batch time: 0.46, accuracy:  66.10%\n",
      "Epoch [83/100], Step [3/60], Loss: 0.9965, batch time: 0.47, accuracy:  67.00%\n",
      "Epoch [83/100], Step [4/60], Loss: 1.0370, batch time: 0.46, accuracy:  69.40%\n",
      "Epoch [83/100], Step [5/60], Loss: 1.0284, batch time: 0.47, accuracy:  65.90%\n",
      "Epoch [83/100], Step [6/60], Loss: 1.0196, batch time: 0.47, accuracy:  68.30%\n",
      "Epoch [83/100], Step [7/60], Loss: 1.0302, batch time: 0.49, accuracy:  67.70%\n",
      "Epoch [83/100], Step [8/60], Loss: 1.0525, batch time: 0.48, accuracy:  67.30%\n",
      "Epoch [83/100], Step [9/60], Loss: 1.0045, batch time: 0.47, accuracy:  67.40%\n",
      "Epoch [83/100], Step [10/60], Loss: 1.0611, batch time: 0.46, accuracy:  67.10%\n",
      "Epoch [83/100], Step [11/60], Loss: 1.0212, batch time: 0.46, accuracy:  65.60%\n",
      "Epoch [83/100], Step [12/60], Loss: 1.0683, batch time: 0.46, accuracy:  66.50%\n",
      "Epoch [83/100], Step [13/60], Loss: 1.0398, batch time: 0.47, accuracy:  68.10%\n",
      "Epoch [83/100], Step [14/60], Loss: 0.9820, batch time: 0.47, accuracy:  67.10%\n",
      "Epoch [83/100], Step [15/60], Loss: 0.9542, batch time: 0.54, accuracy:  67.90%\n",
      "Epoch [83/100], Step [16/60], Loss: 1.0780, batch time: 0.50, accuracy:  66.50%\n",
      "Epoch [83/100], Step [17/60], Loss: 1.0767, batch time: 0.47, accuracy:  64.90%\n",
      "Epoch [83/100], Step [18/60], Loss: 1.0287, batch time: 0.47, accuracy:  64.30%\n",
      "Epoch [83/100], Step [19/60], Loss: 1.0385, batch time: 0.47, accuracy:  68.60%\n",
      "Epoch [83/100], Step [20/60], Loss: 1.0132, batch time: 0.46, accuracy:  68.00%\n",
      "Epoch [83/100], Step [21/60], Loss: 1.0656, batch time: 0.47, accuracy:  66.70%\n",
      "Epoch [83/100], Step [22/60], Loss: 0.9729, batch time: 0.47, accuracy:  67.80%\n",
      "Epoch [83/100], Step [23/60], Loss: 0.9662, batch time: 0.46, accuracy:  68.10%\n",
      "Epoch [83/100], Step [24/60], Loss: 1.0434, batch time: 0.51, accuracy:  66.00%\n",
      "Epoch [83/100], Step [25/60], Loss: 1.1371, batch time: 0.54, accuracy:  64.50%\n",
      "Epoch [83/100], Step [26/60], Loss: 1.0272, batch time: 0.55, accuracy:  66.00%\n",
      "Epoch [83/100], Step [27/60], Loss: 1.0954, batch time: 0.54, accuracy:  68.00%\n",
      "Epoch [83/100], Step [28/60], Loss: 0.9910, batch time: 0.48, accuracy:  68.60%\n",
      "Epoch [83/100], Step [29/60], Loss: 1.0062, batch time: 0.43, accuracy:  66.90%\n",
      "Epoch [83/100], Step [30/60], Loss: 1.0674, batch time: 0.43, accuracy:  64.50%\n",
      "Epoch [83/100], Step [31/60], Loss: 1.0143, batch time: 0.43, accuracy:  67.50%\n",
      "Epoch [83/100], Step [32/60], Loss: 1.0310, batch time: 0.43, accuracy:  65.30%\n",
      "Epoch [83/100], Step [33/60], Loss: 1.0820, batch time: 0.58, accuracy:  68.40%\n",
      "Epoch [83/100], Step [34/60], Loss: 0.9811, batch time: 0.72, accuracy:  69.10%\n",
      "Epoch [83/100], Step [35/60], Loss: 1.0391, batch time: 0.72, accuracy:  65.60%\n",
      "Epoch [83/100], Step [36/60], Loss: 1.0766, batch time: 0.61, accuracy:  67.50%\n",
      "Epoch [83/100], Step [37/60], Loss: 1.0250, batch time: 0.73, accuracy:  66.90%\n",
      "Epoch [83/100], Step [38/60], Loss: 0.9626, batch time: 0.72, accuracy:  69.90%\n",
      "Epoch [83/100], Step [39/60], Loss: 0.9670, batch time: 0.72, accuracy:  68.50%\n",
      "Epoch [83/100], Step [40/60], Loss: 1.0560, batch time: 0.72, accuracy:  65.70%\n",
      "Epoch [83/100], Step [41/60], Loss: 1.1295, batch time: 0.73, accuracy:  65.50%\n",
      "Epoch [83/100], Step [42/60], Loss: 1.0858, batch time: 0.62, accuracy:  67.10%\n",
      "Epoch [83/100], Step [43/60], Loss: 1.0260, batch time: 0.68, accuracy:  67.30%\n",
      "Epoch [83/100], Step [44/60], Loss: 1.0237, batch time: 0.65, accuracy:  67.50%\n",
      "Epoch [83/100], Step [45/60], Loss: 1.0504, batch time: 0.77, accuracy:  68.20%\n",
      "Epoch [83/100], Step [46/60], Loss: 1.0121, batch time: 0.75, accuracy:  67.30%\n",
      "Epoch [83/100], Step [47/60], Loss: 1.0591, batch time: 0.63, accuracy:  65.00%\n",
      "Epoch [83/100], Step [48/60], Loss: 1.0322, batch time: 0.86, accuracy:  66.20%\n",
      "Epoch [83/100], Step [49/60], Loss: 1.0641, batch time: 0.73, accuracy:  66.10%\n",
      "Epoch [83/100], Step [50/60], Loss: 1.0461, batch time: 0.84, accuracy:  67.00%\n",
      "Epoch [83/100], Step [51/60], Loss: 1.0361, batch time: 0.83, accuracy:  68.40%\n",
      "Epoch [83/100], Step [52/60], Loss: 1.0874, batch time: 0.84, accuracy:  66.10%\n",
      "Epoch [83/100], Step [53/60], Loss: 0.9563, batch time: 0.75, accuracy:  69.80%\n",
      "Epoch [83/100], Step [54/60], Loss: 0.9989, batch time: 0.85, accuracy:  68.30%\n",
      "Epoch [83/100], Step [55/60], Loss: 1.0184, batch time: 0.71, accuracy:  68.10%\n",
      "Epoch [83/100], Step [56/60], Loss: 1.0377, batch time: 0.74, accuracy:  67.50%\n",
      "Epoch [83/100], Step [57/60], Loss: 1.0550, batch time: 0.66, accuracy:  65.50%\n",
      "Epoch [83/100], Step [58/60], Loss: 1.0454, batch time: 0.65, accuracy:  67.80%\n",
      "Epoch [83/100], Step [59/60], Loss: 1.0144, batch time: 0.71, accuracy:  67.90%\n",
      "Epoch [83/100], Step [60/60], Loss: 1.0309, batch time: 0.69, accuracy:  68.70%\n",
      "Epoch [84/100], Step [1/60], Loss: 1.1317, batch time: 0.66, accuracy:  65.20%\n",
      "Epoch [84/100], Step [2/60], Loss: 0.9775, batch time: 0.67, accuracy:  68.70%\n",
      "Epoch [84/100], Step [3/60], Loss: 1.0509, batch time: 0.67, accuracy:  65.80%\n",
      "Epoch [84/100], Step [4/60], Loss: 1.0576, batch time: 0.73, accuracy:  65.70%\n",
      "Epoch [84/100], Step [5/60], Loss: 1.0297, batch time: 0.69, accuracy:  65.90%\n",
      "Epoch [84/100], Step [6/60], Loss: 0.9788, batch time: 0.72, accuracy:  69.00%\n",
      "Epoch [84/100], Step [7/60], Loss: 1.0064, batch time: 0.70, accuracy:  67.50%\n",
      "Epoch [84/100], Step [8/60], Loss: 1.0240, batch time: 0.75, accuracy:  66.30%\n",
      "Epoch [84/100], Step [9/60], Loss: 0.9743, batch time: 0.73, accuracy:  70.30%\n",
      "Epoch [84/100], Step [10/60], Loss: 1.0233, batch time: 0.78, accuracy:  66.50%\n",
      "Epoch [84/100], Step [11/60], Loss: 1.0180, batch time: 0.87, accuracy:  68.20%\n",
      "Epoch [84/100], Step [12/60], Loss: 1.0331, batch time: 0.84, accuracy:  70.70%\n",
      "Epoch [84/100], Step [13/60], Loss: 1.0394, batch time: 0.87, accuracy:  66.60%\n",
      "Epoch [84/100], Step [14/60], Loss: 1.0300, batch time: 0.87, accuracy:  65.80%\n",
      "Epoch [84/100], Step [15/60], Loss: 1.0401, batch time: 0.78, accuracy:  66.90%\n",
      "Epoch [84/100], Step [16/60], Loss: 0.9906, batch time: 0.71, accuracy:  66.70%\n",
      "Epoch [84/100], Step [17/60], Loss: 1.0851, batch time: 0.67, accuracy:  66.20%\n",
      "Epoch [84/100], Step [18/60], Loss: 1.0358, batch time: 0.72, accuracy:  67.10%\n",
      "Epoch [84/100], Step [19/60], Loss: 1.0516, batch time: 0.66, accuracy:  65.20%\n",
      "Epoch [84/100], Step [20/60], Loss: 1.0159, batch time: 0.70, accuracy:  68.60%\n",
      "Epoch [84/100], Step [21/60], Loss: 1.1429, batch time: 0.65, accuracy:  64.40%\n",
      "Epoch [84/100], Step [22/60], Loss: 0.9901, batch time: 0.63, accuracy:  68.00%\n",
      "Epoch [84/100], Step [23/60], Loss: 0.9992, batch time: 0.59, accuracy:  68.20%\n",
      "Epoch [84/100], Step [24/60], Loss: 1.0262, batch time: 0.65, accuracy:  68.90%\n",
      "Epoch [84/100], Step [25/60], Loss: 1.0515, batch time: 0.66, accuracy:  66.30%\n",
      "Epoch [84/100], Step [26/60], Loss: 1.0286, batch time: 0.70, accuracy:  68.50%\n",
      "Epoch [84/100], Step [27/60], Loss: 1.0234, batch time: 0.67, accuracy:  67.90%\n",
      "Epoch [84/100], Step [28/60], Loss: 0.9404, batch time: 0.68, accuracy:  68.10%\n",
      "Epoch [84/100], Step [29/60], Loss: 1.0225, batch time: 0.73, accuracy:  66.70%\n",
      "Epoch [84/100], Step [30/60], Loss: 1.0256, batch time: 0.62, accuracy:  67.70%\n",
      "Epoch [84/100], Step [31/60], Loss: 1.0007, batch time: 0.72, accuracy:  68.60%\n",
      "Epoch [84/100], Step [32/60], Loss: 1.0498, batch time: 0.72, accuracy:  67.00%\n",
      "Epoch [84/100], Step [33/60], Loss: 1.0490, batch time: 0.73, accuracy:  67.30%\n",
      "Epoch [84/100], Step [34/60], Loss: 1.0766, batch time: 0.72, accuracy:  67.70%\n",
      "Epoch [84/100], Step [35/60], Loss: 1.0873, batch time: 0.85, accuracy:  67.70%\n",
      "Epoch [84/100], Step [36/60], Loss: 1.0776, batch time: 0.83, accuracy:  67.00%\n",
      "Epoch [84/100], Step [37/60], Loss: 1.0782, batch time: 0.83, accuracy:  68.50%\n",
      "Epoch [84/100], Step [38/60], Loss: 1.0581, batch time: 0.69, accuracy:  64.10%\n",
      "Epoch [84/100], Step [39/60], Loss: 0.9757, batch time: 0.74, accuracy:  68.70%\n",
      "Epoch [84/100], Step [40/60], Loss: 1.0704, batch time: 0.57, accuracy:  64.90%\n",
      "Epoch [84/100], Step [41/60], Loss: 0.9495, batch time: 0.57, accuracy:  71.00%\n",
      "Epoch [84/100], Step [42/60], Loss: 1.0808, batch time: 0.68, accuracy:  65.60%\n",
      "Epoch [84/100], Step [43/60], Loss: 1.0900, batch time: 0.67, accuracy:  66.60%\n",
      "Epoch [84/100], Step [44/60], Loss: 1.0217, batch time: 0.67, accuracy:  67.10%\n",
      "Epoch [84/100], Step [45/60], Loss: 1.0306, batch time: 0.65, accuracy:  66.10%\n",
      "Epoch [84/100], Step [46/60], Loss: 0.9880, batch time: 0.57, accuracy:  68.60%\n",
      "Epoch [84/100], Step [47/60], Loss: 0.9810, batch time: 0.67, accuracy:  69.00%\n",
      "Epoch [84/100], Step [48/60], Loss: 1.0147, batch time: 0.67, accuracy:  69.10%\n",
      "Epoch [84/100], Step [49/60], Loss: 1.0813, batch time: 0.68, accuracy:  66.30%\n",
      "Epoch [84/100], Step [50/60], Loss: 1.0030, batch time: 0.71, accuracy:  69.80%\n",
      "Epoch [84/100], Step [51/60], Loss: 1.0159, batch time: 0.72, accuracy:  67.70%\n",
      "Epoch [84/100], Step [52/60], Loss: 1.0145, batch time: 0.70, accuracy:  66.30%\n",
      "Epoch [84/100], Step [53/60], Loss: 1.0485, batch time: 0.76, accuracy:  66.20%\n",
      "Epoch [84/100], Step [54/60], Loss: 1.0166, batch time: 0.65, accuracy:  68.10%\n",
      "Epoch [84/100], Step [55/60], Loss: 0.9680, batch time: 0.89, accuracy:  71.10%\n",
      "Epoch [84/100], Step [56/60], Loss: 0.9658, batch time: 0.88, accuracy:  68.40%\n",
      "Epoch [84/100], Step [57/60], Loss: 1.0547, batch time: 0.88, accuracy:  64.80%\n",
      "Epoch [84/100], Step [58/60], Loss: 1.0211, batch time: 0.87, accuracy:  66.00%\n",
      "Epoch [84/100], Step [59/60], Loss: 0.9916, batch time: 0.71, accuracy:  67.10%\n",
      "Epoch [84/100], Step [60/60], Loss: 1.0535, batch time: 0.66, accuracy:  63.90%\n",
      "Epoch [85/100], Step [1/60], Loss: 1.0181, batch time: 0.71, accuracy:  68.90%\n",
      "Epoch [85/100], Step [2/60], Loss: 1.0378, batch time: 0.60, accuracy:  68.70%\n",
      "Epoch [85/100], Step [3/60], Loss: 1.0690, batch time: 0.72, accuracy:  65.40%\n",
      "Epoch [85/100], Step [4/60], Loss: 1.0234, batch time: 0.72, accuracy:  68.60%\n",
      "Epoch [85/100], Step [5/60], Loss: 1.0472, batch time: 0.72, accuracy:  65.30%\n",
      "Epoch [85/100], Step [6/60], Loss: 1.0231, batch time: 0.71, accuracy:  65.20%\n",
      "Epoch [85/100], Step [7/60], Loss: 1.0362, batch time: 0.71, accuracy:  66.30%\n",
      "Epoch [85/100], Step [8/60], Loss: 0.9899, batch time: 0.72, accuracy:  70.10%\n",
      "Epoch [85/100], Step [9/60], Loss: 1.0519, batch time: 0.72, accuracy:  66.00%\n",
      "Epoch [85/100], Step [10/60], Loss: 0.9581, batch time: 0.71, accuracy:  69.90%\n",
      "Epoch [85/100], Step [11/60], Loss: 1.0498, batch time: 0.77, accuracy:  67.70%\n",
      "Epoch [85/100], Step [12/60], Loss: 1.0696, batch time: 0.76, accuracy:  64.20%\n",
      "Epoch [85/100], Step [13/60], Loss: 1.0835, batch time: 0.76, accuracy:  63.90%\n",
      "Epoch [85/100], Step [14/60], Loss: 0.9653, batch time: 0.76, accuracy:  69.80%\n",
      "Epoch [85/100], Step [15/60], Loss: 1.0842, batch time: 0.83, accuracy:  64.90%\n",
      "Epoch [85/100], Step [16/60], Loss: 1.0258, batch time: 0.73, accuracy:  66.50%\n",
      "Epoch [85/100], Step [17/60], Loss: 1.0516, batch time: 0.75, accuracy:  66.70%\n",
      "Epoch [85/100], Step [18/60], Loss: 0.9928, batch time: 0.76, accuracy:  67.50%\n",
      "Epoch [85/100], Step [19/60], Loss: 1.0273, batch time: 0.76, accuracy:  68.20%\n",
      "Epoch [85/100], Step [20/60], Loss: 0.9865, batch time: 0.80, accuracy:  69.40%\n",
      "Epoch [85/100], Step [21/60], Loss: 0.9961, batch time: 0.84, accuracy:  67.30%\n",
      "Epoch [85/100], Step [22/60], Loss: 1.0341, batch time: 0.84, accuracy:  66.00%\n",
      "Epoch [85/100], Step [23/60], Loss: 0.9975, batch time: 0.78, accuracy:  68.50%\n",
      "Epoch [85/100], Step [24/60], Loss: 0.9622, batch time: 0.71, accuracy:  70.20%\n",
      "Epoch [85/100], Step [25/60], Loss: 0.9919, batch time: 0.70, accuracy:  69.10%\n",
      "Epoch [85/100], Step [26/60], Loss: 0.9964, batch time: 0.71, accuracy:  68.20%\n",
      "Epoch [85/100], Step [27/60], Loss: 1.1069, batch time: 0.71, accuracy:  66.50%\n",
      "Epoch [85/100], Step [28/60], Loss: 1.0469, batch time: 0.72, accuracy:  65.60%\n",
      "Epoch [85/100], Step [29/60], Loss: 1.0010, batch time: 0.71, accuracy:  68.50%\n",
      "Epoch [85/100], Step [30/60], Loss: 1.0640, batch time: 0.71, accuracy:  67.80%\n",
      "Epoch [85/100], Step [31/60], Loss: 1.0531, batch time: 0.71, accuracy:  66.40%\n",
      "Epoch [85/100], Step [32/60], Loss: 0.9993, batch time: 0.71, accuracy:  67.90%\n",
      "Epoch [85/100], Step [33/60], Loss: 1.0737, batch time: 0.72, accuracy:  66.70%\n",
      "Epoch [85/100], Step [34/60], Loss: 1.0125, batch time: 0.72, accuracy:  68.10%\n",
      "Epoch [85/100], Step [35/60], Loss: 1.0444, batch time: 0.73, accuracy:  66.80%\n",
      "Epoch [85/100], Step [36/60], Loss: 1.0035, batch time: 0.75, accuracy:  67.60%\n",
      "Epoch [85/100], Step [37/60], Loss: 1.0586, batch time: 0.76, accuracy:  67.00%\n",
      "Epoch [85/100], Step [38/60], Loss: 1.0278, batch time: 0.76, accuracy:  68.70%\n",
      "Epoch [85/100], Step [39/60], Loss: 0.9685, batch time: 0.77, accuracy:  68.40%\n",
      "Epoch [85/100], Step [40/60], Loss: 0.9984, batch time: 0.77, accuracy:  65.90%\n",
      "Epoch [85/100], Step [41/60], Loss: 1.0351, batch time: 0.76, accuracy:  66.40%\n",
      "Epoch [85/100], Step [42/60], Loss: 1.1011, batch time: 0.89, accuracy:  65.40%\n",
      "Epoch [85/100], Step [43/60], Loss: 0.9937, batch time: 0.72, accuracy:  67.40%\n",
      "Epoch [85/100], Step [44/60], Loss: 1.0395, batch time: 0.43, accuracy:  68.30%\n",
      "Epoch [85/100], Step [45/60], Loss: 0.9934, batch time: 0.66, accuracy:  68.50%\n",
      "Epoch [85/100], Step [46/60], Loss: 1.0360, batch time: 0.43, accuracy:  68.60%\n",
      "Epoch [85/100], Step [47/60], Loss: 1.0051, batch time: 0.63, accuracy:  66.30%\n",
      "Epoch [85/100], Step [48/60], Loss: 1.0445, batch time: 0.47, accuracy:  67.90%\n",
      "Epoch [85/100], Step [49/60], Loss: 1.0008, batch time: 0.43, accuracy:  68.90%\n",
      "Epoch [85/100], Step [50/60], Loss: 1.0414, batch time: 0.71, accuracy:  68.20%\n",
      "Epoch [85/100], Step [51/60], Loss: 0.9373, batch time: 0.71, accuracy:  71.30%\n",
      "Epoch [85/100], Step [52/60], Loss: 1.0717, batch time: 0.50, accuracy:  67.70%\n",
      "Epoch [85/100], Step [53/60], Loss: 1.0286, batch time: 0.43, accuracy:  65.40%\n",
      "Epoch [85/100], Step [54/60], Loss: 0.9414, batch time: 0.70, accuracy:  69.80%\n",
      "Epoch [85/100], Step [55/60], Loss: 1.0589, batch time: 0.70, accuracy:  69.20%\n",
      "Epoch [85/100], Step [56/60], Loss: 1.0077, batch time: 0.69, accuracy:  70.80%\n",
      "Epoch [85/100], Step [57/60], Loss: 0.9929, batch time: 0.70, accuracy:  67.90%\n",
      "Epoch [85/100], Step [58/60], Loss: 1.0149, batch time: 0.69, accuracy:  66.90%\n",
      "Epoch [85/100], Step [59/60], Loss: 1.0182, batch time: 0.70, accuracy:  67.50%\n",
      "Epoch [85/100], Step [60/60], Loss: 1.0010, batch time: 0.67, accuracy:  67.40%\n",
      "Epoch [86/100], Step [1/60], Loss: 1.0229, batch time: 0.47, accuracy:  67.60%\n",
      "Epoch [86/100], Step [2/60], Loss: 0.9755, batch time: 0.76, accuracy:  67.40%\n",
      "Epoch [86/100], Step [3/60], Loss: 1.0883, batch time: 0.88, accuracy:  65.80%\n",
      "Epoch [86/100], Step [4/60], Loss: 1.1097, batch time: 0.88, accuracy:  63.10%\n",
      "Epoch [86/100], Step [5/60], Loss: 1.0187, batch time: 0.88, accuracy:  66.90%\n",
      "Epoch [86/100], Step [6/60], Loss: 1.0538, batch time: 0.97, accuracy:  66.00%\n",
      "Epoch [86/100], Step [7/60], Loss: 1.0183, batch time: 0.88, accuracy:  69.20%\n",
      "Epoch [86/100], Step [8/60], Loss: 0.9874, batch time: 0.88, accuracy:  70.90%\n",
      "Epoch [86/100], Step [9/60], Loss: 1.0341, batch time: 0.89, accuracy:  67.50%\n",
      "Epoch [86/100], Step [10/60], Loss: 1.0296, batch time: 0.89, accuracy:  67.60%\n",
      "Epoch [86/100], Step [11/60], Loss: 1.0311, batch time: 0.88, accuracy:  64.40%\n",
      "Epoch [86/100], Step [12/60], Loss: 1.0340, batch time: 0.87, accuracy:  67.40%\n",
      "Epoch [86/100], Step [13/60], Loss: 1.0046, batch time: 0.88, accuracy:  66.80%\n",
      "Epoch [86/100], Step [14/60], Loss: 0.9865, batch time: 0.88, accuracy:  68.60%\n",
      "Epoch [86/100], Step [15/60], Loss: 1.0771, batch time: 0.76, accuracy:  66.80%\n",
      "Epoch [86/100], Step [16/60], Loss: 1.0575, batch time: 0.79, accuracy:  64.50%\n",
      "Epoch [86/100], Step [17/60], Loss: 1.0447, batch time: 0.80, accuracy:  66.60%\n",
      "Epoch [86/100], Step [18/60], Loss: 1.0154, batch time: 0.77, accuracy:  68.50%\n",
      "Epoch [86/100], Step [19/60], Loss: 0.9702, batch time: 0.70, accuracy:  68.30%\n",
      "Epoch [86/100], Step [20/60], Loss: 1.0223, batch time: 0.71, accuracy:  69.00%\n",
      "Epoch [86/100], Step [21/60], Loss: 0.9321, batch time: 0.71, accuracy:  69.80%\n",
      "Epoch [86/100], Step [22/60], Loss: 0.9543, batch time: 0.71, accuracy:  68.60%\n",
      "Epoch [86/100], Step [23/60], Loss: 1.0150, batch time: 0.71, accuracy:  68.90%\n",
      "Epoch [86/100], Step [24/60], Loss: 1.0682, batch time: 0.71, accuracy:  68.50%\n",
      "Epoch [86/100], Step [25/60], Loss: 1.0179, batch time: 0.71, accuracy:  69.50%\n",
      "Epoch [86/100], Step [26/60], Loss: 0.9737, batch time: 0.68, accuracy:  68.00%\n",
      "Epoch [86/100], Step [27/60], Loss: 1.0196, batch time: 0.70, accuracy:  64.90%\n",
      "Epoch [86/100], Step [28/60], Loss: 1.0215, batch time: 0.68, accuracy:  67.40%\n",
      "Epoch [86/100], Step [29/60], Loss: 1.0450, batch time: 0.72, accuracy:  68.60%\n",
      "Epoch [86/100], Step [30/60], Loss: 0.9751, batch time: 0.70, accuracy:  71.70%\n",
      "Epoch [86/100], Step [31/60], Loss: 0.9641, batch time: 0.72, accuracy:  71.60%\n",
      "Epoch [86/100], Step [32/60], Loss: 1.0504, batch time: 0.74, accuracy:  68.30%\n",
      "Epoch [86/100], Step [33/60], Loss: 1.0083, batch time: 0.73, accuracy:  67.30%\n",
      "Epoch [86/100], Step [34/60], Loss: 1.0527, batch time: 0.75, accuracy:  69.00%\n",
      "Epoch [86/100], Step [35/60], Loss: 1.0225, batch time: 0.73, accuracy:  66.80%\n",
      "Epoch [86/100], Step [36/60], Loss: 1.0174, batch time: 0.76, accuracy:  67.50%\n",
      "Epoch [86/100], Step [37/60], Loss: 1.0496, batch time: 0.87, accuracy:  67.20%\n",
      "Epoch [86/100], Step [38/60], Loss: 0.9575, batch time: 0.87, accuracy:  70.70%\n",
      "Epoch [86/100], Step [39/60], Loss: 1.0093, batch time: 0.71, accuracy:  69.40%\n",
      "Epoch [86/100], Step [40/60], Loss: 1.0507, batch time: 0.71, accuracy:  67.80%\n",
      "Epoch [86/100], Step [41/60], Loss: 1.0477, batch time: 0.72, accuracy:  68.20%\n",
      "Epoch [86/100], Step [42/60], Loss: 0.9544, batch time: 0.70, accuracy:  69.60%\n",
      "Epoch [86/100], Step [43/60], Loss: 1.0258, batch time: 0.71, accuracy:  68.80%\n",
      "Epoch [86/100], Step [44/60], Loss: 1.0347, batch time: 0.71, accuracy:  67.10%\n",
      "Epoch [86/100], Step [45/60], Loss: 0.9977, batch time: 0.69, accuracy:  69.80%\n",
      "Epoch [86/100], Step [46/60], Loss: 0.9598, batch time: 0.72, accuracy:  68.70%\n",
      "Epoch [86/100], Step [47/60], Loss: 0.9775, batch time: 0.70, accuracy:  69.40%\n",
      "Epoch [86/100], Step [48/60], Loss: 1.0573, batch time: 0.70, accuracy:  68.40%\n",
      "Epoch [86/100], Step [49/60], Loss: 1.0068, batch time: 0.70, accuracy:  69.00%\n",
      "Epoch [86/100], Step [50/60], Loss: 1.0053, batch time: 0.71, accuracy:  66.80%\n",
      "Epoch [86/100], Step [51/60], Loss: 0.9613, batch time: 0.74, accuracy:  69.90%\n",
      "Epoch [86/100], Step [52/60], Loss: 1.0213, batch time: 0.73, accuracy:  66.90%\n",
      "Epoch [86/100], Step [53/60], Loss: 0.9990, batch time: 0.78, accuracy:  67.30%\n",
      "Epoch [86/100], Step [54/60], Loss: 1.0755, batch time: 0.74, accuracy:  65.70%\n",
      "Epoch [86/100], Step [55/60], Loss: 0.9952, batch time: 0.81, accuracy:  69.80%\n",
      "Epoch [86/100], Step [56/60], Loss: 1.0327, batch time: 0.86, accuracy:  67.90%\n",
      "Epoch [86/100], Step [57/60], Loss: 1.0052, batch time: 0.68, accuracy:  66.80%\n",
      "Epoch [86/100], Step [58/60], Loss: 1.0272, batch time: 0.69, accuracy:  67.40%\n",
      "Epoch [86/100], Step [59/60], Loss: 0.9252, batch time: 0.61, accuracy:  69.80%\n",
      "Epoch [86/100], Step [60/60], Loss: 1.0761, batch time: 0.68, accuracy:  64.20%\n",
      "Epoch [87/100], Step [1/60], Loss: 0.9758, batch time: 0.69, accuracy:  68.30%\n",
      "Epoch [87/100], Step [2/60], Loss: 1.0473, batch time: 0.64, accuracy:  66.60%\n",
      "Epoch [87/100], Step [3/60], Loss: 1.0446, batch time: 0.67, accuracy:  64.90%\n",
      "Epoch [87/100], Step [4/60], Loss: 1.0030, batch time: 0.70, accuracy:  67.80%\n",
      "Epoch [87/100], Step [5/60], Loss: 1.0326, batch time: 0.69, accuracy:  68.70%\n",
      "Epoch [87/100], Step [6/60], Loss: 1.0082, batch time: 0.70, accuracy:  65.90%\n",
      "Epoch [87/100], Step [7/60], Loss: 1.0014, batch time: 0.69, accuracy:  68.30%\n",
      "Epoch [87/100], Step [8/60], Loss: 1.0623, batch time: 0.69, accuracy:  68.30%\n",
      "Epoch [87/100], Step [9/60], Loss: 0.9649, batch time: 0.73, accuracy:  70.00%\n",
      "Epoch [87/100], Step [10/60], Loss: 0.9639, batch time: 0.69, accuracy:  68.20%\n",
      "Epoch [87/100], Step [11/60], Loss: 0.9907, batch time: 0.73, accuracy:  67.20%\n",
      "Epoch [87/100], Step [12/60], Loss: 0.9913, batch time: 0.83, accuracy:  66.90%\n",
      "Epoch [87/100], Step [13/60], Loss: 0.9921, batch time: 0.82, accuracy:  67.50%\n",
      "Epoch [87/100], Step [14/60], Loss: 0.9499, batch time: 0.86, accuracy:  70.20%\n",
      "Epoch [87/100], Step [15/60], Loss: 0.9858, batch time: 0.86, accuracy:  69.00%\n",
      "Epoch [87/100], Step [16/60], Loss: 0.9718, batch time: 0.69, accuracy:  69.70%\n",
      "Epoch [87/100], Step [17/60], Loss: 0.9520, batch time: 0.59, accuracy:  69.10%\n",
      "Epoch [87/100], Step [18/60], Loss: 1.0867, batch time: 0.60, accuracy:  66.00%\n",
      "Epoch [87/100], Step [19/60], Loss: 1.0208, batch time: 0.69, accuracy:  66.90%\n",
      "Epoch [87/100], Step [20/60], Loss: 1.0274, batch time: 0.70, accuracy:  68.50%\n",
      "Epoch [87/100], Step [21/60], Loss: 0.9722, batch time: 0.70, accuracy:  69.50%\n",
      "Epoch [87/100], Step [22/60], Loss: 1.0049, batch time: 0.70, accuracy:  67.90%\n",
      "Epoch [87/100], Step [23/60], Loss: 1.0615, batch time: 0.69, accuracy:  65.60%\n",
      "Epoch [87/100], Step [24/60], Loss: 1.0091, batch time: 0.68, accuracy:  67.40%\n",
      "Epoch [87/100], Step [25/60], Loss: 0.9813, batch time: 0.70, accuracy:  67.60%\n",
      "Epoch [87/100], Step [26/60], Loss: 0.9958, batch time: 0.69, accuracy:  68.70%\n",
      "Epoch [87/100], Step [27/60], Loss: 1.0012, batch time: 0.69, accuracy:  67.20%\n",
      "Epoch [87/100], Step [28/60], Loss: 1.0494, batch time: 0.69, accuracy:  67.30%\n",
      "Epoch [87/100], Step [29/60], Loss: 0.9967, batch time: 0.71, accuracy:  68.90%\n",
      "Epoch [87/100], Step [30/60], Loss: 0.9148, batch time: 0.73, accuracy:  71.30%\n",
      "Epoch [87/100], Step [31/60], Loss: 1.0060, batch time: 0.83, accuracy:  67.40%\n",
      "Epoch [87/100], Step [32/60], Loss: 0.9408, batch time: 0.84, accuracy:  70.00%\n",
      "Epoch [87/100], Step [33/60], Loss: 0.9814, batch time: 0.83, accuracy:  67.90%\n",
      "Epoch [87/100], Step [34/60], Loss: 0.9742, batch time: 0.83, accuracy:  69.20%\n",
      "Epoch [87/100], Step [35/60], Loss: 1.0254, batch time: 0.83, accuracy:  68.40%\n",
      "Epoch [87/100], Step [36/60], Loss: 1.0138, batch time: 0.83, accuracy:  68.70%\n",
      "Epoch [87/100], Step [37/60], Loss: 1.0192, batch time: 0.83, accuracy:  71.00%\n",
      "Epoch [87/100], Step [38/60], Loss: 0.9946, batch time: 0.83, accuracy:  69.00%\n",
      "Epoch [87/100], Step [39/60], Loss: 1.0034, batch time: 0.83, accuracy:  69.00%\n",
      "Epoch [87/100], Step [40/60], Loss: 0.9660, batch time: 0.79, accuracy:  68.60%\n",
      "Epoch [87/100], Step [41/60], Loss: 1.0059, batch time: 0.68, accuracy:  68.30%\n",
      "Epoch [87/100], Step [42/60], Loss: 1.0256, batch time: 0.68, accuracy:  68.90%\n",
      "Epoch [87/100], Step [43/60], Loss: 1.0042, batch time: 0.68, accuracy:  67.30%\n",
      "Epoch [87/100], Step [44/60], Loss: 1.0217, batch time: 0.68, accuracy:  67.40%\n",
      "Epoch [87/100], Step [45/60], Loss: 0.9862, batch time: 0.69, accuracy:  68.60%\n",
      "Epoch [87/100], Step [46/60], Loss: 0.9772, batch time: 0.69, accuracy:  68.90%\n",
      "Epoch [87/100], Step [47/60], Loss: 1.0526, batch time: 0.69, accuracy:  67.20%\n",
      "Epoch [87/100], Step [48/60], Loss: 0.9978, batch time: 0.69, accuracy:  66.70%\n",
      "Epoch [87/100], Step [49/60], Loss: 1.1207, batch time: 0.60, accuracy:  65.90%\n",
      "Epoch [87/100], Step [50/60], Loss: 1.0299, batch time: 0.68, accuracy:  68.40%\n",
      "Epoch [87/100], Step [51/60], Loss: 0.9255, batch time: 0.58, accuracy:  69.00%\n",
      "Epoch [87/100], Step [52/60], Loss: 0.9873, batch time: 0.69, accuracy:  68.10%\n",
      "Epoch [87/100], Step [53/60], Loss: 1.0188, batch time: 0.69, accuracy:  66.50%\n",
      "Epoch [87/100], Step [54/60], Loss: 1.0138, batch time: 0.73, accuracy:  68.30%\n",
      "Epoch [87/100], Step [55/60], Loss: 0.9570, batch time: 0.74, accuracy:  69.50%\n",
      "Epoch [87/100], Step [56/60], Loss: 1.0594, batch time: 0.73, accuracy:  68.10%\n",
      "Epoch [87/100], Step [57/60], Loss: 0.9313, batch time: 0.73, accuracy:  69.70%\n",
      "Epoch [87/100], Step [58/60], Loss: 1.1073, batch time: 0.83, accuracy:  67.00%\n",
      "Epoch [87/100], Step [59/60], Loss: 0.9712, batch time: 0.85, accuracy:  70.20%\n",
      "Epoch [87/100], Step [60/60], Loss: 1.0088, batch time: 0.84, accuracy:  69.70%\n",
      "Epoch [88/100], Step [1/60], Loss: 1.0986, batch time: 0.63, accuracy:  67.00%\n",
      "Epoch [88/100], Step [2/60], Loss: 0.9772, batch time: 0.69, accuracy:  69.70%\n",
      "Epoch [88/100], Step [3/60], Loss: 0.9802, batch time: 0.57, accuracy:  68.20%\n",
      "Epoch [88/100], Step [4/60], Loss: 1.0431, batch time: 0.68, accuracy:  65.60%\n",
      "Epoch [88/100], Step [5/60], Loss: 0.9739, batch time: 0.69, accuracy:  70.80%\n",
      "Epoch [88/100], Step [6/60], Loss: 0.9650, batch time: 0.68, accuracy:  69.20%\n",
      "Epoch [88/100], Step [7/60], Loss: 0.9618, batch time: 0.64, accuracy:  68.00%\n",
      "Epoch [88/100], Step [8/60], Loss: 0.9479, batch time: 0.68, accuracy:  70.50%\n",
      "Epoch [88/100], Step [9/60], Loss: 1.0043, batch time: 0.46, accuracy:  67.40%\n",
      "Epoch [88/100], Step [10/60], Loss: 1.0150, batch time: 0.70, accuracy:  64.60%\n",
      "Epoch [88/100], Step [11/60], Loss: 1.0286, batch time: 0.51, accuracy:  69.00%\n",
      "Epoch [88/100], Step [12/60], Loss: 1.0023, batch time: 0.61, accuracy:  69.60%\n",
      "Epoch [88/100], Step [13/60], Loss: 0.9933, batch time: 0.70, accuracy:  67.80%\n",
      "Epoch [88/100], Step [14/60], Loss: 1.0414, batch time: 0.50, accuracy:  69.00%\n",
      "Epoch [88/100], Step [15/60], Loss: 1.0273, batch time: 0.45, accuracy:  66.90%\n",
      "Epoch [88/100], Step [16/60], Loss: 0.9704, batch time: 0.48, accuracy:  68.50%\n",
      "Epoch [88/100], Step [17/60], Loss: 0.9992, batch time: 0.71, accuracy:  67.80%\n",
      "Epoch [88/100], Step [18/60], Loss: 1.0469, batch time: 0.73, accuracy:  66.40%\n",
      "Epoch [88/100], Step [19/60], Loss: 0.9796, batch time: 0.74, accuracy:  71.00%\n",
      "Epoch [88/100], Step [20/60], Loss: 1.0321, batch time: 0.73, accuracy:  67.10%\n",
      "Epoch [88/100], Step [21/60], Loss: 1.0133, batch time: 0.73, accuracy:  68.10%\n",
      "Epoch [88/100], Step [22/60], Loss: 1.0017, batch time: 0.73, accuracy:  67.50%\n",
      "Epoch [88/100], Step [23/60], Loss: 1.0002, batch time: 0.79, accuracy:  69.10%\n",
      "Epoch [88/100], Step [24/60], Loss: 1.0139, batch time: 0.86, accuracy:  67.00%\n",
      "Epoch [88/100], Step [25/60], Loss: 1.0459, batch time: 0.85, accuracy:  66.10%\n",
      "Epoch [88/100], Step [26/60], Loss: 1.0023, batch time: 0.80, accuracy:  70.20%\n",
      "Epoch [88/100], Step [27/60], Loss: 1.0423, batch time: 0.69, accuracy:  65.20%\n",
      "Epoch [88/100], Step [28/60], Loss: 0.9952, batch time: 0.69, accuracy:  68.60%\n",
      "Epoch [88/100], Step [29/60], Loss: 0.9697, batch time: 0.69, accuracy:  68.80%\n",
      "Epoch [88/100], Step [30/60], Loss: 1.0773, batch time: 0.70, accuracy:  66.10%\n",
      "Epoch [88/100], Step [31/60], Loss: 1.0055, batch time: 0.71, accuracy:  66.90%\n",
      "Epoch [88/100], Step [32/60], Loss: 0.9374, batch time: 0.69, accuracy:  70.60%\n",
      "Epoch [88/100], Step [33/60], Loss: 1.0714, batch time: 0.70, accuracy:  69.00%\n",
      "Epoch [88/100], Step [34/60], Loss: 1.0028, batch time: 0.77, accuracy:  68.80%\n",
      "Epoch [88/100], Step [35/60], Loss: 0.9795, batch time: 0.45, accuracy:  67.60%\n",
      "Epoch [88/100], Step [36/60], Loss: 0.9794, batch time: 0.43, accuracy:  67.80%\n",
      "Epoch [88/100], Step [37/60], Loss: 0.9905, batch time: 0.42, accuracy:  71.10%\n",
      "Epoch [88/100], Step [38/60], Loss: 1.0358, batch time: 0.43, accuracy:  68.00%\n",
      "Epoch [88/100], Step [39/60], Loss: 0.9977, batch time: 0.45, accuracy:  70.70%\n",
      "Epoch [88/100], Step [40/60], Loss: 0.9966, batch time: 0.45, accuracy:  69.40%\n",
      "Epoch [88/100], Step [41/60], Loss: 1.0125, batch time: 0.46, accuracy:  67.50%\n",
      "Epoch [88/100], Step [42/60], Loss: 1.0305, batch time: 0.70, accuracy:  67.70%\n",
      "Epoch [88/100], Step [43/60], Loss: 1.0412, batch time: 0.75, accuracy:  68.00%\n",
      "Epoch [88/100], Step [44/60], Loss: 1.0145, batch time: 0.74, accuracy:  67.50%\n",
      "Epoch [88/100], Step [45/60], Loss: 0.9328, batch time: 0.74, accuracy:  70.20%\n",
      "Epoch [88/100], Step [46/60], Loss: 1.0009, batch time: 0.74, accuracy:  68.70%\n",
      "Epoch [88/100], Step [47/60], Loss: 0.9850, batch time: 0.74, accuracy:  70.20%\n",
      "Epoch [88/100], Step [48/60], Loss: 0.8859, batch time: 0.74, accuracy:  72.40%\n",
      "Epoch [88/100], Step [49/60], Loss: 0.9999, batch time: 0.74, accuracy:  69.40%\n",
      "Epoch [88/100], Step [50/60], Loss: 1.0182, batch time: 0.74, accuracy:  68.70%\n",
      "Epoch [88/100], Step [51/60], Loss: 0.9728, batch time: 0.75, accuracy:  67.20%\n",
      "Epoch [88/100], Step [52/60], Loss: 0.9863, batch time: 0.74, accuracy:  68.10%\n",
      "Epoch [88/100], Step [53/60], Loss: 1.0211, batch time: 0.74, accuracy:  66.60%\n",
      "Epoch [88/100], Step [54/60], Loss: 0.9215, batch time: 0.65, accuracy:  68.60%\n",
      "Epoch [88/100], Step [55/60], Loss: 0.9820, batch time: 0.70, accuracy:  69.50%\n",
      "Epoch [88/100], Step [56/60], Loss: 0.9141, batch time: 0.85, accuracy:  70.30%\n",
      "Epoch [88/100], Step [57/60], Loss: 1.0358, batch time: 0.87, accuracy:  67.80%\n",
      "Epoch [88/100], Step [58/60], Loss: 0.9366, batch time: 0.85, accuracy:  69.30%\n",
      "Epoch [88/100], Step [59/60], Loss: 0.9303, batch time: 0.57, accuracy:  72.70%\n",
      "Epoch [88/100], Step [60/60], Loss: 0.9419, batch time: 0.42, accuracy:  68.70%\n",
      "Epoch [89/100], Step [1/60], Loss: 0.9629, batch time: 0.46, accuracy:  68.30%\n",
      "Epoch [89/100], Step [2/60], Loss: 0.9587, batch time: 0.42, accuracy:  70.30%\n",
      "Epoch [89/100], Step [3/60], Loss: 0.9867, batch time: 0.42, accuracy:  68.50%\n",
      "Epoch [89/100], Step [4/60], Loss: 1.0069, batch time: 0.46, accuracy:  69.50%\n",
      "Epoch [89/100], Step [5/60], Loss: 1.0120, batch time: 0.42, accuracy:  67.50%\n",
      "Epoch [89/100], Step [6/60], Loss: 0.9980, batch time: 0.43, accuracy:  68.20%\n",
      "Epoch [89/100], Step [7/60], Loss: 0.9277, batch time: 0.44, accuracy:  70.00%\n",
      "Epoch [89/100], Step [8/60], Loss: 0.9658, batch time: 0.42, accuracy:  68.40%\n",
      "Epoch [89/100], Step [9/60], Loss: 0.9467, batch time: 0.43, accuracy:  69.10%\n",
      "Epoch [89/100], Step [10/60], Loss: 0.9793, batch time: 0.43, accuracy:  71.00%\n",
      "Epoch [89/100], Step [11/60], Loss: 0.9908, batch time: 0.42, accuracy:  67.80%\n",
      "Epoch [89/100], Step [12/60], Loss: 0.9774, batch time: 0.42, accuracy:  68.70%\n",
      "Epoch [89/100], Step [13/60], Loss: 0.9819, batch time: 0.54, accuracy:  70.20%\n",
      "Epoch [89/100], Step [14/60], Loss: 1.0259, batch time: 0.63, accuracy:  65.50%\n",
      "Epoch [89/100], Step [15/60], Loss: 0.9139, batch time: 0.64, accuracy:  71.20%\n",
      "Epoch [89/100], Step [16/60], Loss: 1.0114, batch time: 0.63, accuracy:  67.30%\n",
      "Epoch [89/100], Step [17/60], Loss: 1.0783, batch time: 0.67, accuracy:  66.60%\n",
      "Epoch [89/100], Step [18/60], Loss: 0.9853, batch time: 0.72, accuracy:  68.00%\n",
      "Epoch [89/100], Step [19/60], Loss: 0.9791, batch time: 0.74, accuracy:  66.70%\n",
      "Epoch [89/100], Step [20/60], Loss: 0.9424, batch time: 0.80, accuracy:  70.30%\n",
      "Epoch [89/100], Step [21/60], Loss: 1.0268, batch time: 0.85, accuracy:  69.80%\n",
      "Epoch [89/100], Step [22/60], Loss: 0.9650, batch time: 0.76, accuracy:  70.10%\n",
      "Epoch [89/100], Step [23/60], Loss: 1.0112, batch time: 0.85, accuracy:  68.60%\n",
      "Epoch [89/100], Step [24/60], Loss: 0.9906, batch time: 0.86, accuracy:  69.10%\n",
      "Epoch [89/100], Step [25/60], Loss: 1.0403, batch time: 0.90, accuracy:  66.60%\n",
      "Epoch [89/100], Step [26/60], Loss: 0.9735, batch time: 0.78, accuracy:  70.20%\n",
      "Epoch [89/100], Step [27/60], Loss: 1.0324, batch time: 0.54, accuracy:  70.00%\n",
      "Epoch [89/100], Step [28/60], Loss: 1.0160, batch time: 0.70, accuracy:  68.40%\n",
      "Epoch [89/100], Step [29/60], Loss: 1.0117, batch time: 0.72, accuracy:  69.20%\n",
      "Epoch [89/100], Step [30/60], Loss: 0.9988, batch time: 0.66, accuracy:  68.10%\n",
      "Epoch [89/100], Step [31/60], Loss: 0.9863, batch time: 0.69, accuracy:  68.40%\n",
      "Epoch [89/100], Step [32/60], Loss: 0.9529, batch time: 0.61, accuracy:  68.40%\n",
      "Epoch [89/100], Step [33/60], Loss: 0.9074, batch time: 0.69, accuracy:  73.10%\n",
      "Epoch [89/100], Step [34/60], Loss: 1.0178, batch time: 0.58, accuracy:  66.70%\n",
      "Epoch [89/100], Step [35/60], Loss: 0.9758, batch time: 0.69, accuracy:  69.50%\n",
      "Epoch [89/100], Step [36/60], Loss: 1.0564, batch time: 0.71, accuracy:  67.30%\n",
      "Epoch [89/100], Step [37/60], Loss: 1.0227, batch time: 0.70, accuracy:  66.40%\n",
      "Epoch [89/100], Step [38/60], Loss: 0.9292, batch time: 0.58, accuracy:  69.20%\n",
      "Epoch [89/100], Step [39/60], Loss: 1.0460, batch time: 0.71, accuracy:  68.40%\n",
      "Epoch [89/100], Step [40/60], Loss: 1.0231, batch time: 0.72, accuracy:  68.60%\n",
      "Epoch [89/100], Step [41/60], Loss: 0.9561, batch time: 0.74, accuracy:  69.70%\n",
      "Epoch [89/100], Step [42/60], Loss: 1.0092, batch time: 0.76, accuracy:  67.10%\n",
      "Epoch [89/100], Step [43/60], Loss: 0.9339, batch time: 0.76, accuracy:  70.00%\n",
      "Epoch [89/100], Step [44/60], Loss: 0.9649, batch time: 0.76, accuracy:  70.70%\n",
      "Epoch [89/100], Step [45/60], Loss: 0.9944, batch time: 0.75, accuracy:  69.50%\n",
      "Epoch [89/100], Step [46/60], Loss: 0.9808, batch time: 0.76, accuracy:  68.90%\n",
      "Epoch [89/100], Step [47/60], Loss: 1.0009, batch time: 0.76, accuracy:  69.60%\n",
      "Epoch [89/100], Step [48/60], Loss: 0.9836, batch time: 0.76, accuracy:  71.20%\n",
      "Epoch [89/100], Step [49/60], Loss: 1.0635, batch time: 0.75, accuracy:  66.90%\n",
      "Epoch [89/100], Step [50/60], Loss: 0.9585, batch time: 0.76, accuracy:  69.10%\n",
      "Epoch [89/100], Step [51/60], Loss: 1.0293, batch time: 0.75, accuracy:  67.10%\n",
      "Epoch [89/100], Step [52/60], Loss: 0.9361, batch time: 0.73, accuracy:  70.00%\n",
      "Epoch [89/100], Step [53/60], Loss: 1.0107, batch time: 0.76, accuracy:  69.60%\n",
      "Epoch [89/100], Step [54/60], Loss: 0.9677, batch time: 0.73, accuracy:  69.60%\n",
      "Epoch [89/100], Step [55/60], Loss: 0.9270, batch time: 0.79, accuracy:  68.50%\n",
      "Epoch [89/100], Step [56/60], Loss: 1.0520, batch time: 0.88, accuracy:  63.70%\n",
      "Epoch [89/100], Step [57/60], Loss: 0.9965, batch time: 0.80, accuracy:  67.30%\n",
      "Epoch [89/100], Step [58/60], Loss: 1.0067, batch time: 0.70, accuracy:  68.30%\n",
      "Epoch [89/100], Step [59/60], Loss: 0.9629, batch time: 0.71, accuracy:  71.60%\n",
      "Epoch [89/100], Step [60/60], Loss: 0.9503, batch time: 0.71, accuracy:  69.10%\n",
      "Epoch [90/100], Step [1/60], Loss: 1.0227, batch time: 0.71, accuracy:  68.70%\n",
      "Epoch [90/100], Step [2/60], Loss: 0.9574, batch time: 0.71, accuracy:  69.40%\n",
      "Epoch [90/100], Step [3/60], Loss: 0.9722, batch time: 0.71, accuracy:  68.20%\n",
      "Epoch [90/100], Step [4/60], Loss: 0.9953, batch time: 0.71, accuracy:  69.20%\n",
      "Epoch [90/100], Step [5/60], Loss: 1.0277, batch time: 0.71, accuracy:  69.90%\n",
      "Epoch [90/100], Step [6/60], Loss: 1.0011, batch time: 0.71, accuracy:  67.30%\n",
      "Epoch [90/100], Step [7/60], Loss: 0.9647, batch time: 0.71, accuracy:  68.80%\n",
      "Epoch [90/100], Step [8/60], Loss: 0.9013, batch time: 0.71, accuracy:  72.90%\n",
      "Epoch [90/100], Step [9/60], Loss: 0.9387, batch time: 0.75, accuracy:  69.30%\n",
      "Epoch [90/100], Step [10/60], Loss: 0.9968, batch time: 0.76, accuracy:  67.40%\n",
      "Epoch [90/100], Step [11/60], Loss: 1.0104, batch time: 0.75, accuracy:  68.40%\n",
      "Epoch [90/100], Step [12/60], Loss: 1.0365, batch time: 0.73, accuracy:  68.70%\n",
      "Epoch [90/100], Step [13/60], Loss: 0.9275, batch time: 0.75, accuracy:  71.20%\n",
      "Epoch [90/100], Step [14/60], Loss: 1.0360, batch time: 0.81, accuracy:  68.50%\n",
      "Epoch [90/100], Step [15/60], Loss: 0.8646, batch time: 0.88, accuracy:  73.40%\n",
      "Epoch [90/100], Step [16/60], Loss: 0.9543, batch time: 0.88, accuracy:  70.80%\n",
      "Epoch [90/100], Step [17/60], Loss: 1.0122, batch time: 0.88, accuracy:  68.50%\n",
      "Epoch [90/100], Step [18/60], Loss: 0.9824, batch time: 0.77, accuracy:  69.30%\n",
      "Epoch [90/100], Step [19/60], Loss: 1.0138, batch time: 0.71, accuracy:  66.30%\n",
      "Epoch [90/100], Step [20/60], Loss: 0.9936, batch time: 0.71, accuracy:  69.70%\n",
      "Epoch [90/100], Step [21/60], Loss: 0.9716, batch time: 0.71, accuracy:  68.60%\n",
      "Epoch [90/100], Step [22/60], Loss: 0.9537, batch time: 0.71, accuracy:  69.40%\n",
      "Epoch [90/100], Step [23/60], Loss: 0.9379, batch time: 0.71, accuracy:  68.50%\n",
      "Epoch [90/100], Step [24/60], Loss: 0.9267, batch time: 0.70, accuracy:  69.80%\n",
      "Epoch [90/100], Step [25/60], Loss: 1.0051, batch time: 0.71, accuracy:  67.50%\n",
      "Epoch [90/100], Step [26/60], Loss: 0.9410, batch time: 0.71, accuracy:  70.70%\n",
      "Epoch [90/100], Step [27/60], Loss: 1.0269, batch time: 0.71, accuracy:  68.50%\n",
      "Epoch [90/100], Step [28/60], Loss: 1.0172, batch time: 0.71, accuracy:  65.80%\n",
      "Epoch [90/100], Step [29/60], Loss: 0.9731, batch time: 0.71, accuracy:  69.70%\n",
      "Epoch [90/100], Step [30/60], Loss: 0.9472, batch time: 0.75, accuracy:  70.40%\n",
      "Epoch [90/100], Step [31/60], Loss: 0.9554, batch time: 0.76, accuracy:  68.30%\n",
      "Epoch [90/100], Step [32/60], Loss: 0.9849, batch time: 0.76, accuracy:  68.00%\n",
      "Epoch [90/100], Step [33/60], Loss: 0.9331, batch time: 0.76, accuracy:  71.80%\n",
      "Epoch [90/100], Step [34/60], Loss: 0.9421, batch time: 0.81, accuracy:  69.20%\n",
      "Epoch [90/100], Step [35/60], Loss: 1.0352, batch time: 0.73, accuracy:  68.40%\n",
      "Epoch [90/100], Step [36/60], Loss: 0.9607, batch time: 0.81, accuracy:  68.50%\n",
      "Epoch [90/100], Step [37/60], Loss: 0.9818, batch time: 0.88, accuracy:  70.70%\n",
      "Epoch [90/100], Step [38/60], Loss: 0.9356, batch time: 0.88, accuracy:  68.50%\n",
      "Epoch [90/100], Step [39/60], Loss: 0.9750, batch time: 0.79, accuracy:  69.60%\n",
      "Epoch [90/100], Step [40/60], Loss: 0.9989, batch time: 0.70, accuracy:  67.80%\n",
      "Epoch [90/100], Step [41/60], Loss: 1.0619, batch time: 0.71, accuracy:  68.60%\n",
      "Epoch [90/100], Step [42/60], Loss: 1.0303, batch time: 0.70, accuracy:  69.70%\n",
      "Epoch [90/100], Step [43/60], Loss: 0.9820, batch time: 0.71, accuracy:  68.50%\n",
      "Epoch [90/100], Step [44/60], Loss: 0.9446, batch time: 0.71, accuracy:  71.80%\n",
      "Epoch [90/100], Step [45/60], Loss: 1.0476, batch time: 0.71, accuracy:  64.60%\n",
      "Epoch [90/100], Step [46/60], Loss: 0.9119, batch time: 0.71, accuracy:  69.90%\n",
      "Epoch [90/100], Step [47/60], Loss: 0.9409, batch time: 0.71, accuracy:  71.10%\n",
      "Epoch [90/100], Step [48/60], Loss: 0.9821, batch time: 0.71, accuracy:  69.70%\n",
      "Epoch [90/100], Step [49/60], Loss: 1.0497, batch time: 0.72, accuracy:  68.50%\n",
      "Epoch [90/100], Step [50/60], Loss: 0.9210, batch time: 0.72, accuracy:  70.00%\n",
      "Epoch [90/100], Step [51/60], Loss: 1.0009, batch time: 0.75, accuracy:  67.30%\n",
      "Epoch [90/100], Step [52/60], Loss: 1.0393, batch time: 0.76, accuracy:  68.90%\n",
      "Epoch [90/100], Step [53/60], Loss: 0.9679, batch time: 0.76, accuracy:  68.60%\n",
      "Epoch [90/100], Step [54/60], Loss: 1.0144, batch time: 0.76, accuracy:  70.10%\n",
      "Epoch [90/100], Step [55/60], Loss: 0.9570, batch time: 0.76, accuracy:  68.30%\n",
      "Epoch [90/100], Step [56/60], Loss: 0.9952, batch time: 0.80, accuracy:  68.30%\n",
      "Epoch [90/100], Step [57/60], Loss: 1.0374, batch time: 0.87, accuracy:  67.70%\n",
      "Epoch [90/100], Step [58/60], Loss: 0.9396, batch time: 0.88, accuracy:  69.20%\n",
      "Epoch [90/100], Step [59/60], Loss: 0.9831, batch time: 0.88, accuracy:  68.50%\n",
      "Epoch [90/100], Step [60/60], Loss: 1.0336, batch time: 0.77, accuracy:  68.50%\n",
      "Epoch [91/100], Step [1/60], Loss: 0.9893, batch time: 0.71, accuracy:  68.30%\n",
      "Epoch [91/100], Step [2/60], Loss: 0.9431, batch time: 0.73, accuracy:  70.60%\n",
      "Epoch [91/100], Step [3/60], Loss: 0.9738, batch time: 0.70, accuracy:  70.10%\n",
      "Epoch [91/100], Step [4/60], Loss: 0.9632, batch time: 0.70, accuracy:  70.90%\n",
      "Epoch [91/100], Step [5/60], Loss: 0.9412, batch time: 0.68, accuracy:  69.30%\n",
      "Epoch [91/100], Step [6/60], Loss: 0.9867, batch time: 0.71, accuracy:  67.70%\n",
      "Epoch [91/100], Step [7/60], Loss: 0.9647, batch time: 0.70, accuracy:  71.10%\n",
      "Epoch [91/100], Step [8/60], Loss: 1.0794, batch time: 0.70, accuracy:  68.40%\n",
      "Epoch [91/100], Step [9/60], Loss: 0.9902, batch time: 0.70, accuracy:  69.00%\n",
      "Epoch [91/100], Step [10/60], Loss: 0.9951, batch time: 0.64, accuracy:  68.80%\n",
      "Epoch [91/100], Step [11/60], Loss: 1.0175, batch time: 0.65, accuracy:  65.80%\n",
      "Epoch [91/100], Step [12/60], Loss: 1.0233, batch time: 0.65, accuracy:  68.30%\n",
      "Epoch [91/100], Step [13/60], Loss: 0.9057, batch time: 0.70, accuracy:  70.20%\n",
      "Epoch [91/100], Step [14/60], Loss: 1.0453, batch time: 0.74, accuracy:  66.10%\n",
      "Epoch [91/100], Step [15/60], Loss: 0.9238, batch time: 0.76, accuracy:  72.00%\n",
      "Epoch [91/100], Step [16/60], Loss: 0.9531, batch time: 0.86, accuracy:  68.50%\n",
      "Epoch [91/100], Step [17/60], Loss: 1.0398, batch time: 0.94, accuracy:  66.30%\n",
      "Epoch [91/100], Step [18/60], Loss: 0.9481, batch time: 0.85, accuracy:  68.70%\n",
      "Epoch [91/100], Step [19/60], Loss: 0.9527, batch time: 0.87, accuracy:  69.10%\n",
      "Epoch [91/100], Step [20/60], Loss: 0.9549, batch time: 0.87, accuracy:  69.30%\n",
      "Epoch [91/100], Step [21/60], Loss: 0.9235, batch time: 0.77, accuracy:  69.70%\n",
      "Epoch [91/100], Step [22/60], Loss: 1.0286, batch time: 0.58, accuracy:  67.00%\n",
      "Epoch [91/100], Step [23/60], Loss: 0.9549, batch time: 0.69, accuracy:  70.40%\n",
      "Epoch [91/100], Step [24/60], Loss: 1.0522, batch time: 0.68, accuracy:  68.30%\n",
      "Epoch [91/100], Step [25/60], Loss: 0.9710, batch time: 0.65, accuracy:  69.90%\n",
      "Epoch [91/100], Step [26/60], Loss: 0.9548, batch time: 0.69, accuracy:  68.90%\n",
      "Epoch [91/100], Step [27/60], Loss: 0.9473, batch time: 0.68, accuracy:  69.40%\n",
      "Epoch [91/100], Step [28/60], Loss: 0.9468, batch time: 0.70, accuracy:  70.30%\n",
      "Epoch [91/100], Step [29/60], Loss: 0.9891, batch time: 0.70, accuracy:  68.00%\n",
      "Epoch [91/100], Step [30/60], Loss: 1.0522, batch time: 0.70, accuracy:  68.40%\n",
      "Epoch [91/100], Step [31/60], Loss: 0.9356, batch time: 0.70, accuracy:  70.60%\n",
      "Epoch [91/100], Step [32/60], Loss: 1.0022, batch time: 0.70, accuracy:  70.30%\n",
      "Epoch [91/100], Step [33/60], Loss: 0.9942, batch time: 0.71, accuracy:  68.60%\n",
      "Epoch [91/100], Step [34/60], Loss: 0.8907, batch time: 0.61, accuracy:  71.30%\n",
      "Epoch [91/100], Step [35/60], Loss: 0.9112, batch time: 0.64, accuracy:  72.10%\n",
      "Epoch [91/100], Step [36/60], Loss: 0.9514, batch time: 0.74, accuracy:  70.20%\n",
      "Epoch [91/100], Step [37/60], Loss: 0.9721, batch time: 0.75, accuracy:  67.80%\n",
      "Epoch [91/100], Step [38/60], Loss: 0.9889, batch time: 0.66, accuracy:  69.80%\n",
      "Epoch [91/100], Step [39/60], Loss: 0.9779, batch time: 0.73, accuracy:  69.90%\n",
      "Epoch [91/100], Step [40/60], Loss: 0.9387, batch time: 0.71, accuracy:  70.20%\n",
      "Epoch [91/100], Step [41/60], Loss: 0.9121, batch time: 0.73, accuracy:  72.40%\n",
      "Epoch [91/100], Step [42/60], Loss: 0.9851, batch time: 0.85, accuracy:  68.60%\n",
      "Epoch [91/100], Step [43/60], Loss: 1.0377, batch time: 0.84, accuracy:  68.40%\n",
      "Epoch [91/100], Step [44/60], Loss: 0.9971, batch time: 0.69, accuracy:  69.60%\n",
      "Epoch [91/100], Step [45/60], Loss: 0.9216, batch time: 0.70, accuracy:  69.90%\n",
      "Epoch [91/100], Step [46/60], Loss: 0.9812, batch time: 0.70, accuracy:  70.70%\n",
      "Epoch [91/100], Step [47/60], Loss: 1.0380, batch time: 0.69, accuracy:  67.60%\n",
      "Epoch [91/100], Step [48/60], Loss: 0.8997, batch time: 0.70, accuracy:  70.50%\n",
      "Epoch [91/100], Step [49/60], Loss: 0.9514, batch time: 0.70, accuracy:  68.50%\n",
      "Epoch [91/100], Step [50/60], Loss: 0.9446, batch time: 0.70, accuracy:  68.60%\n",
      "Epoch [91/100], Step [51/60], Loss: 0.9715, batch time: 0.70, accuracy:  71.10%\n",
      "Epoch [91/100], Step [52/60], Loss: 0.9328, batch time: 0.70, accuracy:  70.90%\n",
      "Epoch [91/100], Step [53/60], Loss: 1.0660, batch time: 0.78, accuracy:  65.00%\n",
      "Epoch [91/100], Step [54/60], Loss: 0.9833, batch time: 0.70, accuracy:  68.30%\n",
      "Epoch [91/100], Step [55/60], Loss: 0.9594, batch time: 0.70, accuracy:  71.00%\n",
      "Epoch [91/100], Step [56/60], Loss: 1.0188, batch time: 0.73, accuracy:  67.60%\n",
      "Epoch [91/100], Step [57/60], Loss: 0.9769, batch time: 0.74, accuracy:  70.20%\n",
      "Epoch [91/100], Step [58/60], Loss: 1.0277, batch time: 0.75, accuracy:  68.10%\n",
      "Epoch [91/100], Step [59/60], Loss: 0.9366, batch time: 0.85, accuracy:  70.40%\n",
      "Epoch [91/100], Step [60/60], Loss: 0.9445, batch time: 0.87, accuracy:  70.60%\n",
      "Epoch [92/100], Step [1/60], Loss: 0.9285, batch time: 0.82, accuracy:  71.40%\n",
      "Epoch [92/100], Step [2/60], Loss: 1.0050, batch time: 0.78, accuracy:  69.70%\n",
      "Epoch [92/100], Step [3/60], Loss: 1.0439, batch time: 0.75, accuracy:  67.60%\n",
      "Epoch [92/100], Step [4/60], Loss: 0.9496, batch time: 0.72, accuracy:  67.60%\n",
      "Epoch [92/100], Step [5/60], Loss: 0.9558, batch time: 0.69, accuracy:  69.80%\n",
      "Epoch [92/100], Step [6/60], Loss: 0.9559, batch time: 0.60, accuracy:  70.90%\n",
      "Epoch [92/100], Step [7/60], Loss: 1.0016, batch time: 0.61, accuracy:  66.40%\n",
      "Epoch [92/100], Step [8/60], Loss: 0.9252, batch time: 0.61, accuracy:  70.20%\n",
      "Epoch [92/100], Step [9/60], Loss: 1.0008, batch time: 0.70, accuracy:  68.90%\n",
      "Epoch [92/100], Step [10/60], Loss: 0.9211, batch time: 0.70, accuracy:  69.70%\n",
      "Epoch [92/100], Step [11/60], Loss: 0.8943, batch time: 0.69, accuracy:  69.60%\n",
      "Epoch [92/100], Step [12/60], Loss: 1.0028, batch time: 0.69, accuracy:  67.30%\n",
      "Epoch [92/100], Step [13/60], Loss: 1.0295, batch time: 0.69, accuracy:  67.10%\n",
      "Epoch [92/100], Step [14/60], Loss: 0.9878, batch time: 0.70, accuracy:  68.60%\n",
      "Epoch [92/100], Step [15/60], Loss: 0.9967, batch time: 0.69, accuracy:  68.80%\n",
      "Epoch [92/100], Step [16/60], Loss: 0.9042, batch time: 0.50, accuracy:  69.50%\n",
      "Epoch [92/100], Step [17/60], Loss: 0.9915, batch time: 0.71, accuracy:  68.30%\n",
      "Epoch [92/100], Step [18/60], Loss: 1.0148, batch time: 0.56, accuracy:  66.70%\n",
      "Epoch [92/100], Step [19/60], Loss: 0.9997, batch time: 0.72, accuracy:  69.40%\n",
      "Epoch [92/100], Step [20/60], Loss: 0.9606, batch time: 0.69, accuracy:  70.50%\n",
      "Epoch [92/100], Step [21/60], Loss: 0.9177, batch time: 0.83, accuracy:  69.90%\n",
      "Epoch [92/100], Step [22/60], Loss: 0.9124, batch time: 0.91, accuracy:  71.00%\n",
      "Epoch [92/100], Step [23/60], Loss: 0.9929, batch time: 0.67, accuracy:  67.70%\n",
      "Epoch [92/100], Step [24/60], Loss: 1.0211, batch time: 0.58, accuracy:  69.80%\n",
      "Epoch [92/100], Step [25/60], Loss: 0.9852, batch time: 0.70, accuracy:  68.60%\n",
      "Epoch [92/100], Step [26/60], Loss: 0.9222, batch time: 0.66, accuracy:  68.70%\n",
      "Epoch [92/100], Step [27/60], Loss: 0.9619, batch time: 0.70, accuracy:  72.00%\n",
      "Epoch [92/100], Step [28/60], Loss: 0.9534, batch time: 0.70, accuracy:  68.40%\n",
      "Epoch [92/100], Step [29/60], Loss: 0.9748, batch time: 0.62, accuracy:  67.90%\n",
      "Epoch [92/100], Step [30/60], Loss: 0.9042, batch time: 0.70, accuracy:  70.80%\n",
      "Epoch [92/100], Step [31/60], Loss: 1.0281, batch time: 0.70, accuracy:  69.70%\n",
      "Epoch [92/100], Step [32/60], Loss: 0.9759, batch time: 0.69, accuracy:  70.80%\n",
      "Epoch [92/100], Step [33/60], Loss: 1.0361, batch time: 0.69, accuracy:  68.80%\n",
      "Epoch [92/100], Step [34/60], Loss: 0.9904, batch time: 0.69, accuracy:  70.40%\n",
      "Epoch [92/100], Step [35/60], Loss: 0.9607, batch time: 0.69, accuracy:  70.90%\n",
      "Epoch [92/100], Step [36/60], Loss: 0.9643, batch time: 0.71, accuracy:  66.20%\n",
      "Epoch [92/100], Step [37/60], Loss: 0.9711, batch time: 0.73, accuracy:  68.70%\n",
      "Epoch [92/100], Step [38/60], Loss: 0.9950, batch time: 0.84, accuracy:  67.90%\n",
      "Epoch [92/100], Step [39/60], Loss: 0.9499, batch time: 0.83, accuracy:  69.90%\n",
      "Epoch [92/100], Step [40/60], Loss: 0.9688, batch time: 0.83, accuracy:  69.00%\n",
      "Epoch [92/100], Step [41/60], Loss: 0.9108, batch time: 0.83, accuracy:  69.00%\n",
      "Epoch [92/100], Step [42/60], Loss: 0.9338, batch time: 0.83, accuracy:  70.60%\n",
      "Epoch [92/100], Step [43/60], Loss: 0.8849, batch time: 0.83, accuracy:  72.20%\n",
      "Epoch [92/100], Step [44/60], Loss: 1.0698, batch time: 0.91, accuracy:  69.30%\n",
      "Epoch [92/100], Step [45/60], Loss: 1.0160, batch time: 0.83, accuracy:  69.30%\n",
      "Epoch [92/100], Step [46/60], Loss: 0.9436, batch time: 0.83, accuracy:  71.30%\n",
      "Epoch [92/100], Step [47/60], Loss: 1.0285, batch time: 0.83, accuracy:  70.50%\n",
      "Epoch [92/100], Step [48/60], Loss: 1.0192, batch time: 0.83, accuracy:  68.40%\n",
      "Epoch [92/100], Step [49/60], Loss: 0.9694, batch time: 0.77, accuracy:  71.60%\n",
      "Epoch [92/100], Step [50/60], Loss: 1.0295, batch time: 0.68, accuracy:  67.30%\n",
      "Epoch [92/100], Step [51/60], Loss: 0.9344, batch time: 0.69, accuracy:  71.60%\n",
      "Epoch [92/100], Step [52/60], Loss: 0.9569, batch time: 0.69, accuracy:  71.20%\n",
      "Epoch [92/100], Step [53/60], Loss: 1.0240, batch time: 0.68, accuracy:  70.80%\n",
      "Epoch [92/100], Step [54/60], Loss: 0.9601, batch time: 0.68, accuracy:  70.70%\n",
      "Epoch [92/100], Step [55/60], Loss: 0.9284, batch time: 0.68, accuracy:  69.50%\n",
      "Epoch [92/100], Step [56/60], Loss: 0.9595, batch time: 0.69, accuracy:  69.20%\n",
      "Epoch [92/100], Step [57/60], Loss: 0.9653, batch time: 0.68, accuracy:  69.60%\n",
      "Epoch [92/100], Step [58/60], Loss: 0.9184, batch time: 0.68, accuracy:  70.40%\n",
      "Epoch [92/100], Step [59/60], Loss: 0.9276, batch time: 0.68, accuracy:  71.70%\n",
      "Epoch [92/100], Step [60/60], Loss: 0.9055, batch time: 0.69, accuracy:  73.20%\n",
      "Epoch [93/100], Step [1/60], Loss: 1.0276, batch time: 0.44, accuracy:  69.70%\n",
      "Epoch [93/100], Step [2/60], Loss: 0.9256, batch time: 0.42, accuracy:  71.30%\n",
      "Epoch [93/100], Step [3/60], Loss: 1.0208, batch time: 0.45, accuracy:  68.60%\n",
      "Epoch [93/100], Step [4/60], Loss: 0.9187, batch time: 0.72, accuracy:  70.00%\n",
      "Epoch [93/100], Step [5/60], Loss: 0.9743, batch time: 0.74, accuracy:  68.40%\n",
      "Epoch [93/100], Step [6/60], Loss: 0.9619, batch time: 0.72, accuracy:  67.50%\n",
      "Epoch [93/100], Step [7/60], Loss: 0.9088, batch time: 0.79, accuracy:  70.80%\n",
      "Epoch [93/100], Step [8/60], Loss: 0.8669, batch time: 0.83, accuracy:  71.80%\n",
      "Epoch [93/100], Step [9/60], Loss: 0.9723, batch time: 0.79, accuracy:  69.00%\n",
      "Epoch [93/100], Step [10/60], Loss: 0.9714, batch time: 0.87, accuracy:  68.10%\n",
      "Epoch [93/100], Step [11/60], Loss: 0.9856, batch time: 0.87, accuracy:  69.80%\n",
      "Epoch [93/100], Step [12/60], Loss: 0.9411, batch time: 0.84, accuracy:  69.20%\n",
      "Epoch [93/100], Step [13/60], Loss: 1.0340, batch time: 0.71, accuracy:  68.40%\n",
      "Epoch [93/100], Step [14/60], Loss: 0.9686, batch time: 0.71, accuracy:  69.30%\n",
      "Epoch [93/100], Step [15/60], Loss: 0.9847, batch time: 0.68, accuracy:  68.20%\n",
      "Epoch [93/100], Step [16/60], Loss: 0.9167, batch time: 0.57, accuracy:  68.30%\n",
      "Epoch [93/100], Step [17/60], Loss: 0.9016, batch time: 0.60, accuracy:  71.60%\n",
      "Epoch [93/100], Step [18/60], Loss: 1.0085, batch time: 0.70, accuracy:  70.10%\n",
      "Epoch [93/100], Step [19/60], Loss: 0.9355, batch time: 0.69, accuracy:  68.70%\n",
      "Epoch [93/100], Step [20/60], Loss: 0.9253, batch time: 0.69, accuracy:  71.90%\n",
      "Epoch [93/100], Step [21/60], Loss: 0.9346, batch time: 0.68, accuracy:  70.50%\n",
      "Epoch [93/100], Step [22/60], Loss: 0.9742, batch time: 0.57, accuracy:  68.50%\n",
      "Epoch [93/100], Step [23/60], Loss: 1.0474, batch time: 0.71, accuracy:  69.00%\n",
      "Epoch [93/100], Step [24/60], Loss: 1.0128, batch time: 0.63, accuracy:  70.50%\n",
      "Epoch [93/100], Step [25/60], Loss: 0.8980, batch time: 0.67, accuracy:  73.60%\n",
      "Epoch [93/100], Step [26/60], Loss: 0.9794, batch time: 0.73, accuracy:  70.00%\n",
      "Epoch [93/100], Step [27/60], Loss: 1.0473, batch time: 0.71, accuracy:  67.50%\n",
      "Epoch [93/100], Step [28/60], Loss: 1.0269, batch time: 0.71, accuracy:  66.20%\n",
      "Epoch [93/100], Step [29/60], Loss: 0.9956, batch time: 0.71, accuracy:  68.10%\n",
      "Epoch [93/100], Step [30/60], Loss: 0.9501, batch time: 0.71, accuracy:  70.10%\n",
      "Epoch [93/100], Step [31/60], Loss: 1.0217, batch time: 0.71, accuracy:  71.10%\n",
      "Epoch [93/100], Step [32/60], Loss: 0.9164, batch time: 0.77, accuracy:  68.70%\n",
      "Epoch [93/100], Step [33/60], Loss: 0.9658, batch time: 0.86, accuracy:  67.40%\n",
      "Epoch [93/100], Step [34/60], Loss: 0.8936, batch time: 0.83, accuracy:  69.00%\n",
      "Epoch [93/100], Step [35/60], Loss: 0.9144, batch time: 0.85, accuracy:  71.70%\n",
      "Epoch [93/100], Step [36/60], Loss: 0.9456, batch time: 0.85, accuracy:  71.00%\n",
      "Epoch [93/100], Step [37/60], Loss: 0.9537, batch time: 0.75, accuracy:  69.20%\n",
      "Epoch [93/100], Step [38/60], Loss: 0.9680, batch time: 0.65, accuracy:  69.20%\n",
      "Epoch [93/100], Step [39/60], Loss: 0.9838, batch time: 0.64, accuracy:  68.30%\n",
      "Epoch [93/100], Step [40/60], Loss: 0.9345, batch time: 0.65, accuracy:  70.40%\n",
      "Epoch [93/100], Step [41/60], Loss: 0.9458, batch time: 0.65, accuracy:  71.70%\n",
      "Epoch [93/100], Step [42/60], Loss: 0.9624, batch time: 0.65, accuracy:  71.30%\n",
      "Epoch [93/100], Step [43/60], Loss: 0.8485, batch time: 0.68, accuracy:  71.20%\n",
      "Epoch [93/100], Step [44/60], Loss: 0.9865, batch time: 0.70, accuracy:  70.30%\n",
      "Epoch [93/100], Step [45/60], Loss: 0.9291, batch time: 0.67, accuracy:  69.70%\n",
      "Epoch [93/100], Step [46/60], Loss: 0.9977, batch time: 0.68, accuracy:  69.30%\n",
      "Epoch [93/100], Step [47/60], Loss: 1.0140, batch time: 0.70, accuracy:  69.20%\n",
      "Epoch [93/100], Step [48/60], Loss: 1.0101, batch time: 0.67, accuracy:  68.00%\n",
      "Epoch [93/100], Step [49/60], Loss: 1.0451, batch time: 0.70, accuracy:  67.80%\n",
      "Epoch [93/100], Step [50/60], Loss: 0.9388, batch time: 0.72, accuracy:  71.00%\n",
      "Epoch [93/100], Step [51/60], Loss: 0.9413, batch time: 0.60, accuracy:  70.20%\n",
      "Epoch [93/100], Step [52/60], Loss: 0.9490, batch time: 0.59, accuracy:  70.20%\n",
      "Epoch [93/100], Step [53/60], Loss: 0.9211, batch time: 0.79, accuracy:  68.80%\n",
      "Epoch [93/100], Step [54/60], Loss: 1.0027, batch time: 0.78, accuracy:  70.20%\n",
      "Epoch [93/100], Step [55/60], Loss: 0.9322, batch time: 0.80, accuracy:  69.60%\n",
      "Epoch [93/100], Step [56/60], Loss: 0.9614, batch time: 0.88, accuracy:  69.80%\n",
      "Epoch [93/100], Step [57/60], Loss: 0.9276, batch time: 0.83, accuracy:  70.30%\n",
      "Epoch [93/100], Step [58/60], Loss: 0.9611, batch time: 0.72, accuracy:  69.90%\n",
      "Epoch [93/100], Step [59/60], Loss: 0.9999, batch time: 0.71, accuracy:  69.60%\n",
      "Epoch [93/100], Step [60/60], Loss: 1.0383, batch time: 0.71, accuracy:  70.00%\n",
      "Epoch [94/100], Step [1/60], Loss: 0.9790, batch time: 0.71, accuracy:  69.60%\n",
      "Epoch [94/100], Step [2/60], Loss: 1.0043, batch time: 0.72, accuracy:  68.50%\n",
      "Epoch [94/100], Step [3/60], Loss: 0.9440, batch time: 0.71, accuracy:  70.80%\n",
      "Epoch [94/100], Step [4/60], Loss: 0.9255, batch time: 0.50, accuracy:  70.30%\n",
      "Epoch [94/100], Step [5/60], Loss: 0.9134, batch time: 0.43, accuracy:  69.10%\n",
      "Epoch [94/100], Step [6/60], Loss: 0.9625, batch time: 0.43, accuracy:  67.80%\n",
      "Epoch [94/100], Step [7/60], Loss: 0.9768, batch time: 0.45, accuracy:  70.90%\n",
      "Epoch [94/100], Step [8/60], Loss: 1.0155, batch time: 0.43, accuracy:  68.10%\n",
      "Epoch [94/100], Step [9/60], Loss: 0.9994, batch time: 0.43, accuracy:  69.00%\n",
      "Epoch [94/100], Step [10/60], Loss: 0.9984, batch time: 0.45, accuracy:  70.30%\n",
      "Epoch [94/100], Step [11/60], Loss: 0.9534, batch time: 0.43, accuracy:  71.00%\n",
      "Epoch [94/100], Step [12/60], Loss: 0.9153, batch time: 0.46, accuracy:  70.60%\n",
      "Epoch [94/100], Step [13/60], Loss: 1.0150, batch time: 0.48, accuracy:  68.50%\n",
      "Epoch [94/100], Step [14/60], Loss: 0.9934, batch time: 0.46, accuracy:  68.60%\n",
      "Epoch [94/100], Step [15/60], Loss: 0.9497, batch time: 0.47, accuracy:  70.30%\n",
      "Epoch [94/100], Step [16/60], Loss: 0.9706, batch time: 0.46, accuracy:  68.80%\n",
      "Epoch [94/100], Step [17/60], Loss: 0.9447, batch time: 0.47, accuracy:  70.10%\n",
      "Epoch [94/100], Step [18/60], Loss: 0.9424, batch time: 0.47, accuracy:  70.30%\n",
      "Epoch [94/100], Step [19/60], Loss: 0.9489, batch time: 0.46, accuracy:  69.10%\n",
      "Epoch [94/100], Step [20/60], Loss: 0.9529, batch time: 0.47, accuracy:  69.00%\n",
      "Epoch [94/100], Step [21/60], Loss: 0.9807, batch time: 0.48, accuracy:  68.10%\n",
      "Epoch [94/100], Step [22/60], Loss: 0.9955, batch time: 0.46, accuracy:  69.60%\n",
      "Epoch [94/100], Step [23/60], Loss: 1.0286, batch time: 0.48, accuracy:  70.80%\n",
      "Epoch [94/100], Step [24/60], Loss: 1.0061, batch time: 0.46, accuracy:  71.00%\n",
      "Epoch [94/100], Step [25/60], Loss: 0.9641, batch time: 0.47, accuracy:  71.80%\n",
      "Epoch [94/100], Step [26/60], Loss: 0.8900, batch time: 0.47, accuracy:  71.50%\n",
      "Epoch [94/100], Step [27/60], Loss: 0.9471, batch time: 0.46, accuracy:  70.10%\n",
      "Epoch [94/100], Step [28/60], Loss: 0.9139, batch time: 0.47, accuracy:  69.60%\n",
      "Epoch [94/100], Step [29/60], Loss: 0.9537, batch time: 0.47, accuracy:  68.60%\n",
      "Epoch [94/100], Step [30/60], Loss: 0.9566, batch time: 0.49, accuracy:  69.90%\n",
      "Epoch [94/100], Step [31/60], Loss: 0.8966, batch time: 0.47, accuracy:  70.90%\n",
      "Epoch [94/100], Step [32/60], Loss: 0.9808, batch time: 0.47, accuracy:  68.30%\n",
      "Epoch [94/100], Step [33/60], Loss: 0.9004, batch time: 0.47, accuracy:  71.90%\n",
      "Epoch [94/100], Step [34/60], Loss: 0.9063, batch time: 0.47, accuracy:  71.40%\n",
      "Epoch [94/100], Step [35/60], Loss: 0.9270, batch time: 0.46, accuracy:  68.90%\n",
      "Epoch [94/100], Step [36/60], Loss: 0.8951, batch time: 0.53, accuracy:  68.40%\n",
      "Epoch [94/100], Step [37/60], Loss: 0.9304, batch time: 0.47, accuracy:  71.60%\n",
      "Epoch [94/100], Step [38/60], Loss: 1.0022, batch time: 0.47, accuracy:  67.30%\n",
      "Epoch [94/100], Step [39/60], Loss: 1.0350, batch time: 0.49, accuracy:  71.10%\n",
      "Epoch [94/100], Step [40/60], Loss: 0.8756, batch time: 0.46, accuracy:  70.70%\n",
      "Epoch [94/100], Step [41/60], Loss: 0.9040, batch time: 0.47, accuracy:  70.80%\n",
      "Epoch [94/100], Step [42/60], Loss: 0.9291, batch time: 0.47, accuracy:  68.90%\n",
      "Epoch [94/100], Step [43/60], Loss: 0.9584, batch time: 0.58, accuracy:  68.70%\n",
      "Epoch [94/100], Step [44/60], Loss: 1.0046, batch time: 0.47, accuracy:  69.50%\n",
      "Epoch [94/100], Step [45/60], Loss: 0.9458, batch time: 0.46, accuracy:  68.80%\n",
      "Epoch [94/100], Step [46/60], Loss: 0.9673, batch time: 0.47, accuracy:  70.80%\n",
      "Epoch [94/100], Step [47/60], Loss: 0.9868, batch time: 0.48, accuracy:  70.10%\n",
      "Epoch [94/100], Step [48/60], Loss: 1.0141, batch time: 0.47, accuracy:  69.00%\n",
      "Epoch [94/100], Step [49/60], Loss: 0.9212, batch time: 0.47, accuracy:  71.40%\n",
      "Epoch [94/100], Step [50/60], Loss: 0.9233, batch time: 0.47, accuracy:  70.70%\n",
      "Epoch [94/100], Step [51/60], Loss: 1.0181, batch time: 0.47, accuracy:  70.10%\n",
      "Epoch [94/100], Step [52/60], Loss: 1.0215, batch time: 0.47, accuracy:  68.70%\n",
      "Epoch [94/100], Step [53/60], Loss: 0.9925, batch time: 0.46, accuracy:  66.30%\n",
      "Epoch [94/100], Step [54/60], Loss: 0.9123, batch time: 0.47, accuracy:  69.60%\n",
      "Epoch [94/100], Step [55/60], Loss: 0.9281, batch time: 0.47, accuracy:  69.00%\n",
      "Epoch [94/100], Step [56/60], Loss: 1.0364, batch time: 0.50, accuracy:  68.70%\n",
      "Epoch [94/100], Step [57/60], Loss: 0.9563, batch time: 0.46, accuracy:  69.70%\n",
      "Epoch [94/100], Step [58/60], Loss: 1.0092, batch time: 0.48, accuracy:  69.10%\n",
      "Epoch [94/100], Step [59/60], Loss: 0.9374, batch time: 0.47, accuracy:  68.20%\n",
      "Epoch [94/100], Step [60/60], Loss: 0.9320, batch time: 0.46, accuracy:  71.40%\n",
      "Epoch [95/100], Step [1/60], Loss: 0.9912, batch time: 0.49, accuracy:  68.90%\n",
      "Epoch [95/100], Step [2/60], Loss: 0.9728, batch time: 0.46, accuracy:  68.30%\n",
      "Epoch [95/100], Step [3/60], Loss: 0.9875, batch time: 0.47, accuracy:  69.00%\n",
      "Epoch [95/100], Step [4/60], Loss: 1.0405, batch time: 0.47, accuracy:  69.40%\n",
      "Epoch [95/100], Step [5/60], Loss: 0.9997, batch time: 0.49, accuracy:  67.90%\n",
      "Epoch [95/100], Step [6/60], Loss: 0.9867, batch time: 0.48, accuracy:  68.50%\n",
      "Epoch [95/100], Step [7/60], Loss: 0.9210, batch time: 0.46, accuracy:  69.80%\n",
      "Epoch [95/100], Step [8/60], Loss: 0.9056, batch time: 0.47, accuracy:  71.40%\n",
      "Epoch [95/100], Step [9/60], Loss: 0.9223, batch time: 0.47, accuracy:  70.90%\n",
      "Epoch [95/100], Step [10/60], Loss: 0.9125, batch time: 0.46, accuracy:  71.10%\n",
      "Epoch [95/100], Step [11/60], Loss: 0.9516, batch time: 0.48, accuracy:  68.80%\n",
      "Epoch [95/100], Step [12/60], Loss: 0.9517, batch time: 0.53, accuracy:  69.30%\n",
      "Epoch [95/100], Step [13/60], Loss: 0.9706, batch time: 0.46, accuracy:  69.10%\n",
      "Epoch [95/100], Step [14/60], Loss: 0.8987, batch time: 0.49, accuracy:  70.50%\n",
      "Epoch [95/100], Step [15/60], Loss: 0.9735, batch time: 0.46, accuracy:  71.70%\n",
      "Epoch [95/100], Step [16/60], Loss: 0.9019, batch time: 0.47, accuracy:  71.40%\n",
      "Epoch [95/100], Step [17/60], Loss: 0.9278, batch time: 0.47, accuracy:  68.70%\n",
      "Epoch [95/100], Step [18/60], Loss: 0.8990, batch time: 0.46, accuracy:  72.10%\n",
      "Epoch [95/100], Step [19/60], Loss: 0.9636, batch time: 0.48, accuracy:  71.70%\n",
      "Epoch [95/100], Step [20/60], Loss: 0.9288, batch time: 0.46, accuracy:  71.70%\n",
      "Epoch [95/100], Step [21/60], Loss: 0.9039, batch time: 0.47, accuracy:  73.20%\n",
      "Epoch [95/100], Step [22/60], Loss: 0.9724, batch time: 0.55, accuracy:  69.40%\n",
      "Epoch [95/100], Step [23/60], Loss: 0.9831, batch time: 0.77, accuracy:  67.50%\n",
      "Epoch [95/100], Step [24/60], Loss: 0.9226, batch time: 0.85, accuracy:  70.40%\n",
      "Epoch [95/100], Step [25/60], Loss: 0.9324, batch time: 0.70, accuracy:  70.00%\n",
      "Epoch [95/100], Step [26/60], Loss: 0.9526, batch time: 0.70, accuracy:  69.90%\n",
      "Epoch [95/100], Step [27/60], Loss: 0.9814, batch time: 0.71, accuracy:  69.30%\n",
      "Epoch [95/100], Step [28/60], Loss: 0.9991, batch time: 0.73, accuracy:  68.80%\n",
      "Epoch [95/100], Step [29/60], Loss: 1.0040, batch time: 0.71, accuracy:  67.80%\n",
      "Epoch [95/100], Step [30/60], Loss: 0.9477, batch time: 0.72, accuracy:  70.80%\n",
      "Epoch [95/100], Step [31/60], Loss: 0.9755, batch time: 0.71, accuracy:  70.80%\n",
      "Epoch [95/100], Step [32/60], Loss: 0.8356, batch time: 0.58, accuracy:  72.70%\n",
      "Epoch [95/100], Step [33/60], Loss: 0.9570, batch time: 0.71, accuracy:  68.80%\n",
      "Epoch [95/100], Step [34/60], Loss: 0.9409, batch time: 0.62, accuracy:  70.60%\n",
      "Epoch [95/100], Step [35/60], Loss: 0.9543, batch time: 0.71, accuracy:  69.40%\n",
      "Epoch [95/100], Step [36/60], Loss: 0.9632, batch time: 0.73, accuracy:  67.50%\n",
      "Epoch [95/100], Step [37/60], Loss: 0.9618, batch time: 0.70, accuracy:  69.60%\n",
      "Epoch [95/100], Step [38/60], Loss: 0.9637, batch time: 0.66, accuracy:  69.90%\n",
      "Epoch [95/100], Step [39/60], Loss: 0.9447, batch time: 0.74, accuracy:  70.70%\n",
      "Epoch [95/100], Step [40/60], Loss: 0.9298, batch time: 0.75, accuracy:  71.90%\n",
      "Epoch [95/100], Step [41/60], Loss: 1.0020, batch time: 0.72, accuracy:  69.00%\n",
      "Epoch [95/100], Step [42/60], Loss: 0.9338, batch time: 0.75, accuracy:  69.80%\n",
      "Epoch [95/100], Step [43/60], Loss: 0.9720, batch time: 0.58, accuracy:  68.50%\n",
      "Epoch [95/100], Step [44/60], Loss: 0.8929, batch time: 0.78, accuracy:  70.90%\n",
      "Epoch [95/100], Step [45/60], Loss: 0.8876, batch time: 0.87, accuracy:  71.20%\n",
      "Epoch [95/100], Step [46/60], Loss: 0.9937, batch time: 0.80, accuracy:  69.60%\n",
      "Epoch [95/100], Step [47/60], Loss: 0.9771, batch time: 0.65, accuracy:  70.20%\n",
      "Epoch [95/100], Step [48/60], Loss: 0.9430, batch time: 0.65, accuracy:  68.90%\n",
      "Epoch [95/100], Step [49/60], Loss: 0.9251, batch time: 0.71, accuracy:  70.30%\n",
      "Epoch [95/100], Step [50/60], Loss: 1.0195, batch time: 0.69, accuracy:  69.40%\n",
      "Epoch [95/100], Step [51/60], Loss: 0.9358, batch time: 0.70, accuracy:  70.90%\n",
      "Epoch [95/100], Step [52/60], Loss: 1.0687, batch time: 0.67, accuracy:  68.80%\n",
      "Epoch [95/100], Step [53/60], Loss: 0.9097, batch time: 0.68, accuracy:  70.10%\n",
      "Epoch [95/100], Step [54/60], Loss: 0.9331, batch time: 0.72, accuracy:  69.20%\n",
      "Epoch [95/100], Step [55/60], Loss: 0.9022, batch time: 0.68, accuracy:  72.60%\n",
      "Epoch [95/100], Step [56/60], Loss: 0.8885, batch time: 0.72, accuracy:  71.90%\n",
      "Epoch [95/100], Step [57/60], Loss: 0.9566, batch time: 0.71, accuracy:  70.90%\n",
      "Epoch [95/100], Step [58/60], Loss: 0.9697, batch time: 0.72, accuracy:  67.90%\n",
      "Epoch [95/100], Step [59/60], Loss: 0.9271, batch time: 0.71, accuracy:  69.10%\n",
      "Epoch [95/100], Step [60/60], Loss: 0.9373, batch time: 0.74, accuracy:  71.70%\n",
      "Epoch [96/100], Step [1/60], Loss: 0.9875, batch time: 0.66, accuracy:  69.90%\n",
      "Epoch [96/100], Step [2/60], Loss: 1.0436, batch time: 0.74, accuracy:  67.90%\n",
      "Epoch [96/100], Step [3/60], Loss: 0.9150, batch time: 0.89, accuracy:  70.60%\n",
      "Epoch [96/100], Step [4/60], Loss: 0.9530, batch time: 0.82, accuracy:  69.90%\n",
      "Epoch [96/100], Step [5/60], Loss: 0.9669, batch time: 0.75, accuracy:  69.90%\n",
      "Epoch [96/100], Step [6/60], Loss: 0.9860, batch time: 0.80, accuracy:  68.70%\n",
      "Epoch [96/100], Step [7/60], Loss: 0.9223, batch time: 0.82, accuracy:  69.30%\n",
      "Epoch [96/100], Step [8/60], Loss: 0.9227, batch time: 0.84, accuracy:  71.10%\n",
      "Epoch [96/100], Step [9/60], Loss: 1.0312, batch time: 0.85, accuracy:  70.00%\n",
      "Epoch [96/100], Step [10/60], Loss: 0.9306, batch time: 0.83, accuracy:  73.00%\n",
      "Epoch [96/100], Step [11/60], Loss: 0.9674, batch time: 0.71, accuracy:  70.60%\n",
      "Epoch [96/100], Step [12/60], Loss: 0.8706, batch time: 0.77, accuracy:  71.40%\n",
      "Epoch [96/100], Step [13/60], Loss: 0.8701, batch time: 0.69, accuracy:  72.40%\n",
      "Epoch [96/100], Step [14/60], Loss: 0.8857, batch time: 0.67, accuracy:  70.90%\n",
      "Epoch [96/100], Step [15/60], Loss: 0.9244, batch time: 0.69, accuracy:  70.60%\n",
      "Epoch [96/100], Step [16/60], Loss: 0.9536, batch time: 0.69, accuracy:  70.10%\n",
      "Epoch [96/100], Step [17/60], Loss: 0.9217, batch time: 0.62, accuracy:  70.60%\n",
      "Epoch [96/100], Step [18/60], Loss: 0.9643, batch time: 0.70, accuracy:  69.50%\n",
      "Epoch [96/100], Step [19/60], Loss: 0.9274, batch time: 0.69, accuracy:  69.90%\n",
      "Epoch [96/100], Step [20/60], Loss: 0.9878, batch time: 0.70, accuracy:  69.10%\n",
      "Epoch [96/100], Step [21/60], Loss: 0.9618, batch time: 0.51, accuracy:  69.60%\n",
      "Epoch [96/100], Step [22/60], Loss: 0.9784, batch time: 0.44, accuracy:  67.80%\n",
      "Epoch [96/100], Step [23/60], Loss: 0.9648, batch time: 0.66, accuracy:  66.30%\n",
      "Epoch [96/100], Step [24/60], Loss: 0.9682, batch time: 0.70, accuracy:  70.20%\n",
      "Epoch [96/100], Step [25/60], Loss: 0.9304, batch time: 0.71, accuracy:  70.20%\n",
      "Epoch [96/100], Step [26/60], Loss: 0.9699, batch time: 0.74, accuracy:  70.20%\n",
      "Epoch [96/100], Step [27/60], Loss: 0.9936, batch time: 0.74, accuracy:  67.30%\n",
      "Epoch [96/100], Step [28/60], Loss: 0.9938, batch time: 0.75, accuracy:  66.70%\n",
      "Epoch [96/100], Step [29/60], Loss: 0.9390, batch time: 0.45, accuracy:  70.00%\n",
      "Epoch [96/100], Step [30/60], Loss: 0.9804, batch time: 0.83, accuracy:  69.20%\n",
      "Epoch [96/100], Step [31/60], Loss: 0.8347, batch time: 0.84, accuracy:  74.40%\n",
      "Epoch [96/100], Step [32/60], Loss: 0.9405, batch time: 0.86, accuracy:  69.20%\n",
      "Epoch [96/100], Step [33/60], Loss: 1.0167, batch time: 0.83, accuracy:  69.10%\n",
      "Epoch [96/100], Step [34/60], Loss: 1.0082, batch time: 0.85, accuracy:  69.60%\n",
      "Epoch [96/100], Step [35/60], Loss: 0.9597, batch time: 0.68, accuracy:  71.10%\n",
      "Epoch [96/100], Step [36/60], Loss: 0.9116, batch time: 0.66, accuracy:  72.60%\n",
      "Epoch [96/100], Step [37/60], Loss: 0.9733, batch time: 0.73, accuracy:  69.10%\n",
      "Epoch [96/100], Step [38/60], Loss: 0.9396, batch time: 0.66, accuracy:  71.10%\n",
      "Epoch [96/100], Step [39/60], Loss: 0.9328, batch time: 0.68, accuracy:  70.40%\n",
      "Epoch [96/100], Step [40/60], Loss: 0.9205, batch time: 0.67, accuracy:  68.80%\n",
      "Epoch [96/100], Step [41/60], Loss: 0.9439, batch time: 0.69, accuracy:  69.60%\n",
      "Epoch [96/100], Step [42/60], Loss: 0.9732, batch time: 0.71, accuracy:  70.10%\n",
      "Epoch [96/100], Step [43/60], Loss: 0.9284, batch time: 0.70, accuracy:  70.30%\n",
      "Epoch [96/100], Step [44/60], Loss: 0.8877, batch time: 0.69, accuracy:  71.10%\n",
      "Epoch [96/100], Step [45/60], Loss: 0.9317, batch time: 0.67, accuracy:  72.30%\n",
      "Epoch [96/100], Step [46/60], Loss: 0.8999, batch time: 0.69, accuracy:  72.90%\n",
      "Epoch [96/100], Step [47/60], Loss: 0.8827, batch time: 0.63, accuracy:  71.30%\n",
      "Epoch [96/100], Step [48/60], Loss: 0.9129, batch time: 0.75, accuracy:  69.80%\n",
      "Epoch [96/100], Step [49/60], Loss: 0.9297, batch time: 0.74, accuracy:  69.60%\n",
      "Epoch [96/100], Step [50/60], Loss: 0.9418, batch time: 0.73, accuracy:  69.40%\n",
      "Epoch [96/100], Step [51/60], Loss: 0.9301, batch time: 0.75, accuracy:  71.40%\n",
      "Epoch [96/100], Step [52/60], Loss: 0.9663, batch time: 0.79, accuracy:  67.70%\n",
      "Epoch [96/100], Step [53/60], Loss: 0.9457, batch time: 0.83, accuracy:  69.80%\n",
      "Epoch [96/100], Step [54/60], Loss: 0.9685, batch time: 0.85, accuracy:  71.40%\n",
      "Epoch [96/100], Step [55/60], Loss: 0.9413, batch time: 0.78, accuracy:  70.80%\n",
      "Epoch [96/100], Step [56/60], Loss: 0.9450, batch time: 0.69, accuracy:  69.50%\n",
      "Epoch [96/100], Step [57/60], Loss: 0.9279, batch time: 0.69, accuracy:  71.20%\n",
      "Epoch [96/100], Step [58/60], Loss: 0.9400, batch time: 0.69, accuracy:  73.00%\n",
      "Epoch [96/100], Step [59/60], Loss: 0.9631, batch time: 0.69, accuracy:  69.90%\n",
      "Epoch [96/100], Step [60/60], Loss: 0.8735, batch time: 0.67, accuracy:  73.10%\n",
      "Epoch [97/100], Step [1/60], Loss: 0.9748, batch time: 0.71, accuracy:  70.40%\n",
      "Epoch [97/100], Step [2/60], Loss: 0.9421, batch time: 0.70, accuracy:  70.70%\n",
      "Epoch [97/100], Step [3/60], Loss: 0.9237, batch time: 0.62, accuracy:  70.20%\n",
      "Epoch [97/100], Step [4/60], Loss: 0.9259, batch time: 0.70, accuracy:  70.30%\n",
      "Epoch [97/100], Step [5/60], Loss: 0.9625, batch time: 0.60, accuracy:  70.40%\n",
      "Epoch [97/100], Step [6/60], Loss: 0.8896, batch time: 0.69, accuracy:  71.70%\n",
      "Epoch [97/100], Step [7/60], Loss: 0.9464, batch time: 0.69, accuracy:  69.60%\n",
      "Epoch [97/100], Step [8/60], Loss: 0.9317, batch time: 0.69, accuracy:  69.10%\n",
      "Epoch [97/100], Step [9/60], Loss: 0.9363, batch time: 0.70, accuracy:  69.80%\n",
      "Epoch [97/100], Step [10/60], Loss: 0.9628, batch time: 0.70, accuracy:  71.90%\n",
      "Epoch [97/100], Step [11/60], Loss: 0.9725, batch time: 0.64, accuracy:  69.70%\n",
      "Epoch [97/100], Step [12/60], Loss: 0.9035, batch time: 1.03, accuracy:  71.40%\n",
      "Epoch [97/100], Step [13/60], Loss: 0.8730, batch time: 0.69, accuracy:  73.00%\n",
      "Epoch [97/100], Step [14/60], Loss: 0.9458, batch time: 0.67, accuracy:  70.70%\n",
      "Epoch [97/100], Step [15/60], Loss: 0.9799, batch time: 0.69, accuracy:  71.60%\n",
      "Epoch [97/100], Step [16/60], Loss: 0.9147, batch time: 0.49, accuracy:  69.60%\n",
      "Epoch [97/100], Step [17/60], Loss: 0.9121, batch time: 0.43, accuracy:  70.20%\n",
      "Epoch [97/100], Step [18/60], Loss: 1.0276, batch time: 0.43, accuracy:  69.90%\n",
      "Epoch [97/100], Step [19/60], Loss: 0.9869, batch time: 0.45, accuracy:  69.20%\n",
      "Epoch [97/100], Step [20/60], Loss: 0.9605, batch time: 0.43, accuracy:  69.00%\n",
      "Epoch [97/100], Step [21/60], Loss: 0.9040, batch time: 0.43, accuracy:  71.30%\n",
      "Epoch [97/100], Step [22/60], Loss: 0.9155, batch time: 0.43, accuracy:  71.30%\n",
      "Epoch [97/100], Step [23/60], Loss: 0.9453, batch time: 0.43, accuracy:  70.50%\n",
      "Epoch [97/100], Step [24/60], Loss: 0.9249, batch time: 0.43, accuracy:  69.80%\n",
      "Epoch [97/100], Step [25/60], Loss: 1.0053, batch time: 0.60, accuracy:  68.70%\n",
      "Epoch [97/100], Step [26/60], Loss: 0.9550, batch time: 0.61, accuracy:  71.30%\n",
      "Epoch [97/100], Step [27/60], Loss: 0.8747, batch time: 0.42, accuracy:  72.10%\n",
      "Epoch [97/100], Step [28/60], Loss: 0.9449, batch time: 0.47, accuracy:  71.00%\n",
      "Epoch [97/100], Step [29/60], Loss: 0.9023, batch time: 0.46, accuracy:  71.20%\n",
      "Epoch [97/100], Step [30/60], Loss: 0.9521, batch time: 0.46, accuracy:  70.20%\n",
      "Epoch [97/100], Step [31/60], Loss: 0.9386, batch time: 0.46, accuracy:  69.80%\n",
      "Epoch [97/100], Step [32/60], Loss: 0.9891, batch time: 0.46, accuracy:  66.80%\n",
      "Epoch [97/100], Step [33/60], Loss: 1.0260, batch time: 0.47, accuracy:  68.10%\n",
      "Epoch [97/100], Step [34/60], Loss: 0.9184, batch time: 0.46, accuracy:  71.40%\n",
      "Epoch [97/100], Step [35/60], Loss: 0.9133, batch time: 0.46, accuracy:  70.20%\n",
      "Epoch [97/100], Step [36/60], Loss: 0.9450, batch time: 0.46, accuracy:  68.00%\n",
      "Epoch [97/100], Step [37/60], Loss: 0.8204, batch time: 0.48, accuracy:  72.70%\n",
      "Epoch [97/100], Step [38/60], Loss: 0.9311, batch time: 0.46, accuracy:  70.00%\n",
      "Epoch [97/100], Step [39/60], Loss: 0.8916, batch time: 0.46, accuracy:  71.70%\n",
      "Epoch [97/100], Step [40/60], Loss: 0.9325, batch time: 0.46, accuracy:  70.20%\n",
      "Epoch [97/100], Step [41/60], Loss: 0.9546, batch time: 0.47, accuracy:  70.00%\n",
      "Epoch [97/100], Step [42/60], Loss: 0.9833, batch time: 0.46, accuracy:  68.50%\n",
      "Epoch [97/100], Step [43/60], Loss: 0.8918, batch time: 0.47, accuracy:  70.40%\n",
      "Epoch [97/100], Step [44/60], Loss: 0.9073, batch time: 0.46, accuracy:  72.80%\n",
      "Epoch [97/100], Step [45/60], Loss: 0.9642, batch time: 0.47, accuracy:  70.90%\n",
      "Epoch [97/100], Step [46/60], Loss: 0.8943, batch time: 0.48, accuracy:  71.10%\n",
      "Epoch [97/100], Step [47/60], Loss: 0.8763, batch time: 0.77, accuracy:  72.50%\n",
      "Epoch [97/100], Step [48/60], Loss: 0.9778, batch time: 0.87, accuracy:  68.90%\n",
      "Epoch [97/100], Step [49/60], Loss: 0.9942, batch time: 0.77, accuracy:  70.70%\n",
      "Epoch [97/100], Step [50/60], Loss: 0.9562, batch time: 0.69, accuracy:  71.80%\n",
      "Epoch [97/100], Step [51/60], Loss: 0.9333, batch time: 0.70, accuracy:  69.20%\n",
      "Epoch [97/100], Step [52/60], Loss: 0.9302, batch time: 0.69, accuracy:  70.80%\n",
      "Epoch [97/100], Step [53/60], Loss: 0.9740, batch time: 0.73, accuracy:  70.10%\n",
      "Epoch [97/100], Step [54/60], Loss: 0.9528, batch time: 0.58, accuracy:  72.10%\n",
      "Epoch [97/100], Step [55/60], Loss: 0.9543, batch time: 0.60, accuracy:  70.20%\n",
      "Epoch [97/100], Step [56/60], Loss: 1.0244, batch time: 0.61, accuracy:  69.40%\n",
      "Epoch [97/100], Step [57/60], Loss: 0.9761, batch time: 0.70, accuracy:  70.10%\n",
      "Epoch [97/100], Step [58/60], Loss: 0.8676, batch time: 0.67, accuracy:  73.40%\n",
      "Epoch [97/100], Step [59/60], Loss: 0.9203, batch time: 0.70, accuracy:  70.60%\n",
      "Epoch [97/100], Step [60/60], Loss: 0.9949, batch time: 0.68, accuracy:  67.90%\n",
      "Epoch [98/100], Step [1/60], Loss: 0.8962, batch time: 0.71, accuracy:  71.80%\n",
      "Epoch [98/100], Step [2/60], Loss: 1.0135, batch time: 0.71, accuracy:  68.90%\n",
      "Epoch [98/100], Step [3/60], Loss: 0.9817, batch time: 0.74, accuracy:  69.30%\n",
      "Epoch [98/100], Step [4/60], Loss: 0.9052, batch time: 0.74, accuracy:  71.00%\n",
      "Epoch [98/100], Step [5/60], Loss: 0.9268, batch time: 0.72, accuracy:  69.30%\n",
      "Epoch [98/100], Step [6/60], Loss: 0.8907, batch time: 0.74, accuracy:  72.20%\n",
      "Epoch [98/100], Step [7/60], Loss: 0.9344, batch time: 0.74, accuracy:  70.90%\n",
      "Epoch [98/100], Step [8/60], Loss: 1.0483, batch time: 0.73, accuracy:  67.90%\n",
      "Epoch [98/100], Step [9/60], Loss: 0.9891, batch time: 0.65, accuracy:  67.60%\n",
      "Epoch [98/100], Step [10/60], Loss: 0.9658, batch time: 0.77, accuracy:  69.00%\n",
      "Epoch [98/100], Step [11/60], Loss: 0.9545, batch time: 0.86, accuracy:  71.80%\n",
      "Epoch [98/100], Step [12/60], Loss: 0.9541, batch time: 0.59, accuracy:  70.20%\n",
      "Epoch [98/100], Step [13/60], Loss: 0.9700, batch time: 0.54, accuracy:  70.20%\n",
      "Epoch [98/100], Step [14/60], Loss: 0.9763, batch time: 0.55, accuracy:  69.80%\n",
      "Epoch [98/100], Step [15/60], Loss: 0.9401, batch time: 0.53, accuracy:  70.50%\n",
      "Epoch [98/100], Step [16/60], Loss: 1.0290, batch time: 0.57, accuracy:  68.70%\n",
      "Epoch [98/100], Step [17/60], Loss: 0.9159, batch time: 0.48, accuracy:  72.10%\n",
      "Epoch [98/100], Step [18/60], Loss: 0.9240, batch time: 0.43, accuracy:  71.70%\n",
      "Epoch [98/100], Step [19/60], Loss: 0.8976, batch time: 0.44, accuracy:  71.50%\n",
      "Epoch [98/100], Step [20/60], Loss: 0.9612, batch time: 0.42, accuracy:  70.50%\n",
      "Epoch [98/100], Step [21/60], Loss: 0.9253, batch time: 0.43, accuracy:  70.40%\n",
      "Epoch [98/100], Step [22/60], Loss: 0.9190, batch time: 0.43, accuracy:  71.70%\n",
      "Epoch [98/100], Step [23/60], Loss: 0.8934, batch time: 0.42, accuracy:  73.10%\n",
      "Epoch [98/100], Step [24/60], Loss: 0.9483, batch time: 0.43, accuracy:  69.90%\n",
      "Epoch [98/100], Step [25/60], Loss: 0.9135, batch time: 0.45, accuracy:  71.60%\n",
      "Epoch [98/100], Step [26/60], Loss: 0.8526, batch time: 0.42, accuracy:  72.20%\n",
      "Epoch [98/100], Step [27/60], Loss: 0.9283, batch time: 0.43, accuracy:  70.60%\n",
      "Epoch [98/100], Step [28/60], Loss: 0.9159, batch time: 0.43, accuracy:  71.40%\n",
      "Epoch [98/100], Step [29/60], Loss: 0.9975, batch time: 0.42, accuracy:  69.30%\n",
      "Epoch [98/100], Step [30/60], Loss: 0.9050, batch time: 0.43, accuracy:  70.40%\n",
      "Epoch [98/100], Step [31/60], Loss: 0.8988, batch time: 0.49, accuracy:  71.90%\n",
      "Epoch [98/100], Step [32/60], Loss: 0.8709, batch time: 0.42, accuracy:  71.50%\n",
      "Epoch [98/100], Step [33/60], Loss: 1.0095, batch time: 0.43, accuracy:  67.40%\n",
      "Epoch [98/100], Step [34/60], Loss: 0.9323, batch time: 0.44, accuracy:  71.80%\n",
      "Epoch [98/100], Step [35/60], Loss: 0.9222, batch time: 0.42, accuracy:  71.40%\n",
      "Epoch [98/100], Step [36/60], Loss: 0.9160, batch time: 0.46, accuracy:  68.70%\n",
      "Epoch [98/100], Step [37/60], Loss: 0.8822, batch time: 0.45, accuracy:  72.10%\n",
      "Epoch [98/100], Step [38/60], Loss: 0.9268, batch time: 0.46, accuracy:  68.90%\n",
      "Epoch [98/100], Step [39/60], Loss: 0.9047, batch time: 0.48, accuracy:  73.70%\n",
      "Epoch [98/100], Step [40/60], Loss: 0.9199, batch time: 0.46, accuracy:  70.50%\n",
      "Epoch [98/100], Step [41/60], Loss: 0.9639, batch time: 0.46, accuracy:  69.60%\n",
      "Epoch [98/100], Step [42/60], Loss: 0.9292, batch time: 0.47, accuracy:  70.70%\n",
      "Epoch [98/100], Step [43/60], Loss: 0.9006, batch time: 0.47, accuracy:  71.10%\n",
      "Epoch [98/100], Step [44/60], Loss: 0.9770, batch time: 0.48, accuracy:  70.70%\n",
      "Epoch [98/100], Step [45/60], Loss: 0.8692, batch time: 0.47, accuracy:  72.00%\n",
      "Epoch [98/100], Step [46/60], Loss: 0.9060, batch time: 0.46, accuracy:  72.60%\n",
      "Epoch [98/100], Step [47/60], Loss: 0.9914, batch time: 0.47, accuracy:  69.40%\n",
      "Epoch [98/100], Step [48/60], Loss: 0.8476, batch time: 0.46, accuracy:  72.90%\n",
      "Epoch [98/100], Step [49/60], Loss: 0.9273, batch time: 0.46, accuracy:  72.70%\n",
      "Epoch [98/100], Step [50/60], Loss: 0.9508, batch time: 0.48, accuracy:  70.70%\n",
      "Epoch [98/100], Step [51/60], Loss: 0.9241, batch time: 0.46, accuracy:  69.90%\n",
      "Epoch [98/100], Step [52/60], Loss: 0.9809, batch time: 0.47, accuracy:  69.90%\n",
      "Epoch [98/100], Step [53/60], Loss: 0.9614, batch time: 0.48, accuracy:  68.60%\n",
      "Epoch [98/100], Step [54/60], Loss: 0.9115, batch time: 0.46, accuracy:  72.50%\n",
      "Epoch [98/100], Step [55/60], Loss: 0.9387, batch time: 0.47, accuracy:  69.70%\n",
      "Epoch [98/100], Step [56/60], Loss: 0.9028, batch time: 0.47, accuracy:  72.70%\n",
      "Epoch [98/100], Step [57/60], Loss: 0.9258, batch time: 0.46, accuracy:  71.30%\n",
      "Epoch [98/100], Step [58/60], Loss: 0.9671, batch time: 0.47, accuracy:  69.70%\n",
      "Epoch [98/100], Step [59/60], Loss: 0.8962, batch time: 0.46, accuracy:  70.70%\n",
      "Epoch [98/100], Step [60/60], Loss: 0.9462, batch time: 0.46, accuracy:  70.90%\n",
      "Epoch [99/100], Step [1/60], Loss: 0.9672, batch time: 0.52, accuracy:  69.60%\n",
      "Epoch [99/100], Step [2/60], Loss: 0.8680, batch time: 0.46, accuracy:  72.90%\n",
      "Epoch [99/100], Step [3/60], Loss: 0.9264, batch time: 0.48, accuracy:  68.50%\n",
      "Epoch [99/100], Step [4/60], Loss: 0.9343, batch time: 0.46, accuracy:  69.40%\n",
      "Epoch [99/100], Step [5/60], Loss: 0.9390, batch time: 0.45, accuracy:  69.90%\n",
      "Epoch [99/100], Step [6/60], Loss: 0.8841, batch time: 0.47, accuracy:  72.20%\n",
      "Epoch [99/100], Step [7/60], Loss: 0.9731, batch time: 0.46, accuracy:  70.70%\n",
      "Epoch [99/100], Step [8/60], Loss: 1.0049, batch time: 0.46, accuracy:  69.00%\n",
      "Epoch [99/100], Step [9/60], Loss: 0.8898, batch time: 0.71, accuracy:  71.60%\n",
      "Epoch [99/100], Step [10/60], Loss: 0.9165, batch time: 0.62, accuracy:  69.20%\n",
      "Epoch [99/100], Step [11/60], Loss: 0.8835, batch time: 0.47, accuracy:  72.30%\n",
      "Epoch [99/100], Step [12/60], Loss: 0.9475, batch time: 0.46, accuracy:  69.90%\n",
      "Epoch [99/100], Step [13/60], Loss: 0.9765, batch time: 0.47, accuracy:  70.10%\n",
      "Epoch [99/100], Step [14/60], Loss: 0.9100, batch time: 0.47, accuracy:  70.60%\n",
      "Epoch [99/100], Step [15/60], Loss: 0.9367, batch time: 0.46, accuracy:  72.40%\n",
      "Epoch [99/100], Step [16/60], Loss: 0.9056, batch time: 0.48, accuracy:  69.40%\n",
      "Epoch [99/100], Step [17/60], Loss: 0.9253, batch time: 0.46, accuracy:  71.40%\n",
      "Epoch [99/100], Step [18/60], Loss: 0.8825, batch time: 0.48, accuracy:  71.10%\n",
      "Epoch [99/100], Step [19/60], Loss: 0.9461, batch time: 0.48, accuracy:  71.00%\n",
      "Epoch [99/100], Step [20/60], Loss: 0.9048, batch time: 0.46, accuracy:  73.40%\n",
      "Epoch [99/100], Step [21/60], Loss: 0.9964, batch time: 0.47, accuracy:  69.90%\n",
      "Epoch [99/100], Step [22/60], Loss: 0.9645, batch time: 0.52, accuracy:  70.00%\n",
      "Epoch [99/100], Step [23/60], Loss: 0.9330, batch time: 0.46, accuracy:  69.60%\n",
      "Epoch [99/100], Step [24/60], Loss: 0.9392, batch time: 0.47, accuracy:  71.20%\n",
      "Epoch [99/100], Step [25/60], Loss: 0.9191, batch time: 0.45, accuracy:  70.00%\n",
      "Epoch [99/100], Step [26/60], Loss: 0.8591, batch time: 0.46, accuracy:  74.20%\n",
      "Epoch [99/100], Step [27/60], Loss: 0.9708, batch time: 0.50, accuracy:  70.80%\n",
      "Epoch [99/100], Step [28/60], Loss: 0.8741, batch time: 0.46, accuracy:  73.90%\n",
      "Epoch [99/100], Step [29/60], Loss: 0.9744, batch time: 0.47, accuracy:  70.10%\n",
      "Epoch [99/100], Step [30/60], Loss: 0.9714, batch time: 0.47, accuracy:  69.50%\n",
      "Epoch [99/100], Step [31/60], Loss: 0.9327, batch time: 0.46, accuracy:  70.00%\n",
      "Epoch [99/100], Step [32/60], Loss: 1.0200, batch time: 0.47, accuracy:  67.90%\n",
      "Epoch [99/100], Step [33/60], Loss: 0.8837, batch time: 0.46, accuracy:  72.30%\n",
      "Epoch [99/100], Step [34/60], Loss: 0.9587, batch time: 0.46, accuracy:  68.50%\n",
      "Epoch [99/100], Step [35/60], Loss: 0.9637, batch time: 0.47, accuracy:  70.70%\n",
      "Epoch [99/100], Step [36/60], Loss: 0.9115, batch time: 0.47, accuracy:  69.80%\n",
      "Epoch [99/100], Step [37/60], Loss: 0.8714, batch time: 0.45, accuracy:  73.30%\n",
      "Epoch [99/100], Step [38/60], Loss: 1.0191, batch time: 0.47, accuracy:  67.70%\n",
      "Epoch [99/100], Step [39/60], Loss: 0.8517, batch time: 0.46, accuracy:  73.80%\n",
      "Epoch [99/100], Step [40/60], Loss: 1.0481, batch time: 0.54, accuracy:  69.80%\n",
      "Epoch [99/100], Step [41/60], Loss: 0.9263, batch time: 0.53, accuracy:  70.60%\n",
      "Epoch [99/100], Step [42/60], Loss: 0.8386, batch time: 0.52, accuracy:  72.20%\n",
      "Epoch [99/100], Step [43/60], Loss: 0.9360, batch time: 0.54, accuracy:  70.40%\n",
      "Epoch [99/100], Step [44/60], Loss: 0.9532, batch time: 0.52, accuracy:  70.80%\n",
      "Epoch [99/100], Step [45/60], Loss: 0.9050, batch time: 0.44, accuracy:  71.60%\n",
      "Epoch [99/100], Step [46/60], Loss: 0.9519, batch time: 0.44, accuracy:  71.40%\n",
      "Epoch [99/100], Step [47/60], Loss: 0.8773, batch time: 0.43, accuracy:  73.20%\n",
      "Epoch [99/100], Step [48/60], Loss: 0.8763, batch time: 0.44, accuracy:  71.40%\n",
      "Epoch [99/100], Step [49/60], Loss: 0.9722, batch time: 0.44, accuracy:  70.50%\n",
      "Epoch [99/100], Step [50/60], Loss: 0.8589, batch time: 0.43, accuracy:  72.50%\n",
      "Epoch [99/100], Step [51/60], Loss: 0.9196, batch time: 0.44, accuracy:  68.90%\n",
      "Epoch [99/100], Step [52/60], Loss: 0.9217, batch time: 0.43, accuracy:  70.20%\n",
      "Epoch [99/100], Step [53/60], Loss: 0.9500, batch time: 0.43, accuracy:  71.00%\n",
      "Epoch [99/100], Step [54/60], Loss: 0.9410, batch time: 0.45, accuracy:  71.30%\n",
      "Epoch [99/100], Step [55/60], Loss: 0.9523, batch time: 0.42, accuracy:  70.70%\n",
      "Epoch [99/100], Step [56/60], Loss: 0.9478, batch time: 0.43, accuracy:  68.20%\n",
      "Epoch [99/100], Step [57/60], Loss: 0.8888, batch time: 0.43, accuracy:  74.00%\n",
      "Epoch [99/100], Step [58/60], Loss: 0.9092, batch time: 0.43, accuracy:  69.80%\n",
      "Epoch [99/100], Step [59/60], Loss: 0.9982, batch time: 0.44, accuracy:  69.80%\n",
      "Epoch [99/100], Step [60/60], Loss: 0.8643, batch time: 0.44, accuracy:  72.10%\n",
      "Epoch [100/100], Step [1/60], Loss: 0.9249, batch time: 0.45, accuracy:  69.90%\n",
      "Epoch [100/100], Step [2/60], Loss: 0.9209, batch time: 0.44, accuracy:  73.10%\n",
      "Epoch [100/100], Step [3/60], Loss: 0.9084, batch time: 0.48, accuracy:  72.50%\n",
      "Epoch [100/100], Step [4/60], Loss: 0.9549, batch time: 0.46, accuracy:  69.40%\n",
      "Epoch [100/100], Step [5/60], Loss: 0.8914, batch time: 0.48, accuracy:  71.40%\n",
      "Epoch [100/100], Step [6/60], Loss: 0.9279, batch time: 0.46, accuracy:  69.80%\n",
      "Epoch [100/100], Step [7/60], Loss: 0.9383, batch time: 0.47, accuracy:  69.10%\n",
      "Epoch [100/100], Step [8/60], Loss: 1.0175, batch time: 0.47, accuracy:  67.40%\n",
      "Epoch [100/100], Step [9/60], Loss: 0.9345, batch time: 0.46, accuracy:  69.30%\n",
      "Epoch [100/100], Step [10/60], Loss: 0.9596, batch time: 0.48, accuracy:  70.20%\n",
      "Epoch [100/100], Step [11/60], Loss: 0.9865, batch time: 0.47, accuracy:  68.20%\n",
      "Epoch [100/100], Step [12/60], Loss: 0.9212, batch time: 0.49, accuracy:  72.60%\n",
      "Epoch [100/100], Step [13/60], Loss: 0.8862, batch time: 0.48, accuracy:  71.90%\n",
      "Epoch [100/100], Step [14/60], Loss: 0.9094, batch time: 0.47, accuracy:  72.10%\n",
      "Epoch [100/100], Step [15/60], Loss: 1.0044, batch time: 0.47, accuracy:  68.80%\n",
      "Epoch [100/100], Step [16/60], Loss: 0.9367, batch time: 0.47, accuracy:  69.80%\n",
      "Epoch [100/100], Step [17/60], Loss: 0.9415, batch time: 0.46, accuracy:  70.50%\n",
      "Epoch [100/100], Step [18/60], Loss: 0.8939, batch time: 0.48, accuracy:  70.60%\n",
      "Epoch [100/100], Step [19/60], Loss: 0.8684, batch time: 0.46, accuracy:  74.00%\n",
      "Epoch [100/100], Step [20/60], Loss: 0.9216, batch time: 0.46, accuracy:  70.70%\n",
      "Epoch [100/100], Step [21/60], Loss: 0.8940, batch time: 0.50, accuracy:  69.90%\n",
      "Epoch [100/100], Step [22/60], Loss: 0.9664, batch time: 0.46, accuracy:  70.10%\n",
      "Epoch [100/100], Step [23/60], Loss: 0.8554, batch time: 0.48, accuracy:  73.80%\n",
      "Epoch [100/100], Step [24/60], Loss: 0.9011, batch time: 0.47, accuracy:  72.30%\n",
      "Epoch [100/100], Step [25/60], Loss: 0.8955, batch time: 0.53, accuracy:  70.20%\n",
      "Epoch [100/100], Step [26/60], Loss: 1.0045, batch time: 0.85, accuracy:  68.60%\n",
      "Epoch [100/100], Step [27/60], Loss: 0.9842, batch time: 0.84, accuracy:  71.70%\n",
      "Epoch [100/100], Step [28/60], Loss: 0.9738, batch time: 0.84, accuracy:  69.30%\n",
      "Epoch [100/100], Step [29/60], Loss: 0.8948, batch time: 0.84, accuracy:  73.70%\n",
      "Epoch [100/100], Step [30/60], Loss: 0.9067, batch time: 0.63, accuracy:  72.00%\n",
      "Epoch [100/100], Step [31/60], Loss: 0.9268, batch time: 0.49, accuracy:  70.70%\n",
      "Epoch [100/100], Step [32/60], Loss: 0.9313, batch time: 0.43, accuracy:  70.50%\n",
      "Epoch [100/100], Step [33/60], Loss: 0.8555, batch time: 0.45, accuracy:  72.20%\n",
      "Epoch [100/100], Step [34/60], Loss: 0.9015, batch time: 0.43, accuracy:  72.60%\n",
      "Epoch [100/100], Step [35/60], Loss: 0.9426, batch time: 0.44, accuracy:  67.70%\n",
      "Epoch [100/100], Step [36/60], Loss: 0.9342, batch time: 0.45, accuracy:  71.40%\n",
      "Epoch [100/100], Step [37/60], Loss: 0.8552, batch time: 0.43, accuracy:  72.00%\n",
      "Epoch [100/100], Step [38/60], Loss: 0.8821, batch time: 0.44, accuracy:  71.30%\n",
      "Epoch [100/100], Step [39/60], Loss: 0.9339, batch time: 0.44, accuracy:  69.60%\n",
      "Epoch [100/100], Step [40/60], Loss: 0.9022, batch time: 0.43, accuracy:  73.50%\n",
      "Epoch [100/100], Step [41/60], Loss: 0.8981, batch time: 0.44, accuracy:  72.00%\n",
      "Epoch [100/100], Step [42/60], Loss: 0.8813, batch time: 0.43, accuracy:  73.10%\n",
      "Epoch [100/100], Step [43/60], Loss: 0.9407, batch time: 0.43, accuracy:  71.10%\n",
      "Epoch [100/100], Step [44/60], Loss: 0.9721, batch time: 0.47, accuracy:  70.60%\n",
      "Epoch [100/100], Step [45/60], Loss: 0.8821, batch time: 0.43, accuracy:  72.20%\n",
      "Epoch [100/100], Step [46/60], Loss: 0.9291, batch time: 0.43, accuracy:  71.50%\n",
      "Epoch [100/100], Step [47/60], Loss: 0.9217, batch time: 0.44, accuracy:  71.00%\n",
      "Epoch [100/100], Step [48/60], Loss: 0.9517, batch time: 0.46, accuracy:  69.10%\n",
      "Epoch [100/100], Step [49/60], Loss: 0.9283, batch time: 0.47, accuracy:  69.80%\n",
      "Epoch [100/100], Step [50/60], Loss: 0.9120, batch time: 0.48, accuracy:  71.00%\n",
      "Epoch [100/100], Step [51/60], Loss: 0.8957, batch time: 0.47, accuracy:  72.00%\n",
      "Epoch [100/100], Step [52/60], Loss: 0.8613, batch time: 0.47, accuracy:  72.40%\n",
      "Epoch [100/100], Step [53/60], Loss: 0.9784, batch time: 0.49, accuracy:  68.80%\n",
      "Epoch [100/100], Step [54/60], Loss: 0.9881, batch time: 0.47, accuracy:  68.40%\n",
      "Epoch [100/100], Step [55/60], Loss: 0.9799, batch time: 0.48, accuracy:  69.80%\n",
      "Epoch [100/100], Step [56/60], Loss: 0.9407, batch time: 0.46, accuracy:  70.10%\n",
      "Epoch [100/100], Step [57/60], Loss: 0.8464, batch time: 0.47, accuracy:  73.90%\n",
      "Epoch [100/100], Step [58/60], Loss: 0.8242, batch time: 0.47, accuracy:  73.10%\n",
      "Epoch [100/100], Step [59/60], Loss: 0.9329, batch time: 0.46, accuracy:  70.60%\n",
      "Epoch [100/100], Step [60/60], Loss: 0.9132, batch time: 0.48, accuracy:  72.50%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#############################################\n",
    "### Training loop ###########################\n",
    "\n",
    "### (Optional) Start from pretrained model ##\n",
    "# model_qt = torch.load('L16/tq_mm_acc_99_bsf')\n",
    "# model_qt.eval()  # Set the model to evaluation mode\n",
    "#############################################\n",
    "\n",
    "loss_list = [] \n",
    "acc_list = [] \n",
    "acc_best = 0\n",
    "for epoch in range(num_epochs):\n",
    "    model_qt.train()\n",
    "    train_loss = 0\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        since_batch = time.time()\n",
    "        \n",
    "        images, labels = images.to(device), labels.to(device)  # Move data to GPU\n",
    "        optimizer.zero_grad()\n",
    "        # Forward pass\n",
    "        outputs = model_qt(images)\n",
    "        # print(\"output: \", outputs)\n",
    "        labels_one_hot = F.one_hot(labels, num_classes=10).float()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        # Compute loss\n",
    "        loss = criterion(outputs, labels_one_hot)\n",
    "        # log_loss = torch.log(loss + 1e-6)\n",
    "        \n",
    "        loss_list.append(loss.cpu().detach().numpy())\n",
    "        acc = 100 * correct / total\n",
    "        acc_list.append(acc)\n",
    "        train_loss += loss.cpu().detach().numpy()\n",
    "        \n",
    "        # np.array(loss_list).dump(\"L16/3/loss_list.dat\")\n",
    "        # np.array(acc_list).dump(\"L16/3/acc_list.dat\")\n",
    "        if acc > acc_best:\n",
    "            # torch.save(model_qt, 'L16/3/tq_mm_acc_'+str(int(acc))+'_bsf')\n",
    "            acc_best = acc\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        # if (i+1) % 100 == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}, batch time: {time.time() - since_batch:.2f}, accuracy:  {(acc):.2f}%\")\n",
    "    \n",
    "    train_loss /= len(train_loader)\n",
    "    scheduler.step(train_loss)\n",
    "    \n",
    "#############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient of MappingNetwork.input_layer.weight: tensor([[-7.9607e+00, -7.3004e+00, -7.4006e+00, -6.6216e+00, -1.1015e+01,\n",
      "         -3.7132e-01, -3.8950e+00, -4.8194e+00,  3.5117e-01, -3.9566e+00,\n",
      "         -2.9183e+00, -2.7443e-01,  3.9356e-02, -3.5626e-01],\n",
      "        [ 5.5427e+00,  5.0829e+00,  5.1527e+00,  4.6103e+00,  7.6690e+00,\n",
      "          2.5853e-01,  2.7119e+00,  3.3555e+00, -2.4450e-01,  2.7548e+00,\n",
      "          2.0319e+00,  1.9108e-01, -2.7402e-02,  2.4805e-01],\n",
      "        [-3.0348e+00, -2.7830e+00, -2.8212e+00, -2.5243e+00, -4.1990e+00,\n",
      "         -1.4155e-01, -1.4848e+00, -1.8372e+00,  1.3387e-01, -1.5083e+00,\n",
      "         -1.1125e+00, -1.0462e-01,  1.5003e-02, -1.3581e-01],\n",
      "        [ 1.5247e-01,  1.3982e-01,  1.4174e-01,  1.2682e-01,  2.1096e-01,\n",
      "          7.1115e-03,  7.4599e-02,  9.2304e-02, -6.7258e-03,  7.5780e-02,\n",
      "          5.5894e-02,  5.2562e-03, -7.5391e-04,  6.8233e-03]], device='cuda:1')\n",
      "Gradient of MappingNetwork.input_layer.bias: tensor([ 8.9407e-08, -5.9605e-08, -1.4901e-08, -2.1886e-08], device='cuda:1')\n",
      "Gradient of MappingNetwork.hidden_layers.0.weight: tensor([[ 0.3615,  0.3823, -0.4653, -1.2855],\n",
      "        [-0.1000, -0.1057,  0.1287,  0.3555],\n",
      "        [ 0.1934,  0.2046, -0.2490, -0.6878],\n",
      "        [ 0.4767,  0.5041, -0.6136, -1.6949],\n",
      "        [-0.7480, -0.7910,  0.9627,  2.6594],\n",
      "        [ 0.1823,  0.1927, -0.2346, -0.6480],\n",
      "        [ 0.5060,  0.5351, -0.6513, -1.7991],\n",
      "        [-0.2087, -0.2207,  0.2687,  0.7421],\n",
      "        [-0.3984, -0.4213,  0.5128,  1.4166],\n",
      "        [ 0.9237,  0.9768, -1.1889, -3.2843],\n",
      "        [-0.0105, -0.0111,  0.0135,  0.0374],\n",
      "        [ 0.2237,  0.2366, -0.2879, -0.7954],\n",
      "        [ 0.3231,  0.3417, -0.4158, -1.1487],\n",
      "        [ 0.3387,  0.3582, -0.4360, -1.2044],\n",
      "        [ 0.9878,  1.0447, -1.2715, -3.5124],\n",
      "        [ 0.1072,  0.1134, -0.1380, -0.3813],\n",
      "        [-0.2241, -0.2370,  0.2885,  0.7970],\n",
      "        [-0.0380, -0.0402,  0.0489,  0.1352],\n",
      "        [-1.1007, -1.1640,  1.4167,  3.9135],\n",
      "        [-0.5425, -0.5738,  0.6983,  1.9291]], device='cuda:1')\n",
      "Gradient of MappingNetwork.hidden_layers.0.bias: tensor([-2.9802e-08, -3.7253e-09, -1.4901e-08, -1.4901e-08, -8.9407e-08,\n",
      "        -1.4901e-08, -2.9802e-08,  4.8429e-08,  2.9802e-08, -1.7881e-07,\n",
      "        -6.7521e-09, -3.3528e-08, -1.4901e-08,  2.9802e-08,  2.9802e-08,\n",
      "        -1.8626e-08, -7.4506e-09, -1.3039e-08, -5.9605e-08, -1.4901e-08],\n",
      "       device='cuda:1')\n",
      "Gradient of MappingNetwork.hidden_layers.1.weight: tensor([[ 0.1156, -1.5559,  4.0297,  2.2302, -1.4594, -0.6014, -0.8662,  2.3803,\n",
      "          0.0675, -0.6686, -5.4274, -1.8728,  4.0427,  2.2892,  1.5308,  0.9241,\n",
      "          1.3543,  2.6736,  1.5359,  3.9676],\n",
      "        [ 0.0451, -0.6078,  1.5742,  0.8712, -0.5701, -0.2349, -0.3384,  0.9299,\n",
      "          0.0264, -0.2612, -2.1202, -0.7316,  1.5793,  0.8943,  0.5980,  0.3610,\n",
      "          0.5290,  1.0444,  0.6000,  1.5499],\n",
      "        [ 0.0611, -0.8230,  2.1314,  1.1796, -0.7719, -0.3181, -0.4582,  1.2590,\n",
      "          0.0357, -0.3537, -2.8707, -0.9906,  2.1383,  1.2108,  0.8097,  0.4888,\n",
      "          0.7163,  1.4142,  0.8124,  2.0986],\n",
      "        [ 0.0822, -1.1066,  2.8660,  1.5862, -1.0380, -0.4277, -0.6161,  1.6929,\n",
      "          0.0480, -0.4756, -3.8601, -1.3320,  2.8753,  1.6281,  1.0888,  0.6572,\n",
      "          0.9632,  1.9016,  1.0924,  2.8219]], device='cuda:1')\n",
      "Gradient of MappingNetwork.hidden_layers.1.bias: tensor([1.1921e-07, 1.1921e-07, 1.4901e-07, 5.9605e-08], device='cuda:1')\n",
      "Gradient of MappingNetwork.output_layer.weight: tensor([[ 2.7631, -4.2278, -1.7978, -0.9447]], device='cuda:1')\n",
      "Gradient of MappingNetwork.output_layer.bias: tensor([-4.7684e-07], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.0.ops_all.0.params: tensor([[ 0.1848, -0.0558,  0.0000]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.0.ops_all.1.params: tensor([[-0.2728, -0.1130,  0.0000]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.0.ops_all.2.params: tensor([[ 0.7049, -0.0013,  0.0000]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.0.ops_all.3.params: tensor([[ 0.0068, -0.0946,  0.0000]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.0.ops_all.4.params: tensor([[ 0.3533, -0.1875,  0.0000]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.0.ops_all.5.params: tensor([[-0.0175, -0.0900,  0.0000]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.0.ops_all.6.params: tensor([[0.2224, 0.0006, 0.0000]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.0.ops_all.7.params: tensor([[0.0735, 0.0992, 0.0000]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.0.ops_all.8.params: tensor([[-0.0182, -0.0518,  0.0000]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.0.ops_all.9.params: tensor([[0.2985, 0.3791, 0.0000]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.0.ops_all.10.params: tensor([[-0.5186,  0.0706,  0.0000]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.0.ops_all.11.params: tensor([[0.1257, 0.1143, 0.0000]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.0.ops_all.12.params: tensor([[ 0.4708, -0.2667,  0.0000]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.1.ops_all.0.params: tensor([[ 0.1109,  0.0195, -0.2310]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.1.ops_all.1.params: tensor([[-0.2612,  0.3285,  0.2624]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.1.ops_all.2.params: tensor([[0.0941, 0.4297, 0.3523]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.1.ops_all.3.params: tensor([[ 0.2770, -0.0403, -0.0488]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.1.ops_all.4.params: tensor([[ 0.7013, -0.0509, -0.0564]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.1.ops_all.5.params: tensor([[ 0.1813,  0.3071, -0.2689]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.1.ops_all.6.params: tensor([[ 0.3366,  0.2573, -0.1860]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.1.ops_all.7.params: tensor([[-0.1069,  0.0057,  0.0979]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.1.ops_all.8.params: tensor([[ 0.2049, -0.1410,  0.0165]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.1.ops_all.9.params: tensor([[-0.4799, -0.1034, -0.0499]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.1.ops_all.10.params: tensor([[ 0.0366,  0.1900, -0.0153]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.1.ops_all.11.params: tensor([[-0.1854,  0.1892,  0.0097]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.1.ops_all.12.params: tensor([[-0.2260,  0.3143, -0.2924]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.2.ops_all.0.params: tensor([[ 0.1597,  0.0564, -0.0613]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.2.ops_all.1.params: tensor([[0.0086, 0.3291, 0.3199]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.2.ops_all.2.params: tensor([[-0.0229,  0.2380,  0.1330]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.2.ops_all.3.params: tensor([[ 0.3929, -0.2755,  0.2749]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.2.ops_all.4.params: tensor([[-0.2817,  0.0062,  0.0797]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.2.ops_all.5.params: tensor([[0.1527, 0.6009, 0.3250]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.2.ops_all.6.params: tensor([[-0.0166,  0.2835,  0.3157]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.2.ops_all.7.params: tensor([[ 0.1356, -0.1359,  0.1955]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.2.ops_all.8.params: tensor([[-0.1022, -0.1045,  0.0043]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.2.ops_all.9.params: tensor([[-0.4000, -0.0724, -0.0622]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.2.ops_all.10.params: tensor([[ 0.1879, -0.0533,  0.2086]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.2.ops_all.11.params: tensor([[-0.3735,  0.1497,  0.2991]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.2.ops_all.12.params: tensor([[-0.1918, -0.1146, -0.0545]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.3.ops_all.0.params: tensor([[0.0341, 0.2608, 0.0714]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.3.ops_all.1.params: tensor([[ 0.0511, -0.0426, -0.1730]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.3.ops_all.2.params: tensor([[-0.1672, -0.2491,  0.2400]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.3.ops_all.3.params: tensor([[-0.1979,  0.3006, -0.2714]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.3.ops_all.4.params: tensor([[-0.3351,  0.1456,  0.2814]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.3.ops_all.5.params: tensor([[-0.1792, -0.0169,  0.1549]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.3.ops_all.6.params: tensor([[-0.3855,  0.0044,  0.2489]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.3.ops_all.7.params: tensor([[-0.2295,  0.1348, -0.1769]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.3.ops_all.8.params: tensor([[-0.4963,  0.1834,  0.0792]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.3.ops_all.9.params: tensor([[-0.2655,  0.1548, -0.0729]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.3.ops_all.10.params: tensor([[ 0.1154,  0.3085, -0.4184]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.3.ops_all.11.params: tensor([[-0.4026, -0.0431,  0.0700]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.3.ops_all.12.params: tensor([[-0.1902,  0.2288,  0.2021]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.4.ops_all.0.params: tensor([[ 0.3549, -0.1400,  0.2707]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.4.ops_all.1.params: tensor([[-0.3598, -0.3837,  0.5097]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.4.ops_all.2.params: tensor([[-0.1808, -0.0510, -0.0815]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.4.ops_all.3.params: tensor([[-0.0249,  0.0126,  0.2896]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.4.ops_all.4.params: tensor([[ 0.3356, -0.0225, -0.0478]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.4.ops_all.5.params: tensor([[0.2338, 0.4755, 0.4356]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.4.ops_all.6.params: tensor([[-0.0498,  0.2265, -0.1484]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.4.ops_all.7.params: tensor([[-0.0971, -0.1895,  0.1673]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.4.ops_all.8.params: tensor([[-0.0003, -0.2571,  0.2248]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.4.ops_all.9.params: tensor([[ 0.2903,  0.2359, -0.1115]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.4.ops_all.10.params: tensor([[-0.0307, -0.0807,  0.4980]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.4.ops_all.11.params: tensor([[-0.1104,  0.3331, -0.0670]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.4.ops_all.12.params: tensor([[-0.3296,  0.0175, -0.0285]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.5.ops_all.0.params: tensor([[ 0.0315, -0.1779, -0.0328]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.5.ops_all.1.params: tensor([[-0.2373,  0.2411, -0.0634]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.5.ops_all.2.params: tensor([[-0.3530, -0.3753,  0.3736]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.5.ops_all.3.params: tensor([[ 0.2280, -0.0909, -0.0220]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.5.ops_all.4.params: tensor([[-0.2962,  0.1090, -0.0578]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.5.ops_all.5.params: tensor([[0.1054, 0.2530, 0.3247]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.5.ops_all.6.params: tensor([[-0.0335,  0.0551, -0.0078]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.5.ops_all.7.params: tensor([[-0.0931,  0.2264,  0.0646]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.5.ops_all.8.params: tensor([[-0.2809, -0.2989, -0.2960]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.5.ops_all.9.params: tensor([[-0.2863, -0.0710,  0.1288]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.5.ops_all.10.params: tensor([[ 0.0869,  0.1081, -0.2479]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.5.ops_all.11.params: tensor([[-0.0054,  0.2824,  0.1054]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.5.ops_all.12.params: tensor([[ 0.0920, -0.1298, -0.1124]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.6.ops_all.0.params: tensor([[ 0.1884,  0.4519, -0.2877]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.6.ops_all.1.params: tensor([[0.3780, 0.0099, 0.0781]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.6.ops_all.2.params: tensor([[-0.2567, -0.4891, -0.3342]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.6.ops_all.3.params: tensor([[-0.0320, -0.2965, -0.1065]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.6.ops_all.4.params: tensor([[-0.2914,  0.0500,  0.0406]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.6.ops_all.5.params: tensor([[0.0842, 0.1661, 0.2872]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.6.ops_all.6.params: tensor([[ 0.1987, -0.0831,  0.0263]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.6.ops_all.7.params: tensor([[ 0.1596, -0.0033,  0.2289]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.6.ops_all.8.params: tensor([[ 0.2093, -0.2275,  0.2048]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.6.ops_all.9.params: tensor([[-0.1807, -0.0904, -0.0260]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.6.ops_all.10.params: tensor([[-0.2982,  0.6867,  0.2609]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.6.ops_all.11.params: tensor([[-0.2012, -0.1707,  0.3453]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.6.ops_all.12.params: tensor([[ 0.0064, -0.3179, -0.3692]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.7.ops_all.0.params: tensor([[ 0.3719, -0.0143,  0.3858]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.7.ops_all.1.params: tensor([[-0.2827, -0.0143, -0.2879]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.7.ops_all.2.params: tensor([[0.0292, 0.4888, 0.1916]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.7.ops_all.3.params: tensor([[ 0.0780,  0.1464, -0.1020]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.7.ops_all.4.params: tensor([[-0.3117, -0.0231,  0.0167]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.7.ops_all.5.params: tensor([[-0.0805, -0.4988,  0.1569]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.7.ops_all.6.params: tensor([[ 0.0297, -0.0860, -0.1638]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.7.ops_all.7.params: tensor([[-0.3530,  0.1588, -0.4272]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.7.ops_all.8.params: tensor([[-0.0178,  0.4574, -0.4238]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.7.ops_all.9.params: tensor([[ 0.2472, -0.5135, -0.0708]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.7.ops_all.10.params: tensor([[0.7575, 0.2115, 0.4616]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.7.ops_all.11.params: tensor([[-0.1997,  0.4977, -0.1883]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.7.ops_all.12.params: tensor([[ 0.3712,  0.2041, -0.3115]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.8.ops_all.0.params: tensor([[-0.0122,  0.2666,  0.0393]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.8.ops_all.1.params: tensor([[-0.2921,  0.0092, -0.0096]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.8.ops_all.2.params: tensor([[-0.2930, -0.1583,  0.1379]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.8.ops_all.3.params: tensor([[-0.4436, -0.1275,  0.1669]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.8.ops_all.4.params: tensor([[ 0.4779, -0.1886,  0.0088]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.8.ops_all.5.params: tensor([[-0.0424, -0.1211,  0.0606]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.8.ops_all.6.params: tensor([[ 0.0068,  0.0878, -0.0838]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.8.ops_all.7.params: tensor([[0.3039, 0.2609, 0.1226]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.8.ops_all.8.params: tensor([[-0.1108, -0.0135, -0.0314]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.8.ops_all.9.params: tensor([[ 0.2124,  0.0201, -0.3819]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.8.ops_all.10.params: tensor([[-0.3323, -0.1615,  0.0768]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.8.ops_all.11.params: tensor([[0.0838, 0.5686, 0.5851]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.8.ops_all.12.params: tensor([[-0.1134,  0.1128,  0.1784]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.9.ops_all.0.params: tensor([[-0.0904, -0.2164,  0.4005]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.9.ops_all.1.params: tensor([[-0.2536, -0.1897,  0.0017]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.9.ops_all.2.params: tensor([[-0.0230,  0.1014, -0.4451]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.9.ops_all.3.params: tensor([[-0.3566, -0.0562,  0.0125]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.9.ops_all.4.params: tensor([[-0.0074, -0.1259,  0.0062]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.9.ops_all.5.params: tensor([[0.0909, 0.0451, 0.0431]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.9.ops_all.6.params: tensor([[ 0.5861, -0.4532,  0.2236]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.9.ops_all.7.params: tensor([[-0.1025, -0.3628,  0.4079]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.9.ops_all.8.params: tensor([[ 0.1163, -0.3546,  0.2638]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.9.ops_all.9.params: tensor([[0.0624, 0.1651, 0.0131]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.9.ops_all.10.params: tensor([[ 0.2935,  0.2033, -0.3274]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.9.ops_all.11.params: tensor([[-0.4879,  0.1501,  0.5606]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.9.ops_all.12.params: tensor([[0.1699, 0.1926, 0.0979]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.10.ops_all.0.params: tensor([[-0.1374,  0.4048, -0.2170]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.10.ops_all.1.params: tensor([[0.2444, 0.0171, 0.0137]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.10.ops_all.2.params: tensor([[ 0.1684, -0.1580, -0.0037]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.10.ops_all.3.params: tensor([[ 0.4425, -0.1064, -0.3075]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.10.ops_all.4.params: tensor([[-0.2005, -0.2816, -0.1208]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.10.ops_all.5.params: tensor([[-0.0425,  0.0113, -0.0199]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.10.ops_all.6.params: tensor([[ 0.2942,  0.3791, -0.4507]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.10.ops_all.7.params: tensor([[-0.2063, -0.0291, -0.1442]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.10.ops_all.8.params: tensor([[ 0.0126,  0.1803, -0.1364]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.10.ops_all.9.params: tensor([[-0.1517, -0.1983,  0.0576]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.10.ops_all.10.params: tensor([[-0.2448,  0.1569,  0.2200]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.10.ops_all.11.params: tensor([[-0.1037,  0.1309,  0.1347]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.10.ops_all.12.params: tensor([[-0.0621,  0.0340,  0.2739]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.11.ops_all.0.params: tensor([[ 0.0883, -0.0461,  0.1970]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.11.ops_all.1.params: tensor([[ 0.2604, -0.4042, -0.4533]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.11.ops_all.2.params: tensor([[-0.1747,  0.1477, -0.0732]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.11.ops_all.3.params: tensor([[-0.2292,  0.3415,  0.1201]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.11.ops_all.4.params: tensor([[ 0.3686,  0.0458, -0.0686]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.11.ops_all.5.params: tensor([[-0.0460,  0.1172,  0.1103]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.11.ops_all.6.params: tensor([[-0.3396,  0.3921,  0.3679]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.11.ops_all.7.params: tensor([[-0.0368,  0.0962, -0.1910]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.11.ops_all.8.params: tensor([[-0.1776, -0.3470,  0.0687]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.11.ops_all.9.params: tensor([[ 0.3340, -0.1178, -0.2208]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.11.ops_all.10.params: tensor([[0.1312, 0.1763, 0.1695]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.11.ops_all.11.params: tensor([[-0.0145, -0.1732,  0.1382]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.11.ops_all.12.params: tensor([[-0.0623,  0.3145, -0.3128]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.12.ops_all.0.params: tensor([[0.0117, 0.5906, 0.0593]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.12.ops_all.1.params: tensor([[-0.1903, -0.1603, -0.1604]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.12.ops_all.2.params: tensor([[-0.1948, -0.1702,  0.1606]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.12.ops_all.3.params: tensor([[ 0.2028, -0.2216, -0.0975]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.12.ops_all.4.params: tensor([[ 0.0924, -0.3488,  0.2979]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.12.ops_all.5.params: tensor([[-0.3733,  0.1363,  0.0168]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.12.ops_all.6.params: tensor([[ 0.2745, -0.6242,  0.3561]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.12.ops_all.7.params: tensor([[ 0.0393, -0.0049,  0.2388]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.12.ops_all.8.params: tensor([[ 0.6165, -0.1971, -0.1463]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.12.ops_all.9.params: tensor([[-0.1963,  0.1672, -0.1505]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.12.ops_all.10.params: tensor([[0.0896, 0.0676, 0.1657]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.12.ops_all.11.params: tensor([[-0.0926, -0.4766, -0.1472]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.12.ops_all.12.params: tensor([[ 0.0209,  0.0642, -0.0430]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.13.ops_all.0.params: tensor([[-0.2024,  0.6091,  0.5121]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.13.ops_all.1.params: tensor([[-0.2059,  0.0142, -0.0808]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.13.ops_all.2.params: tensor([[0.2138, 0.3633, 0.1563]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.13.ops_all.3.params: tensor([[ 0.0558, -0.0500, -0.0356]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.13.ops_all.4.params: tensor([[-0.0984, -0.3829, -0.2308]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.13.ops_all.5.params: tensor([[ 0.0266, -0.4324, -0.1169]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.13.ops_all.6.params: tensor([[ 0.1450,  0.3768, -0.6652]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.13.ops_all.7.params: tensor([[-0.0322,  0.1569, -0.4124]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.13.ops_all.8.params: tensor([[-0.4398, -0.1081, -0.0734]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.13.ops_all.9.params: tensor([[ 0.1532, -0.0213,  0.0211]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.13.ops_all.10.params: tensor([[ 0.3047, -0.0249,  0.0326]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.13.ops_all.11.params: tensor([[ 0.3278,  0.0137, -0.0454]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.13.ops_all.12.params: tensor([[-0.1197, -0.3852,  0.1577]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.14.ops_all.0.params: tensor([[-0.3036,  0.2242,  0.6069]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.14.ops_all.1.params: tensor([[0.1650, 0.2724, 0.0396]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.14.ops_all.2.params: tensor([[-0.1866,  0.3768,  0.3277]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.14.ops_all.3.params: tensor([[-0.0593,  0.0163, -0.0187]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.14.ops_all.4.params: tensor([[-0.2017, -0.4082,  0.1729]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.14.ops_all.5.params: tensor([[ 0.1207, -0.2747, -0.3810]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.14.ops_all.6.params: tensor([[ 0.0509,  0.0667, -0.1979]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.14.ops_all.7.params: tensor([[0.1418, 0.1272, 0.0625]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.14.ops_all.8.params: tensor([[-0.0137,  0.1888, -0.1566]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.14.ops_all.9.params: tensor([[-0.1744, -0.1230, -0.1193]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.14.ops_all.10.params: tensor([[ 0.0586,  0.1046, -0.5697]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.14.ops_all.11.params: tensor([[-0.0477, -0.0176, -0.3363]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.14.ops_all.12.params: tensor([[ 0.2671, -0.0087, -0.5398]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.15.ops_all.0.params: tensor([[-0.0213,  0.0117, -0.0057]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.15.ops_all.1.params: tensor([[-0.4066, -0.0764,  0.0293]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.15.ops_all.2.params: tensor([[0.0901, 0.1627, 0.1739]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.15.ops_all.3.params: tensor([[-0.1621, -0.0030, -0.0098]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.15.ops_all.4.params: tensor([[0.3152, 0.0614, 0.1214]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.15.ops_all.5.params: tensor([[-0.2495,  0.0259,  0.1134]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.15.ops_all.6.params: tensor([[-0.3737, -0.0562,  0.0807]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.15.ops_all.7.params: tensor([[-0.4436, -0.0185, -0.0553]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.15.ops_all.8.params: tensor([[-0.0682,  0.0689,  0.0938]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.15.ops_all.9.params: tensor([[-0.1762,  0.0254, -0.0218]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.15.ops_all.10.params: tensor([[0.1986, 0.0130, 0.0313]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.15.ops_all.11.params: tensor([[ 0.1040,  0.0368, -0.1472]], device='cuda:1')\n",
      "Gradient of QuantumNN.u3_layers.15.ops_all.12.params: tensor([[ 0.3505,  0.0879, -0.2103]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.0.ops_all.0.params: tensor([[ 0.0091,  0.1952, -0.1801]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.0.ops_all.1.params: tensor([[ 0.2914,  0.3529, -0.0006]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.0.ops_all.2.params: tensor([[-0.0160,  0.0064, -0.0394]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.0.ops_all.3.params: tensor([[ 0.1184,  0.0346, -0.0964]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.0.ops_all.4.params: tensor([[ 0.0272, -0.2177, -0.0388]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.0.ops_all.5.params: tensor([[-0.0289, -0.1878, -0.0011]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.0.ops_all.6.params: tensor([[-0.0182, -0.1828, -0.1815]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.0.ops_all.7.params: tensor([[-0.1246,  0.0206, -0.0476]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.0.ops_all.8.params: tensor([[ 0.3782, -0.1012,  0.3278]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.0.ops_all.9.params: tensor([[-0.0835,  0.0428,  0.1286]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.0.ops_all.10.params: tensor([[ 0.1211, -0.0958,  0.0088]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.0.ops_all.11.params: tensor([[-0.1598, -0.2700, -0.2442]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.0.ops_all.12.params: tensor([[-0.0323, -0.3710, -0.1958]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.1.ops_all.0.params: tensor([[-0.0706,  0.0251,  0.0337]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.1.ops_all.1.params: tensor([[-0.1096,  0.0057,  0.3024]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.1.ops_all.2.params: tensor([[ 0.1375,  0.1803, -0.1350]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.1.ops_all.3.params: tensor([[-0.0086,  0.2920,  0.1613]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.1.ops_all.4.params: tensor([[-8.4669e-06,  2.2121e-01,  2.0337e-01]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.1.ops_all.5.params: tensor([[-0.1032,  0.3323,  0.2740]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.1.ops_all.6.params: tensor([[0.2684, 0.2487, 0.0590]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.1.ops_all.7.params: tensor([[ 0.0418,  0.1015, -0.0437]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.1.ops_all.8.params: tensor([[0.3233, 0.1230, 0.0818]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.1.ops_all.9.params: tensor([[ 0.2592, -0.0279, -0.0465]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.1.ops_all.10.params: tensor([[-0.1190,  0.2989,  0.1889]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.1.ops_all.11.params: tensor([[0.1811, 0.0393, 0.4081]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.1.ops_all.12.params: tensor([[ 0.0944, -0.0442,  0.0365]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.2.ops_all.0.params: tensor([[-0.1618, -0.1926,  0.3095]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.2.ops_all.1.params: tensor([[-0.0338, -0.0863, -0.0883]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.2.ops_all.2.params: tensor([[0.0323, 0.1437, 0.1396]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.2.ops_all.3.params: tensor([[ 0.0503,  0.1340, -0.1411]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.2.ops_all.4.params: tensor([[-0.0716, -0.0158,  0.4301]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.2.ops_all.5.params: tensor([[-0.1406,  0.0848,  0.1194]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.2.ops_all.6.params: tensor([[-0.0454,  0.0117,  0.0528]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.2.ops_all.7.params: tensor([[-0.0651, -0.1323, -0.3160]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.2.ops_all.8.params: tensor([[0.1464, 0.0928, 0.0933]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.2.ops_all.9.params: tensor([[ 0.2304, -0.3596,  0.0055]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.2.ops_all.10.params: tensor([[ 0.2852, -0.1821, -0.1024]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.2.ops_all.11.params: tensor([[ 0.0843,  0.1517, -0.1650]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.2.ops_all.12.params: tensor([[-0.3082,  0.1290,  0.1140]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.3.ops_all.0.params: tensor([[-0.1281,  0.4284, -0.1239]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.3.ops_all.1.params: tensor([[0.0889, 0.2088, 0.0412]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.3.ops_all.2.params: tensor([[0.0740, 0.1634, 0.1744]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.3.ops_all.3.params: tensor([[-0.1402, -0.1026,  0.0908]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.3.ops_all.4.params: tensor([[ 0.1208,  0.3059, -0.1467]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.3.ops_all.5.params: tensor([[0.1491, 0.1405, 0.2933]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.3.ops_all.6.params: tensor([[ 0.0433, -0.1085, -0.1410]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.3.ops_all.7.params: tensor([[0.4641, 0.1151, 0.0738]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.3.ops_all.8.params: tensor([[-0.2278,  0.0281,  0.2944]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.3.ops_all.9.params: tensor([[-0.1372, -0.0664, -0.2559]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.3.ops_all.10.params: tensor([[-0.1925,  0.2503,  0.2741]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.3.ops_all.11.params: tensor([[-0.1379, -0.1439,  0.1133]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.3.ops_all.12.params: tensor([[0.1065, 0.0927, 0.0827]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.4.ops_all.0.params: tensor([[-0.3194,  0.0314, -0.2889]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.4.ops_all.1.params: tensor([[ 0.2608,  0.1715, -0.2531]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.4.ops_all.2.params: tensor([[-0.2715,  0.2445,  0.2792]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.4.ops_all.3.params: tensor([[-0.0743, -0.4052, -0.3699]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.4.ops_all.4.params: tensor([[0.2468, 0.1923, 0.3431]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.4.ops_all.5.params: tensor([[0.0776, 0.0884, 0.3227]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.4.ops_all.6.params: tensor([[ 0.1061, -0.0584, -0.3124]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.4.ops_all.7.params: tensor([[ 0.0397, -0.2353, -0.1964]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.4.ops_all.8.params: tensor([[-0.2430, -0.2968, -0.1896]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.4.ops_all.9.params: tensor([[-0.4775,  0.0156,  0.1828]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.4.ops_all.10.params: tensor([[ 0.0823, -0.2419, -0.0142]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.4.ops_all.11.params: tensor([[ 0.0861, -0.1640, -0.0342]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.4.ops_all.12.params: tensor([[ 0.1282, -0.0471, -0.1544]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.5.ops_all.0.params: tensor([[-0.0880, -0.1462,  0.0169]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.5.ops_all.1.params: tensor([[-0.1336, -0.2018, -0.2429]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.5.ops_all.2.params: tensor([[-0.2287, -0.1966, -0.1810]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.5.ops_all.3.params: tensor([[-0.2844, -0.2574, -0.1890]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.5.ops_all.4.params: tensor([[0.1958, 0.3055, 0.2713]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.5.ops_all.5.params: tensor([[-0.1042,  0.1825,  0.2113]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.5.ops_all.6.params: tensor([[0.1536, 0.2034, 0.2009]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.5.ops_all.7.params: tensor([[ 0.0116,  0.3616, -0.1421]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.5.ops_all.8.params: tensor([[0.3708, 0.3029, 0.2578]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.5.ops_all.9.params: tensor([[ 0.0062, -0.0022, -0.1550]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.5.ops_all.10.params: tensor([[-0.0553,  0.2044,  0.1415]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.5.ops_all.11.params: tensor([[-0.0025,  0.1141,  0.3535]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.5.ops_all.12.params: tensor([[ 0.0531, -0.3270, -0.2172]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.6.ops_all.0.params: tensor([[ 0.1220, -0.0572,  0.2406]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.6.ops_all.1.params: tensor([[-0.0140,  0.1647, -0.5160]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.6.ops_all.2.params: tensor([[-0.0778,  0.0031, -0.1914]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.6.ops_all.3.params: tensor([[ 0.0561, -0.3020, -0.2688]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.6.ops_all.4.params: tensor([[0.3234, 0.2272, 0.2364]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.6.ops_all.5.params: tensor([[0.0394, 0.0070, 0.0877]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.6.ops_all.6.params: tensor([[ 0.0410, -0.4160,  0.0079]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.6.ops_all.7.params: tensor([[ 0.2771, -0.1838,  0.0126]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.6.ops_all.8.params: tensor([[ 0.1584, -0.3384, -0.3580]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.6.ops_all.9.params: tensor([[ 0.1181, -0.1451,  0.0801]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.6.ops_all.10.params: tensor([[-0.0590,  0.0390,  0.0565]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.6.ops_all.11.params: tensor([[-0.1300, -0.1447, -0.1512]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.6.ops_all.12.params: tensor([[0.0455, 0.1287, 0.1948]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.7.ops_all.0.params: tensor([[0.0610, 0.0444, 0.0397]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.7.ops_all.1.params: tensor([[ 0.2070, -0.1611,  0.1897]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.7.ops_all.2.params: tensor([[0.0753, 0.0803, 0.0598]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.7.ops_all.3.params: tensor([[0.2681, 0.1017, 0.0698]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.7.ops_all.4.params: tensor([[ 0.1742,  0.2834, -0.2759]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.7.ops_all.5.params: tensor([[0.1579, 0.0103, 0.0081]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.7.ops_all.6.params: tensor([[-0.4853, -0.0689, -0.0327]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.7.ops_all.7.params: tensor([[ 0.1204, -0.1142,  0.3746]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.7.ops_all.8.params: tensor([[ 0.0820, -0.0859, -0.2175]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.7.ops_all.9.params: tensor([[-0.1092, -0.2573, -0.1227]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.7.ops_all.10.params: tensor([[0.1873, 0.3989, 0.3114]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.7.ops_all.11.params: tensor([[-0.0020,  0.4884,  0.5141]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.7.ops_all.12.params: tensor([[0.0038, 0.1007, 0.0471]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.8.ops_all.0.params: tensor([[-0.0658,  0.1341,  0.1416]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.8.ops_all.1.params: tensor([[-0.0041, -0.1565,  0.1302]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.8.ops_all.2.params: tensor([[-0.1268,  0.0047, -0.1353]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.8.ops_all.3.params: tensor([[0.1166, 0.2024, 0.0076]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.8.ops_all.4.params: tensor([[ 0.0217, -0.0574, -0.2216]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.8.ops_all.5.params: tensor([[ 0.1782,  0.0034, -0.1325]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.8.ops_all.6.params: tensor([[0.2243, 0.3007, 0.1537]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.8.ops_all.7.params: tensor([[0.0665, 0.4825, 0.2052]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.8.ops_all.8.params: tensor([[ 0.2765, -0.1839, -0.1768]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.8.ops_all.9.params: tensor([[ 0.1842, -0.0450,  0.1210]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.8.ops_all.10.params: tensor([[0.0781, 0.0100, 0.0180]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.8.ops_all.11.params: tensor([[0.4474, 0.2813, 0.2961]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.8.ops_all.12.params: tensor([[0.0720, 0.2387, 0.1048]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.9.ops_all.0.params: tensor([[ 0.2409, -0.2378, -0.4411]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.9.ops_all.1.params: tensor([[0.4155, 0.0258, 0.1309]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.9.ops_all.2.params: tensor([[-0.0462, -0.1107,  0.1407]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.9.ops_all.3.params: tensor([[-0.2313, -0.1960, -0.2011]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.9.ops_all.4.params: tensor([[ 0.1156, -0.1749, -0.1100]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.9.ops_all.5.params: tensor([[-0.5545, -0.2599, -0.2624]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.9.ops_all.6.params: tensor([[-0.1823, -0.1150, -0.3336]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.9.ops_all.7.params: tensor([[ 0.1125, -0.0723, -0.2904]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.9.ops_all.8.params: tensor([[ 0.0773, -0.1862, -0.0787]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.9.ops_all.9.params: tensor([[0.0992, 0.1872, 0.1705]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.9.ops_all.10.params: tensor([[0.2464, 0.4433, 0.4586]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.9.ops_all.11.params: tensor([[ 0.0539, -0.0504, -0.1317]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.9.ops_all.12.params: tensor([[-0.0877, -0.0360, -0.0354]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.10.ops_all.0.params: tensor([[ 0.2277, -0.1221,  0.3483]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.10.ops_all.1.params: tensor([[-0.0962, -0.2445, -0.3293]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.10.ops_all.2.params: tensor([[ 0.3324,  0.0638, -0.1627]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.10.ops_all.3.params: tensor([[ 0.3558,  0.1445, -0.0685]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.10.ops_all.4.params: tensor([[-0.1033,  0.0155, -0.0835]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.10.ops_all.5.params: tensor([[-0.1271,  0.2430,  0.2542]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.10.ops_all.6.params: tensor([[0.1048, 0.2195, 0.3814]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.10.ops_all.7.params: tensor([[-0.1913, -0.0445,  0.0671]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.10.ops_all.8.params: tensor([[-0.0498, -0.3390, -0.3165]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.10.ops_all.9.params: tensor([[-0.0797,  0.0309,  0.0184]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.10.ops_all.10.params: tensor([[-0.0465,  0.0367,  0.0294]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.10.ops_all.11.params: tensor([[ 0.0145, -0.0472,  0.2996]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.10.ops_all.12.params: tensor([[-0.0601, -0.2265, -0.0187]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.11.ops_all.0.params: tensor([[ 0.1843,  0.0953, -0.1485]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.11.ops_all.1.params: tensor([[-0.0590,  0.0010, -0.0119]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.11.ops_all.2.params: tensor([[ 0.0804, -0.0873,  0.3517]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.11.ops_all.3.params: tensor([[ 0.1376,  0.1353, -0.1168]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.11.ops_all.4.params: tensor([[0.1015, 0.2076, 0.3080]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.11.ops_all.5.params: tensor([[0.2291, 0.0270, 0.0630]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.11.ops_all.6.params: tensor([[-0.1234,  0.3605,  0.2179]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.11.ops_all.7.params: tensor([[0.1268, 0.2383, 0.0377]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.11.ops_all.8.params: tensor([[0.2237, 0.0169, 0.0496]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.11.ops_all.9.params: tensor([[-0.1162,  0.2116,  0.2223]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.11.ops_all.10.params: tensor([[0.1241, 0.1579, 0.1318]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.11.ops_all.11.params: tensor([[-0.0873, -0.2268,  0.1307]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.11.ops_all.12.params: tensor([[-0.0504,  0.1767,  0.0713]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.12.ops_all.0.params: tensor([[-0.1300,  0.2482,  0.1688]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.12.ops_all.1.params: tensor([[ 0.0550,  0.2687, -0.0577]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.12.ops_all.2.params: tensor([[-0.1293,  0.1726, -0.0134]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.12.ops_all.3.params: tensor([[ 0.0882, -0.3712, -0.4892]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.12.ops_all.4.params: tensor([[-0.2123, -0.2861, -0.0329]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.12.ops_all.5.params: tensor([[-0.3058, -0.4418, -0.4008]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.12.ops_all.6.params: tensor([[ 0.1622, -0.5425, -0.1350]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.12.ops_all.7.params: tensor([[ 0.3298, -0.1934, -0.3170]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.12.ops_all.8.params: tensor([[ 0.0453, -0.1081,  0.0380]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.12.ops_all.9.params: tensor([[0.2289, 0.1703, 0.2053]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.12.ops_all.10.params: tensor([[ 0.0812,  0.2300, -0.2012]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.12.ops_all.11.params: tensor([[ 0.1417, -0.2680, -0.3615]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.12.ops_all.12.params: tensor([[-0.2554,  0.2819,  0.3604]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.13.ops_all.0.params: tensor([[-0.2062,  0.3097,  0.2843]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.13.ops_all.1.params: tensor([[-0.5183,  0.0730,  0.1086]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.13.ops_all.2.params: tensor([[0.1928, 0.2012, 0.1700]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.13.ops_all.3.params: tensor([[-0.0560,  0.1796, -0.3762]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.13.ops_all.4.params: tensor([[ 0.0597, -0.0395, -0.0910]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.13.ops_all.5.params: tensor([[-0.1109, -0.3817,  0.1930]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.13.ops_all.6.params: tensor([[-0.2812, -0.1875, -0.0931]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.13.ops_all.7.params: tensor([[0.1796, 0.0076, 0.0562]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.13.ops_all.8.params: tensor([[-0.0061, -0.1812, -0.0832]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.13.ops_all.9.params: tensor([[-0.2141, -0.3394,  0.2054]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.13.ops_all.10.params: tensor([[ 0.2732, -0.5414, -0.1914]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.13.ops_all.11.params: tensor([[-0.3662, -0.3879, -0.2333]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.13.ops_all.12.params: tensor([[-0.0708, -0.2212, -0.2190]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.14.ops_all.0.params: tensor([[0.1156, 0.2423, 0.4854]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.14.ops_all.1.params: tensor([[ 0.0920, -0.0949,  0.1080]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.14.ops_all.2.params: tensor([[0.2139, 0.1581, 0.1842]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.14.ops_all.3.params: tensor([[-0.2398,  0.2552, -0.2744]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.14.ops_all.4.params: tensor([[ 0.1797,  0.2051, -0.1830]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.14.ops_all.5.params: tensor([[0.0966, 0.1851, 0.1712]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.14.ops_all.6.params: tensor([[ 0.1040, -0.1292,  0.0533]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.14.ops_all.7.params: tensor([[ 0.0034, -0.0079,  0.0871]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.14.ops_all.8.params: tensor([[-0.0633, -0.0042, -0.1055]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.14.ops_all.9.params: tensor([[ 0.4180, -0.1085, -0.0351]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.14.ops_all.10.params: tensor([[0.2402, 0.0085, 0.1382]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.14.ops_all.11.params: tensor([[-0.3978, -0.1340,  0.0676]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.14.ops_all.12.params: tensor([[-0.0073, -0.2459, -0.0160]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.15.ops_all.0.params: tensor([[ 0.3731,  0.0190, -0.0573]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.15.ops_all.1.params: tensor([[0.0921, 0.0000, 0.1627]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.15.ops_all.2.params: tensor([[-1.9608e-02,  7.7300e-08, -2.9554e-03]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.15.ops_all.3.params: tensor([[-2.2346e-01, -5.7742e-08,  6.1414e-02]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.15.ops_all.4.params: tensor([[-1.6625e-01,  4.4703e-08,  2.5869e-02]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.15.ops_all.5.params: tensor([[-2.6100e-01, -1.5832e-08, -5.6202e-02]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.15.ops_all.6.params: tensor([[-1.1918e-01,  1.4901e-08, -1.8461e-02]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.15.ops_all.7.params: tensor([[ 1.7562e-02, -1.9558e-08,  6.8866e-02]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.15.ops_all.8.params: tensor([[ 1.3512e-01, -1.4668e-08,  2.5377e-02]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.15.ops_all.9.params: tensor([[0.3366, 0.0000, 0.0130]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.15.ops_all.10.params: tensor([[-1.6238e-03,  2.1420e-08,  3.6847e-02]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.15.ops_all.11.params: tensor([[-2.3700e-01, -4.8429e-08,  8.7905e-02]], device='cuda:1')\n",
      "Gradient of QuantumNN.cu3_layers.15.ops_all.12.params: tensor([[ 2.2265e-01, -2.0489e-08,  1.1674e-02]], device='cuda:1')\n"
     ]
    }
   ],
   "source": [
    "# Print gradients of all parameters\n",
    "for name, param in model_qt.named_parameters():\n",
    "    print(f\"Gradient of {name}: {param.grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tq",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
